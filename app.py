import pandas as pd
import numpy as np
import streamlit as st
import io
import re
import logging
import zipfile
import openpyxl
from openpyxl.styles import Font, Alignment
from collections import defaultdict
from datetime import datetime
from itertools import combinations
import warnings
import traceback
import hashlib
from functools import lru_cache

# é…ç½®æ—¥å¿—å’Œè­¦å‘Š
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('MultiAccountWashTrade')

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== é…ç½®ç±» ====================
class Config:
    def __init__(self):
        self.min_amount = 10
        self.amount_similarity_threshold = 0.8
        self.min_continuous_periods = 3
        self.max_accounts_in_group = 5
        self.supported_file_types = ['.xlsx', '.xls', '.csv']
        
        # åˆ—åæ˜ å°„é…ç½®
        self.column_mappings = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
        
        # æ´»è·ƒåº¦é˜ˆå€¼é…ç½®
        self.period_thresholds = {
            'low_activity': 10,
            'medium_activity_low': 11,
            'medium_activity_high': 50,
            'high_activity_low': 51,
            'high_activity_high': 100,
            'min_periods_low': 3,
            'min_periods_medium': 5,
            'min_periods_high': 8,
            'min_periods_very_high': 11
        }
        
        # å¤šè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼
        self.account_count_similarity_thresholds = {
            2: 0.8,
            3: 0.85,
            4: 0.9,
            5: 0.95
        }
        
        # è´¦æˆ·æœŸæ•°å·®å¼‚é˜ˆå€¼
        self.account_period_diff_threshold = 101
        
        # ğŸ¯ å…³é”®ä¿®å¤ï¼šæ‰©å±•æ–¹å‘æ¨¡å¼ï¼Œé‡‡ç”¨åˆå¹¶ç­–ç•¥
        # åŸºç¡€æ–¹å‘æ¨¡å¼
        self.base_direction_patterns = {
            # åŸºç¡€æ–¹å‘
            'å°': ['ä¸¤é¢-å°', 'å’Œå€¼-å°', 'å°', 'small', 'xia', 'xiao', 'å’Œå€¼å°', 'æ€»å’Œ-å°', 'æ€»å’Œå°', 'å’Œå€¼_å°', 'æ€»å’Œ_å°'],
            'å¤§': ['ä¸¤é¢-å¤§', 'å’Œå€¼-å¤§', 'å¤§', 'big', 'da', 'large', 'å’Œå€¼å¤§', 'æ€»å’Œ-å¤§', 'æ€»å’Œå¤§', 'å’Œå€¼_å¤§', 'æ€»å’Œ_å¤§'], 
            'å•': ['ä¸¤é¢-å•', 'å’Œå€¼-å•', 'å•', 'odd', 'dan', 'å¥‡æ•°', 'å’Œå€¼å•', 'æ€»å’Œ-å•', 'æ€»å’Œå•', 'å’Œå€¼_å•', 'æ€»å’Œ_å•'],
            'åŒ': ['ä¸¤é¢-åŒ', 'å’Œå€¼-åŒ', 'åŒ', 'even', 'shuang', 'å¶æ•°', 'å’Œå€¼åŒ', 'æ€»å’Œ-åŒ', 'æ€»å’ŒåŒ', 'å’Œå€¼_åŒ', 'æ€»å’Œ_åŒ'],
            'é¾™': ['é¾™', 'long', 'dragon', 'é¾', 'é¾è™-é¾™', 'é¾™è™-é¾™', 'é¾è™_é¾™'],
            'è™': ['è™', 'hu', 'tiger', 'é¾è™-è™', 'é¾™è™-è™', 'é¾è™_è™'],
            'è´¨': ['è´¨', 'è´¨æ•°', 'prime', 'zhi', 'è³ª', 'è³ªæ•¸', 'ç´ æ•°'],
            'åˆ': ['åˆ', 'åˆæ•°', 'composite', 'he', 'åˆæ•¸', 'åˆæˆæ•°'],
        }
        
        # ğŸ¯ å¢å¼ºæ–¹å‘æ¨¡å¼ - ä¿æŒå˜å¼‚å½¢å¼ç‹¬ç«‹æ€§
        self.enhanced_direction_patterns = {
            # å˜å¼‚å½¢å¼ - ä¿æŒç‹¬ç«‹
            'ç‰¹å°': ['ç‰¹å°', 'æå°', 'æœ€å°', 'ç‰¹å°å•', 'ç‰¹å°åŒ', 'ç‰¹ç -å°', 'ç‰¹ç å°', 'ç‰¹ç _å°'],
            'ç‰¹å¤§': ['ç‰¹å¤§', 'æå¤§', 'æœ€å¤§', 'ç‰¹å•å¤§', 'ç‰¹åŒå¤§', 'ç‰¹ç -å¤§', 'ç‰¹ç å¤§', 'ç‰¹ç _å¤§'],
            'ç‰¹å•': ['ç‰¹å•', 'ç‰¹ç -å•', 'ç‰¹ç å•', 'ç‰¹ç _å•'],
            'ç‰¹åŒ': ['ç‰¹åŒ', 'ç‰¹ç -åŒ', 'ç‰¹ç åŒ', 'ç‰¹ç _åŒ'],
            'æ€»å’Œå°': ['æ€»å’Œå°', 'å’Œå°', 'æ€»å’Œ-å°', 'å’Œå€¼å°', 'å’Œå€¼-å°', 'å† äºšå’Œå°', 'å† äºšå’Œ-å°'],
            'æ€»å’Œå¤§': ['æ€»å’Œå¤§', 'å’Œå¤§', 'æ€»å’Œ-å¤§', 'å’Œå€¼å¤§', 'å’Œå€¼-å¤§', 'å† äºšå’Œå¤§', 'å† äºšå’Œ-å¤§'],
            'æ€»å’Œå•': ['æ€»å’Œå•', 'å’Œå•', 'æ€»å’Œ-å•', 'å’Œå€¼å•', 'å’Œå€¼-å•', 'å† äºšå’Œå•', 'å† äºšå’Œ-å•'],
            'æ€»å’ŒåŒ': ['æ€»å’ŒåŒ', 'å’ŒåŒ', 'æ€»å’Œ-åŒ', 'å’Œå€¼åŒ', 'å’Œå€¼-åŒ', 'å† äºšå’ŒåŒ', 'å† äºšå’Œ-åŒ'],
            
            # ğŸ†• æ–°å¢å¤åˆæ–¹å‘
            'å¤§å•': ['å¤§å•', 'å•å¤§', 'big-odd', 'å¤§-å•', 'å•-å¤§'],
            'å¤§åŒ': ['å¤§åŒ', 'åŒå¤§', 'big-even', 'å¤§-åŒ', 'åŒ-å¤§'],
            'å°å•': ['å°å•', 'å•å°', 'small-odd', 'å°-å•', 'å•-å°'],
            'å°åŒ': ['å°åŒ', 'åŒå°', 'small-even', 'å°-åŒ', 'åŒ-å°'],
            
            # ğŸ†• æ–°å¢å…­åˆå½©æ–¹å‘ - ç²¾ç¡®ä½ç½®
            'å¤©è‚–': ['å¤©è‚–', 'å¤©è‚–', 'å¤©', 'å¤©ç”Ÿè‚–', 'å¤©è‚–ç '],
            'åœ°è‚–': ['åœ°è‚–', 'åœ°è‚–', 'åœ°', 'åœ°ç”Ÿè‚–', 'åœ°è‚–ç '],
            'å®¶è‚–': ['å®¶è‚–', 'å®¶ç¦½', 'å®¶è‚–', 'å®¶', 'å®¶ç¦½è‚–', 'å®¶ç”Ÿè‚–'],
            'é‡è‚–': ['é‡è‚–', 'é‡å…½', 'é‡è‚–', 'é‡', 'é‡å…½è‚–', 'é‡ç”Ÿè‚–'],
            'å°¾å¤§': ['å°¾å¤§', 'å°¾å¤§', 'å¤§å°¾', 'å°¾æ•°å¤§', 'å°¾æ•¸å¤§'],
            'å°¾å°': ['å°¾å°', 'å°¾å°', 'å°å°¾', 'å°¾æ•°å°', 'å°¾æ•¸å°'],

            # ğŸ†• æ–°å¢å…­åˆå½©ç‰¹ç ä¸¤é¢ä¸“ç”¨æ–¹å‘
            'å°¾å¤§': ['å°¾å¤§', 'å°¾å¤§', 'å¤§å°¾', 'å°¾æ•°å¤§', 'å°¾æ•¸å¤§', 'ç‰¹ç ä¸¤é¢-å°¾å¤§'],
            'å°¾å°': ['å°¾å°', 'å°¾å°', 'å°å°¾', 'å°¾æ•°å°', 'å°¾æ•¸å°', 'ç‰¹ç ä¸¤é¢-å°¾å°'],
            'ç‰¹å¤§': ['ç‰¹å¤§', 'æå¤§', 'æœ€å¤§', 'ç‰¹å•å¤§', 'ç‰¹åŒå¤§', 'ç‰¹ç -å¤§', 'ç‰¹ç å¤§', 'ç‰¹ç _å¤§', 'ç‰¹ç ä¸¤é¢-ç‰¹å¤§'],
            'ç‰¹å°': ['ç‰¹å°', 'æå°', 'æœ€å°', 'ç‰¹å°å•', 'ç‰¹å°åŒ', 'ç‰¹ç -å°', 'ç‰¹ç å°', 'ç‰¹ç _å°', 'ç‰¹ç ä¸¤é¢-ç‰¹å°'],
            'ç‰¹å•': ['ç‰¹å•', 'ç‰¹ç -å•', 'ç‰¹ç å•', 'ç‰¹ç _å•', 'ç‰¹ç ä¸¤é¢-ç‰¹å•'],
            'ç‰¹åŒ': ['ç‰¹åŒ', 'ç‰¹ç -åŒ', 'ç‰¹ç åŒ', 'ç‰¹ç _åŒ', 'ç‰¹ç ä¸¤é¢-ç‰¹åŒ'],
            
            # ğŸ†• åŸºç¡€æ–¹å‘çš„å…­åˆå½©å˜ä½“
            'å¤§': ['å¤§', 'big', 'large', 'da', 'ç‰¹ç ä¸¤é¢-å¤§'],
            'å°': ['å°', 'small', 'xiao', 'ç‰¹ç ä¸¤é¢-å°'], 
            'å•': ['å•', 'odd', 'dan', 'å¥‡', 'ç‰¹ç ä¸¤é¢-å•'],
            'åŒ': ['åŒ', 'even', 'shuang', 'å¶', 'ç‰¹ç ä¸¤é¢-åŒ'],
            
            # ğŸ†• æ–°å¢å…­åˆå½©æ­£ç ç‰¹æ–¹å‘ - ç²¾ç¡®ä½ç½®
            'æ­£1ç‰¹-å¤§': ['æ­£1ç‰¹-å¤§', 'æ­£ä¸€ç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹-å¤§', 'æ­£1ç‰¹å¤§', 'æ­£ä¸€ç‰¹å¤§', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹-å¤§'],
            'æ­£1ç‰¹-å°': ['æ­£1ç‰¹-å°', 'æ­£ä¸€ç‰¹-å°', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹-å°', 'æ­£1ç‰¹å°', 'æ­£ä¸€ç‰¹å°', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹-å°'],
            'æ­£1ç‰¹-å•': ['æ­£1ç‰¹-å•', 'æ­£ä¸€ç‰¹-å•', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹-å•', 'æ­£1ç‰¹å•', 'æ­£ä¸€ç‰¹å•', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹-å•'],
            'æ­£1ç‰¹-åŒ': ['æ­£1ç‰¹-åŒ', 'æ­£ä¸€ç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹-åŒ', 'æ­£1ç‰¹åŒ', 'æ­£ä¸€ç‰¹åŒ', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹-åŒ'],
            
            'æ­£2ç‰¹-å¤§': ['æ­£2ç‰¹-å¤§', 'æ­£äºŒç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£äºŒç‰¹-å¤§', 'æ­£2ç‰¹å¤§', 'æ­£äºŒç‰¹å¤§', 'æ­£ç ç‰¹-æ­£äºŒç‰¹-å¤§'],
            'æ­£2ç‰¹-å°': ['æ­£2ç‰¹-å°', 'æ­£äºŒç‰¹-å°', 'æ­£ç ç‰¹_æ­£äºŒç‰¹-å°', 'æ­£2ç‰¹å°', 'æ­£äºŒç‰¹å°', 'æ­£ç ç‰¹-æ­£äºŒç‰¹-å°'],
            'æ­£2ç‰¹-å•': ['æ­£2ç‰¹-å•', 'æ­£äºŒç‰¹-å•', 'æ­£ç ç‰¹_æ­£äºŒç‰¹-å•', 'æ­£2ç‰¹å•', 'æ­£äºŒç‰¹å•', 'æ­£ç ç‰¹-æ­£äºŒç‰¹-å•'],
            'æ­£2ç‰¹-åŒ': ['æ­£2ç‰¹-åŒ', 'æ­£äºŒç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£äºŒç‰¹-åŒ', 'æ­£2ç‰¹åŒ', 'æ­£äºŒç‰¹åŒ', 'æ­£ç ç‰¹-æ­£äºŒç‰¹-åŒ'],
            
            'æ­£3ç‰¹-å¤§': ['æ­£3ç‰¹-å¤§', 'æ­£ä¸‰ç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹-å¤§', 'æ­£3ç‰¹å¤§', 'æ­£ä¸‰ç‰¹å¤§', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹-å¤§'],
            'æ­£3ç‰¹-å°': ['æ­£3ç‰¹-å°', 'æ­£ä¸‰ç‰¹-å°', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹-å°', 'æ­£3ç‰¹å°', 'æ­£ä¸‰ç‰¹å°', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹-å°'],
            'æ­£3ç‰¹-å•': ['æ­£3ç‰¹-å•', 'æ­£ä¸‰ç‰¹-å•', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹-å•', 'æ­£3ç‰¹å•', 'æ­£ä¸‰ç‰¹å•', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹-å•'],
            'æ­£3ç‰¹-åŒ': ['æ­£3ç‰¹-åŒ', 'æ­£ä¸‰ç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹-åŒ', 'æ­£3ç‰¹åŒ', 'æ­£ä¸‰ç‰¹åŒ', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹-åŒ'],
            
            'æ­£4ç‰¹-å¤§': ['æ­£4ç‰¹-å¤§', 'æ­£å››ç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£å››ç‰¹-å¤§', 'æ­£4ç‰¹å¤§', 'æ­£å››ç‰¹å¤§', 'æ­£ç ç‰¹-æ­£å››ç‰¹-å¤§'],
            'æ­£4ç‰¹-å°': ['æ­£4ç‰¹-å°', 'æ­£å››ç‰¹-å°', 'æ­£ç ç‰¹_æ­£å››ç‰¹-å°', 'æ­£4ç‰¹å°', 'æ­£å››ç‰¹å°', 'æ­£ç ç‰¹-æ­£å››ç‰¹-å°'],
            'æ­£4ç‰¹-å•': ['æ­£4ç‰¹-å•', 'æ­£å››ç‰¹-å•', 'æ­£ç ç‰¹_æ­£å››ç‰¹-å•', 'æ­£4ç‰¹å•', 'æ­£å››ç‰¹å•', 'æ­£ç ç‰¹-æ­£å››ç‰¹-å•'],
            'æ­£4ç‰¹-åŒ': ['æ­£4ç‰¹-åŒ', 'æ­£å››ç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£å››ç‰¹-åŒ', 'æ­£4ç‰¹åŒ', 'æ­£å››ç‰¹åŒ', 'æ­£ç ç‰¹-æ­£å››ç‰¹-åŒ'],
            
            'æ­£5ç‰¹-å¤§': ['æ­£5ç‰¹-å¤§', 'æ­£äº”ç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£äº”ç‰¹-å¤§', 'æ­£5ç‰¹å¤§', 'æ­£äº”ç‰¹å¤§', 'æ­£ç ç‰¹-æ­£äº”ç‰¹-å¤§'],
            'æ­£5ç‰¹-å°': ['æ­£5ç‰¹-å°', 'æ­£äº”ç‰¹-å°', 'æ­£ç ç‰¹_æ­£äº”ç‰¹-å°', 'æ­£5ç‰¹å°', 'æ­£äº”ç‰¹å°', 'æ­£ç ç‰¹-æ­£äº”ç‰¹-å°'],
            'æ­£5ç‰¹-å•': ['æ­£5ç‰¹-å•', 'æ­£äº”ç‰¹-å•', 'æ­£ç ç‰¹_æ­£äº”ç‰¹-å•', 'æ­£5ç‰¹å•', 'æ­£äº”ç‰¹å•', 'æ­£ç ç‰¹-æ­£äº”ç‰¹-å•'],
            'æ­£5ç‰¹-åŒ': ['æ­£5ç‰¹-åŒ', 'æ­£äº”ç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£äº”ç‰¹-åŒ', 'æ­£5ç‰¹åŒ', 'æ­£äº”ç‰¹åŒ', 'æ­£ç ç‰¹-æ­£äº”ç‰¹-åŒ'],
            
            'æ­£6ç‰¹-å¤§': ['æ­£6ç‰¹-å¤§', 'æ­£å…­ç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£å…­ç‰¹-å¤§', 'æ­£6ç‰¹å¤§', 'æ­£å…­ç‰¹å¤§', 'æ­£ç ç‰¹-æ­£å…­ç‰¹-å¤§'],
            'æ­£6ç‰¹-å°': ['æ­£6ç‰¹-å°', 'æ­£å…­ç‰¹-å°', 'æ­£ç ç‰¹_æ­£å…­ç‰¹-å°', 'æ­£6ç‰¹å°', 'æ­£å…­ç‰¹å°', 'æ­£ç ç‰¹-æ­£å…­ç‰¹-å°'],
            'æ­£6ç‰¹-å•': ['æ­£6ç‰¹-å•', 'æ­£å…­ç‰¹-å•', 'æ­£ç ç‰¹_æ­£å…­ç‰¹-å•', 'æ­£6ç‰¹å•', 'æ­£å…­ç‰¹å•', 'æ­£ç ç‰¹-æ­£å…­ç‰¹-å•'],
            'æ­£6ç‰¹-åŒ': ['æ­£6ç‰¹-åŒ', 'æ­£å…­ç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£å…­ç‰¹-åŒ', 'æ­£6ç‰¹åŒ', 'æ­£å…­ç‰¹åŒ', 'æ­£ç ç‰¹-æ­£å…­ç‰¹-åŒ'],
            
            # ğŸ†• æ–°å¢å…­åˆå½©æ­£ç æ–¹å‘ - ç²¾ç¡®ä½ç½®
            'æ­£1-å¤§': ['æ­£1-å¤§', 'æ­£ç 1-å¤§', 'æ­£ä¸€-å¤§', 'æ­£ç _æ­£ä¸€-å¤§', 'æ­£ç 1å¤§', 'æ­£ä¸€å¤§'],
            'æ­£1-å°': ['æ­£1-å°', 'æ­£ç 1-å°', 'æ­£ä¸€-å°', 'æ­£ç _æ­£ä¸€-å°', 'æ­£ç 1å°', 'æ­£ä¸€å°'],
            'æ­£1-å•': ['æ­£1-å•', 'æ­£ç 1-å•', 'æ­£ä¸€-å•', 'æ­£ç _æ­£ä¸€-å•', 'æ­£ç 1å•', 'æ­£ä¸€å•'],
            'æ­£1-åŒ': ['æ­£1-åŒ', 'æ­£ç 1-åŒ', 'æ­£ä¸€-åŒ', 'æ­£ç _æ­£ä¸€-åŒ', 'æ­£ç 1åŒ', 'æ­£ä¸€åŒ'],
            
            'æ­£2-å¤§': ['æ­£2-å¤§', 'æ­£ç 2-å¤§', 'æ­£äºŒ-å¤§', 'æ­£ç _æ­£äºŒ-å¤§', 'æ­£ç 2å¤§', 'æ­£äºŒå¤§'],
            'æ­£2-å°': ['æ­£2-å°', 'æ­£ç 2-å°', 'æ­£äºŒ-å°', 'æ­£ç _æ­£äºŒ-å°', 'æ­£ç 2å°', 'æ­£äºŒå°'],
            'æ­£2-å•': ['æ­£2-å•', 'æ­£ç 2-å•', 'æ­£äºŒ-å•', 'æ­£ç _æ­£äºŒ-å•', 'æ­£ç 2å•', 'æ­£äºŒå•'],
            'æ­£2-åŒ': ['æ­£2-åŒ', 'æ­£ç 2-åŒ', 'æ­£äºŒ-åŒ', 'æ­£ç _æ­£äºŒ-åŒ', 'æ­£ç 2åŒ', 'æ­£äºŒåŒ'],
            
            'æ­£3-å¤§': ['æ­£3-å¤§', 'æ­£ç 3-å¤§', 'æ­£ä¸‰-å¤§', 'æ­£ç _æ­£ä¸‰-å¤§', 'æ­£ç 3å¤§', 'æ­£ä¸‰å¤§'],
            'æ­£3-å°': ['æ­£3-å°', 'æ­£ç 3-å°', 'æ­£ä¸‰-å°', 'æ­£ç _æ­£ä¸‰-å°', 'æ­£ç 3å°', 'æ­£ä¸‰å°'],
            'æ­£3-å•': ['æ­£3-å•', 'æ­£ç 3-å•', 'æ­£ä¸‰-å•', 'æ­£ç _æ­£ä¸‰-å•', 'æ­£ç 3å•', 'æ­£ä¸‰å•'],
            'æ­£3-åŒ': ['æ­£3-åŒ', 'æ­£ç 3-åŒ', 'æ­£ä¸‰-åŒ', 'æ­£ç _æ­£ä¸‰-åŒ', 'æ­£ç 3åŒ', 'æ­£ä¸‰åŒ'],
            
            'æ­£4-å¤§': ['æ­£4-å¤§', 'æ­£ç 4-å¤§', 'æ­£å››-å¤§', 'æ­£ç _æ­£å››-å¤§', 'æ­£ç 4å¤§', 'æ­£å››å¤§'],
            'æ­£4-å°': ['æ­£4-å°', 'æ­£ç 4-å°', 'æ­£å››-å°', 'æ­£ç _æ­£å››-å°', 'æ­£ç 4å°', 'æ­£å››å°'],
            'æ­£4-å•': ['æ­£4-å•', 'æ­£ç 4-å•', 'æ­£å››-å•', 'æ­£ç _æ­£å››-å•', 'æ­£ç 4å•', 'æ­£å››å•'],
            'æ­£4-åŒ': ['æ­£4-åŒ', 'æ­£ç 4-åŒ', 'æ­£å››-åŒ', 'æ­£ç _æ­£å››-åŒ', 'æ­£ç 4åŒ', 'æ­£å››åŒ'],
            
            'æ­£5-å¤§': ['æ­£5-å¤§', 'æ­£ç 5-å¤§', 'æ­£äº”-å¤§', 'æ­£ç _æ­£äº”-å¤§', 'æ­£ç 5å¤§', 'æ­£äº”å¤§'],
            'æ­£5-å°': ['æ­£5-å°', 'æ­£ç 5-å°', 'æ­£äº”-å°', 'æ­£ç _æ­£äº”-å°', 'æ­£ç 5å°', 'æ­£äº”å°'],
            'æ­£5-å•': ['æ­£5-å•', 'æ­£ç 5-å•', 'æ­£äº”-å•', 'æ­£ç _æ­£äº”-å•', 'æ­£ç 5å•', 'æ­£äº”å•'],
            'æ­£5-åŒ': ['æ­£5-åŒ', 'æ­£ç 5-åŒ', 'æ­£äº”-åŒ', 'æ­£ç _æ­£äº”-åŒ', 'æ­£ç 5åŒ', 'æ­£äº”åŒ'],
            
            'æ­£6-å¤§': ['æ­£6-å¤§', 'æ­£ç 6-å¤§', 'æ­£å…­-å¤§', 'æ­£ç _æ­£å…­-å¤§', 'æ­£ç 6å¤§', 'æ­£å…­å¤§'],
            'æ­£6-å°': ['æ­£6-å°', 'æ­£ç 6-å°', 'æ­£å…­-å°', 'æ­£ç _æ­£å…­-å°', 'æ­£ç 6å°', 'æ­£å…­å°'],
            'æ­£6-å•': ['æ­£6-å•', 'æ­£ç 6-å•', 'æ­£å…­-å•', 'æ­£ç _æ­£å…­-å•', 'æ­£ç 6å•', 'æ­£å…­å•'],
            'æ­£6-åŒ': ['æ­£6-åŒ', 'æ­£ç 6-åŒ', 'æ­£å…­-åŒ', 'æ­£ç _æ­£å…­-åŒ', 'æ­£ç 6åŒ', 'æ­£å…­åŒ'],
        }
        
        # ğŸ¯ åˆå¹¶æ–¹å‘æ¨¡å¼ - å¢å¼ºæ¨¡å¼ä¼˜å…ˆ
        self.direction_patterns = {**self.base_direction_patterns, **self.enhanced_direction_patterns}
        
        # ğŸ¯ ä¿®å¤ï¼šæ‰©å±•å¯¹ç«‹ç»„ï¼ŒåŒ…å«å˜å¼‚å½¢å¼å’Œå¤åˆå¯¹ç«‹
        self.opposite_groups = [
            # åŸºç¡€å¯¹ç«‹ç»„
            {'å¤§', 'å°'}, {'å•', 'åŒ'}, {'é¾™', 'è™'}, {'è´¨', 'åˆ'},
            # å˜å¼‚å½¢å¼å¯¹ç«‹ç»„
            {'ç‰¹å¤§', 'ç‰¹å°'}, {'ç‰¹å•', 'ç‰¹åŒ'}, 
            {'æ€»å’Œå¤§', 'æ€»å’Œå°'}, {'æ€»å’Œå•', 'æ€»å’ŒåŒ'},
            # ğŸ†• æ–°å¢å¤åˆå¯¹ç«‹ç»„
            {'å¤§å•', 'å°åŒ'}, {'å¤§åŒ', 'å°å•'},
            # ğŸ†• æ–°å¢å…­åˆå½©å¯¹ç«‹ç»„
            {'å¤©è‚–', 'åœ°è‚–'}, {'å®¶è‚–', 'é‡è‚–'}, {'å°¾å¤§', 'å°¾å°'},
            
            # ğŸ†• æ–°å¢å…­åˆå½©æ­£ç ç‰¹å¯¹ç«‹ç»„
            {'æ­£1ç‰¹-å¤§', 'æ­£1ç‰¹-å°'}, {'æ­£1ç‰¹-å•', 'æ­£1ç‰¹-åŒ'},
            {'æ­£2ç‰¹-å¤§', 'æ­£2ç‰¹-å°'}, {'æ­£2ç‰¹-å•', 'æ­£2ç‰¹-åŒ'},
            {'æ­£3ç‰¹-å¤§', 'æ­£3ç‰¹-å°'}, {'æ­£3ç‰¹-å•', 'æ­£3ç‰¹-åŒ'},
            {'æ­£4ç‰¹-å¤§', 'æ­£4ç‰¹-å°'}, {'æ­£4ç‰¹-å•', 'æ­£4ç‰¹-åŒ'},
            {'æ­£5ç‰¹-å¤§', 'æ­£5ç‰¹-å°'}, {'æ­£5ç‰¹-å•', 'æ­£5ç‰¹-åŒ'},
            {'æ­£6ç‰¹-å¤§', 'æ­£6ç‰¹-å°'}, {'æ­£6ç‰¹-å•', 'æ­£6ç‰¹-åŒ'},
            
            # ğŸ†• æ–°å¢å…­åˆå½©æ­£ç å¯¹ç«‹ç»„
            {'æ­£1-å¤§', 'æ­£1-å°'}, {'æ­£1-å•', 'æ­£1-åŒ'},
            {'æ­£2-å¤§', 'æ­£2-å°'}, {'æ­£2-å•', 'æ­£2-åŒ'},
            {'æ­£3-å¤§', 'æ­£3-å°'}, {'æ­£3-å•', 'æ­£3-åŒ'},
            {'æ­£4-å¤§', 'æ­£4-å°'}, {'æ­£4-å•', 'æ­£4-åŒ'},
            {'æ­£5-å¤§', 'æ­£5-å°'}, {'æ­£5-å•', 'æ­£5-åŒ'},
            {'æ­£6-å¤§', 'æ­£6-å°'}, {'æ­£6-å•', 'æ­£6-åŒ'},
            
            # ğŸ†• æ–°å¢å…­åˆå½©ç‰¹ç ä¸¤é¢å¯¹ç«‹ç»„
            {'å°¾å¤§', 'å°¾å°'},
            {'ç‰¹å¤§', 'ç‰¹å°'},
            {'ç‰¹å•', 'ç‰¹åŒ'},
            {'ç‰¹ç ä¸¤é¢-å°¾å¤§', 'ç‰¹ç ä¸¤é¢-å°¾å°'},
            {'ç‰¹ç ä¸¤é¢-ç‰¹å¤§', 'ç‰¹ç ä¸¤é¢-ç‰¹å°'},
            {'ç‰¹ç ä¸¤é¢-ç‰¹å•', 'ç‰¹ç ä¸¤é¢-ç‰¹åŒ'},
        ]
        
        # ä½ç½®å…³é”®è¯æ˜ å°„ - æ‰©å±•å…­åˆå½©ä½ç½®
        self.position_keywords = {
            'PK10': {
                'å† å†›': ['å† å†›', 'ç¬¬1å', 'ç¬¬ä¸€å', 'å‰ä¸€', 'å†  å†›', 'å† ã€€å†›'],
                'äºšå†›': ['äºšå†›', 'ç¬¬2å', 'ç¬¬äºŒå', 'äºš å†›', 'äºšã€€å†›'],
                'å­£å†›': ['å­£å†›', 'ç¬¬3å', 'ç¬¬ä¸‰å', 'å­£ å†›', 'å­£ã€€å†›'],
                'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å'],
                'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å'],
                'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å'],
                'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å'],
                'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å'],
                'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å'],
                'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å']
            },
            '3D': {
                'ç™¾ä½': ['ç™¾ä½', 'å®šä½_ç™¾ä½', 'ç™¾ä½å®šä½'],
                'åä½': ['åä½', 'å®šä½_åä½', 'åä½å®šä½'],
                'ä¸ªä½': ['ä¸ªä½', 'å®šä½_ä¸ªä½', 'ä¸ªä½å®šä½']
            },
            'SSC': {
                'ç¬¬1çƒ': ['ç¬¬1çƒ', 'ä¸‡ä½', 'ç¬¬ä¸€ä½', 'å®šä½_ä¸‡ä½', 'ä¸‡ä½å®šä½'],
                'ç¬¬2çƒ': ['ç¬¬2çƒ', 'åƒä½', 'ç¬¬äºŒä½', 'å®šä½_åƒä½', 'åƒä½å®šä½'],
                'ç¬¬3çƒ': ['ç¬¬3çƒ', 'ç™¾ä½', 'ç¬¬ä¸‰ä½', 'å®šä½_ç™¾ä½', 'ç™¾ä½å®šä½'],
                'ç¬¬4çƒ': ['ç¬¬4çƒ', 'åä½', 'ç¬¬å››ä½', 'å®šä½_åä½', 'åä½å®šä½'],
                'ç¬¬5çƒ': ['ç¬¬5çƒ', 'ä¸ªä½', 'ç¬¬äº”ä½', 'å®šä½_ä¸ªä½', 'ä¸ªä½å®šä½']
            },
            'LHC': {
                'ç‰¹ç ': ['ç‰¹ç ', 'ç‰¹è‚–', 'æ­£ç ç‰¹', 'ç‰¹ç A', 'ç‰¹ç B'],
                'æ­£1ç‰¹': ['æ­£1ç‰¹', 'æ­£ä¸€ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹'],
                'æ­£2ç‰¹': ['æ­£2ç‰¹', 'æ­£äºŒç‰¹', 'æ­£ç ç‰¹_æ­£äºŒç‰¹', 'æ­£ç ç‰¹-æ­£äºŒç‰¹'],
                'æ­£3ç‰¹': ['æ­£3ç‰¹', 'æ­£ä¸‰ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹'],
                'æ­£4ç‰¹': ['æ­£4ç‰¹', 'æ­£å››ç‰¹', 'æ­£ç ç‰¹_æ­£å››ç‰¹', 'æ­£ç ç‰¹-æ­£å››ç‰¹'],
                'æ­£5ç‰¹': ['æ­£5ç‰¹', 'æ­£äº”ç‰¹', 'æ­£ç ç‰¹_æ­£äº”ç‰¹', 'æ­£ç ç‰¹-æ­£äº”ç‰¹'],
                'æ­£6ç‰¹': ['æ­£6ç‰¹', 'æ­£å…­ç‰¹', 'æ­£ç ç‰¹_æ­£å…­ç‰¹', 'æ­£ç ç‰¹-æ­£å…­ç‰¹'],
                'æ­£1': ['æ­£1', 'æ­£ä¸€', 'æ­£ç 1', 'æ­£ç _æ­£ä¸€'],
                'æ­£2': ['æ­£2', 'æ­£äºŒ', 'æ­£ç 2', 'æ­£ç _æ­£äºŒ'],
                'æ­£3': ['æ­£3', 'æ­£ä¸‰', 'æ­£ç 3', 'æ­£ç _æ­£ä¸‰'],
                'æ­£4': ['æ­£4', 'æ­£å››', 'æ­£ç 4', 'æ­£ç _æ­£å››'],
                'æ­£5': ['æ­£5', 'æ­£äº”', 'æ­£ç 5', 'æ­£ç _æ­£äº”'],
                'æ­£6': ['æ­£6', 'æ­£å…­', 'æ­£ç 6', 'æ­£ç _æ­£å…­'],
                'å¹³ç‰¹': ['å¹³ç‰¹', 'å¹³ç‰¹è‚–', 'å¹³ç '],
                'è¿è‚–': ['è¿è‚–', 'äºŒè¿è‚–', 'ä¸‰è¿è‚–', 'å››è¿è‚–'],
                'è¿å°¾': ['è¿å°¾', 'äºŒè¿å°¾', 'ä¸‰è¿å°¾', 'å››è¿å°¾'],
                'è‰²æ³¢': ['è‰²æ³¢', 'çº¢æ³¢', 'è“æ³¢', 'ç»¿æ³¢'],
                'äº”è¡Œ': ['äº”è¡Œ', 'é‡‘', 'æœ¨', 'æ°´', 'ç«', 'åœŸ']
            }
        }

        # ==================== ğŸ†• æ–°å¢ï¼šé‡‘é¢é˜ˆå€¼é…ç½® ====================
        self.amount_threshold = {
            'max_amount_ratio': 10,           # æœ€å¤§é‡‘é¢å·®è·å€æ•°ï¼ˆ10å€ = ååˆ†ä¹‹ä¸€ï¼‰
            'enable_threshold_filter': True   # æ˜¯å¦å¯ç”¨é‡‘é¢å¹³è¡¡è¿‡æ»¤
        }

# ==================== æ•°æ®å¤„ç†å™¨ç±» ====================
class DataProcessor:
    def __init__(self):
        self.required_columns = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹', 'é‡‘é¢']
        self.column_mapping = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID', 'ç”¨æˆ·åç§°', 'ç©å®¶åç§°'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°', 'å½©ç³»', 'æ¸¸æˆåç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·', 'å¼€å¥–æœŸå·', 'å¥–æœŸå·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»', 'ç©æ³•åç§°', 'æŠ•æ³¨æ–¹å¼'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯', 'å·ç ', 'é€‰å·'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼', 'å•æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é’±', 'å…ƒ']
        }
        
        self.similarity_threshold = 0.7
    
    def smart_column_identification(self, df_columns):
        """æ™ºèƒ½åˆ—è¯†åˆ«"""
        identified_columns = {}
        actual_columns = [str(col).strip() for col in df_columns]
        
        with st.expander("ğŸ” åˆ—åè¯†åˆ«è¯¦æƒ…", expanded=False):
            st.info(f"æ£€æµ‹åˆ°çš„åˆ—å: {actual_columns}")
            
            for standard_col, possible_names in self.column_mapping.items():
                found = False
                for actual_col in actual_columns:
                    actual_col_lower = actual_col.lower().replace(' ', '').replace('_', '').replace('-', '')
                    
                    for possible_name in possible_names:
                        possible_name_lower = possible_name.lower().replace(' ', '').replace('_', '').replace('-', '')
                        
                        # ğŸ†• ä¿®å¤ï¼šç›´æ¥åœ¨è¿™é‡Œè®¡ç®—ç›¸ä¼¼åº¦ï¼Œä¸è°ƒç”¨å¤–éƒ¨æ–¹æ³•
                        set1 = set(possible_name_lower)
                        set2 = set(actual_col_lower)
                        intersection = set1 & set2
                        
                        similarity_score = len(intersection) / len(set1) if set1 else 0
                        
                        if (possible_name_lower in actual_col_lower or 
                            actual_col_lower in possible_name_lower or
                            similarity_score >= self.similarity_threshold):
                            
                            identified_columns[actual_col] = standard_col
                            st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col} (ç›¸ä¼¼åº¦: {similarity_score:.2f})")
                            found = True
                            break
                    
                    if found:
                        break
                
                if not found:
                    st.warning(f"âš ï¸ æœªè¯†åˆ«åˆ° {standard_col} å¯¹åº”çš„åˆ—å")
        
        return identified_columns
    
    def find_data_start(self, df):
        """æ™ºèƒ½æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®"""
        for row_idx in range(min(20, len(df))):
            for col_idx in range(min(10, len(df.columns))):
                cell_value = str(df.iloc[row_idx, col_idx])
                if pd.notna(cell_value) and any(keyword in cell_value for keyword in ['ä¼šå‘˜', 'è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•', 'å†…å®¹', 'è®¢å•', 'ç”¨æˆ·']):
                    return row_idx, col_idx
        return 0, 0
    
    def validate_data_quality(self, df):
        """æ•°æ®è´¨é‡éªŒè¯"""
        logger.info("æ­£åœ¨è¿›è¡Œæ•°æ®è´¨é‡éªŒè¯...")
        issues = []
        
        # æ£€æŸ¥å¿…è¦åˆ—
        missing_cols = [col for col in self.required_columns if col not in df.columns]
        if missing_cols:
            issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        
        # æ£€æŸ¥ç©ºå€¼
        for col in self.required_columns:
            if col in df.columns:
                null_count = df[col].isnull().sum()
                if null_count > 0:
                    issues.append(f"åˆ— '{col}' æœ‰ {null_count} ä¸ªç©ºå€¼")

        if 'ä¼šå‘˜è´¦å·' in df.columns:
            # æ£€æŸ¥æˆªæ–­è´¦å·
            truncated_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(r'\.\.\.|â€¦', na=False)]
            if len(truncated_accounts) > 0:
                issues.append(f"å‘ç° {len(truncated_accounts)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„ä¼šå‘˜è´¦å·")
            
            # æ£€æŸ¥è´¦å·é•¿åº¦å¼‚å¸¸
            account_lengths = df['ä¼šå‘˜è´¦å·'].str.len()
            if account_lengths.max() > 50:
                issues.append("å‘ç°å¼‚å¸¸é•¿åº¦çš„ä¼šå‘˜è´¦å·")
            
            # æ˜¾ç¤ºè´¦å·æ ¼å¼æ ·æœ¬
            unique_accounts = df['ä¼šå‘˜è´¦å·'].unique()[:5]
            sample_info = " | ".join([f"'{acc}'" for acc in unique_accounts])
            st.info(f"ä¼šå‘˜è´¦å·æ ¼å¼æ ·æœ¬: {sample_info}")
        
        if 'æœŸå·' in df.columns:
            df['æœŸå·'] = df['æœŸå·'].astype(str).str.replace(r'\.0$', '', regex=True)
            invalid_periods = df[~df['æœŸå·'].str.match(r'^[\dA-Za-z]+$')]
            if len(invalid_periods) > 0:
                issues.append(f"å‘ç° {len(invalid_periods)} æ¡æ— æ•ˆæœŸå·è®°å½•")
        
        if 'å½©ç§' in df.columns:
            lottery_stats = df['å½©ç§'].value_counts()
            st.info(f"ğŸ² å½©ç§åˆ†å¸ƒ: å…±{len(lottery_stats)}ç§ï¼Œå‰5: {', '.join([f'{k}({v}æ¡)' for k,v in lottery_stats.head().items()])}")
        
        if hasattr(df, 'æŠ•æ³¨æ–¹å‘') and 'æŠ•æ³¨æ–¹å‘' in df.columns:
            direction_stats = df['æŠ•æ³¨æ–¹å‘'].value_counts().head(10)
            with st.expander("ğŸ¯ æŠ•æ³¨æ–¹å‘åˆ†å¸ƒTOP10", expanded=False):
                for direction, count in direction_stats.items():
                    st.write(f"  - {direction}: {count}æ¬¡")
        
        # ç‰¹åˆ«æ£€æŸ¥ä¼šå‘˜è´¦å·çš„å®Œæ•´æ€§
        if 'ä¼šå‘˜è´¦å·' in df.columns:
            truncated_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(r'\.\.\.|â€¦', na=False)]
            if len(truncated_accounts) > 0:
                issues.append(f"å‘ç° {len(truncated_accounts)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„ä¼šå‘˜è´¦å·")
            
            account_lengths = df['ä¼šå‘˜è´¦å·'].str.len()
            if account_lengths.max() > 50:
                issues.append("å‘ç°å¼‚å¸¸é•¿åº¦çš„ä¼šå‘˜è´¦å·")
            
            unique_accounts = df['ä¼šå‘˜è´¦å·'].unique()[:5]
            sample_info = " | ".join([f"'{acc}'" for acc in unique_accounts])
            st.info(f"ä¼šå‘˜è´¦å·æ ¼å¼æ ·æœ¬: {sample_info}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if 'æœŸå·' in df.columns:
            df['æœŸå·'] = df['æœŸå·'].astype(str).str.replace(r'\.0$', '', regex=True)
            invalid_periods = df[~df['æœŸå·'].str.match(r'^[\dA-Za-z]+$')]
            if len(invalid_periods) > 0:
                issues.append(f"å‘ç° {len(invalid_periods)} æ¡æ— æ•ˆæœŸå·è®°å½•")
        
        # æ£€æŸ¥é‡å¤æ•°æ®
        duplicate_count = df.duplicated().sum()
        if duplicate_count > 0:
            issues.append(f"å‘ç° {duplicate_count} æ¡é‡å¤è®°å½•")
        
        if issues:
            with st.expander("âš ï¸ æ•°æ®è´¨é‡é—®é¢˜", expanded=True):
                for issue in issues:
                    st.warning(f"  - {issue}")
        else:
            st.success("âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
        
        return issues
    
    def clean_data(self, uploaded_file):
        """æ•°æ®æ¸…æ´—ä¸»å‡½æ•°"""
        try:
            df_temp = pd.read_excel(uploaded_file, header=None, nrows=50)
            st.info(f"åŸå§‹æ•°æ®ç»´åº¦: {df_temp.shape}")
            
            start_row, start_col = self.find_data_start(df_temp)
            st.info(f"æ•°æ®èµ·å§‹ä½ç½®: ç¬¬{start_row+1}è¡Œ, ç¬¬{start_col+1}åˆ—")
            
            df_clean = pd.read_excel(
                uploaded_file, 
                header=start_row,
                skiprows=range(start_row + 1) if start_row > 0 else None,
                dtype=str,
                na_filter=False,
                keep_default_na=False
            )
            
            if start_col > 0:
                df_clean = df_clean.iloc[:, start_col:]
            
            st.info(f"æ¸…ç†åæ•°æ®ç»´åº¦: {df_clean.shape}")
            
            column_mapping = self.smart_column_identification(df_clean.columns)
            if column_mapping:
                df_clean = df_clean.rename(columns=column_mapping)
                st.success("âœ… åˆ—åè¯†åˆ«å®Œæˆ!")
            
            missing_columns = [col for col in self.required_columns if col not in df_clean.columns]
            if missing_columns and len(df_clean.columns) >= 4:
                st.warning("è‡ªåŠ¨æ˜ å°„åˆ—å...")
                manual_mapping = {}
                col_names = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'å†…å®¹', 'ç©æ³•', 'é‡‘é¢']
                for i, col_name in enumerate(col_names):
                    if i < len(df_clean.columns):
                        manual_mapping[df_clean.columns[i]] = col_name
                
                df_clean = df_clean.rename(columns=manual_mapping)
                st.info(f"æ‰‹åŠ¨é‡å‘½ååçš„åˆ—: {list(df_clean.columns)}")
            
            initial_count = len(df_clean)
            df_clean = df_clean.dropna(subset=[col for col in self.required_columns if col in df_clean.columns])
            df_clean = df_clean.dropna(axis=1, how='all')
            
            for col in self.required_columns:
                if col in df_clean.columns:
                    if col == 'ä¼šå‘˜è´¦å·':
                        df_clean[col] = df_clean[col].apply(
                            lambda x: str(x) if pd.notna(x) else ''
                        )
                    else:
                        df_clean[col] = df_clean[col].astype(str).str.strip()
            
            if 'æœŸå·' in df_clean.columns:
                df_clean['æœŸå·'] = df_clean['æœŸå·'].str.replace(r'\.0$', '', regex=True)
            
            # ğŸ†• æ–°å¢ï¼šé¢„å¤„ç†é‡‘é¢åˆ—æ ¼å¼
            if 'é‡‘é¢' in df_clean.columns:
                df_clean['é‡‘é¢'] = df_clean['é‡‘é¢'].apply(self.preprocess_amount_column)
            
            # ğŸ†• æ–°å¢ï¼šé¢„å¤„ç†å†…å®¹åˆ—æ ¼å¼  
            if 'å†…å®¹' in df_clean.columns:
                df_clean['å†…å®¹'] = df_clean['å†…å®¹'].apply(self.preprocess_content_column)
            
            # ========== ğŸ”„ ä¿®å¤è¿™é‡Œï¼šè°ƒç”¨å¢å¼ºçš„æ•°æ®éªŒè¯ ==========
            self.validate_data_quality(df_clean)
            
            st.success(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆ: {initial_count} -> {len(df_clean)} æ¡è®°å½•")
            
            st.info(f"ğŸ“Š å”¯ä¸€ä¼šå‘˜è´¦å·æ•°: {df_clean['ä¼šå‘˜è´¦å·'].nunique()}")
            
            if 'å½©ç§' in df_clean.columns:
                lottery_dist = df_clean['å½©ç§'].value_counts()
                with st.expander("ğŸ¯ å½©ç§åˆ†å¸ƒ", expanded=False):
                    st.dataframe(lottery_dist.reset_index().rename(columns={'index': 'å½©ç§', 'å½©ç§': 'æ•°é‡'}))
            
            return df_clean
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            logger.error(f"æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            return None
    
    def preprocess_amount_column(self, amount_text):
        """é¢„å¤„ç†é‡‘é¢åˆ—æ ¼å¼"""
        if pd.isna(amount_text):
            return amount_text
        
        text = str(amount_text).strip()
        
        # ğŸ†• æ ‡å‡†åŒ–é‡‘é¢æ ¼å¼
        if 'æŠ•æ³¨ï¼š' in text and 'æŠµç”¨ï¼š' in text:
            # æå–æŠ•æ³¨éƒ¨åˆ†ï¼Œç§»é™¤å…¶ä»–ä¿¡æ¯
            try:
                bet_part = text.split('æŠ•æ³¨ï¼š')[1].split('æŠµç”¨ï¼š')[0].strip()
                return f"æŠ•æ³¨ï¼š{bet_part}"
            except:
                return text
        
        return text
    
    def preprocess_content_column(self, content_text):
        """é¢„å¤„ç†å†…å®¹åˆ—æ ¼å¼"""
        if pd.isna(content_text):
            return content_text
        
        text = str(content_text).strip()
        
        # ğŸ†• æ ‡å‡†åŒ–å…­åˆå½©ç‰¹ç ä¸¤é¢æ ¼å¼
        if 'ç‰¹ç ä¸¤é¢-' in text:
            # ç»Ÿä¸€æ ¼å¼ï¼Œå»é™¤å¯èƒ½çš„å¤šä½™ç©ºæ ¼
            text = text.replace('ç‰¹ç ä¸¤é¢ - ', 'ç‰¹ç ä¸¤é¢-')
            text = text.replace('ç‰¹ç ä¸¤é¢- ', 'ç‰¹ç ä¸¤é¢-')
            return text
        
        return text

# ==================== å½©ç§è¯†åˆ«å™¨ ====================
LOTTERY_CONFIGS = {
    'PK10': {
        'lotteries': [
            'åˆ†åˆ†PKæ‹¾', 'ä¸‰åˆ†PKæ‹¾', 'äº”åˆ†PKæ‹¾', 'æ–°å¹¸è¿é£è‰‡', 'æ¾³æ´²å¹¸è¿10',
            'ä¸€åˆ†PK10', 'å®¾æœPK10', 'æé€Ÿé£è‰‡', 'æ¾³æ´²é£è‰‡', 'å¹¸è¿èµ›è½¦',
            'åˆ†åˆ†èµ›è½¦', 'åŒ—äº¬PK10', 'æ—§åŒ—äº¬PK10', 'æé€Ÿèµ›è½¦', 'å¹¸è¿èµ›è»Š', 
            'åŒ—äº¬èµ›è½¦', 'æé€ŸPK10', 'å¹¸è¿PK10', 'èµ›è½¦', 'èµ›è»Š'
        ],
        'min_number': 1,
        'max_number': 10,
        'gyh_min': 3,
        'gyh_max': 19,
        'position_names': ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                          'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
    },
    'K3': {
        'lotteries': [
            'åˆ†åˆ†å¿«ä¸‰', 'ä¸‰åˆ†å¿«3', 'äº”åˆ†å¿«3', 'æ¾³æ´²å¿«ä¸‰', 'å®¾æœå¿«ä¸‰',
            '1åˆ†å¿«ä¸‰', '3åˆ†å¿«ä¸‰', '5åˆ†å¿«ä¸‰', '10åˆ†å¿«ä¸‰', 'åŠ å·å¿«ä¸‰',
            'å¹¸è¿å¿«ä¸‰', 'å¤§å‘å¿«ä¸‰', 'å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 
            'æ¾³é—¨å¿«ä¸‰', 'é¦™æ¸¯å¿«ä¸‰', 'æ±Ÿè‹å¿«ä¸‰'
        ],
        'min_number': 1,
        'max_number': 6,
        'hezhi_min': 3,
        'hezhi_max': 18
    },
    'LHC': {
        'lotteries': [
            'æ–°æ¾³é—¨å…­åˆå½©', 'æ¾³é—¨å…­åˆå½©', 'é¦™æ¸¯å…­åˆå½©', 'ä¸€åˆ†å…­åˆå½©',
            'äº”åˆ†å…­åˆå½©', 'ä¸‰åˆ†å…­åˆå½©', 'é¦™æ¸¯â‘¥åˆå½©', 'åˆ†åˆ†å…­åˆå½©',
            'å¿«ä¹6åˆå½©', 'æ¸¯â‘¥åˆå½©', 'å°æ¹¾å¤§ä¹é€', 'å…­åˆ', 'lhc', 'å…­åˆå½©',
            'â‘¥åˆ', '6åˆ', 'å¤§å‘å…­åˆå½©'
        ],
        'min_number': 1,
        'max_number': 49
    },
    'SSC': {
        'lotteries': [
            'åˆ†åˆ†æ—¶æ—¶å½©', 'ä¸‰åˆ†æ—¶æ—¶å½©', 'äº”åˆ†æ—¶æ—¶å½©', 'å®¾æœæ—¶æ—¶å½©',
            '1åˆ†æ—¶æ—¶å½©', '3åˆ†æ—¶æ—¶å½©', '5åˆ†æ—¶æ—¶å½©', 'æ—§é‡åº†æ—¶æ—¶å½©',
            'å¹¸è¿æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©', 'æ–°ç–†æ—¶æ—¶å½©', 'å¤©æ´¥æ—¶æ—¶å½©',
            'é‡åº†æ—¶æ—¶å½©', 'ä¸Šæµ·æ—¶æ—¶å½©', 'å¹¿ä¸œæ—¶æ—¶å½©', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©'
        ],
        'min_number': 0,
        'max_number': 9
    },
    '3D': {
        'lotteries': [
            'æ’åˆ—ä¸‰', 'æ’åˆ—3', 'å¹¸è¿æ’åˆ—3', 'ä¸€åˆ†æ’åˆ—3', 'äºŒåˆ†æ’åˆ—3', 'ä¸‰åˆ†æ’åˆ—3', 
            'äº”åˆ†æ’åˆ—3', 'ååˆ†æ’åˆ—3', 'å¤§å‘æ’åˆ—3', 'å¥½è¿æ’åˆ—3', 'ç¦å½©3D', 'æé€Ÿ3D',
            'æé€Ÿæ’åˆ—3', 'å¹¸è¿3D', 'ä¸€åˆ†3D', 'äºŒåˆ†3D', 'ä¸‰åˆ†3D', 'äº”åˆ†3D', 
            'ååˆ†3D', 'å¤§å‘3D', 'å¥½è¿3D'
        ],
        'min_number': 0,
        'max_number': 9,
        'position_names': ['ç™¾ä½', 'åä½', 'ä¸ªä½']
    }
}

class LotteryIdentifier:
    def __init__(self):
        self.lottery_configs = LOTTERY_CONFIGS
        self.general_keywords = {
            'PK10': ['pk10', 'pkæ‹¾', 'é£è‰‡', 'èµ›è½¦', 'èµ›è»Š', 'å¹¸è¿10', 'åŒ—äº¬èµ›è½¦', 'æé€Ÿèµ›è½¦'],
            'K3': ['å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 'éª°å®', 'ä¸‰å†›'],
            'LHC': ['å…­åˆ', 'lhc', 'å…­åˆå½©', 'â‘¥åˆ', '6åˆ', 'ç‰¹ç ', 'å¹³ç‰¹', 'è¿è‚–'],
            'SSC': ['æ—¶æ—¶å½©', 'ssc', 'åˆ†åˆ†å½©', 'æ™‚æ™‚å½©', 'é‡åº†æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©'],
            '3D': ['æ’åˆ—ä¸‰', 'æ’åˆ—3', 'ç¦å½©3d', '3d', 'æé€Ÿ3d', 'æ’åˆ—', 'p3', 'pä¸‰']
        }
        
        self.lottery_aliases = {
            'åˆ†åˆ†PKæ‹¾': 'PK10', 'ä¸‰åˆ†PKæ‹¾': 'PK10', 'äº”åˆ†PKæ‹¾': 'PK10',
            'æ–°å¹¸è¿é£è‰‡': 'PK10', 'æ¾³æ´²å¹¸è¿10': 'PK10', 'ä¸€åˆ†PK10': 'PK10',
            'å®¾æœPK10': 'PK10', 'æé€Ÿé£è‰‡': 'PK10', 'æ¾³æ´²é£è‰‡': 'PK10',
            'å¹¸è¿èµ›è½¦': 'PK10', 'åˆ†åˆ†èµ›è½¦': 'PK10', 'åŒ—äº¬PK10': 'PK10',
            'æ—§åŒ—äº¬PK10': 'PK10', 'æé€Ÿèµ›è½¦': 'PK10', 'å¹¸è¿èµ›è»Š': 'PK10',
            'åŒ—äº¬èµ›è½¦': 'PK10', 'æé€ŸPK10': 'PK10', 'å¹¸è¿PK10': 'PK10',
            'åˆ†åˆ†å¿«ä¸‰': 'K3', 'ä¸‰åˆ†å¿«3': 'K3', 'äº”åˆ†å¿«3': 'K3', 'æ¾³æ´²å¿«ä¸‰': 'K3',
            'å®¾æœå¿«ä¸‰': 'K3', '1åˆ†å¿«ä¸‰': 'K3', '3åˆ†å¿«ä¸‰': 'K3', '5åˆ†å¿«ä¸‰': 'K3',
            '10åˆ†å¿«ä¸‰': 'K3', 'åŠ å·å¿«ä¸‰': 'K3', 'å¹¸è¿å¿«ä¸‰': 'K3', 'å¤§å‘å¿«ä¸‰': 'K3',
            'æ¾³é—¨å¿«ä¸‰': 'K3', 'é¦™æ¸¯å¿«ä¸‰': 'K3', 'æ±Ÿè‹å¿«ä¸‰': 'K3',
            'æ–°æ¾³é—¨å…­åˆå½©': 'LHC', 'æ¾³é—¨å…­åˆå½©': 'LHC', 'é¦™æ¸¯å…­åˆå½©': 'LHC',
            'ä¸€åˆ†å…­åˆå½©': 'LHC', 'äº”åˆ†å…­åˆå½©': 'LHC', 'ä¸‰åˆ†å…­åˆå½©': 'LHC',
            'é¦™æ¸¯â‘¥åˆå½©': 'LHC', 'åˆ†åˆ†å…­åˆå½©': 'LHC', 'å¿«ä¹6åˆå½©': 'LHC',
            'æ¸¯â‘¥åˆå½©': 'LHC', 'å°æ¹¾å¤§ä¹é€': 'LHC', 'å¤§å‘å…­åˆå½©': 'LHC',
            'åˆ†åˆ†æ—¶æ—¶å½©': 'SSC', 'ä¸‰åˆ†æ—¶æ—¶å½©': 'SSC', 'äº”åˆ†æ—¶æ—¶å½©': 'SSC',
            'å®¾æœæ—¶æ—¶å½©': 'SSC', '1åˆ†æ—¶æ—¶å½©': 'SSC', '3åˆ†æ—¶æ—¶å½©': 'SSC',
            '5åˆ†æ—¶æ—¶å½©': 'SSC', 'æ—§é‡åº†æ—¶æ—¶å½©': 'SSC', 'å¹¸è¿æ—¶æ—¶å½©': 'SSC',
            'è…¾è®¯åˆ†åˆ†å½©': 'SSC', 'æ–°ç–†æ—¶æ—¶å½©': 'SSC', 'å¤©æ´¥æ—¶æ—¶å½©': 'SSC',
            'é‡åº†æ—¶æ—¶å½©': 'SSC', 'ä¸Šæµ·æ—¶æ—¶å½©': 'SSC', 'å¹¿ä¸œæ—¶æ—¶å½©': 'SSC',
            'æ’åˆ—ä¸‰': '3D', 'æ’åˆ—3': '3D', 'å¹¸è¿æ’åˆ—3': '3D', 'ä¸€åˆ†æ’åˆ—3': '3D',
            'äºŒåˆ†æ’åˆ—3': '3D', 'ä¸‰åˆ†æ’åˆ—3': '3D', 'äº”åˆ†æ’åˆ—3': '3D', 'ååˆ†æ’åˆ—3': '3D',
            'å¤§å‘æ’åˆ—3': '3D', 'å¥½è¿æ’åˆ—3': '3D', 'ç¦å½©3D': '3D', 'æé€Ÿ3D': '3D',
            'æé€Ÿæ’åˆ—3': '3D', 'å¹¸è¿3D': '3D', 'ä¸€åˆ†3D': '3D', 'äºŒåˆ†3D': '3D',
            'ä¸‰åˆ†3D': '3D', 'äº”åˆ†3D': '3D', 'ååˆ†3D': '3D', 'å¤§å‘3D': '3D', 'å¥½è¿3D': '3D'
        }

    def identify_lottery_type(self, lottery_name):
        """å½©ç§ç±»å‹è¯†åˆ«"""
        lottery_str = str(lottery_name).strip()
        
        if lottery_str in self.lottery_aliases:
            return self.lottery_aliases[lottery_str]
        
        for lottery_type, config in self.lottery_configs.items():
            for lottery in config['lotteries']:
                if lottery in lottery_str:
                    return lottery_type
        
        lottery_lower = lottery_str.lower()
        
        for lottery_type, keywords in self.general_keywords.items():
            for keyword in keywords:
                if keyword.lower() in lottery_lower:
                    return lottery_type
        
        return lottery_str

# ==================== ç©æ³•åˆ†ç±»å™¨ ====================
class PlayCategoryNormalizer:
    def __init__(self):
        self.category_mapping = self._create_category_mapping()
    
    def _create_category_mapping(self):
        """åˆ›å»ºç©æ³•åˆ†ç±»æ˜ å°„"""
        mapping = {
            # å¿«ä¸‰ç©æ³•
            'å’Œå€¼': 'å’Œå€¼', 'å’Œå€¼_å¤§å°å•åŒ': 'å’Œå€¼', 'ä¸¤é¢': 'ä¸¤é¢',
            'äºŒä¸åŒå·': 'äºŒä¸åŒå·', 'ä¸‰ä¸åŒå·': 'ä¸‰ä¸åŒå·', 'ç‹¬èƒ†': 'ç‹¬èƒ†',
            'ç‚¹æ•°': 'å’Œå€¼', 'ä¸‰å†›': 'ç‹¬èƒ†', 'ä¸‰è»': 'ç‹¬èƒ†',
            
            # å…­åˆå½©ç©æ³•
            'ç‰¹ç ': 'ç‰¹ç ', 'æ­£1ç‰¹': 'æ­£1ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹': 'æ­£1ç‰¹',
            'æ­£2ç‰¹': 'æ­£2ç‰¹', 'æ­£ç ç‰¹_æ­£äºŒç‰¹': 'æ­£2ç‰¹', 'æ­£3ç‰¹': 'æ­£3ç‰¹',
            'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹', 'æ­£4ç‰¹': 'æ­£4ç‰¹', 'æ­£ç ç‰¹_æ­£å››ç‰¹': 'æ­£4ç‰¹',
            'æ­£5ç‰¹': 'æ­£5ç‰¹', 'æ­£ç ç‰¹_æ­£äº”ç‰¹': 'æ­£5ç‰¹', 'æ­£6ç‰¹': 'æ­£6ç‰¹',
            'æ­£ç ç‰¹_æ­£å…­ç‰¹': 'æ­£6ç‰¹', 'æ­£ç ': 'æ­£ç ', 'æ­£ç‰¹': 'æ­£ç‰¹',
            'å°¾æ•°': 'å°¾æ•°', 'ç‰¹è‚–': 'ç‰¹è‚–', 'å¹³ç‰¹': 'å¹³ç‰¹', 'ä¸€è‚–': 'ä¸€è‚–',
            'è¿è‚–': 'è¿è‚–', 'è¿å°¾': 'è¿å°¾', 'é¾™è™': 'é¾™è™', 'äº”è¡Œ': 'äº”è¡Œ',
            'è‰²æ³¢': 'è‰²æ³¢', 'åŠæ³¢': 'åŠæ³¢', 'å¤©è‚–': 'å¤©è‚–', 'åœ°è‚–': 'åœ°è‚–',
            'å®¶è‚–': 'å®¶è‚–', 'é‡è‚–': 'é‡è‚–',

            # ğŸ†• å¢å¼ºå…­åˆå½©ç©æ³•æ˜ å°„
            'æ­£1ç‰¹': 'æ­£1ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹': 'æ­£1ç‰¹', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹': 'æ­£1ç‰¹',
            'æ­£2ç‰¹': 'æ­£2ç‰¹', 'æ­£ç ç‰¹_æ­£äºŒç‰¹': 'æ­£2ç‰¹', 'æ­£ç ç‰¹-æ­£äºŒç‰¹': 'æ­£2ç‰¹',
            'æ­£3ç‰¹': 'æ­£3ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹',
            'æ­£4ç‰¹': 'æ­£4ç‰¹', 'æ­£ç ç‰¹_æ­£å››ç‰¹': 'æ­£4ç‰¹', 'æ­£ç ç‰¹-æ­£å››ç‰¹': 'æ­£4ç‰¹',
            'æ­£5ç‰¹': 'æ­£5ç‰¹', 'æ­£ç ç‰¹_æ­£äº”ç‰¹': 'æ­£5ç‰¹', 'æ­£ç ç‰¹-æ­£äº”ç‰¹': 'æ­£5ç‰¹',
            'æ­£6ç‰¹': 'æ­£6ç‰¹', 'æ­£ç ç‰¹_æ­£å…­ç‰¹': 'æ­£6ç‰¹', 'æ­£ç ç‰¹-æ­£å…­ç‰¹': 'æ­£6ç‰¹',
            
            'æ­£1': 'æ­£1', 'æ­£ç 1': 'æ­£1', 'æ­£ç _æ­£ä¸€': 'æ­£1',
            'æ­£2': 'æ­£2', 'æ­£ç 2': 'æ­£2', 'æ­£ç _æ­£äºŒ': 'æ­£2',
            'æ­£3': 'æ­£3', 'æ­£ç 3': 'æ­£3', 'æ­£ç _æ­£ä¸‰': 'æ­£3',
            'æ­£4': 'æ­£4', 'æ­£ç 4': 'æ­£4', 'æ­£ç _æ­£å››': 'æ­£4',
            'æ­£5': 'æ­£5', 'æ­£ç 5': 'æ­£5', 'æ­£ç _æ­£äº”': 'æ­£5',
            'æ­£6': 'æ­£6', 'æ­£ç 6': 'æ­£6', 'æ­£ç _æ­£å…­': 'æ­£6',
            
            # 3Dç³»åˆ—ç©æ³•
            'ä¸¤é¢': 'ä¸¤é¢', 'å¤§å°å•åŒ': 'ä¸¤é¢', 'ç™¾ä½': 'ç™¾ä½', 'åä½': 'åä½', 
            'ä¸ªä½': 'ä¸ªä½', 'ç™¾å': 'ç™¾å', 'ç™¾ä¸ª': 'ç™¾ä¸ª', 'åä¸ª': 'åä¸ª',
            'ç™¾åä¸ª': 'ç™¾åä¸ª', 'å®šä½èƒ†': 'å®šä½èƒ†', 'å®šä½èƒ†_ç™¾ä½': 'å®šä½èƒ†_ç™¾ä½',
            'å®šä½èƒ†_åä½': 'å®šä½èƒ†_åä½', 'å®šä½èƒ†_ä¸ªä½': 'å®šä½èƒ†_ä¸ªä½',
            
            # æ—¶æ—¶å½©ç©æ³•
            'æ–—ç‰›': 'æ–—ç‰›', '1-5çƒ': '1-5çƒ', 'ç¬¬1çƒ': 'ç¬¬1çƒ', 'ç¬¬2çƒ': 'ç¬¬2çƒ',
            'ç¬¬3çƒ': 'ç¬¬3çƒ', 'ç¬¬4çƒ': 'ç¬¬4çƒ', 'ç¬¬5çƒ': 'ç¬¬5çƒ', 'æ€»å’Œ': 'æ€»å’Œ',
            'æ­£ç ': 'æ­£ç ', 'å®šä½èƒ†': 'å®šä½èƒ†',
            
            # PKæ‹¾/èµ›è½¦ç©æ³•
            'å‰ä¸€': 'å† å†›', 'å®šä½èƒ†': 'å®šä½èƒ†', '1-5å': '1-5å', '6-10å': '6-10å',
            'å† å†›': 'å† å†›', 'äºšå†›': 'äºšå†›', 'å­£å†›': 'ç¬¬ä¸‰å', 'ç¬¬3å': 'ç¬¬ä¸‰å',
            'ç¬¬4å': 'ç¬¬å››å', 'ç¬¬5å': 'ç¬¬äº”å', 'ç¬¬6å': 'ç¬¬å…­å',
            'ç¬¬7å': 'ç¬¬ä¸ƒå', 'ç¬¬8å': 'ç¬¬å…«å', 'ç¬¬9å': 'ç¬¬ä¹å',
            'ç¬¬10å': 'ç¬¬åå', 'åŒé¢': 'ä¸¤é¢', 'å† äºšå’Œ': 'å† äºšå’Œ'
        }
        return mapping
    
    def normalize_category(self, category):
        """ç»Ÿä¸€ç©æ³•åˆ†ç±»åç§°"""
        category_str = str(category).strip()
        
        # ç›´æ¥æ˜ å°„
        if category_str in self.category_mapping:
            return self.category_mapping[category_str]
        
        # å…³é”®è¯åŒ¹é…
        for key, value in self.category_mapping.items():
            if key in category_str:
                return value
        
        # æ™ºèƒ½åŒ¹é…
        category_lower = category_str.lower()
        
        # PK10/èµ›è½¦æ™ºèƒ½åŒ¹é…
        if any(word in category_lower for word in ['å† å†›', 'ç¬¬ä¸€å', 'ç¬¬1å', '1st']):
            return 'å† å†›'
        elif any(word in category_lower for word in ['äºšå†›', 'ç¬¬äºŒå', 'ç¬¬2å', '2nd']):
            return 'äºšå†›'
        elif any(word in category_lower for word in ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›', '3rd']):
            return 'ç¬¬ä¸‰å'
        elif any(word in category_lower for word in ['ç¬¬å››å', 'ç¬¬4å', '4th']):
            return 'ç¬¬å››å'
        elif any(word in category_lower for word in ['ç¬¬äº”å', 'ç¬¬5å', '5th']):
            return 'ç¬¬äº”å'
        elif any(word in category_lower for word in ['ç¬¬å…­å', 'ç¬¬6å', '6th']):
            return 'ç¬¬å…­å'
        elif any(word in category_lower for word in ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th']):
            return 'ç¬¬ä¸ƒå'
        elif any(word in category_lower for word in ['ç¬¬å…«å', 'ç¬¬8å', '8th']):
            return 'ç¬¬å…«å'
        elif any(word in category_lower for word in ['ç¬¬ä¹å', 'ç¬¬9å', '9th']):
            return 'ç¬¬ä¹å'
        elif any(word in category_lower for word in ['ç¬¬åå', 'ç¬¬10å', '10th']):
            return 'ç¬¬åå'
        
        # 3Dç³»åˆ—æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ç™¾ä½']):
            return 'ç™¾ä½'
        elif any(word in category_lower for word in ['åä½']):
            return 'åä½'
        elif any(word in category_lower for word in ['ä¸ªä½']):
            return 'ä¸ªä½'
        
        # æ—¶æ—¶å½©æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ç¬¬1çƒ', 'ä¸‡ä½']):
            return 'ç¬¬1çƒ'
        elif any(word in category_lower for word in ['ç¬¬2çƒ', 'åƒä½']):
            return 'ç¬¬2çƒ'
        elif any(word in category_lower for word in ['ç¬¬3çƒ', 'ç™¾ä½']):
            return 'ç¬¬3çƒ'
        elif any(word in category_lower for word in ['ç¬¬4çƒ', 'åä½']):
            return 'ç¬¬4çƒ'
        elif any(word in category_lower for word in ['ç¬¬5çƒ', 'ä¸ªä½']):
            return 'ç¬¬5çƒ'
        
        # å…­åˆå½©æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['å¤©è‚–']):
            return 'å¤©è‚–'
        elif any(word in category_lower for word in ['åœ°è‚–']):
            return 'åœ°è‚–'
        elif any(word in category_lower for word in ['å®¶è‚–', 'å®¶ç¦½']):
            return 'å®¶è‚–'
        elif any(word in category_lower for word in ['é‡è‚–', 'é‡å…½']):
            return 'é‡è‚–'

        # æ­£ç ç‰¹æ™ºèƒ½åŒ¹é…
        if any(word in category_lower for word in ['æ­£1ç‰¹', 'æ­£ä¸€ç‰¹']):
            return 'æ­£1ç‰¹'
        elif any(word in category_lower for word in ['æ­£2ç‰¹', 'æ­£äºŒç‰¹']):
            return 'æ­£2ç‰¹'
        elif any(word in category_lower for word in ['æ­£3ç‰¹', 'æ­£ä¸‰ç‰¹']):
            return 'æ­£3ç‰¹'
        elif any(word in category_lower for word in ['æ­£4ç‰¹', 'æ­£å››ç‰¹']):
            return 'æ­£4ç‰¹'
        elif any(word in category_lower for word in ['æ­£5ç‰¹', 'æ­£äº”ç‰¹']):
            return 'æ­£5ç‰¹'
        elif any(word in category_lower for word in ['æ­£6ç‰¹', 'æ­£å…­ç‰¹']):
            return 'æ­£6ç‰¹'
        
        # æ­£ç æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['æ­£1', 'æ­£ä¸€']):
            return 'æ­£1'
        elif any(word in category_lower for word in ['æ­£2', 'æ­£äºŒ']):
            return 'æ­£2'
        elif any(word in category_lower for word in ['æ­£3', 'æ­£ä¸‰']):
            return 'æ­£3'
        elif any(word in category_lower for word in ['æ­£4', 'æ­£å››']):
            return 'æ­£4'
        elif any(word in category_lower for word in ['æ­£5', 'æ­£äº”']):
            return 'æ­£5'
        elif any(word in category_lower for word in ['æ­£6', 'æ­£å…­']):
            return 'æ­£6'
        
        return category_str

# ==================== å†…å®¹è§£æå™¨ ====================
class ContentParser:
    """å†…å®¹è§£æå™¨ - æ”¯æŒå˜å¼‚å½¢å¼ä½†æ˜ å°„åˆ°åŸºç¡€æ–¹å‘"""
    
    @staticmethod
    def extract_basic_directions(content, config):
        """æå–æ–¹å‘ - ä¿æŒå˜å¼‚å½¢å¼ç‹¬ç«‹æ€§"""
        content_str = str(content).strip()
        directions = []
        
        if not content_str:
            return directions
        
        content_lower = content_str.lower()
        
        # ğŸ¯ æå–æ‰€æœ‰å¯èƒ½çš„æ–¹å‘ï¼ˆä¿æŒå˜å¼‚å½¢å¼ç‹¬ç«‹æ€§ï¼‰
        for direction, patterns in config.direction_patterns.items():
            for pattern in patterns:
                pattern_lower = pattern.lower()
                # ç²¾ç¡®åŒ¹é…æ£€æŸ¥
                if (pattern_lower == content_lower or 
                    pattern_lower in content_lower or 
                    content_lower in pattern_lower):
                    directions.append(direction)
                    break
        
        return directions

    # ğŸ†• æ–°å¢ï¼šå¢å¼ºæ–¹å‘æå–æ–¹æ³•
    @staticmethod
    def enhanced_extract_directions(content, config):
        """ğŸ¯ å¢å¼ºç‰ˆæ–¹å‘æå– - ç‰¹åˆ«ä¼˜åŒ–å…­åˆå½©ç‰¹ç ä¸¤é¢"""
        try:
            if pd.isna(content):
                return []
            
            content_str = str(content).strip()
            
            # ğŸ†• ä¸“é—¨å¤„ç†å…­åˆå½©ç‰¹ç ä¸¤é¢æ ¼å¼
            if 'ç‰¹ç ä¸¤é¢-' in content_str:
                direction_part = content_str.split('ç‰¹ç ä¸¤é¢-')[-1].strip()
                # æ£€æŸ¥æ˜¯å¦åŒ¹é…å·²çŸ¥æ–¹å‘
                for direction, patterns in config.direction_patterns.items():
                    for pattern in patterns:
                        if direction_part == pattern or direction_part in pattern:
                            return [direction]
            
            # ğŸ†• å¤„ç†å…¶ä»–å…­åˆå½©å˜ä½“æ ¼å¼
            lhc_special_patterns = {
                'ç‰¹ç ä¸¤é¢-å°¾å¤§': 'å°¾å¤§',
                'ç‰¹ç ä¸¤é¢-å°¾å°': 'å°¾å°', 
                'ç‰¹ç ä¸¤é¢-ç‰¹å¤§': 'ç‰¹å¤§',
                'ç‰¹ç ä¸¤é¢-ç‰¹å°': 'ç‰¹å°',
                'ç‰¹ç ä¸¤é¢-ç‰¹å•': 'ç‰¹å•',
                'ç‰¹ç ä¸¤é¢-ç‰¹åŒ': 'ç‰¹åŒ',
                'ç‰¹ç ä¸¤é¢-å¤§': 'å¤§',
                'ç‰¹ç ä¸¤é¢-å°': 'å°',
                'ç‰¹ç ä¸¤é¢-å•': 'å•',
                'ç‰¹ç ä¸¤é¢-åŒ': 'åŒ'
            }
            
            for pattern, direction in lhc_special_patterns.items():
                if pattern in content_str:
                    return [direction]
            
            # åŸæœ‰çš„å¤šå±‚çº§æ–¹å‘æå–é€»è¾‘
            content_clean = ContentParser.preprocess_content(content_str)
            directions = ContentParser.multi_level_direction_extraction(content_clean, config)
            
            return directions
                
        except Exception as e:
            logger.warning(f"æ–¹å‘æå–å¤±è´¥: {content}, é”™è¯¯: {e}")
            return []

    @staticmethod
    def preprocess_content(content):
        """ğŸ†• å†…å®¹é¢„å¤„ç†"""
        content_str = str(content).strip()
        
        # ç»Ÿä¸€æ ‡ç‚¹ç¬¦å·
        content_str = content_str.replace('ï¼Œ', ',').replace('ï¼›', ';').replace('ï¼š', ':')
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        content_str = re.sub(r'\s+', ' ', content_str).strip()
        
        # å¤„ç†ç‰¹æ®Šå­—ç¬¦
        content_str = re.sub(r'[\(\)ï¼ˆï¼‰ã€ã€‘]', '', content_str)
        
        return content_str

    @staticmethod
    def multi_level_direction_extraction(content, config):
        """ğŸ†• å¤šå±‚çº§æ–¹å‘æå– - å¢å¼ºå…­åˆå½©ç²¾ç¡®ä½ç½®è¯†åˆ«"""
        directions = set()
        
        # ç¬¬ä¸€å±‚ï¼šç²¾ç¡®åŒ¹é…
        for direction, patterns in config.direction_patterns.items():
            for pattern in patterns:
                if pattern == content:  # å®Œå…¨åŒ¹é…
                    directions.add(direction)
                    break
        
        # ç¬¬äºŒå±‚ï¼šåŒ…å«åŒ¹é…
        if not directions:
            for direction, patterns in config.direction_patterns.items():
                for pattern in patterns:
                    if pattern in content:
                        directions.add(direction)
        
        # ç¬¬ä¸‰å±‚ï¼šæ™ºèƒ½ç»„åˆåŒ¹é… - ç‰¹åˆ«å¤„ç†å…­åˆå½©ç²¾ç¡®ä½ç½®
        if not directions:
            directions = ContentParser.smart_lhc_position_extraction(content, config)
        
        return list(directions)

    @staticmethod
    def smart_lhc_position_extraction(content, config):
        """ğŸ†• æ™ºèƒ½å…­åˆå½©ä½ç½®æå– - ç²¾ç¡®è¯†åˆ«æ­£ç ç‰¹å’Œæ­£ç """
        directions = set()
        content_lower = content.lower()
        
        # ğŸ¯ å…­åˆå½©ä½ç½®å…³é”®è¯æ˜ å°„
        lhc_position_map = {
            'æ­£1ç‰¹': ['æ­£1ç‰¹', 'æ­£ä¸€ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹'],
            'æ­£2ç‰¹': ['æ­£2ç‰¹', 'æ­£äºŒç‰¹', 'æ­£ç ç‰¹_æ­£äºŒç‰¹'], 
            'æ­£3ç‰¹': ['æ­£3ç‰¹', 'æ­£ä¸‰ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹'],
            'æ­£4ç‰¹': ['æ­£4ç‰¹', 'æ­£å››ç‰¹', 'æ­£ç ç‰¹_æ­£å››ç‰¹'],
            'æ­£5ç‰¹': ['æ­£5ç‰¹', 'æ­£äº”ç‰¹', 'æ­£ç ç‰¹_æ­£äº”ç‰¹'],
            'æ­£6ç‰¹': ['æ­£6ç‰¹', 'æ­£å…­ç‰¹', 'æ­£ç ç‰¹_æ­£å…­ç‰¹'],
            'æ­£1': ['æ­£1', 'æ­£ä¸€', 'æ­£ç 1', 'æ­£ç _æ­£ä¸€'],
            'æ­£2': ['æ­£2', 'æ­£äºŒ', 'æ­£ç 2', 'æ­£ç _æ­£äºŒ'],
            'æ­£3': ['æ­£3', 'æ­£ä¸‰', 'æ­£ç 3', 'æ­£ç _æ­£ä¸‰'],
            'æ­£4': ['æ­£4', 'æ­£å››', 'æ­£ç 4', 'æ­£ç _æ­£å››'],
            'æ­£5': ['æ­£5', 'æ­£äº”', 'æ­£ç 5', 'æ­£ç _æ­£äº”'],
            'æ­£6': ['æ­£6', 'æ­£å…­', 'æ­£ç 6', 'æ­£ç _æ­£å…­']
        }
        
        # ğŸ¯ åŸºç¡€æ–¹å‘å…³é”®è¯
        base_directions = {
            'å¤§': ['å¤§', 'big', 'large', 'da'],
            'å°': ['å°', 'small', 'xiao'],
            'å•': ['å•', 'odd', 'dan', 'å¥‡'],
            'åŒ': ['åŒ', 'even', 'shuang', 'å¶']
        }
        
        # ğŸ¯ æ£€æŸ¥å…­åˆå½©ç²¾ç¡®ä½ç½®
        for position, keywords in lhc_position_map.items():
            for keyword in keywords:
                if keyword in content_lower:
                    # æ‰¾åˆ°ä½ç½®åï¼Œæ£€æŸ¥åŸºç¡€æ–¹å‘
                    for direction, dir_keywords in base_directions.items():
                        for dir_keyword in dir_keywords:
                            if dir_keyword in content_lower:
                                # ç»„åˆä½ç½®å’Œæ–¹å‘
                                combined_direction = f"{position}-{direction}"
                                directions.add(combined_direction)
                                break
        
        # ğŸ¯ å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç²¾ç¡®ä½ç½®ï¼Œæ£€æŸ¥åŸºç¡€æ–¹å‘
        if not directions:
            for direction, keywords in base_directions.items():
                for keyword in keywords:
                    if (keyword in content_lower and 
                        (len(keyword) > 1 or 
                         (len(keyword) == 1 and 
                          (content_lower == keyword or 
                           f" {keyword} " in f" {content_lower} " or
                           content_lower.startswith(keyword + ' ') or
                           content_lower.endswith(' ' + keyword))))):
                        directions.add(direction)
                        break
        
        return directions

    @staticmethod
    def prioritize_directions(directions, content, play_category):
        """ğŸ†• æ–¹å‘ä¼˜å…ˆçº§æ’åº"""
        if not directions:
            return ""
        
        if len(directions) == 1:
            return directions[0]
        
        content_lower = content.lower()
        play_lower = play_category.lower() if play_category else ""
        
        # ğŸ†• ä¼˜å…ˆçº§è§„åˆ™
        priority_scores = {}
        
        for direction in directions:
            score = 0
            
            # 1. å®Œå…¨åŒ¹é…åŠ åˆ†
            if direction == content_lower:
                score += 100
            
            # 2. ç©æ³•ç›¸å…³åŠ åˆ†
            if any(word in play_lower for word in ['ä¸¤é¢', 'å’Œå€¼', 'å¤§å°å•åŒ']):
                score += 50
            
            # 3. å†…å®¹å…³é”®è¯åŠ åˆ†
            if 'æ€»' in content_lower and 'æ€»å’Œ' in direction:
                score += 30
            elif 'ç‰¹' in content_lower and 'ç‰¹' in direction:
                score += 30
            
            # 4. åŸºç¡€æ–¹å‘ä¼˜å…ˆçº§
            if direction in ['å¤§', 'å°', 'å•', 'åŒ']:
                score += 20
            
            priority_scores[direction] = score
        
        # è¿”å›æœ€é«˜åˆ†çš„æ–¹å‘
        return max(priority_scores.items(), key=lambda x: x[1])[0]

    @staticmethod
    def extract_position_from_play_category(play_category, lottery_type, config):
        """ä»ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½®ä¿¡æ¯ - å¢å¼ºå…­åˆå½©æ”¯æŒ"""
        play_str = str(play_category).strip()
        
        if not play_str:
            return 'æœªçŸ¥ä½ç½®'
        
        # æ ¹æ®å½©ç§ç±»å‹è·å–ä½ç½®å…³é”®è¯
        position_keywords = config.position_keywords.get(lottery_type, {})
        
        for position, keywords in position_keywords.items():
            for keyword in keywords:
                if keyword in play_str:
                    return position
        
        # ğŸ†• ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœç©æ³•åˆ†ç±»åŒ…å«"æ­£ç ç‰¹"ä½†æ²¡æœ‰å…·ä½“ä½ç½®ï¼Œé»˜è®¤ä¸º"ç‰¹ç "
        if lottery_type == 'LHC':
            if 'æ­£ç ç‰¹' in play_str or 'æ­£ç‰¹' in play_str:
                return 'ç‰¹ç '
            elif 'æ­£ç ' in play_str and 'ç‰¹' not in play_str:
                return 'æ­£ç '
        
        return 'æœªçŸ¥ä½ç½®'

    @staticmethod
    def parse_pk10_vertical_format(content):
        """è§£æPK10ç«–çº¿åˆ†éš”æ ¼å¼"""
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                        'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
            
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    # æ³¨æ„ï¼šè¿™é‡Œè§£ææ•°å­—ï¼Œä½†æˆ‘ä»¬åªå…³å¿ƒæ–¹å‘ï¼Œæ‰€ä»¥è¿™ä¸ªå‡½æ•°ä¸»è¦ç”¨äºä½ç½®æå–
                    numbers = []
                    if ',' in part_clean:
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£æPK10ç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)

    @staticmethod
    def parse_3d_vertical_format(content):
        """è§£æ3Dç«–çº¿åˆ†éš”æ ¼å¼"""
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            positions = ['ç™¾ä½', 'åä½', 'ä¸ªä½']
            
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    # æ³¨æ„ï¼šè¿™é‡Œè§£ææ•°å­—ï¼Œä½†æˆ‘ä»¬åªå…³å¿ƒæ–¹å‘
                    numbers = []
                    if ',' in part_clean:
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£æ3Dç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)

# ==================== å¯¹åˆ·æ£€æµ‹å™¨ ====================
class WashTradeDetector:
    def __init__(self, config=None):
        self.config = config or Config()
        self.data_processor = DataProcessor()
        self.lottery_identifier = LotteryIdentifier()
        self.play_normalizer = PlayCategoryNormalizer()
        self.content_parser = ContentParser()
        
        self.data_processed = False
        self.df_valid = None
        self.export_data = []
        
        # æŒ‰å½©ç§å­˜å‚¨è´¦æˆ·ç»Ÿè®¡
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        self.performance_stats = {}

    def filter_accounts_by_amount_balance(self, account_group, directions, amounts):
        """æ ¹æ®ç»„å†…é‡‘é¢å¹³è¡¡æ€§è¿‡æ»¤è´¦æˆ· - ç¡®ä¿ç»„å†…é‡‘é¢å·®è·ä¸è¶…è¿‡10å€"""
        if not self.config.amount_threshold['enable_threshold_filter']:
            return account_group, directions, amounts
        
        if not amounts or len(amounts) < 2:
            return account_group, directions, amounts
        
        # ğŸ†• æ£€æŸ¥ç»„å†…é‡‘é¢å¹³è¡¡æ€§
        max_amount = max(amounts)
        min_amount = min(amounts)
        
        # è®¡ç®—æœ€å¤§é‡‘é¢å·®è·æ¯”ä¾‹
        amount_ratio = max_amount / min_amount if min_amount > 0 else float('inf')
        
        # ğŸ†• å¦‚æœé‡‘é¢å·®è·è¶…è¿‡è®¾å®šå€æ•°ï¼Œè¿‡æ»¤æ‰é‡‘é¢å¤ªå°çš„è´¦æˆ·
        max_allowed_ratio = self.config.amount_threshold['max_amount_ratio']
        if amount_ratio > max_allowed_ratio:
            # æ‰¾å‡ºé‡‘é¢å¤ªå°çš„è´¦æˆ·ï¼ˆå°äºæœ€å¤§é‡‘é¢çš„1/max_allowed_ratioï¼‰
            min_required = max_amount / max_allowed_ratio
            valid_indices = [i for i, amount in enumerate(amounts) if amount >= min_required]
            
            if len(valid_indices) >= 2:
                filtered_accounts = [account_group[i] for i in valid_indices]
                filtered_directions = [directions[i] for i in valid_indices]
                filtered_amounts = [amounts[i] for i in valid_indices]
                
                logger.info(f"é‡‘é¢å¹³è¡¡è¿‡æ»¤: {len(account_group)} -> {len(filtered_accounts)} ä¸ªè´¦æˆ· (åŸæ¯”ä¾‹: {amount_ratio:.1f}å€)")
                return filtered_accounts, filtered_directions, filtered_amounts
            else:
                # è¿‡æ»¤åä¸è¶³2ä¸ªæœ‰æ•ˆè´¦æˆ·ï¼Œè¿”å›ç©º
                return [], [], []
        
        # é‡‘é¢å¹³è¡¡ï¼Œä¸éœ€è¦è¿‡æ»¤
        return account_group, directions, amounts

    def upload_and_process(self, uploaded_file):
        """ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶"""
        try:
            if uploaded_file is None:
                st.error("âŒ æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
                return None, None
            
            filename = uploaded_file.name
            logger.info(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {filename}")
            
            if not any(filename.endswith(ext) for ext in self.config.supported_file_types):
                st.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
                return None, None
            
            with st.spinner("ğŸ”„ æ­£åœ¨æ¸…æ´—æ•°æ®..."):
                df_clean = self.data_processor.clean_data(uploaded_file)
            
            if df_clean is not None and len(df_clean) > 0:
                df_enhanced = self.enhance_data_processing(df_clean)
                return df_enhanced, filename
            else:
                return None, None
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            return None, None
    
    def enhance_data_processing(self, df_clean):
        """å¢å¼ºçš„æ•°æ®å¤„ç†æµç¨‹"""
        try:
            # å½©ç§è¯†åˆ«
            if 'å½©ç§' in df_clean.columns:
                df_clean['åŸå§‹å½©ç§'] = df_clean['å½©ç§']
                df_clean['å½©ç§ç±»å‹'] = df_clean['å½©ç§'].apply(self.lottery_identifier.identify_lottery_type)
            
            # ç©æ³•åˆ†ç±»ç»Ÿä¸€
            if 'ç©æ³•' in df_clean.columns:
                df_clean['ç©æ³•åˆ†ç±»'] = df_clean['ç©æ³•'].apply(self.play_normalizer.normalize_category)
            
            # è®¡ç®—è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
            self.calculate_account_total_periods_by_lottery(df_clean)
            
            # æå–æŠ•æ³¨é‡‘é¢å’Œæ–¹å‘ - ä¸ä½¿ç”¨ç¼“å­˜ç‰ˆæœ¬
            st.info("ğŸ’° æ­£åœ¨æå–æŠ•æ³¨é‡‘é¢å’Œæ–¹å‘...")
            progress_bar = st.progress(0)
            total_rows = len(df_clean)
            
            # åˆ†æ‰¹å¤„ç†æ˜¾ç¤ºè¿›åº¦
            batch_size = 1000
            for i in range(0, total_rows, batch_size):
                end_idx = min(i + batch_size, total_rows)
                batch_df = df_clean.iloc[i:end_idx]
                
                # ğŸ†• ç›´æ¥è°ƒç”¨æ–¹æ³•ï¼Œä¸ä½¿ç”¨ç¼“å­˜
                # å¤„ç†é‡‘é¢
                df_clean.loc[i:end_idx-1, 'æŠ•æ³¨é‡‘é¢'] = batch_df['é‡‘é¢'].apply(
                    lambda x: self.extract_bet_amount_safe(str(x))
                )
                
                # å¤„ç†æ–¹å‘
                df_clean.loc[i:end_idx-1, 'æŠ•æ³¨æ–¹å‘'] = batch_df.apply(
                    lambda row: self.enhanced_extract_direction_with_position(
                        row['å†…å®¹'], 
                        row.get('ç©æ³•åˆ†ç±»', ''), 
                        row.get('å½©ç§ç±»å‹', 'æœªçŸ¥')
                    ), 
                    axis=1
                )
                
                # æ›´æ–°è¿›åº¦
                progress = (end_idx) / total_rows
                progress_bar.progress(progress)
            
            progress_bar.empty()
            
            # è¿‡æ»¤æœ‰æ•ˆè®°å½•
            df_valid = df_clean[
                (df_clean['æŠ•æ³¨æ–¹å‘'] != '') & 
                (df_clean['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
            ].copy()
            
            if len(df_valid) == 0:
                st.error("âŒ è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆè®°å½•")
                return pd.DataFrame()
            
            self.data_processed = True
            self.df_valid = df_valid

            return df_valid
            
        except Exception as e:
            logger.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            st.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def extract_bet_amount_safe(self, amount_text):
        """å®‰å…¨æå–æŠ•æ³¨é‡‘é¢ - å¢å¼ºç‰ˆæœ¬"""
        try:
            if pd.isna(amount_text):
                return 0
            
            text = str(amount_text).strip()
            
            # ğŸ†• æ–°å¢ï¼šä¸“é—¨å¤„ç† "æŠ•æ³¨ï¼š8.000 æŠµç”¨ï¼š0 ä¸­å¥–ï¼š0.000" æ ¼å¼
            if 'æŠ•æ³¨ï¼š' in text and 'æŠµç”¨ï¼š' in text:
                try:
                    # æå– "æŠ•æ³¨ï¼š" åé¢çš„æ•°å­—éƒ¨åˆ†
                    bet_part = text.split('æŠ•æ³¨ï¼š')[1].split('æŠµç”¨ï¼š')[0].strip()
                    # ç§»é™¤å¯èƒ½çš„åƒåˆ†ä½é€—å·ï¼Œç›´æ¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                    amount = float(bet_part.replace(',', ''))
                    if amount >= self.config.min_amount:
                        return amount
                except (ValueError, IndexError) as e:
                    logger.debug(f"ç‰¹æ®Šæ ¼å¼é‡‘é¢æå–å¤±è´¥: {text}, é”™è¯¯: {e}")
            
            # ğŸ†• æ–°å¢ï¼šå¤„ç†ç®€åŒ–çš„ "æŠ•æ³¨ï¼š8.000" æ ¼å¼
            if text.startswith('æŠ•æ³¨ï¼š'):
                try:
                    bet_part = text.replace('æŠ•æ³¨ï¼š', '').strip()
                    # æå–ç¬¬ä¸€ä¸ªæ•°å­—éƒ¨åˆ†ï¼ˆå¯èƒ½åé¢æœ‰å…¶ä»–æ–‡å­—ï¼‰
                    bet_part_clean = re.split(r'[^\d.]', bet_part)[0]
                    amount = float(bet_part_clean)
                    if amount >= self.config.min_amount:
                        return amount
                except (ValueError, IndexError) as e:
                    logger.debug(f"ç®€åŒ–æ ¼å¼é‡‘é¢æå–å¤±è´¥: {text}, é”™è¯¯: {e}")
            
            # ğŸ†• æ–°å¢ï¼šå¤„ç†åŒ…å« "æŠ•æ³¨:" çš„æ ¼å¼ï¼ˆä¸­æ–‡å†’å·ï¼‰
            if 'æŠ•æ³¨:' in text:
                try:
                    bet_part = text.split('æŠ•æ³¨:')[1].split()[0].strip()
                    amount = float(bet_part.replace(',', ''))
                    if amount >= self.config.min_amount:
                        return amount
                except (ValueError, IndexError) as e:
                    logger.debug(f"ä¸­æ–‡å†’å·æ ¼å¼é‡‘é¢æå–å¤±è´¥: {text}, é”™è¯¯: {e}")
            
            # åŸæœ‰çš„å¤„ç†é€»è¾‘ä¿æŒä¸å˜
            # å¤„ç†ç§‘å­¦è®¡æ•°æ³•
            if 'E' in text or 'e' in text:
                try:
                    amount = float(text)
                    if amount >= self.config.min_amount:
                        return amount
                except:
                    pass
            
            # ç›´æ¥è½¬æ¢
            try:
                cleaned_text = re.sub(r'[^\d.-]', '', text)
                if cleaned_text and cleaned_text != '-':
                    amount = float(cleaned_text)
                    if amount >= self.config.min_amount:
                        return amount
            except:
                pass
            
            # åŸæœ‰çš„æ¨¡å¼åŒ¹é…é€»è¾‘...
            patterns = [
                r'æŠ•æ³¨[:ï¼š]?\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'ä¸‹æ³¨[:ï¼š]?\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'é‡‘é¢[:ï¼š]?\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'æ€»é¢[:ï¼š]?\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'([-]?\d+[,ï¼Œ]?\d*\.?\d*)\s*å…ƒ',
                r'ï¿¥\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'Â¥\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'[\$ï¿¥Â¥]?\s*([-]?\d+[,ï¼Œ]?\d*\.?\d+)',
                r'([-]?\d+[,ï¼Œ]?\d*\.?\d+)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text)
                if match:
                    amount_str = match.group(1).replace(',', '').replace('ï¼Œ', '').replace(' ', '')
                    try:
                        amount = float(amount_str)
                        if amount >= self.config.min_amount:
                            return amount
                    except:
                        continue
            
            return 0
            
        except Exception as e:
            logger.warning(f"é‡‘é¢æå–å¤±è´¥: {amount_text}, é”™è¯¯: {e}")
            return 0
    
    def enhanced_extract_direction_with_position(self, content, play_category, lottery_type):
        """ğŸ¯ æ–¹å‘æå– - ä½¿ç”¨å¢å¼ºçš„æ–¹å‘è¯†åˆ« - ä¿®å¤ï¼šä¼˜åŒ–æ–¹å‘æå–é€»è¾‘"""
        try:
            if pd.isna(content):
                return ""
            
            content_str = str(content).strip()
            
            # ğŸ¯ ä½¿ç”¨å¢å¼ºçš„å†…å®¹è§£æå™¨æå–æ–¹å‘
            directions = self.content_parser.enhanced_extract_directions(content_str, self.config)
            
            if not directions:
                return ""
            
            # ğŸ¯ ä»ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½®ä¿¡æ¯
            position = self.content_parser.extract_position_from_play_category(play_category, lottery_type, self.config)
            
            # ğŸ¯ æ–¹å‘ä¼˜å…ˆçº§æ’åºå’Œé€‰æ‹© - ä¿®å¤ï¼šä¼˜åŒ–ä¼˜å…ˆçº§é€»è¾‘
            main_direction = self.content_parser.prioritize_directions(directions, content_str, play_category)
            
            if not main_direction:
                return ""
            
            # ğŸ¯ ç»„åˆä½ç½®å’Œæ–¹å‘ - ä¿®å¤ï¼šä¼˜åŒ–ä½ç½®ç»„åˆé€»è¾‘
            if position and position != 'æœªçŸ¥ä½ç½®':
                # ä¿®å¤ï¼šå¯¹äºå…­åˆå½©ï¼Œç¡®ä¿ä½ç½®ä¿¡æ¯æ­£ç¡®
                if lottery_type == 'LHC':
                    # å…­åˆå½©çš„ç‰¹æ®Šä½ç½®å¤„ç†
                    if main_direction in ['å¤©è‚–', 'åœ°è‚–', 'å®¶è‚–', 'é‡è‚–', 'å°¾å¤§', 'å°¾å°']:
                        # è¿™äº›æ–¹å‘é€šå¸¸ä¸ç‰¹ç ç›¸å…³
                        return f"ç‰¹ç -{main_direction}"
                    elif main_direction in ['ç‰¹å¤§', 'ç‰¹å°', 'ç‰¹å•', 'ç‰¹åŒ']:
                        return f"ç‰¹ç -{main_direction}"
                    else:
                        return f"{position}-{main_direction}"
                else:
                    return f"{position}-{main_direction}"
            else:
                return main_direction
            
        except Exception as e:
            logger.warning(f"æ–¹å‘æå–å¤±è´¥: {content}, é”™è¯¯: {e}")
            return ""
    
    def _select_primary_direction(self, directions, content):
        """é€‰æ‹©ä¸»è¦æ–¹å‘"""
        if not directions:
            return ""
        
        if len(directions) == 1:
            return directions[0]
        
        content_str = str(content)
        
        # ğŸ¯ ä¼˜å…ˆçº§è§„åˆ™
        priority_rules = [
            # æœ€é«˜ä¼˜å…ˆçº§ï¼šæ€»å’Œç›¸å…³
            lambda d: any(keyword in content_str for keyword in ['æ€»å’Œ', 'æ€»']) and d in directions,
            # é«˜ä¼˜å…ˆçº§ï¼šç‰¹å­—ç›¸å…³
            lambda d: 'ç‰¹' in content_str and d in directions,
            # ä¸­ä¼˜å…ˆçº§ï¼šå’Œå€¼ç›¸å…³
            lambda d: any(keyword in content_str for keyword in ['å’Œå€¼', 'å’Œ']) and d in directions,
            # åŸºç¡€ä¼˜å…ˆçº§ï¼šä¸¤é¢ç›¸å…³
            lambda d: 'ä¸¤é¢' in content_str and d in directions,
            # é»˜è®¤ä¼˜å…ˆçº§
            lambda d: d in directions
        ]
        
        for rule in priority_rules:
            matching_directions = [d for d in directions if rule(d)]
            if matching_directions:
                return matching_directions[0]
        
        return directions[0]
    
    def _extract_position_from_content(self, content, lottery_type):
        """ä»å†…å®¹ä¸­æå–ä½ç½®ä¿¡æ¯"""
        content_str = str(content).strip()
        
        # æ ¹æ®å½©ç§ç±»å‹è·å–ä½ç½®å…³é”®è¯
        position_keywords = self.config.position_keywords.get(lottery_type, {})
        
        for position, keywords in position_keywords.items():
            for keyword in keywords:
                if keyword in content_str:
                    return position
        
        # ç‰¹æ®Šå¤„ç†ç«–çº¿æ ¼å¼
        if '|' in content_str:
            if lottery_type == 'PK10':
                bets_by_position = self.content_parser.parse_pk10_vertical_format(content_str)
                for position in bets_by_position:
                    if bets_by_position[position]:
                        return position
            elif lottery_type == '3D':
                bets_by_position = self.content_parser.parse_3d_vertical_format(content_str)
                for position in bets_by_position:
                    if bets_by_position[position]:
                        return position
        
        return 'æœªçŸ¥ä½ç½®'
    
    def calculate_account_total_periods_by_lottery(self, df):
        """æŒ‰å½©ç§è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°ç»Ÿè®¡"""
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        
        lottery_col = 'åŸå§‹å½©ç§' if 'åŸå§‹å½©ç§' in df.columns else 'å½©ç§'
        
        for lottery in df[lottery_col].unique():
            df_lottery = df[df[lottery_col] == lottery]
            
            period_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·')['æœŸå·'].nunique().to_dict()
            self.account_total_periods_by_lottery[lottery] = period_counts
            
            record_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·').size().to_dict()
            self.account_record_stats_by_lottery[lottery] = record_counts
    
    def detect_all_wash_trades(self):
        """æ£€æµ‹æ‰€æœ‰ç±»å‹çš„å¯¹åˆ·äº¤æ˜“"""
        if not self.data_processed or self.df_valid is None or len(self.df_valid) == 0:
            st.error("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ç”¨äºæ£€æµ‹")
            return []
        
        self.performance_stats = {
            'start_time': datetime.now(),
            'total_records': len(self.df_valid),
            'total_periods': self.df_valid['æœŸå·'].nunique(),
            'total_accounts': self.df_valid['ä¼šå‘˜è´¦å·'].nunique()
        }
        
        df_filtered = self.exclude_multi_direction_accounts(self.df_valid)
        
        if len(df_filtered) == 0:
            st.error("âŒ è¿‡æ»¤åæ— æœ‰æ•ˆæ•°æ®")
            return []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_patterns = []
        total_steps = self.config.max_accounts_in_group - 1
        
        for account_count in range(2, self.config.max_accounts_in_group + 1):
            status_text.text(f"ğŸ” æ£€æµ‹{account_count}ä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼...")
            patterns = self.detect_n_account_patterns_optimized(df_filtered, account_count)
            all_patterns.extend(patterns)
            
            progress = (account_count - 1) / total_steps
            progress_bar.progress(progress)
        
        progress_bar.progress(1.0)
        status_text.text("âœ… æ£€æµ‹å®Œæˆ")
        
        self.performance_stats['end_time'] = datetime.now()
        self.performance_stats['detection_time'] = (
            self.performance_stats['end_time'] - self.performance_stats['start_time']
        ).total_seconds()
        self.performance_stats['total_patterns'] = len(all_patterns)
        
        self.display_performance_stats()
        
        return all_patterns
    
    def detect_n_account_patterns_optimized(self, df_filtered, n_accounts):
        """Nä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼æ£€æµ‹"""
        wash_records = []
        
        period_groups = df_filtered.groupby(['æœŸå·', 'åŸå§‹å½©ç§'])
        
        valid_direction_combinations = self._get_valid_direction_combinations(n_accounts)
        
        batch_size = 100
        period_keys = list(period_groups.groups.keys())
        
        for i in range(0, len(period_keys), batch_size):
            batch_keys = period_keys[i:i+batch_size]
            
            for period_key in batch_keys:
                period_data = period_groups.get_group(period_key)
                period_accounts = period_data['ä¼šå‘˜è´¦å·'].unique()
                
                if len(period_accounts) < n_accounts:
                    continue
                
                batch_patterns = self._detect_combinations_for_period(
                    period_data, period_accounts, n_accounts, valid_direction_combinations
                )
                wash_records.extend(batch_patterns)
        
        return self.find_continuous_patterns_optimized(wash_records)
    
    def _get_valid_direction_combinations(self, n_accounts):
        """ğŸ¯ æœ‰æ•ˆæ–¹å‘ç»„åˆç”Ÿæˆ - ä½¿ç”¨å¢å¼ºçš„å¯¹ç«‹ç»„ - ä¿®å¤ï¼šä¼˜åŒ–ç»„åˆç”Ÿæˆé€»è¾‘"""
        valid_combinations = []
        
        # ğŸ¯ åŸºç¡€å¯¹ç«‹ç»„å¤„ç† - ä½¿ç”¨å¢å¼ºçš„å¯¹ç«‹ç»„
        for opposites in self.config.opposite_groups:
            opposite_list = list(opposites)
            
            if n_accounts == 2:
                # 2ä¸ªè´¦æˆ·ï¼šæ ‡å‡†çš„1v1å¯¹ç«‹
                if len(opposite_list) == 2:
                    dir1, dir2 = opposite_list
                    valid_combinations.append({
                        'directions': [dir1, dir2],
                        'dir1_count': 1,
                        'dir2_count': 1,
                        'opposite_type': f"{dir1}-{dir2}",
                        'combination_type': 'basic'
                    })
            else:
                # 3ä¸ªåŠä»¥ä¸Šè´¦æˆ·ï¼šå¤šç§åˆ†å¸ƒ
                for i in range(1, n_accounts):
                    j = n_accounts - i
                    if len(opposite_list) == 2:
                        dir1, dir2 = opposite_list
                        valid_combinations.append({
                            'directions': [dir1] * i + [dir2] * j,
                            'dir1_count': i,
                            'dir2_count': j,
                            'opposite_type': f"{dir1}-{dir2}",
                            'combination_type': 'basic'
                        })
        
        # ğŸ¯ å¸¦ä½ç½®çš„å¯¹ç«‹ç»„ - åŠ¨æ€ç”Ÿæˆï¼ˆæ”¯æŒå˜å¼‚å½¢å¼ï¼‰
        positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                    'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå',
                    'ç™¾ä½', 'åä½', 'ä¸ªä½', 'ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ',
                    'ç‰¹ç ', 'æ­£ç ', 'å¹³ç‰¹', 'è¿è‚–', 'è¿å°¾', 'è‰²æ³¢', 'äº”è¡Œ']  # ğŸ†• æ–°å¢å…­åˆå½©ä½ç½®
        
        for position in positions:
            for opposites in self.config.opposite_groups:
                if len(opposites) == 2:
                    dir1, dir2 = list(opposites)
                    if n_accounts == 2:
                        valid_combinations.append({
                            'directions': [f"{position}-{dir1}", f"{position}-{dir2}"],
                            'dir1_count': 1,
                            'dir2_count': 1,
                            'opposite_type': f"{position}-{dir1} vs {position}-{dir2}",
                            'combination_type': 'positional'
                        })
                    else:
                        for i in range(1, n_accounts):
                            j = n_accounts - i
                            valid_combinations.append({
                                'directions': [f"{position}-{dir1}"] * i + [f"{position}-{dir2}"] * j,
                                'dir1_count': i,
                                'dir2_count': j,
                                'opposite_type': f"{position}-{dir1} vs {position}-{dir2}",
                                'combination_type': 'positional'
                            })
        
        # ä¿®å¤ï¼šæ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼Œå¸®åŠ©è¯Šæ–­é—®é¢˜
        logger.info(f"ä¸º{n_accounts}ä¸ªè´¦æˆ·ç”Ÿæˆ{len(valid_combinations)}ä¸ªæœ‰æ•ˆæ–¹å‘ç»„åˆ")
        
        return valid_combinations
    
    def _detect_combinations_for_period(self, period_data, period_accounts, n_accounts, valid_combinations):
        """ä¸ºå•ä¸ªæœŸå·æ£€æµ‹ç»„åˆ - ä¿®å¤é‡å¤ç»Ÿè®¡é—®é¢˜"""
        patterns = []
        detected_combinations = set()  # ç”¨äºå»é‡
        
        # è·å–å½“å‰å½©ç§
        lottery = period_data['åŸå§‹å½©ç§'].iloc[0] if 'åŸå§‹å½©ç§' in period_data.columns else period_data['å½©ç§'].iloc[0]
        
        # ğŸ¯ æ„å»ºè´¦æˆ·ä¿¡æ¯å­—å…¸
        account_info = {}
        for _, row in period_data.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            direction = row['æŠ•æ³¨æ–¹å‘']
            amount = row['æŠ•æ³¨é‡‘é¢']
            
            if account not in account_info:
                account_info[account] = []
            account_info[account].append({
                'direction': direction,
                'amount': amount
            })
        
        # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„è´¦æˆ·ç»„åˆ
        for account_group in combinations(period_accounts, n_accounts):
            # æ£€æŸ¥è´¦æˆ·æœŸæ•°å·®å¼‚
            if not self._check_account_period_difference(account_group, lottery):
                continue
            
            group_directions = []
            group_amounts = []
            
            for account in account_group:
                if account in account_info and account_info[account]:
                    first_bet = account_info[account][0]
                    group_directions.append(first_bet['direction'])
                    group_amounts.append(first_bet['amount'])
            
            if len(group_directions) != n_accounts:
                continue
            
            # åº”ç”¨é‡‘é¢å¹³è¡¡è¿‡æ»¤
            filtered_account_group, filtered_directions, filtered_amounts = self.filter_accounts_by_amount_balance(
                account_group, group_directions, group_amounts
            )
            
            # å¦‚æœè¿‡æ»¤åè´¦æˆ·ä¸è¶³2ä¸ªï¼Œè·³è¿‡è¯¥ç»„åˆ
            if len(filtered_account_group) < 2:
                continue
            
            # ä½¿ç”¨è¿‡æ»¤åçš„æ•°æ®
            account_group = filtered_account_group
            group_directions = filtered_directions
            group_amounts = filtered_amounts
            n_accounts = len(account_group)  # æ›´æ–°è´¦æˆ·æ•°é‡

            # ğŸ†• å¢å¼ºå»é‡é€»è¾‘ï¼šåŸºäºè´¦æˆ·ç»„+æ–¹å‘ç»„+é‡‘é¢ç»„çš„å”¯ä¸€é”®
            combination_key = (
                tuple(sorted(account_group)), 
                tuple(sorted(group_directions)),
                tuple(sorted(group_amounts))
            )
            
            if combination_key in detected_combinations:
                continue  # è·³è¿‡å·²æ£€æµ‹çš„ç»„åˆ
            
            # ğŸ¯ æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æœ‰æ•ˆçš„æ–¹å‘ç»„åˆ
            for combo in valid_combinations:
                target_directions = combo['directions']
                
                actual_directions_sorted = sorted(group_directions)
                target_directions_sorted = sorted(target_directions)
                
                if actual_directions_sorted == target_directions_sorted:
                    # ğŸ†• æ ‡è®°è¯¥ç»„åˆä¸ºå·²æ£€æµ‹
                    detected_combinations.add(combination_key)
                    
                    # è®¡ç®—ä¸¤ä¸ªæ–¹å‘çš„æ€»é‡‘é¢
                    dir1_total = 0
                    dir2_total = 0
                    dir1 = combo['directions'][0]  # å–ç¬¬ä¸€ä¸ªæ–¹å‘ä½œä¸ºå‚è€ƒ
                    
                    for direction, amount in zip(group_directions, group_amounts):
                        if direction == dir1:
                            dir1_total += amount
                        else:
                            dir2_total += amount
                    
                    # æ£€æŸ¥é‡‘é¢ç›¸ä¼¼åº¦
                    similarity_threshold = self.config.account_count_similarity_thresholds.get(
                        n_accounts, self.config.amount_similarity_threshold
                    )
                    
                    if dir1_total > 0 and dir2_total > 0:
                        similarity = min(dir1_total, dir2_total) / max(dir1_total, dir2_total)
                        
                        if similarity >= similarity_threshold:
                            lottery_type = period_data['å½©ç§ç±»å‹'].iloc[0] if 'å½©ç§ç±»å‹' in period_data.columns else 'æœªçŸ¥'
                            
                            # ğŸ¯ ä¿®å¤æ¨¡å¼å­—ç¬¦ä¸²ç”Ÿæˆ
                            if ' vs ' in combo['opposite_type']:
                                pattern_parts = combo['opposite_type'].split(' vs ')
                                if len(pattern_parts) == 2:
                                    dir1_part = pattern_parts[0].split('-')
                                    dir2_part = pattern_parts[1].split('-')
                                    if len(dir1_part) == 2 and len(dir2_part) == 2:
                                        pattern_str = f"{dir1_part[0]}-{dir1_part[1]}({combo['dir1_count']}ä¸ª) vs {dir2_part[0]}-{dir2_part[1]}({combo['dir2_count']}ä¸ª)"
                                    else:
                                        pattern_str = f"{pattern_parts[0]}({combo['dir1_count']}ä¸ª) vs {pattern_parts[1]}({combo['dir2_count']}ä¸ª)"
                                else:
                                    pattern_str = combo['opposite_type']
                            else:
                                opposite_parts = combo['opposite_type'].split('-')
                                if len(opposite_parts) == 2:
                                    pattern_str = f"{opposite_parts[0]}({combo['dir1_count']}ä¸ª) vs {opposite_parts[1]}({combo['dir2_count']}ä¸ª)"
                                else:
                                    pattern_str = combo['opposite_type']
                            
                            record = {
                                'æœŸå·': period_data['æœŸå·'].iloc[0],
                                'å½©ç§': lottery,
                                'å½©ç§ç±»å‹': lottery_type,
                                'è´¦æˆ·ç»„': list(account_group),
                                'æ–¹å‘ç»„': group_directions,
                                'é‡‘é¢ç»„': group_amounts,
                                'æ€»é‡‘é¢': dir1_total + dir2_total,
                                'ç›¸ä¼¼åº¦': similarity,
                                'è´¦æˆ·æ•°é‡': n_accounts,
                                'æ¨¡å¼': pattern_str,
                                'å¯¹ç«‹ç±»å‹': combo['opposite_type']
                            }
                            
                            patterns.append(record)
                            break  # ğŸ†• æ‰¾åˆ°ä¸€ä¸ªåŒ¹é…åè·³å‡ºå¾ªç¯ï¼Œé¿å…é‡å¤åŒ¹é…å…¶ä»–ç»„åˆ
        
        return patterns
    
    def _check_account_period_difference(self, account_group, lottery):
        """æ£€æŸ¥è´¦æˆ·ç»„å†…è´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°å·®å¼‚æ˜¯å¦åœ¨é˜ˆå€¼å†…"""
        if lottery not in self.account_total_periods_by_lottery:
            return True  # å¦‚æœæ²¡æœ‰è¯¥å½©ç§çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œé»˜è®¤å…è®¸ç»„åˆ
        
        total_periods_stats = self.account_total_periods_by_lottery[lottery]
        
        # è·å–è´¦æˆ·ç»„å†…æ¯ä¸ªè´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°
        account_periods = []
        for account in account_group:
            if account in total_periods_stats:
                account_periods.append(total_periods_stats[account])
            else:
                # å¦‚æœæŸä¸ªè´¦æˆ·æ²¡æœ‰ç»Ÿè®¡ä¿¡æ¯ï¼Œæ— æ³•æ¯”è¾ƒï¼Œé»˜è®¤å…è®¸ç»„åˆ
                return True
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªè´¦æˆ·æœ‰æœŸæ•°ä¿¡æ¯ï¼Œæ— æ³•æ¯”è¾ƒï¼Œé»˜è®¤å…è®¸ç»„åˆ
        if len(account_periods) < 2:
            return True
        
        # è®¡ç®—æœ€å¤§å’Œæœ€å°æœŸæ•°å·®å¼‚
        max_period = max(account_periods)
        min_period = min(account_periods)
        period_diff = max_period - min_period
        
        # å¦‚æœæœŸæ•°å·®å¼‚è¶…è¿‡é˜ˆå€¼ï¼Œä¸å…è®¸ç»„åˆ
        if period_diff > self.config.account_period_diff_threshold:
            logger.info(f"è·³è¿‡è´¦æˆ·ç»„ {account_group}ï¼ŒæœŸæ•°å·®å¼‚ {period_diff} > {self.config.account_period_diff_threshold}")
            return False
        
        return True
    
    def find_continuous_patterns_optimized(self, wash_records):
        """è¿ç»­å¯¹åˆ·æ¨¡å¼æ£€æµ‹"""
        if not wash_records:
            return []
        
        account_group_patterns = defaultdict(list)
        for record in wash_records:
            account_group_key = (tuple(sorted(record['è´¦æˆ·ç»„'])), record['å½©ç§'])
            account_group_patterns[account_group_key].append(record)
        
        continuous_patterns = []
        
        for (account_group, lottery), records in account_group_patterns.items():
            sorted_records = sorted(records, key=lambda x: x['æœŸå·'])
            
            # æ ¹æ®æ–°çš„é˜ˆå€¼è¦æ±‚ç¡®å®šæœ€å°å¯¹åˆ·æœŸæ•°
            required_min_periods = self.get_required_min_periods(account_group, lottery)
            
            if len(sorted_records) >= required_min_periods:
                total_investment = sum(r['æ€»é‡‘é¢'] for r in sorted_records)
                similarities = [r['ç›¸ä¼¼åº¦'] for r in sorted_records]
                avg_similarity = np.mean(similarities) if similarities else 0
                
                opposite_type_counts = defaultdict(int)
                for record in sorted_records:
                    opposite_type_counts[record['å¯¹ç«‹ç±»å‹']] += 1
                
                pattern_count = defaultdict(int)
                for record in sorted_records:
                    pattern_count[record['æ¨¡å¼']] += 1
                
                # ğŸ¯ ä¼˜åŒ–ä¸»è¦å¯¹ç«‹ç±»å‹æ˜¾ç¤º
                main_opposite_type = max(opposite_type_counts.items(), key=lambda x: x[1])[0]
                # å¦‚æœä¸»è¦å¯¹ç«‹ç±»å‹åŒ…å« " vs "ï¼Œåˆ™è¿›è¡Œæ ¼å¼åŒ–
                if ' vs ' in main_opposite_type:
                    parts = main_opposite_type.split(' vs ')
                    if len(parts) == 2:
                        # æå–ä½ç½®å’Œæ–¹å‘ï¼Œæ ¼å¼åŒ–ä¸º "ä½ç½®-æ–¹å‘1-æ–¹å‘2"
                        pos_dir1 = parts[0].split('-')
                        pos_dir2 = parts[1].split('-')
                        if len(pos_dir1) >= 2 and len(pos_dir2) >= 2:
                            # å‡è®¾ä½ç½®ç›¸åŒï¼Œåªæ˜¾ç¤ºä¸€æ¬¡ä½ç½®
                            position = pos_dir1[0]  # å–ç¬¬ä¸€ä¸ªä½ç½®
                            dir1 = pos_dir1[-1]     # å–æœ€åä¸€ä¸ªéƒ¨åˆ†ä½œä¸ºæ–¹å‘
                            dir2 = pos_dir2[-1]     # å–æœ€åä¸€ä¸ªéƒ¨åˆ†ä½œä¸ºæ–¹å‘
                            main_opposite_type = f"{position}-{dir1}-{dir2}"
                        else:
                            main_opposite_type = f"{parts[0]}-{parts[1].split('-')[-1]}" if '-' in parts[1] else f"{parts[0]}-{parts[1]}"
                
                # è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
                account_stats_info = []
                total_periods_stats = self.account_total_periods_by_lottery.get(lottery, {})
                record_stats = self.account_record_stats_by_lottery.get(lottery, {})
                
                for account in account_group:
                    total_periods = total_periods_stats.get(account, 0)
                    records_count = record_stats.get(account, 0)
                    account_stats_info.append(f"{account}({total_periods}æœŸ/{records_count}è®°å½•)")
                
                activity_level = self.get_account_group_activity_level(account_group, lottery)
                
                continuous_patterns.append({
                    'è´¦æˆ·ç»„': list(account_group),
                    'å½©ç§': lottery,
                    'å½©ç§ç±»å‹': records[0]['å½©ç§ç±»å‹'] if records else 'æœªçŸ¥',
                    'è´¦æˆ·æ•°é‡': len(account_group),
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': main_opposite_type,
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': dict(opposite_type_counts),
                    'å¯¹åˆ·æœŸæ•°': len(sorted_records),
                    'æ€»æŠ•æ³¨é‡‘é¢': total_investment,
                    'å¹³å‡ç›¸ä¼¼åº¦': avg_similarity,
                    'æ¨¡å¼åˆ†å¸ƒ': dict(pattern_count),
                    'è¯¦ç»†è®°å½•': sorted_records,
                    'è´¦æˆ·æ´»è·ƒåº¦': activity_level,
                    'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': account_stats_info,
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': required_min_periods
                })
        
        return continuous_patterns

    def _calculate_detailed_account_stats(self, patterns):
        """è®¡ç®—è¯¦ç»†è´¦æˆ·ç»Ÿè®¡"""
        account_participation = defaultdict(lambda: {
            'periods': set(),
            'lotteries': set(),
            'positions': set(),
            'total_combinations': 0,
            'total_bet_amount': 0,
            'continuous_periods': 0,
            'actual_bet_records': []
        })
        
        # ä»åŸå§‹æ•°æ®ä¸­æ”¶é›†è´¦æˆ·çš„å®é™…æŠ•æ³¨é‡‘é¢
        if self.df_valid is not None:
            for _, row in self.df_valid.iterrows():
                account = row['ä¼šå‘˜è´¦å·']
                amount = row['æŠ•æ³¨é‡‘é¢']
                period = row['æœŸå·']
                lottery = row['å½©ç§'] if 'å½©ç§' in row else 'æœªçŸ¥'
                
                if account in account_participation:
                    account_participation[account]['actual_bet_records'].append({
                        'amount': amount,
                        'period': period,
                        'lottery': lottery
                    })
        
        # æ”¶é›†è´¦æˆ·å‚ä¸ä¿¡æ¯
        for pattern in patterns:
            for account in pattern['è´¦æˆ·ç»„']:
                account_info = account_participation[account]
                
                # æ·»åŠ æœŸå·
                for record in pattern['è¯¦ç»†è®°å½•']:
                    account_info['periods'].add(record['æœŸå·'])
                
                # æ·»åŠ å½©ç§
                account_info['lotteries'].add(pattern['å½©ç§'])
                
                # æ·»åŠ ä½ç½®ä¿¡æ¯
                for record in pattern['è¯¦ç»†è®°å½•']:
                    for direction in record['æ–¹å‘ç»„']:
                        if '-' in direction:
                            position = direction.split('-')[0]
                            account_info['positions'].add(position)
                
                account_info['total_combinations'] += 1
                account_info['continuous_periods'] = max(account_info['continuous_periods'], pattern['å¯¹åˆ·æœŸæ•°'])
                
                # è®¡ç®—è¯¥è´¦æˆ·åœ¨å¯¹åˆ·æ¨¡å¼ä¸­çš„å®é™…æŠ•æ³¨é‡‘é¢
                pattern_bet_amount = 0
                for record in pattern['è¯¦ç»†è®°å½•']:
                    for acc, amt in zip(record['è´¦æˆ·ç»„'], record['é‡‘é¢ç»„']):
                        if acc == account:
                            pattern_bet_amount += amt
                
                account_info['total_bet_amount'] += pattern_bet_amount
        
        # è½¬æ¢ä¸ºæ˜¾ç¤ºæ ¼å¼
        account_stats = []
        for account, info in account_participation.items():
            stat_record = {
                'è´¦æˆ·': account,
                'å‚ä¸ç»„åˆæ•°': info['total_combinations'],
                'æ¶‰åŠæœŸæ•°': len(info['periods']),
                'æ¶‰åŠå½©ç§': len(info['lotteries']),
                'æ€»æŠ•æ³¨é‡‘é¢': f"Â¥{info['total_bet_amount']:,.2f}",
                'å¹³å‡æ¯ç»„é‡‘é¢': f"Â¥{info['total_bet_amount'] / info['total_combinations']:,.2f}" if info['total_combinations'] > 0 else "Â¥0.00"
            }
            
            account_stats.append(stat_record)
        
        return sorted(account_stats, key=lambda x: x['å‚ä¸ç»„åˆæ•°'], reverse=True)

    def exclude_multi_direction_accounts(self, df_valid):
        """æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨"""
        multi_direction_mask = (
            df_valid.groupby(['æœŸå·', 'ä¼šå‘˜è´¦å·'])['æŠ•æ³¨æ–¹å‘']
            .transform('nunique') > 1
        )
        
        df_filtered = df_valid[~multi_direction_mask].copy()
        
        return df_filtered
    
    def get_account_group_activity_level(self, account_group, lottery):
        """è·å–æ´»è·ƒåº¦æ°´å¹³"""
        if lottery not in self.account_total_periods_by_lottery:
            return 'unknown'
        
        total_periods_stats = self.account_total_periods_by_lottery[lottery]
        
        # è®¡ç®—è´¦æˆ·ç»„ä¸­åœ¨æŒ‡å®šå½©ç§çš„æœ€å°æ€»æŠ•æ³¨æœŸæ•°
        min_total_periods = min(total_periods_stats.get(account, 0) for account in account_group)
        
        # æŒ‰ç…§æ–°çš„æ´»è·ƒåº¦é˜ˆå€¼
        if min_total_periods <= self.config.period_thresholds['low_activity']:
            return 'low'        # æ€»æŠ•æ³¨æœŸæ•°1-10
        elif min_total_periods <= self.config.period_thresholds['medium_activity_high']:
            return 'medium'     # æ€»æŠ•æ³¨æœŸæ•°11-50
        elif min_total_periods <= self.config.period_thresholds['high_activity_low']:
            return 'high'       # æ€»æŠ•æ³¨æœŸæ•°51-100
        else:
            return 'very_high'  # æ€»æŠ•æ³¨æœŸæ•°100ä»¥ä¸Š
    
    def get_required_min_periods(self, account_group, lottery):
        """æ ¹æ®æ–°çš„æ´»è·ƒåº¦é˜ˆå€¼è·å–æ‰€éœ€çš„æœ€å°å¯¹åˆ·æœŸæ•°"""
        activity_level = self.get_account_group_activity_level(account_group, lottery)
        
        if activity_level == 'low':
            return self.config.period_thresholds['min_periods_low']      # 3æœŸ
        elif activity_level == 'medium':
            return self.config.period_thresholds['min_periods_medium']   # 5æœŸ
        elif activity_level == 'high':
            return self.config.period_thresholds['min_periods_high']     # 8æœŸ
        else:
            return self.config.period_thresholds['min_periods_very_high'] # 11æœŸ
    
    def display_performance_stats(self):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
        if not self.performance_stats:
            return
        
        with st.expander("ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡", expanded=False):
            st.write(f"**æ•°æ®å¤„ç†ç»Ÿè®¡:**")
            st.write(f"- æ€»è®°å½•æ•°: {self.performance_stats['total_records']:,}")
            st.write(f"- æ€»æœŸå·æ•°: {self.performance_stats['total_periods']:,}")
            st.write(f"- æ€»è´¦æˆ·æ•°: {self.performance_stats['total_accounts']:,}")
            
            if 'detection_time' in self.performance_stats:
                st.write(f"**æ£€æµ‹æ€§èƒ½:**")
                st.write(f"- æ£€æµ‹æ—¶é—´: {self.performance_stats['detection_time']:.2f} ç§’")
                st.write(f"- å‘ç°æ¨¡å¼: {self.performance_stats['total_patterns']} ä¸ª")

    def enhanced_analyze_opposite_patterns(self, patterns):
        """ğŸ†• å¢å¼ºå¯¹ç«‹æ¨¡å¼åˆ†æ"""
        if not patterns:
            return {}
        
        analysis = {
            'total_groups': len(patterns),
            'opposite_type_stats': defaultdict(int),
            'position_stats': defaultdict(int),
            'combination_type_stats': defaultdict(int),
            'lottery_opposite_stats': defaultdict(lambda: defaultdict(int))
        }
        
        for pattern in patterns:
            # ç»Ÿè®¡å¯¹ç«‹ç±»å‹
            main_opposite = pattern['ä¸»è¦å¯¹ç«‹ç±»å‹']
            analysis['opposite_type_stats'][main_opposite] += 1
            
            # ç»Ÿè®¡ä½ç½®åˆ†å¸ƒ
            for record in pattern['è¯¦ç»†è®°å½•']:
                for direction in record['æ–¹å‘ç»„']:
                    if '-' in direction:
                        position = direction.split('-')[0]
                        analysis['position_stats'][position] += 1
            
            # ç»Ÿè®¡å½©ç§å¯¹ç«‹æ¨¡å¼
            lottery = pattern['å½©ç§']
            analysis['lottery_opposite_stats'][lottery][main_opposite] += 1
        
        return analysis
    
    def display_enhanced_opposite_analysis(self, patterns):
        """ğŸ†• æ˜¾ç¤ºå¢å¼ºçš„å¯¹ç«‹æ¨¡å¼åˆ†æ"""
        if not patterns:
            return
        
        analysis = self.enhanced_analyze_opposite_patterns(patterns)
        
        st.subheader("ğŸ¯ å¯¹ç«‹æ¨¡å¼æ·±åº¦åˆ†æ")
        
        # å¯¹ç«‹ç±»å‹åˆ†å¸ƒ
        with st.expander("ğŸ“Š å¯¹ç«‹ç±»å‹åˆ†å¸ƒ", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ä¸»è¦å¯¹ç«‹ç±»å‹:**")
                for opposite_type, count in sorted(analysis['opposite_type_stats'].items(), key=lambda x: x[1], reverse=True)[:10]:
                    st.write(f"- {opposite_type}: {count}ç»„")
            
            with col2:
                st.write("**ä½ç½®åˆ†å¸ƒ:**")
                for position, count in sorted(analysis['position_stats'].items(), key=lambda x: x[1], reverse=True)[:10]:
                    st.write(f"- {position}: {count}æ¬¡")
        
        # å½©ç§å¯¹ç«‹æ¨¡å¼åˆ†æ
        with st.expander("ğŸ² å½©ç§å¯¹ç«‹æ¨¡å¼åˆ†æ", expanded=False):
            for lottery, opposite_stats in analysis['lottery_opposite_stats'].items():
                st.write(f"**{lottery}:**")
                for opposite_type, count in sorted(opposite_stats.items(), key=lambda x: x[1], reverse=True)[:5]:
                    st.write(f"  - {opposite_type}: {count}ç»„")
    
    def display_detailed_results(self, patterns):
        """æ˜¾ç¤ºè¯¦ç»†æ£€æµ‹ç»“æœ - æ·»åŠ æœŸå·å»é‡éªŒè¯"""
        if not patterns:
            st.error("âŒ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„è¿ç»­å¯¹åˆ·æ¨¡å¼")
            return
    
        # ğŸ†• æœŸå·å»é‡éªŒè¯
        period_validation = defaultdict(list)
        for pattern in patterns:
            for record in pattern['è¯¦ç»†è®°å½•']:
                key = (record['æœŸå·'], tuple(record['è´¦æˆ·ç»„']))
                period_validation[key].append(record)
        
        # æ£€æŸ¥é‡å¤æœŸå·
        duplicate_periods = {k: v for k, v in period_validation.items() if len(v) > 1}
        if duplicate_periods:
            logger.warning(f"å‘ç°é‡å¤æœŸå·è®°å½•: {duplicate_periods}")
    
        # ========== æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡ ==========
        st.subheader("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        
        total_groups = len(patterns)
        total_accounts = sum(p['è´¦æˆ·æ•°é‡'] for p in patterns)
        total_wash_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        # ğŸ†• ä¿®æ”¹ï¼šä½¿ç”¨ä¸ç¬¬ä¸€å¥—ä»£ç ç±»ä¼¼çš„æŒ‡æ ‡å±•ç¤º
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»å¯¹åˆ·ç»„æ•°", total_groups)
        
        with col2:
            st.metric("æ¶‰åŠè´¦æˆ·æ•°", total_accounts)
        
        with col3:
            st.metric("æ€»å¯¹åˆ·æœŸæ•°", total_wash_periods)
        
        with col4:
            st.metric("æ€»æ¶‰åŠé‡‘é¢", f"Â¥{total_amount:,.2f}")
        
        # ========== å½©ç§ç±»å‹ç»Ÿè®¡ ==========
        st.subheader("ğŸ² å½©ç§ç±»å‹ç»Ÿè®¡")
        
        lottery_stats = defaultdict(int)
        for pattern in patterns:
            lottery_stats[pattern['å½©ç§']] += 1
        
        # ğŸ†• ä¿®æ”¹ï¼šåˆ›å»ºå½©ç§ç»Ÿè®¡åˆ—
        lottery_cols = st.columns(min(5, len(lottery_stats)))
        
        for i, (lottery, count) in enumerate(lottery_stats.items()):
            if i < len(lottery_cols):
                with lottery_cols[i]:
                    st.metric(
                        label=lottery,
                        value=f"{count}ç»„"
                    )
        
        # ========== å‚ä¸è´¦æˆ·è¯¦ç»†ç»Ÿè®¡ ==========
        st.subheader("ğŸ‘¥ å‚ä¸è´¦æˆ·è¯¦ç»†ç»Ÿè®¡")
        
        # è®¡ç®—è´¦æˆ·å‚ä¸ç»Ÿè®¡
        account_stats = self._calculate_detailed_account_stats(patterns)
        
        if account_stats:
            df_stats = pd.DataFrame(account_stats)
            
            # ğŸ†• ä¿®æ”¹ï¼šä½¿ç”¨è¡¨æ ¼å½¢å¼å±•ç¤º
            st.dataframe(
                df_stats,
                use_container_width=True,
                hide_index=True,
                height=min(400, len(df_stats) * 35 + 38)
            )
        
        # ========== è¯¦ç»†å¯¹åˆ·ç»„åˆ†æ ==========
        st.subheader("ğŸ” è¯¦ç»†å¯¹åˆ·ç»„åˆ†æ")
        
        patterns_by_lottery = defaultdict(list)
        for pattern in patterns:
            lottery_key = pattern['å½©ç§']
            patterns_by_lottery[lottery_key].append(pattern)
        
        for lottery, lottery_patterns in patterns_by_lottery.items():
            with st.expander(f"ğŸ² å½©ç§ï¼š{lottery}ï¼ˆå‘ç°{len(lottery_patterns)}ç»„ï¼‰", expanded=True):
                for i, pattern in enumerate(lottery_patterns, 1):
                    st.markdown(f"**å¯¹åˆ·ç»„ {i}:** {' â†” '.join(pattern['è´¦æˆ·ç»„'])}")
                    
                    # ğŸ†• ä¿®æ”¹ï¼šä½¿ç”¨æ›´æ¸…æ™°çš„æ´»è·ƒåº¦æ˜¾ç¤º
                    activity_icon = "ğŸŸ¢" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'low' else "ğŸŸ¡" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'medium' else "ğŸŸ " if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'high' else "ğŸ”´"
                    activity_text = {
                        'low': 'ä½æ´»è·ƒåº¦', 
                        'medium': 'ä¸­æ´»è·ƒåº¦', 
                        'high': 'é«˜æ´»è·ƒåº¦', 
                        'very_high': 'æé«˜æ´»è·ƒåº¦'
                    }.get(pattern['è´¦æˆ·æ´»è·ƒåº¦'], pattern['è´¦æˆ·æ´»è·ƒåº¦'])
                    
                    st.markdown(f"**æ´»è·ƒåº¦:** {activity_icon} {activity_text} | **å½©ç§:** {pattern['å½©ç§']} | **ä¸»è¦ç±»å‹:** {pattern['ä¸»è¦å¯¹ç«‹ç±»å‹']}")
                    st.markdown(f"**è´¦æˆ·åœ¨è¯¥å½©ç§æŠ•æ³¨æœŸæ•°/è®°å½•æ•°:** {', '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯'])}")
                    st.markdown(f"**å¯¹åˆ·æœŸæ•°:** {pattern['å¯¹åˆ·æœŸæ•°']}æœŸ (è¦æ±‚â‰¥{pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°']}æœŸ)")
                    st.markdown(f"**æ€»é‡‘é¢:** {pattern['æ€»æŠ•æ³¨é‡‘é¢']:.2f}å…ƒ | **å¹³å‡åŒ¹é…:** {pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}")
                    
                    st.markdown("**è¯¦ç»†è®°å½•:**")
                    for j, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                        account_directions = []
                        for account, direction, amount in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„']):
                            account_directions.append(f"{account}({direction}:Â¥{amount})")
                        
                        st.write(f"{j}. æœŸå·: {record['æœŸå·']} | æ–¹å‘: {' â†” '.join(account_directions)} | åŒ¹é…åº¦: {record['ç›¸ä¼¼åº¦']:.2%}")
                    
                    if i < len(lottery_patterns):
                        st.markdown("---")
    
    def display_summary_statistics(self, patterns):
        """æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡"""
        if not patterns:
            return
            
        st.subheader("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        
        total_groups = len(patterns)
        total_accounts = sum(p['è´¦æˆ·æ•°é‡'] for p in patterns)
        total_wash_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        account_count_stats = defaultdict(int)
        for pattern in patterns:
            account_count_stats[pattern['è´¦æˆ·æ•°é‡']] += 1
        
        lottery_stats = defaultdict(int)
        for pattern in patterns:
            lottery_stats[pattern['å½©ç§']] += 1
        
        activity_stats = defaultdict(int)
        for pattern in patterns:
            activity_stats[pattern['è´¦æˆ·æ´»è·ƒåº¦']] += 1
        
        opposite_type_stats = defaultdict(int)
        for pattern in patterns:
            for opposite_type, count in pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ'].items():
                opposite_type_stats[opposite_type] += count
        
        # ========== ç¬¬ä¸€è¡Œï¼šæ€»ä½“æŒ‡æ ‡ ==========
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»å¯¹åˆ·ç»„æ•°", total_groups)
        
        with col2:
            st.metric("æ¶‰åŠè´¦æˆ·æ•°", total_accounts)
        
        with col3:
            st.metric("æ€»å¯¹åˆ·æœŸæ•°", total_wash_periods)
        
        with col4:
            st.metric("æ€»æ¶‰åŠé‡‘é¢", f"Â¥{total_amount:,.2f}")
        
        # ========== ç¬¬äºŒè¡Œï¼šå½©ç§ç±»å‹ç»Ÿè®¡ ==========
        st.subheader("ğŸ² å½©ç§ç±»å‹ç»Ÿè®¡")
        
        # å®šä¹‰å½©ç§ç±»å‹æ˜¾ç¤ºåç§°
        lottery_display_names = {
            'PK10': 'PK10/èµ›è½¦',
            'K3': 'å¿«ä¸‰',
            'LHC': 'å…­åˆå½©', 
            'SSC': 'æ—¶æ—¶å½©',
            '3D': '3Dç³»åˆ—'
        }
        
        # åˆ›å»ºå½©ç§ç»Ÿè®¡åˆ—
        lottery_cols = st.columns(min(5, len(lottery_stats)))
        
        for i, (lottery, count) in enumerate(lottery_stats.items()):
            if i < len(lottery_cols):
                with lottery_cols[i]:
                    display_name = lottery_display_names.get(lottery, lottery)
                    st.metric(
                        label=display_name,
                        value=f"{count}ç»„"
                    )
        
        # ========== ç¬¬ä¸‰è¡Œï¼šè´¦æˆ·ç»„åˆåˆ†å¸ƒå’Œæ´»è·ƒåº¦åˆ†å¸ƒ ==========
        col_left, col_right = st.columns(2)
        
        with col_left:
            st.subheader("ğŸ‘¥ è´¦æˆ·ç»„åˆåˆ†å¸ƒ")
            
            for account_count, group_count in sorted(account_count_stats.items()):
                # è®¡ç®—è¯¥ç±»å‹ç»„åˆçš„æ€»å¯¹åˆ·æœŸæ•°
                account_type_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns if p['è´¦æˆ·æ•°é‡'] == account_count)
                st.write(f"- **{account_count}ç»„**: {group_count}ç»„ ({account_type_periods}æœŸ)")
        
        with col_right:
            st.subheader("ğŸ“ˆ æ´»è·ƒåº¦åˆ†å¸ƒ")
            
            activity_display_names = {
                'low': 'ä½æ´»è·ƒåº¦',
                'medium': 'ä¸­æ´»è·ƒåº¦',
                'high': 'é«˜æ´»è·ƒåº¦',
                'very_high': 'æé«˜æ´»è·ƒåº¦'
            }
            
            for activity, count in activity_stats.items():
                display_name = activity_display_names.get(activity, activity)
                # è®¡ç®—è¯¥æ´»è·ƒåº¦çš„æ€»å¯¹åˆ·æœŸæ•°
                activity_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns if p['è´¦æˆ·æ´»è·ƒåº¦'] == activity)
                st.write(f"- **{display_name}**: {count}ç»„ ({activity_periods}æœŸ)")
        
        # ========== ç¬¬å››è¡Œï¼šå…³é”®æŒ‡æ ‡ ==========
        st.subheader("ğŸ“ˆ å…³é”®æŒ‡æ ‡")
        
        # è®¡ç®—å¹³å‡æ¯ç»„é‡‘é¢
        avg_group_amount = total_amount / total_groups if total_groups > 0 else 0
        
        metric_col1, metric_col2, metric_col3 = st.columns(3)
        
        with metric_col1:
            st.metric("å¹³å‡æ¯ç»„é‡‘é¢", f"Â¥{avg_group_amount:,.2f}")
        
        with metric_col2:
            # è®¡ç®—ä¸šåŠ¡ç±»å‹æ€»é‡‘é¢
            business_total = total_amount
            st.metric("ä¸šåŠ¡ç±»å‹æ€»é¢", f"Â¥{business_total:,.2f}")
        
        with metric_col3:
            # æ˜¾ç¤ºæ€»è´¦æˆ·æ•°
            st.metric("å‚ä¸æ€»è´¦æˆ·æ•°", total_accounts)
        
        # ========== ç¬¬äº”è¡Œï¼šä¸»è¦å¯¹ç«‹ç±»å‹ ==========
        st.subheader("ğŸ¯ ä¸»è¦å¯¹ç«‹ç±»å‹")
        
        # æ˜¾ç¤ºå‰3ä¸ªä¸»è¦å¯¹ç«‹ç±»å‹
        top_opposites = sorted(opposite_type_stats.items(), key=lambda x: x[1], reverse=True)[:3]
        
        for opposite_type, count in top_opposites:
            # ç®€åŒ–å¯¹ç«‹ç±»å‹æ˜¾ç¤º
            if ' vs ' in opposite_type:
                display_type = opposite_type.replace(' vs ', '-')
            else:
                display_type = opposite_type
            st.write(f"- **{display_type}**: {count}æœŸ")

    def export_detection_results(self, patterns, export_format='excel'):
        """å¯¼å‡ºæ£€æµ‹ç»“æœ"""
        if not patterns:
            st.warning("âŒ æ²¡æœ‰æ£€æµ‹ç»“æœå¯ä¾›å¯¼å‡º")
            return None
        
        try:
            # åˆ›å»ºä¸»ç»“æœDataFrame
            main_data = []
            detailed_data = []
            
            for i, pattern in enumerate(patterns, 1):
                # ä¸»è¡¨æ•°æ®
                main_record = {
                    'ç»„ID': f"ç»„{i}",
                    'è´¦æˆ·ç»„': ' â†” '.join(pattern['è´¦æˆ·ç»„']),
                    'å½©ç§': pattern['å½©ç§'],
                    'å½©ç§ç±»å‹': pattern['å½©ç§ç±»å‹'],
                    'è´¦æˆ·æ•°é‡': pattern['è´¦æˆ·æ•°é‡'],
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': pattern['ä¸»è¦å¯¹ç«‹ç±»å‹'],
                    'å¯¹åˆ·æœŸæ•°': pattern['å¯¹åˆ·æœŸæ•°'],
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°'],
                    'æ€»æŠ•æ³¨é‡‘é¢': pattern['æ€»æŠ•æ³¨é‡‘é¢'],
                    'å¹³å‡ç›¸ä¼¼åº¦': pattern['å¹³å‡ç›¸ä¼¼åº¦'],
                    'è´¦æˆ·æ´»è·ƒåº¦': pattern['è´¦æˆ·æ´»è·ƒåº¦'],
                    'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': '; '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯'])
                }
                main_data.append(main_record)
                
                # è¯¦ç»†è®°å½•æ•°æ®
                for j, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                    detailed_record = {
                        'ç»„ID': f"ç»„{i}",
                        'è´¦æˆ·ç»„': ' â†” '.join(pattern['è´¦æˆ·ç»„']),
                        'æœŸå·': record['æœŸå·'],
                        'å½©ç§': record['å½©ç§'],
                        'å½©ç§ç±»å‹': record['å½©ç§ç±»å‹'],
                        'æ–¹å‘ç»„': ' â†” '.join([f"{acc}({dir})" for acc, dir in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'])]),
                        'é‡‘é¢ç»„': ' â†” '.join([f"Â¥{amt}" for amt in record['é‡‘é¢ç»„']]),
                        'æ€»é‡‘é¢': record['æ€»é‡‘é¢'],
                        'ç›¸ä¼¼åº¦': record['ç›¸ä¼¼åº¦'],
                        'è´¦æˆ·æ•°é‡': record['è´¦æˆ·æ•°é‡'],
                        'æ¨¡å¼': record['æ¨¡å¼'],
                        'å¯¹ç«‹ç±»å‹': record['å¯¹ç«‹ç±»å‹']
                    }
                    detailed_data.append(detailed_record)
            
            # åˆ›å»ºDataFrame
            df_main = pd.DataFrame(main_data)
            df_detailed = pd.DataFrame(detailed_data)
            
            # æ ¼å¼åŒ–æ•°å­—åˆ—
            numeric_columns = ['æ€»æŠ•æ³¨é‡‘é¢', 'å¹³å‡ç›¸ä¼¼åº¦', 'æ€»é‡‘é¢', 'ç›¸ä¼¼åº¦']
            for col in numeric_columns:
                if col in df_main.columns:
                    df_main[col] = df_main[col].apply(lambda x: f"Â¥{x:,.2f}" if 'é‡‘é¢' in col else f"{x:.2%}")
                if col in df_detailed.columns:
                    df_detailed[col] = df_detailed[col].apply(lambda x: f"Â¥{x:,.2f}" if 'é‡‘é¢' in col else f"{x:.2%}")
            
            if export_format == 'excel':
                return self._export_to_excel(df_main, df_detailed)
            else:
                return self._export_to_csv(df_main, df_detailed)
                
        except Exception as e:
            logger.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            return None

    def _export_to_excel(self, df_main, df_detailed):
        """å¯¼å‡ºåˆ°Excelæ ¼å¼"""
        try:
            output = io.BytesIO()
            
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # å†™å…¥ä¸»è¡¨
                df_main.to_excel(writer, sheet_name='å¯¹åˆ·ç»„æ±‡æ€»', index=False)
                
                # å†™å…¥è¯¦ç»†è¡¨
                df_detailed.to_excel(writer, sheet_name='è¯¦ç»†è®°å½•', index=False)
                
                # è·å–workbookå’Œworksheets
                workbook = writer.book
                main_sheet = workbook['å¯¹åˆ·ç»„æ±‡æ€»']
                detailed_sheet = workbook['è¯¦ç»†è®°å½•']
                
                # è®¾ç½®åˆ—å®½
                for sheet in [main_sheet, detailed_sheet]:
                    for column in sheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        adjusted_width = min(max_length + 2, 50)
                        sheet.column_dimensions[column_letter].width = adjusted_width
                
                # æ·»åŠ æ ‡é¢˜å’Œå…ƒæ•°æ®
                main_sheet.insert_rows(0, 3)
                main_sheet['A1'] = "å¯¹åˆ·æ£€æµ‹ç»“æœæŠ¥å‘Š"
                main_sheet['A2'] = f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                main_sheet['A3'] = f"æ€»å¯¹åˆ·ç»„æ•°: {len(df_main)}"
                
                # åˆå¹¶æ ‡é¢˜è¡Œ
                main_sheet.merge_cells('A1:L1')
                main_sheet.merge_cells('A2:L2')
                main_sheet.merge_cells('A3:L3')
                
                # è®¾ç½®æ ‡é¢˜æ ·å¼
                for cell in ['A1', 'A2', 'A3']:
                    main_sheet[cell].font = Font(bold=True, size=12)
                    main_sheet[cell].alignment = Alignment(horizontal='center')
            
            output.seek(0)
            return output
            
        except Exception as e:
            logger.error(f"Excelå¯¼å‡ºå¤±è´¥: {str(e)}")
            raise e

    def _export_to_csv(self, df_main, df_detailed):
        """å¯¼å‡ºåˆ°CSVæ ¼å¼"""
        try:
            # åˆ›å»ºZIPæ–‡ä»¶åŒ…å«ä¸¤ä¸ªCSV
            zip_buffer = io.BytesIO()
            
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                # ä¸»è¡¨CSV
                main_csv = df_main.to_csv(index=False, encoding='utf-8-sig')
                zip_file.writestr('å¯¹åˆ·ç»„æ±‡æ€».csv', main_csv)
                
                # è¯¦ç»†è¡¨CSV
                detailed_csv = df_detailed.to_csv(index=False, encoding='utf-8-sig')
                zip_file.writestr('è¯¦ç»†è®°å½•.csv', detailed_csv)
                
                # æ·»åŠ è¯´æ˜æ–‡ä»¶
                readme_content = f"""å¯¹åˆ·æ£€æµ‹ç»“æœå¯¼å‡ºæ–‡ä»¶
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æ€»å¯¹åˆ·ç»„æ•°: {len(df_main)}

æ–‡ä»¶è¯´æ˜:
1. å¯¹åˆ·ç»„æ±‡æ€».csv - åŒ…å«æ‰€æœ‰å¯¹åˆ·ç»„çš„æ±‡æ€»ä¿¡æ¯
2. è¯¦ç»†è®°å½•.csv - åŒ…å«æ¯ä¸ªå¯¹åˆ·ç»„çš„è¯¦ç»†æœŸå·è®°å½•

æ£€æµ‹å‚æ•°:
- æœ€å°æŠ•æ³¨é‡‘é¢: {self.config.min_amount}å…ƒ
- åŸºç¡€åŒ¹é…åº¦é˜ˆå€¼: {self.config.amount_similarity_threshold:.0%}
- æœ€å¤§æ£€æµ‹è´¦æˆ·æ•°: {self.config.max_accounts_in_group}
"""
                zip_file.writestr('è¯´æ˜.txt', readme_content)
            
            zip_buffer.seek(0)
            return zip_buffer
            
        except Exception as e:
            logger.error(f"CSVå¯¼å‡ºå¤±è´¥: {str(e)}")
            raise e

    def display_export_buttons(self, patterns):
        """æ˜¾ç¤ºå¯¼å‡ºæŒ‰é’®"""
        if not patterns:
            return
        
        st.markdown("---")
        st.subheader("ğŸ“¤ å¯¼å‡ºæ£€æµ‹ç»“æœ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“Š å¯¼å‡ºExcelæŠ¥å‘Š", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”ŸæˆExcelæŠ¥å‘Š..."):
                    excel_data = self.export_detection_results(patterns, 'excel')
                    if excel_data:
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½Excelæ–‡ä»¶",
                            data=excel_data,
                            file_name=f"å¯¹åˆ·æ£€æµ‹æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
        
        with col2:
            if st.button("ğŸ“„ å¯¼å‡ºCSVæ–‡ä»¶", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”ŸæˆCSVæ–‡ä»¶..."):
                    csv_data = self.export_detection_results(patterns, 'csv')
                    if csv_data:
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½CSVå‹ç¼©åŒ…",
                            data=csv_data,
                            file_name=f"å¯¹åˆ·æ£€æµ‹æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                            mime="application/zip",
                            use_container_width=True
                        )
        
        # æ˜¾ç¤ºå¯¼å‡ºç»Ÿè®¡
        st.info(f"ğŸ“Š å¯¼å‡ºå†…å®¹: {len(patterns)}ä¸ªå¯¹åˆ·ç»„, å…±{sum(len(p['è¯¦ç»†è®°å½•']) for p in patterns)}æ¡è¯¦ç»†è®°å½•")

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ¯ æ™ºèƒ½å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    with st.sidebar:
        st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æŠ•æ³¨æ•°æ®æ–‡ä»¶", 
            type=['xlsx', 'xls', 'csv'],
            help="è¯·ä¸Šä¼ åŒ…å«å½©ç¥¨æŠ•æ³¨æ•°æ®çš„Excelæˆ–CSVæ–‡ä»¶"
        )
    
    if uploaded_file is not None:
        try:
            # ğŸ†• é¦–å…ˆåˆ›å»º Config å¯¹è±¡
            config = Config()
            
            # é…ç½®å‚æ•°
            st.sidebar.header("âš™ï¸ æ£€æµ‹å‚æ•°è®¾ç½®")
            
            # ğŸ†• ä¿®æ”¹ï¼šä½¿ç”¨æ»‘å—è®¾ç½®æœ€å°æŠ•æ³¨é‡‘é¢ï¼Œé»˜è®¤10
            min_amount = st.sidebar.slider(
                "æœ€å°æŠ•æ³¨é‡‘é¢é˜ˆå€¼", 
                min_value=1, 
                max_value=50, 
                value=10,
                help="æŠ•æ³¨é‡‘é¢ä½äºæ­¤å€¼çš„è®°å½•å°†ä¸å‚ä¸æ£€æµ‹"
            )
            
            base_similarity_threshold = st.sidebar.slider(
                "åŸºç¡€é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼", 
                0.8, 1.0, 0.8, 0.01, 
                help="2ä¸ªè´¦æˆ·çš„åŸºç¡€åŒ¹é…åº¦é˜ˆå€¼"
            )
            
            max_accounts = st.sidebar.slider(
                "æœ€å¤§æ£€æµ‹è´¦æˆ·æ•°", 
                2, 8, 5, 
                help="æ£€æµ‹çš„æœ€å¤§è´¦æˆ·ç»„åˆæ•°é‡"
            )
            
            # ğŸ†• ä¿®æ”¹ï¼šè´¦æˆ·æœŸæ•°å·®å¼‚é˜ˆå€¼é…ç½®ï¼Œä½¿ç”¨æ›´ç›´è§‚çš„æè¿°
            period_diff_threshold = st.sidebar.slider(
                "è´¦æˆ·æœŸæ•°æœ€å¤§å·®å¼‚é˜ˆå€¼", 
                min_value=0, 
                max_value=500,
                value=101,
                help="è´¦æˆ·æ€»æŠ•æ³¨æœŸæ•°æœ€å¤§å…è®¸å·®å¼‚ï¼Œè¶…è¿‡æ­¤å€¼ä¸è¿›è¡Œç»„åˆæ£€æµ‹"
            )
            
            # ==================== ğŸ†• ä¿®æ”¹ï¼šé‡‘é¢å¹³è¡¡é…ç½®æ§ä»¶ ====================
            st.sidebar.subheader("ğŸ’° é‡‘é¢å¹³è¡¡è®¾ç½®")
            
            enable_balance_filter = st.sidebar.checkbox("å¯ç”¨é‡‘é¢å¹³è¡¡è¿‡æ»¤", value=True,
                                                      help="ç¡®ä¿å¯¹åˆ·ç»„å†…è´¦æˆ·é‡‘é¢å·®è·ä¸è¶…è¿‡è®¾å®šå€æ•°")
            
            max_ratio = 10  # é»˜è®¤å€¼
            if enable_balance_filter:
                max_ratio = st.sidebar.slider("æœ€å¤§é‡‘é¢å·®è·å€æ•°", 
                                             min_value=2, 
                                             max_value=20, 
                                             value=10, 
                                             step=1,
                                             help="ç»„å†…æœ€å¤§é‡‘é¢ä¸æœ€å°é‡‘é¢çš„å…è®¸å€æ•°ï¼ˆä¾‹å¦‚ï¼š10è¡¨ç¤º10å€å·®è·ï¼‰")
            
            # æ›´æ–°é…ç½®
            config.amount_threshold = {
                'max_amount_ratio': max_ratio,
                'enable_threshold_filter': enable_balance_filter
            }
            
            # ğŸ†• ä¿®æ”¹ï¼šå¯è°ƒæ•´çš„æ´»è·ƒåº¦é˜ˆå€¼é…ç½®
            st.sidebar.subheader("ğŸ› ï¸ è¿ç»­å¯¹åˆ·é˜ˆå€¼é…ç½®")
            
            st.sidebar.markdown("**ä½æ´»è·ƒåº¦(1-10æœŸ):**")
            min_periods_low = st.sidebar.slider(
                "ä½æ´»è·ƒåº¦æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°", 
                min_value=1, max_value=10, value=3,
                help="æ€»æŠ•æ³¨æœŸæ•°1-10æœŸçš„è´¦æˆ·ï¼Œè¦æ±‚çš„æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°"
            )
            
            st.sidebar.markdown("**ä¸­æ´»è·ƒåº¦(11-50æœŸ):**")
            min_periods_medium = st.sidebar.slider(
                "ä¸­æ´»è·ƒåº¦æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°", 
                min_value=3, max_value=15, value=5,
                help="æ€»æŠ•æ³¨æœŸæ•°11-50æœŸçš„è´¦æˆ·ï¼Œè¦æ±‚çš„æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°"
            )
            
            st.sidebar.markdown("**é«˜æ´»è·ƒåº¦(51-100æœŸ):**")
            min_periods_high = st.sidebar.slider(
                "é«˜æ´»è·ƒåº¦æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°", 
                min_value=5, max_value=20, value=8,
                help="æ€»æŠ•æ³¨æœŸæ•°51-100æœŸçš„è´¦æˆ·ï¼Œè¦æ±‚çš„æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°"
            )
            
            st.sidebar.markdown("**æé«˜æ´»è·ƒåº¦(100æœŸä»¥ä¸Š):**")
            min_periods_very_high = st.sidebar.slider(
                "æé«˜æ´»è·ƒåº¦æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°", 
                min_value=8, max_value=30, value=11,
                help="æ€»æŠ•æ³¨æœŸæ•°100æœŸä»¥ä¸Šçš„è´¦æˆ·ï¼Œè¦æ±‚çš„æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°"
            )
            
            # ğŸ†• ä¿®æ”¹ï¼šå¯è°ƒæ•´çš„å¤šè´¦æˆ·åŒ¹é…åº¦é…ç½®
            st.sidebar.subheader("ğŸ¯ å¤šè´¦æˆ·åŒ¹é…åº¦é…ç½®")
            
            st.sidebar.markdown("**2ä¸ªè´¦æˆ·:**")
            similarity_2_accounts = st.sidebar.slider(
                "2ä¸ªè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼", 
                min_value=0.5, max_value=1.0, value=0.8, step=0.01,
                help="2ä¸ªè´¦æˆ·å¯¹åˆ·çš„é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼"
            )
            
            st.sidebar.markdown("**3ä¸ªè´¦æˆ·:**")
            similarity_3_accounts = st.sidebar.slider(
                "3ä¸ªè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼", 
                min_value=0.5, max_value=1.0, value=0.85, step=0.01,
                help="3ä¸ªè´¦æˆ·å¯¹åˆ·çš„é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼"
            )
            
            st.sidebar.markdown("**4ä¸ªè´¦æˆ·:**")
            similarity_4_accounts = st.sidebar.slider(
                "4ä¸ªè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼", 
                min_value=0.5, max_value=1.0, value=0.9, step=0.01,
                help="4ä¸ªè´¦æˆ·å¯¹åˆ·çš„é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼"
            )
            
            st.sidebar.markdown("**5ä¸ªè´¦æˆ·:**")
            similarity_5_accounts = st.sidebar.slider(
                "5ä¸ªè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼", 
                min_value=0.5, max_value=1.0, value=0.95, step=0.01,
                help="5ä¸ªè´¦æˆ·å¯¹åˆ·çš„é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼"
            )
            
            # æ›´æ–°é…ç½®å‚æ•°
            config = Config()
            config.min_amount = min_amount
            config.amount_similarity_threshold = base_similarity_threshold
            config.max_accounts_in_group = max_accounts
            config.account_period_diff_threshold = period_diff_threshold
            
            # ğŸ†• æ›´æ–°æ´»è·ƒåº¦é˜ˆå€¼é…ç½®
            config.period_thresholds.update({
                'min_periods_low': min_periods_low,
                'min_periods_medium': min_periods_medium,
                'min_periods_high': min_periods_high,
                'min_periods_very_high': min_periods_very_high
            })
            
            # ğŸ†• æ›´æ–°å¤šè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼
            config.account_count_similarity_thresholds = {
                2: similarity_2_accounts,
                3: similarity_3_accounts,
                4: similarity_4_accounts,
                5: similarity_5_accounts
            }
            
            detector = WashTradeDetector(config)
            
            st.success(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
            
            # ğŸ†• ä¿®æ”¹ï¼šæ˜¾ç¤ºå½“å‰å‚æ•°è®¾ç½®
            st.info(f"ğŸ“Š å½“å‰æ£€æµ‹å‚æ•°: æœ€å°é‡‘é¢ â‰¥ {min_amount}, åŸºç¡€åŒ¹é…åº¦ â‰¥ {base_similarity_threshold*100}%")
            
            with st.spinner("ğŸ”„ æ­£åœ¨è§£ææ•°æ®..."):
                df_enhanced, filename = detector.upload_and_process(uploaded_file)
                
                if df_enhanced is not None and len(df_enhanced) > 0:
                    st.success("âœ… æ•°æ®è§£æå®Œæˆ")
                    
                    # ğŸ†• ä¿®æ”¹ï¼šæ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æœ‰æ•ˆè®°å½•æ•°", f"{len(df_enhanced):,}")
                    with col2:
                        st.metric("å”¯ä¸€æœŸå·æ•°", f"{df_enhanced['æœŸå·'].nunique():,}")
                    with col3:
                        st.metric("å”¯ä¸€è´¦æˆ·æ•°", f"{df_enhanced['ä¼šå‘˜è´¦å·'].nunique():,}")
                    with col4:
                        if 'å½©ç§ç±»å‹' in df_enhanced.columns:
                            st.metric("å½©ç§ç±»å‹æ•°", f"{df_enhanced['å½©ç§ç±»å‹'].nunique()}")
                    
                    # ğŸ†• ä¿®æ”¹ï¼šæ˜¾ç¤ºè¿‡æ»¤ç»Ÿè®¡ä¿¡æ¯
                    initial_count = len(df_enhanced)
                    if hasattr(detector, 'df_valid') and detector.df_valid is not None:
                        valid_count = len(detector.df_valid)
                        filtered_count = initial_count - valid_count
                        if filtered_count > 0:
                            st.info(f"ğŸ“Š è¿‡æ»¤ç»Ÿè®¡: ç§»é™¤äº† {filtered_count} æ¡é‡‘é¢ä½äº{min_amount}çš„è®°å½•")
                    
                    # ğŸ†• ä¿®æ”¹ï¼šæ•°æ®é¢„è§ˆéƒ¨åˆ†
                    with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆ", expanded=False):
                        tab1, tab2, tab3 = st.tabs(["æ•°æ®æ¦‚è§ˆ", "å½©ç§åˆ†å¸ƒ", "é‡‘é¢ç»Ÿè®¡"])
                        
                        with tab1:
                            st.dataframe(df_enhanced.head(50), use_container_width=True)
                        
                        with tab2:
                            if 'å½©ç§ç±»å‹' in df_enhanced.columns:
                                lottery_type_stats = df_enhanced['å½©ç§ç±»å‹'].value_counts()
                                st.bar_chart(lottery_type_stats)
                        
                        with tab3:
                            if 'æŠ•æ³¨é‡‘é¢' in df_enhanced.columns:
                                st.write(f"- æ€»æŠ•æ³¨é¢: {df_enhanced['æŠ•æ³¨é‡‘é¢'].sum():,.2f} å…ƒ")
                                st.write(f"- å¹³å‡æ¯æ³¨: {df_enhanced['æŠ•æ³¨é‡‘é¢'].mean():.2f} å…ƒ")
                                st.write(f"- æœ€å¤§å•æ³¨: {df_enhanced['æŠ•æ³¨é‡‘é¢'].max():.2f} å…ƒ")
                                st.write(f"- æœ€å°å•æ³¨: {df_enhanced['æŠ•æ³¨é‡‘é¢'].min():.2f} å…ƒ")
                                st.write(f"- é‡‘é¢â‰¥{min_amount}çš„è®°å½•: {len(df_enhanced[df_enhanced['æŠ•æ³¨é‡‘é¢'] >= min_amount]):,} æ¡")
                    
                    st.info("ğŸš€ å¼€å§‹æ£€æµ‹å¯¹åˆ·äº¤æ˜“...")
                    with st.spinner("ğŸ” æ­£åœ¨æ£€æµ‹å¯¹åˆ·äº¤æ˜“..."):
                        patterns = detector.detect_all_wash_trades()
                    
                    if patterns:
                        st.success(f"âœ… æ£€æµ‹å®Œæˆï¼å‘ç° {len(patterns)} ä¸ªå¯¹åˆ·ç»„")
                        
                        # æ˜¾ç¤ºåˆ†æç»“æœ
                        detector.display_detailed_results(patterns)
                        
                        # ğŸ†• æ·»åŠ å¯¼å‡ºæŒ‰é’®
                        detector.display_export_buttons(patterns)
                    else:
                        st.warning("âš ï¸ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„å¯¹åˆ·è¡Œä¸º")
                else:
                    st.error("âŒ æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
            
        except Exception as e:
            st.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
            import traceback
            st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
    else:
        # ğŸ†• ä¿®æ”¹ï¼šæœªä¸Šä¼ æ–‡ä»¶æ—¶çš„å±•ç¤ºå†…å®¹
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("ğŸ” æ™ºèƒ½æ£€æµ‹")
            st.markdown("""
            - å¤šè´¦æˆ·å¯¹åˆ·æ¨¡å¼è¯†åˆ«
            - æ™ºèƒ½é‡‘é¢åŒ¹é…åˆ†æ
            - æ´»è·ƒåº¦è‡ªé€‚åº”é˜ˆå€¼
            - å®æ—¶è¿›åº¦ç›‘æ§
            """)
        
        with col2:
            st.subheader("ğŸ“Š ä¸“ä¸šåˆ†æ")
            st.markdown("""
            - å®Œæ•´å½©ç§æ”¯æŒ
            - ç©æ³•åˆ†ç±»æ ‡å‡†åŒ–
            - æ•°æ®è´¨é‡éªŒè¯
            - è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
            """)
        
        with col3:
            st.subheader("ğŸš€ é«˜æ•ˆå¤„ç†")
            st.markdown("""
            - å¤§æ•°æ®é‡ä¼˜åŒ–
            - å¹¶è¡Œæ£€æµ‹ç®—æ³•
            - ä¸€é”®å¯¼å‡ºç»“æœ
            - å®æ—¶æ€§èƒ½ç›‘æ§
            """)
    
    # ğŸ†• ä¿®æ”¹ï¼šç³»ç»Ÿä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ç³»ç»Ÿä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½è¯´æ˜

        **ğŸ¯ æ£€æµ‹é€»è¾‘ï¼š**
        - **é‡‘é¢è¿‡æ»¤**ï¼šæŠ•æ³¨é‡‘é¢ä½äºè®¾å®šé˜ˆå€¼ï¼ˆé»˜è®¤10å…ƒï¼‰çš„è®°å½•ä¸å‚ä¸æ£€æµ‹
        - **æ€»æŠ•æ³¨æœŸæ•°**ï¼šè´¦æˆ·åœ¨ç‰¹å®šå½©ç§ä¸­çš„æ‰€æœ‰æœŸå·æŠ•æ³¨æ¬¡æ•°
        - **å¯¹åˆ·æœŸæ•°**ï¼šè´¦æˆ·ç»„å®é™…å‘ç”Ÿå¯¹åˆ·è¡Œä¸ºçš„æœŸæ•°
        - æ ¹æ®**æ€»æŠ•æ³¨æœŸæ•°**åˆ¤å®šè´¦æˆ·æ´»è·ƒåº¦ï¼Œè®¾ç½®ä¸åŒçš„**å¯¹åˆ·æœŸæ•°**é˜ˆå€¼

        **ğŸ“Š æ´»è·ƒåº¦åˆ¤å®šï¼š**
        - **1-10æœŸ**ï¼šè¦æ±‚â‰¥3æœŸè¿ç»­å¯¹åˆ·
        - **11-50æœŸ**ï¼šè¦æ±‚â‰¥5æœŸè¿ç»­å¯¹åˆ·  
        - **51-100æœŸ**ï¼šè¦æ±‚â‰¥8æœŸè¿ç»­å¯¹åˆ·
        - **100æœŸä»¥ä¸Š**ï¼šè¦æ±‚â‰¥11æœŸè¿ç»­å¯¹åˆ·

        **ğŸ¯ å¤šè´¦æˆ·åŒ¹é…åº¦è¦æ±‚ï¼š**
        - **2ä¸ªè´¦æˆ·**ï¼š80%åŒ¹é…åº¦
        - **3ä¸ªè´¦æˆ·**ï¼š85%åŒ¹é…åº¦  
        - **4ä¸ªè´¦æˆ·**ï¼š90%åŒ¹é…åº¦
        - **5ä¸ªè´¦æˆ·**ï¼š95%åŒ¹é…åº¦

        **ğŸ”„ è´¦æˆ·æœŸæ•°å·®å¼‚æ£€æŸ¥ï¼š**
        - é¿å…æœŸæ•°å·®å¼‚è¿‡å¤§çš„è´¦æˆ·ç»„åˆ
        - é»˜è®¤é˜ˆå€¼ï¼š101æœŸ
        - å¯è‡ªå®šä¹‰è°ƒæ•´é˜ˆå€¼

        **âš¡ è‡ªåŠ¨æ£€æµ‹ï¼š**
        - æ•°æ®ä¸Šä¼ åè‡ªåŠ¨å¼€å§‹å¤„ç†å’Œåˆ†æ
        - æ— éœ€æ‰‹åŠ¨ç‚¹å‡»å¼€å§‹æ£€æµ‹æŒ‰é’®

        **ğŸ² æ–°å¢å…­åˆå½©æ£€æµ‹ï¼š**
        - **å¤©è‚– vs åœ°è‚–**ï¼šå¤©è‚–ä¸åœ°è‚–çš„å¯¹ç«‹æ£€æµ‹
        - **å®¶è‚– vs é‡è‚–**ï¼šå®¶ç¦½è‚–ä¸é‡å…½è‚–çš„å¯¹ç«‹æ£€æµ‹  
        - **å°¾å¤§ vs å°¾å°**ï¼šå°¾æ•°å¤§å°çš„å¯¹ç«‹æ£€æµ‹
        - **ç‰¹å¤§ vs ç‰¹å°**ï¼šç‰¹ç å¤§å°çš„å¯¹ç«‹æ£€æµ‹
        - **ç‰¹å• vs ç‰¹åŒ**ï¼šç‰¹ç å•åŒçš„å¯¹ç«‹æ£€æµ‹
        """)

if __name__ == "__main__":
    main()
