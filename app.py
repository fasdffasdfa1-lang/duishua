import pandas as pd
import numpy as np
import streamlit as st
import io
import re
import logging
from collections import defaultdict
from datetime import datetime
from itertools import combinations
import warnings
import traceback

# é…ç½®æ—¥å¿—å’Œè­¦å‘Š
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('K3WashTrade')

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¿«ä¸‰å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

class Config:
    """é…ç½®å‚æ•°ç±»"""
    def __init__(self):
        self.min_amount = 10
        self.amount_similarity_threshold = 0.9
        self.min_continuous_periods = 3
        self.max_accounts_in_group = 5
        self.supported_file_types = ['.xlsx', '.xls', '.csv']
        
        # åˆ—åæ˜ å°„é…ç½®
        self.column_mappings = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢']
        }
        
        # æ›´å®½æ¾çš„é˜ˆå€¼é…ç½®ï¼ˆç”¨äºè¯Šæ–­ï¼‰
        self.period_thresholds = {
            'low_activity_max': 100,     # æé«˜ä½æ´»è·ƒåº¦é˜ˆå€¼
            'medium1_activity_min': 101,  
            'medium1_activity_max': 500, 
            'medium2_activity_min': 501, 
            
            # é™ä½æœ€å°å¯¹åˆ·æœŸæ•°è¦æ±‚
            'min_periods_low': 2,        
            'min_periods_medium1': 2,    
            'min_periods_medium2': 2,    
            
            # æ”¾å®½æ´»è·ƒåº¦å·®å¼‚æ£€æŸ¥
            'max_period_difference': 1000  # å¤§å¹…æ”¾å®½å·®å¼‚é™åˆ¶
        }
        
        self.direction_patterns = {
            'å°': ['ä¸¤é¢-å°', 'å’Œå€¼-å°', 'å°', 'small', 'xia'],
            'å¤§': ['ä¸¤é¢-å¤§', 'å’Œå€¼-å¤§', 'å¤§', 'big', 'da'], 
            'å•': ['ä¸¤é¢-å•', 'å’Œå€¼-å•', 'å•', 'odd', 'dan'],
            'åŒ': ['ä¸¤é¢-åŒ', 'å’Œå€¼-åŒ', 'åŒ', 'even', 'shuang']
        }
        
        self.opposite_groups = [{'å¤§', 'å°'}, {'å•', 'åŒ'}]

class WashTradeDetector:
    def __init__(self, config=None):
        self.config = config or Config()
        self.data_processed = False
        self.df_valid = None
        self.export_data = []
        self.account_period_stats_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        self.column_mapping_used = {}
        self.performance_stats = {}
        self.debug_info = []  # æ–°å¢ï¼šå­˜å‚¨è°ƒè¯•ä¿¡æ¯
    
    def add_debug_info(self, message):
        """æ·»åŠ è°ƒè¯•ä¿¡æ¯"""
        self.debug_info.append(f"{datetime.now().strftime('%H:%M:%S')} - {message}")
    
    # å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜ï¼Œåªä¿®æ”¹å…³é”®æ£€æµ‹é€»è¾‘
    
    def detect_all_wash_trades(self):
        """æ£€æµ‹æ‰€æœ‰ç±»å‹çš„å¯¹åˆ·äº¤æ˜“ - è¯Šæ–­ç‰ˆæœ¬"""
        if not self.data_processed or self.df_valid is None or len(self.df_valid) == 0:
            st.error("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ç”¨äºæ£€æµ‹")
            return []
        
        # é‡ç½®è°ƒè¯•ä¿¡æ¯
        self.debug_info = []
        self.add_debug_info("å¼€å§‹å¯¹åˆ·æ£€æµ‹")
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'start_time': datetime.now(),
            'total_records': len(self.df_valid),
            'total_periods': self.df_valid['æœŸå·'].nunique(),
            'total_accounts': self.df_valid['ä¼šå‘˜è´¦å·'].nunique()
        }
        
        self.add_debug_info(f"æ•°æ®ç»Ÿè®¡: {len(self.df_valid)}è®°å½•, {self.df_valid['æœŸå·'].nunique()}æœŸå·, {self.df_valid['ä¼šå‘˜è´¦å·'].nunique()}è´¦æˆ·")
        
        # æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨
        df_filtered = self.exclude_multi_direction_accounts(self.df_valid)
        self.add_debug_info(f"è¿‡æ»¤å¤šæ–¹å‘ä¸‹æ³¨å: {len(df_filtered)}è®°å½•")
        
        if len(df_filtered) == 0:
            st.error("âŒ è¿‡æ»¤åæ— æœ‰æ•ˆæ•°æ®")
            return []
        
        # æ˜¾ç¤ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_patterns = []
        total_steps = self.config.max_accounts_in_group - 1
        
        # æ£€æµ‹ä¸åŒè´¦æˆ·æ•°é‡çš„å¯¹åˆ·
        for account_count in range(2, self.config.max_accounts_in_group + 1):
            status_text.text(f"ğŸ” æ£€æµ‹{account_count}ä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼...")
            self.add_debug_info(f"å¼€å§‹æ£€æµ‹{account_count}è´¦æˆ·ç»„åˆ")
            
            patterns = self.detect_n_account_patterns(df_filtered, account_count)
            self.add_debug_info(f"å‘ç°{account_count}è´¦æˆ·å¯¹åˆ·è®°å½•: {len(patterns)}æ¡")
            
            all_patterns.extend(patterns)
            
            # æ›´æ–°è¿›åº¦
            progress = (account_count - 1) / total_steps
            progress_bar.progress(progress)
        
        # å®Œæˆè¿›åº¦
        progress_bar.progress(1.0)
        status_text.text("âœ… æ£€æµ‹å®Œæˆ")
        
        # è®°å½•æ€§èƒ½ç»Ÿè®¡
        self.performance_stats['end_time'] = datetime.now()
        self.performance_stats['detection_time'] = (
            self.performance_stats['end_time'] - self.performance_stats['start_time']
        ).total_seconds()
        self.performance_stats['total_patterns'] = len(all_patterns)
        
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        self.display_debug_info()
        
        # æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡
        self.display_performance_stats()
        
        return all_patterns
    
    def detect_n_account_patterns(self, df_filtered, n_accounts):
        """æ£€æµ‹Nä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼ - è¯Šæ–­ç‰ˆæœ¬"""
        wash_records = []
        
        # æŒ‰æœŸå·å’Œå½©ç§åˆ†ç»„
        period_groups = df_filtered.groupby(['æœŸå·', 'å½©ç§'])
        total_periods = len(period_groups)
        processed_periods = 0
        
        self.add_debug_info(f"å¼€å§‹å¤„ç†{total_periods}ä¸ªæœŸå·ç»„")
        
        for (period, lottery), period_data in period_groups:
            processed_periods += 1
            if processed_periods % 1000 == 0:  # æ¯1000æœŸè¾“å‡ºä¸€æ¬¡è¿›åº¦
                self.add_debug_info(f"å·²å¤„ç†{processed_periods}/{total_periods}æœŸå·")
            
            period_accounts = period_data['ä¼šå‘˜è´¦å·'].unique()
            
            if len(period_accounts) < n_accounts:
                continue
            
            account_combinations = list(combinations(period_accounts, n_accounts))
            self.add_debug_info(f"æœŸå·{period}æœ‰{len(period_accounts)}è´¦æˆ·ï¼Œç”Ÿæˆ{len(account_combinations)}ä¸ªç»„åˆ")
            
            for account_group in account_combinations:
                group_data = period_data[period_data['ä¼šå‘˜è´¦å·'].isin(account_group)]
                if len(group_data) != n_accounts:
                    continue
                
                # æ£€æŸ¥æ–¹å‘ä¸€è‡´æ€§
                result = self._check_direction_consistency(group_data)
                if not result['valid']:
                    continue
                
                opposite_type = result['opposite_type']
                dir1, dir2 = opposite_type.split('-')
                
                # è®¡ç®—ä¸¤ä¸ªæ–¹å‘çš„æ€»é‡‘é¢
                dir1_total = group_data[group_data['æŠ•æ³¨æ–¹å‘'] == dir1]['æŠ•æ³¨é‡‘é¢'].sum()
                dir2_total = group_data[group_data['æŠ•æ³¨æ–¹å‘'] == dir2]['æŠ•æ³¨é‡‘é¢'].sum()
                
                if dir1_total == 0 or dir2_total == 0:
                    continue
                
                similarity = min(dir1_total, dir2_total) / max(dir1_total, dir2_total)
                
                if similarity >= self.config.amount_similarity_threshold:
                    direction_counts = group_data['æŠ•æ³¨æ–¹å‘'].value_counts()
                    dir1_count = direction_counts.get(dir1, 0)
                    dir2_count = direction_counts.get(dir2, 0)
                    
                    record = {
                        'æœŸå·': period,
                        'å½©ç§': lottery,
                        'è´¦æˆ·ç»„': list(account_group),
                        'æ–¹å‘ç»„': group_data['æŠ•æ³¨æ–¹å‘'].tolist(),
                        'é‡‘é¢ç»„': group_data['æŠ•æ³¨é‡‘é¢'].tolist(),
                        'æ€»é‡‘é¢': dir1_total + dir2_total,
                        'ç›¸ä¼¼åº¦': similarity,
                        'è´¦æˆ·æ•°é‡': n_accounts,
                        'æ¨¡å¼': f"{dir1}({dir1_count}ä¸ª) vs {dir2}({dir2_count}ä¸ª)",
                        'å¯¹ç«‹ç±»å‹': opposite_type
                    }
                    
                    wash_records.append(record)
        
        self.add_debug_info(f"å‘ç°{len(wash_records)}æ¡å¯¹åˆ·è®°å½•")
        return self.find_continuous_patterns_diagnostic(wash_records)
    
    def find_continuous_patterns_diagnostic(self, wash_records):
        """è¯Šæ–­ç‰ˆæœ¬çš„è¿ç»­å¯¹åˆ·æ¨¡å¼æ£€æµ‹"""
        if not wash_records:
            self.add_debug_info("æ²¡æœ‰å¯¹åˆ·è®°å½•éœ€è¦å¤„ç†")
            return []
        
        self.add_debug_info(f"å¼€å§‹å¤„ç†{len(wash_records)}æ¡å¯¹åˆ·è®°å½•")
        
        # ä½¿ç”¨å­—å…¸è¿›è¡Œå¿«é€Ÿåˆ†ç»„
        account_group_patterns = defaultdict(list)
        for record in wash_records:
            account_group_key = (tuple(sorted(record['è´¦æˆ·ç»„'])), record['å½©ç§'])
            account_group_patterns[account_group_key].append(record)
        
        self.add_debug_info(f"å‘ç°{len(account_group_patterns)}ä¸ªè´¦æˆ·ç»„")
        
        continuous_patterns = []
        excluded_groups = []
        
        for (account_group, lottery), records in account_group_patterns.items():
            # æŒ‰æœŸå·æ’åº
            sorted_records = sorted(records, key=lambda x: x['æœŸå·'])
            
            # æ£€æŸ¥æ´»è·ƒåº¦å·®å¼‚
            exclude_due_to_disparity, disparity_reason = self.should_exclude_due_to_activity_disparity(account_group, lottery)
            if exclude_due_to_disparity:
                excluded_groups.append({
                    'è´¦æˆ·ç»„': account_group,
                    'å½©ç§': lottery,
                    'åŸå› ': disparity_reason,
                    'æœŸæ•°': len(sorted_records)
                })
                continue
            
            # æ ¹æ®ä¸‰æ¡£æ´»è·ƒåº¦ç¡®å®šæœ€å°å¯¹åˆ·æœŸæ•°è¦æ±‚
            required_min_periods = self.get_required_min_periods(account_group, lottery)
            activity_level = self.get_account_group_activity_level(account_group, lottery)
            
            self.add_debug_info(f"è´¦æˆ·ç»„{account_group} æ´»è·ƒåº¦:{activity_level} è¦æ±‚æœŸæ•°:{required_min_periods} å®é™…æœŸæ•°:{len(sorted_records)}")
            
            if len(sorted_records) >= required_min_periods:
                # ä½¿ç”¨å‘é‡åŒ–è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
                total_investment = sum(r['æ€»é‡‘é¢'] for r in sorted_records)
                similarities = [r['ç›¸ä¼¼åº¦'] for r in sorted_records]
                avg_similarity = np.mean(similarities) if similarities else 0
                
                # åˆ†æå¯¹ç«‹ç±»å‹åˆ†å¸ƒ
                opposite_type_counts = defaultdict(int)
                for record in sorted_records:
                    opposite_type_counts[record['å¯¹ç«‹ç±»å‹']] += 1
                
                # åˆ†ææ¨¡å¼åˆ†å¸ƒ
                pattern_count = defaultdict(int)
                for record in sorted_records:
                    pattern_count[record['æ¨¡å¼']] += 1
                
                # ä¸»è¦å¯¹ç«‹ç±»å‹
                main_opposite_type = max(opposite_type_counts.items(), key=lambda x: x[1])[0]
                
                # è·å–è´¦æˆ·ç»„åœ¨æŒ‡å®šå½©ç§çš„æŠ•æ³¨æœŸæ•°ä¿¡æ¯
                lottery_stats = self.account_period_stats_by_lottery.get(lottery, {})
                record_stats = self.account_record_stats_by_lottery.get(lottery, {})
                account_periods_info = []
                for account in account_group:
                    periods = lottery_stats.get(account, 0)
                    records_count = record_stats.get(account, 0)
                    account_periods_info.append(f"{account}({periods}æœŸ/{records_count}è®°å½•)")
                
                continuous_patterns.append({
                    'è´¦æˆ·ç»„': list(account_group),
                    'å½©ç§': lottery,
                    'è´¦æˆ·æ•°é‡': len(account_group),
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': main_opposite_type,
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': dict(opposite_type_counts),
                    'æ€»æœŸæ•°': len(sorted_records),
                    'æ€»æŠ•æ³¨é‡‘é¢': total_investment,
                    'å¹³å‡ç›¸ä¼¼åº¦': avg_similarity,
                    'æ¨¡å¼åˆ†å¸ƒ': dict(pattern_count),
                    'è¯¦ç»†è®°å½•': sorted_records,
                    'è´¦æˆ·æ´»è·ƒåº¦': activity_level,
                    'è´¦æˆ·æŠ•æ³¨æœŸæ•°': account_periods_info,
                    'æœ€å°æŠ•æ³¨æœŸæ•°': min(lottery_stats.get(account, 0) for account in account_group),
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': required_min_periods,
                    'æ´»è·ƒåº¦å·®å¼‚æ£€æŸ¥': disparity_reason
                })
                self.add_debug_info(f"âœ… æ¥å—è´¦æˆ·ç»„{account_group}: {len(sorted_records)}æœŸ")
            else:
                self.add_debug_info(f"âŒ æ‹’ç»è´¦æˆ·ç»„{account_group}: åªæœ‰{len(sorted_records)}æœŸï¼Œè¦æ±‚{required_min_periods}æœŸ")
        
        # æ˜¾ç¤ºè¢«æ’é™¤çš„ç»„
        if excluded_groups:
            self.add_debug_info(f"å› æ´»è·ƒåº¦å·®å¼‚æ’é™¤äº†{len(excluded_groups)}ä¸ªç»„")
            for excluded in excluded_groups[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                self.add_debug_info(f"  æ’é™¤: {excluded['è´¦æˆ·ç»„']} - {excluded['åŸå› ']}")
        
        self.add_debug_info(f"æœ€ç»ˆå‘ç°{len(continuous_patterns)}ä¸ªè¿ç»­å¯¹åˆ·æ¨¡å¼")
        return continuous_patterns
    
    def display_debug_info(self):
        """æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯"""
        if not self.debug_info:
            return
        
        with st.expander("ğŸ› è°ƒè¯•ä¿¡æ¯", expanded=True):
            st.write("### æ£€æµ‹è¿‡ç¨‹è¯¦æƒ…")
            for info in self.debug_info[-50:]:  # åªæ˜¾ç¤ºæœ€å50æ¡
                st.write(f"`{info}`")
    
    def display_detailed_results(self, patterns):
        """æ˜¾ç¤ºè¯¦ç»†æ£€æµ‹ç»“æœ - ç®€åŒ–ç‰ˆæœ¬"""
        st.write("\n" + "="*60)
        st.write("ğŸ¯ å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç»“æœ")
        st.write("="*60)
        
        if not patterns:
            st.error("âŒ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„è¿ç»­å¯¹åˆ·æ¨¡å¼")
            
            # æä¾›è¯Šæ–­å»ºè®®
            st.info("""
            **ğŸ’¡ è¯Šæ–­å»ºè®®:**
            1. æ£€æŸ¥æ•°æ®æ˜¯å¦åŒ…å«æœ‰æ•ˆçš„å¯¹åˆ·è¡Œä¸º
            2. å°è¯•è°ƒæ•´æ£€æµ‹å‚æ•°ï¼ˆé™ä½é˜ˆå€¼ï¼‰
            3. æŸ¥çœ‹è°ƒè¯•ä¿¡æ¯äº†è§£æ£€æµ‹è¿‡ç¨‹
            4. ç¡®è®¤æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®
            """)
            return
        
        # æ˜¾ç¤ºå‘ç°çš„å¯¹åˆ·ç»„
        st.success(f"âœ… å‘ç° {len(patterns)} ä¸ªå¯¹åˆ·ç»„")
        
        for i, pattern in enumerate(patterns, 1):
            with st.expander(f"å¯¹åˆ·ç»„ {i}: {' â†” '.join(pattern['è´¦æˆ·ç»„'])}", expanded=True):
                st.write(f"**æ´»è·ƒåº¦:** {pattern['è´¦æˆ·æ´»è·ƒåº¦']}")
                st.write(f"**å½©ç§:** {pattern['å½©ç§']}")
                st.write(f"**ä¸»è¦ç±»å‹:** {pattern['ä¸»è¦å¯¹ç«‹ç±»å‹']}")
                st.write(f"**æœŸæ•°:** {pattern['æ€»æœŸæ•°']}æœŸ (è¦æ±‚â‰¥{pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°']}æœŸ)")
                st.write(f"**æ€»é‡‘é¢:** {pattern['æ€»æŠ•æ³¨é‡‘é¢']:.2f}å…ƒ")
                st.write(f"**å¹³å‡åŒ¹é…:** {pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}")
                
                # æ˜¾ç¤ºè´¦æˆ·ç»Ÿè®¡
                st.write("**è´¦æˆ·ç»Ÿè®¡:**")
                for account_info in pattern['è´¦æˆ·æŠ•æ³¨æœŸæ•°']:
                    st.write(f"- {account_info}")
                
                # æ˜¾ç¤ºå‰5æ¡è¯¦ç»†è®°å½•
                st.write("**å‰5æ¡å¯¹åˆ·è®°å½•:**")
                for j, record in enumerate(pattern['è¯¦ç»†è®°å½•'][:5], 1):
                    account_directions = [f"{acc}({dir}:{amt})" for acc, dir, amt in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„'])]
                    st.write(f"{j}. æœŸå·:{record['æœŸå·']} | åŒ¹é…åº¦:{record['ç›¸ä¼¼åº¦']:.2%}")
                    st.write(f"   æ–¹å‘:{' â†” '.join(account_directions)}")

def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ¯ å¿«ä¸‰å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿï¼ˆè¯Šæ–­ç‰ˆï¼‰")
    st.markdown("---")
    
    # ä¾§è¾¹æ é…ç½® - ä½¿ç”¨å®½æ¾çš„é»˜è®¤å€¼
    st.sidebar.header("âš™ï¸ æ£€æµ‹å‚æ•°é…ç½®")
    
    st.sidebar.info("ğŸ’¡ ä½¿ç”¨å®½æ¾å‚æ•°è¿›è¡Œè¯Šæ–­")
    
    min_amount = st.sidebar.number_input("æœ€å°æŠ•æ³¨é‡‘é¢", value=1, min_value=1, help="è¯Šæ–­æ—¶ä½¿ç”¨è¾ƒä½å€¼")
    similarity_threshold = st.sidebar.slider("é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼", 0.5, 1.0, 0.8, 0.05, help="è¯Šæ–­æ—¶ä½¿ç”¨è¾ƒä½é˜ˆå€¼")
    max_accounts = st.sidebar.slider("æœ€å¤§æ£€æµ‹è´¦æˆ·æ•°", 2, 8, 5, help="æ£€æµ‹çš„æœ€å¤§è´¦æˆ·ç»„åˆæ•°é‡")
    
    # å®½æ¾çš„é˜ˆå€¼é…ç½®
    st.sidebar.subheader("ğŸ¯ å®½æ¾é˜ˆå€¼é…ç½®ï¼ˆè¯Šæ–­ç”¨ï¼‰")
    low_activity_max = st.sidebar.number_input("ä½æ´»è·ƒåº¦ä¸Šé™(æœŸ)", value=100, min_value=10, help="è¯Šæ–­æ—¶ä½¿ç”¨è¾ƒé«˜å€¼")
    medium1_activity_min = st.sidebar.number_input("ä¸­æ´»è·ƒåº¦1ä¸‹é™(æœŸ)", value=101, min_value=11, help="è¯Šæ–­æ—¶ä½¿ç”¨è¾ƒé«˜å€¼")
    medium1_activity_max = st.sidebar.number_input("ä¸­æ´»è·ƒåº¦1ä¸Šé™(æœŸ)", value=500, min_value=50, help="è¯Šæ–­æ—¶ä½¿ç”¨è¾ƒé«˜å€¼")
    medium2_activity_min = st.sidebar.number_input("ä¸­æ´»è·ƒåº¦2ä¸‹é™(æœŸ)", value=501, min_value=51, help="è¯Šæ–­æ—¶ä½¿ç”¨è¾ƒé«˜å€¼")
    
    # æœ€å°å¯¹åˆ·æœŸæ•°è¦æ±‚ - ä½¿ç”¨è¾ƒä½å€¼
    st.sidebar.subheader("ğŸ“Š æœ€å°å¯¹åˆ·æœŸæ•°è¦æ±‚")
    min_periods_low = st.sidebar.number_input("ä½æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=2, min_value=1, help="è¯Šæ–­æ—¶ä½¿ç”¨è¾ƒä½å€¼")
    min_periods_medium1 = st.sidebar.number_input("ä¸­æ´»è·ƒåº¦1æœ€å°å¯¹åˆ·æœŸæ•°", value=2, min_value=1, help="è¯Šæ–­æ—¶ä½¿ç”¨è¾ƒä½å€¼")
    min_periods_medium2 = st.sidebar.number_input("ä¸­æ´»è·ƒåº¦2æœ€å°å¯¹åˆ·æœŸæ•°", value=2, min_value=1, help="è¯Šæ–­æ—¶ä½¿ç”¨è¾ƒä½å€¼")
    
    # æ´»è·ƒåº¦å·®å¼‚æ£€æŸ¥ - æ”¾å®½é™åˆ¶
    st.sidebar.subheader("ğŸ” æ´»è·ƒåº¦å·®å¼‚æ£€æŸ¥")
    max_period_difference = st.sidebar.number_input("æœ€å¤§æœŸæ•°å·®å¼‚", value=1000, min_value=100, help="è¯Šæ–­æ—¶æ”¾å®½é™åˆ¶")
    
    # æ–‡ä»¶ä¸Šä¼ 
    st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.file_uploader(
        "è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶ (æ”¯æŒ .xlsx, .xls, .csv)", 
        type=['xlsx', 'xls', 'csv'],
        help="è¯·ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—ï¼šä¼šå‘˜è´¦å·ã€æœŸå·ã€å†…å®¹ã€é‡‘é¢"
    )
    
    if uploaded_file is not None:
        try:
            # æ›´æ–°é…ç½®å‚æ•° - ä½¿ç”¨å®½æ¾å€¼
            config = Config()
            config.min_amount = min_amount
            config.amount_similarity_threshold = similarity_threshold
            config.max_accounts_in_group = max_accounts
            config.period_thresholds = {
                'low_activity_max': low_activity_max,
                'medium1_activity_min': medium1_activity_min,
                'medium1_activity_max': medium1_activity_max,
                'medium2_activity_min': medium2_activity_min,
                'min_periods_low': min_periods_low,
                'min_periods_medium1': min_periods_medium1,
                'min_periods_medium2': min_periods_medium2,
                'max_period_difference': max_period_difference
            }
            
            detector = WashTradeDetector(config)
            
            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            st.success(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
            
            # è§£ææ•°æ®
            with st.spinner("ğŸ”„ æ­£åœ¨è§£ææ•°æ®..."):
                df, filename = detector.upload_and_process(uploaded_file)
                if df is not None:
                    df_valid = detector.parse_column_data(df)
                    
                    if len(df_valid) > 0:
                        st.success("âœ… æ•°æ®è§£æå®Œæˆ")
                        
                        # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
                        with st.expander("ğŸ“Š æ•°æ®ç»Ÿè®¡", expanded=True):
                            st.write(f"æœ‰æ•ˆè®°å½•æ•°: {len(df_valid):,}")
                            st.write(f"å”¯ä¸€æœŸå·æ•°: {df_valid['æœŸå·'].nunique():,}")
                            st.write(f"å”¯ä¸€è´¦æˆ·æ•°: {df_valid['ä¼šå‘˜è´¦å·'].nunique():,}")
                            
                            # æ˜¾ç¤ºå‰10ä¸ªè´¦æˆ·
                            st.write("**å‰10ä¸ªè´¦æˆ·è®°å½•æ•°:**")
                            account_counts = df_valid['ä¼šå‘˜è´¦å·'].value_counts().head(10)
                            for account, count in account_counts.items():
                                st.write(f"- {account}: {count}æ¡è®°å½•")
                        
                        # æ£€æµ‹å¯¹åˆ·äº¤æ˜“
                        if st.button("ğŸš€ å¼€å§‹è¯Šæ–­æ£€æµ‹", type="primary"):
                            with st.spinner("ğŸ” æ­£åœ¨æ£€æµ‹å¯¹åˆ·äº¤æ˜“..."):
                                patterns = detector.detect_all_wash_trades()
                            
                            # æ˜¾ç¤ºç»“æœ
                            detector.display_detailed_results(patterns)
                            
                    else:
                        st.error("âŒ æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
            
        except Exception as e:
            st.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
            st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– è¯Šæ–­è¯´æ˜", expanded=True):
        st.markdown("""
        ### è¯Šæ–­æ¨¡å¼è¯´æ˜
        
        **ğŸ” å½“å‰é—®é¢˜ï¼š** å®Œå–„åæ£€æµ‹ä¸åˆ°å¯¹åˆ·è¡Œä¸º
        
        **ğŸ’¡ è¯Šæ–­æ–¹æ¡ˆï¼š**
        1. **ä½¿ç”¨å®½æ¾å‚æ•°**ï¼šé™ä½æ‰€æœ‰é˜ˆå€¼é™åˆ¶
        2. **æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—**ï¼šæŸ¥çœ‹æ£€æµ‹è¿‡ç¨‹çš„æ¯ä¸€æ­¥
        3. **æä¾›è¯Šæ–­å»ºè®®**ï¼šæ ¹æ®ç»“æœç»™å‡ºè°ƒæ•´å»ºè®®
        
        **ğŸ¯ è¯Šæ–­æ­¥éª¤ï¼š**
        1. ä¸Šä¼ æ‚¨çš„æµ‹è¯•æ–‡ä»¶
        2. ç‚¹å‡»"å¼€å§‹è¯Šæ–­æ£€æµ‹"
        3. æŸ¥çœ‹è°ƒè¯•ä¿¡æ¯äº†è§£æ£€æµ‹è¿‡ç¨‹
        4. æ ¹æ®ç»“æœè°ƒæ•´å‚æ•°
        
        **âš™ï¸ å½“å‰ä½¿ç”¨çš„å®½æ¾å‚æ•°ï¼š**
        - æœ€å°æŠ•æ³¨é‡‘é¢: 1å…ƒ
        - åŒ¹é…åº¦é˜ˆå€¼: 80%
        - æœ€å°å¯¹åˆ·æœŸæ•°: 2æœŸ
        - æ´»è·ƒåº¦å·®å¼‚: å…è®¸1000æœŸå·®å¼‚
        
        å¦‚æœè¿™æ ·èƒ½æ£€æµ‹åˆ°å¯¹åˆ·ï¼Œè¯´æ˜ä¹‹å‰çš„é˜ˆå€¼è®¾ç½®è¿‡äºä¸¥æ ¼ã€‚
        """)

if __name__ == "__main__":
    main()
