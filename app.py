import pandas as pd
import numpy as np
import streamlit as st
import io
import re
import logging
from collections import defaultdict
from datetime import datetime
from itertools import combinations
import warnings
import traceback

# é…ç½®æ—¥å¿—å’Œè­¦å‘Š
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('K3WashTrade')

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¿«ä¸‰å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

print("=== ğŸ¯ å¿«ä¸‰å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿï¼ˆå¤šæ ¼å¼å…¼å®¹ç‰ˆï¼‰===")
print("=" * 50)

class Config:
    """é…ç½®å‚æ•°ç±»"""
    def __init__(self):
        self.min_amount = 10
        self.amount_similarity_threshold = 0.9
        self.min_continuous_periods = 3
        self.max_accounts_in_group = 5
        self.supported_file_types = ['.xlsx', '.xls', '.csv']
        
        # åˆ—åæ˜ å°„é…ç½®
        self.column_mappings = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢']
        }
        
        # æ–°å¢ï¼šæ ¹æ®è´¦æˆ·æŠ•æ³¨æœŸæ•°è®¾ç½®ä¸åŒçš„å¯¹åˆ·æœŸæ•°é˜ˆå€¼
        self.period_thresholds = {
            'low_activity': 10,  # ä½æ´»è·ƒåº¦è´¦æˆ·é˜ˆå€¼
            'min_periods_low': 3,   # ä½æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
            'min_periods_high': 5   # é«˜æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
        }
        
        self.direction_patterns = {
            'å°': ['ä¸¤é¢-å°', 'å’Œå€¼-å°', 'å°', 'small', 'xia'],
            'å¤§': ['ä¸¤é¢-å¤§', 'å’Œå€¼-å¤§', 'å¤§', 'big', 'da'], 
            'å•': ['ä¸¤é¢-å•', 'å’Œå€¼-å•', 'å•', 'odd', 'dan'],
            'åŒ': ['ä¸¤é¢-åŒ', 'å’Œå€¼-åŒ', 'åŒ', 'even', 'shuang']
        }
        
        self.opposite_groups = [{'å¤§', 'å°'}, {'å•', 'åŒ'}]

class WashTradeDetector:
    def __init__(self, config=None):
        self.config = config or Config()
        self.data_processed = False
        self.df_valid = None
        self.export_data = []
        # ä¿®æ”¹ï¼šæŒ‰å½©ç§å­˜å‚¨è´¦æˆ·æŠ•æ³¨æœŸæ•°ç»Ÿè®¡
        self.account_period_stats_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)  # æ–°å¢ï¼šè®°å½•æ•°ç»Ÿè®¡
        self.column_mapping_used = {}  # è®°å½•ä½¿ç”¨çš„åˆ—åæ˜ å°„
    
    def upload_and_process(self, uploaded_file):
        """ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶"""
        try:
            if uploaded_file is None:
                st.error("âŒ æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
                return None, None
            
            filename = uploaded_file.name
            logger.info(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {filename}")
            
            if not any(filename.endswith(ext) for ext in self.config.supported_file_types):
                st.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
                return None, None
            
            if filename.endswith('.csv'):
                df = pd.read_csv(uploaded_file, encoding='utf-8')
            else:
                df = pd.read_excel(uploaded_file)
            
            logger.info(f"åŸå§‹æ•°æ®ç»´åº¦: {df.shape}")
            st.info(f"åŸå§‹æ•°æ®åˆ—å: {df.columns.tolist()}")
            
            return df, filename
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            return None, None
    
    def map_columns(self, df):
        """æ˜ å°„åˆ—ååˆ°æ ‡å‡†æ ¼å¼"""
        st.write("\nğŸ”„ å¼€å§‹åˆ—åæ˜ å°„...")
        
        # åˆ›å»ºåå‘æ˜ å°„ï¼šä»å¯èƒ½çš„åˆ—ååˆ°æ ‡å‡†åˆ—å
        reverse_mapping = {}
        for standard_col, possible_cols in self.config.column_mappings.items():
            for col in possible_cols:
                reverse_mapping[col] = standard_col
        
        # æŸ¥æ‰¾åŒ¹é…çš„åˆ—
        column_mapping = {}
        used_columns = set()
        
        for df_col in df.columns:
            df_col_clean = str(df_col).strip()
            
            # å°è¯•å®Œå…¨åŒ¹é…
            if df_col_clean in reverse_mapping:
                standard_col = reverse_mapping[df_col_clean]
                if standard_col not in used_columns:
                    column_mapping[df_col] = standard_col
                    used_columns.add(standard_col)
                    st.write(f"  âœ… åˆ—æ˜ å°„: '{df_col}' -> '{standard_col}'")
                continue
            
            # å°è¯•éƒ¨åˆ†åŒ¹é…
            for possible_col in reverse_mapping.keys():
                if possible_col in df_col_clean:
                    standard_col = reverse_mapping[possible_col]
                    if standard_col not in used_columns:
                        column_mapping[df_col] = standard_col
                        used_columns.add(standard_col)
                        st.write(f"  âœ… åˆ—æ˜ å°„: '{df_col}' -> '{standard_col}'")
                    break
        
        # é‡å‘½ååˆ—
        if column_mapping:
            df_renamed = df.rename(columns=column_mapping)
            self.column_mapping_used = column_mapping
            st.success(f"âœ… åˆ—åæ˜ å°„å®Œæˆï¼Œä½¿ç”¨äº† {len(column_mapping)} ä¸ªæ˜ å°„")
            return df_renamed
        else:
            st.warning("âŒ æ— æ³•è¯†åˆ«åˆ—åæ ¼å¼ï¼Œä½¿ç”¨åŸå§‹åˆ—å")
            return df
    
    def check_required_columns(self, df):
        """æ£€æŸ¥å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨"""
        required_cols = ['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å†…å®¹', 'é‡‘é¢']
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            st.error(f"âŒ ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
            st.write("å¯ç”¨çš„åˆ—:", df.columns.tolist())
            return False
        
        # æ£€æŸ¥å½©ç§åˆ—ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»º
        if 'å½©ç§' not in df.columns:
            df['å½©ç§'] = 'æœªçŸ¥å½©ç§'
            st.warning("âš ï¸ æœªæ‰¾åˆ°å½©ç§åˆ—ï¼Œå·²æ·»åŠ é»˜è®¤å½©ç§åˆ—")
        
        st.success(f"âœ… å¿…è¦åˆ—æ£€æŸ¥é€šè¿‡")
        return True
    
    def parse_column_data(self, df):
        """è§£æåˆ—ç»“æ„æ•°æ®"""
        st.write("\nå¼€å§‹è§£æåˆ—ç»“æ„æ•°æ®...")
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šåˆ—åæ˜ å°„
            df_mapped = self.map_columns(df)
            
            # ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥å¿…è¦åˆ—
            if not self.check_required_columns(df_mapped):
                return pd.DataFrame()
            
            # æ•°æ®æ¸…ç†
            df_clean = df_mapped[['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å†…å®¹', 'é‡‘é¢', 'å½©ç§']].copy()
            df_clean = df_clean.dropna(subset=['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å†…å®¹', 'é‡‘é¢'])
            
            # å¯¹æ¯ä¸ªåˆ—å•ç‹¬å¤„ç†
            for col in ['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å†…å®¹', 'å½©ç§']:
                if col in df_clean.columns:
                    df_clean[col] = df_clean[col].astype(str).str.strip()
            
            st.write(f"æ¸…æ´—åè®°å½•æ•°: {len(df_clean)}")
            
            # æå–æŠ•æ³¨é‡‘é¢
            df_clean['æŠ•æ³¨é‡‘é¢'] = df_clean['é‡‘é¢'].apply(lambda x: self.extract_bet_amount(x))
            
            # æå–æŠ•æ³¨æ–¹å‘
            df_clean['æŠ•æ³¨æ–¹å‘'] = df_clean['å†…å®¹'].apply(lambda x: self.extract_direction_from_content(x))
            
            # è¿‡æ»¤æœ‰æ•ˆè®°å½•
            df_valid = df_clean[
                (df_clean['æŠ•æ³¨æ–¹å‘'] != '') & 
                (df_clean['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
            ].copy()
            
            if len(df_valid) == 0:
                st.error("âŒ è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆè®°å½•")
                return pd.DataFrame()
            
            # ä¿®æ”¹ï¼šæŒ‰å½©ç§è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„æŠ•æ³¨æœŸæ•°ç»Ÿè®¡
            self.calculate_account_period_stats_by_lottery(df_valid)
            
            st.write(f"\n=== æ•°æ®ç»Ÿè®¡ ===")
            st.write(f"æ€»è®°å½•æ•°: {len(df_clean)}")
            st.write(f"æœ‰æ•ˆè®°å½•æ•°: {len(df_valid)}")
            st.write(f"å”¯ä¸€æœŸå·æ•°: {df_valid['æœŸå·'].nunique()}")
            st.write(f"å”¯ä¸€è´¦æˆ·æ•°: {df_valid['ä¼šå‘˜è´¦å·'].nunique()}")
            
            # å½©ç§åˆ†å¸ƒç»Ÿè®¡
            if len(df_valid) > 0:
                lottery_stats = df_valid['å½©ç§'].value_counts()
                st.write(f"å½©ç§åˆ†å¸ƒ: {dict(lottery_stats)}")
            
            # æ–¹å‘åˆ†å¸ƒç»Ÿè®¡
            if len(df_valid) > 0:
                direction_stats = df_valid['æŠ•æ³¨æ–¹å‘'].value_counts()
                st.write(f"æŠ•æ³¨æ–¹å‘åˆ†å¸ƒ: {dict(direction_stats)}")
            
            # æ–°å¢ï¼šæ˜¾ç¤ºè´¦æˆ·æŠ•æ³¨æœŸæ•°åˆ†å¸ƒï¼ˆæŒ‰å½©ç§ï¼‰
            self.display_account_period_distribution_by_lottery()
            
            # æ–°å¢ï¼šæ˜¾ç¤ºè¯¦ç»†è´¦æˆ·ç»Ÿè®¡ï¼ˆè°ƒè¯•ç”¨ï¼‰
            self.display_detailed_account_stats()
            
            self.data_processed = True
            self.df_valid = df_valid
            return df_valid
            
        except Exception as e:
            logger.error(f"æ•°æ®è§£æå¤±è´¥: {str(e)}")
            st.error(f"æ•°æ®è§£æå¤±è´¥: {str(e)}")
            st.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return pd.DataFrame()
    
    def calculate_account_period_stats_by_lottery(self, df_valid):
        """æŒ‰å½©ç§è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„æŠ•æ³¨æœŸæ•°ç»Ÿè®¡ - ä¿®å¤ç‰ˆæœ¬"""
        st.write("\nğŸ“Š æŒ‰å½©ç§è®¡ç®—è´¦æˆ·æŠ•æ³¨æœŸæ•°ç»Ÿè®¡...")
        
        # é‡ç½®ç»Ÿè®¡å­—å…¸
        self.account_period_stats_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        
        # æŒ‰å½©ç§å’Œè´¦æˆ·åˆ†ç»„ï¼Œè®¡ç®—æ¯ä¸ªè´¦æˆ·åœ¨æ¯ä¸ªå½©ç§çš„æŠ•æ³¨æœŸæ•°å’Œè®°å½•æ•°
        for lottery in df_valid['å½©ç§'].unique():
            df_lottery = df_valid[df_valid['å½©ç§'] == lottery]
            
            # è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„æŠ•æ³¨æœŸæ•°ï¼ˆå”¯ä¸€æœŸå·æ•°ï¼‰
            period_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·')['æœŸå·'].nunique().to_dict()
            self.account_period_stats_by_lottery[lottery] = period_counts
            
            # è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„è®°å½•æ•°
            record_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·').size().to_dict()
            self.account_record_stats_by_lottery[lottery] = record_counts
        
        # è®¡ç®—æ¯ä¸ªå½©ç§çš„ç»Ÿè®¡ä¿¡æ¯
        for lottery, period_stats in self.account_period_stats_by_lottery.items():
            total_accounts = len(period_stats)
            if total_accounts > 0:
                periods = list(period_stats.values())
                max_periods = max(periods)
                min_periods = min(periods)
                avg_periods = np.mean(periods)
                
                # è®¡ç®—è®°å½•æ•°ç»Ÿè®¡
                record_stats = self.account_record_stats_by_lottery[lottery]
                total_records = sum(record_stats.values())
                avg_records = total_records / total_accounts
                
                # è®¡ç®—ä¸åŒæ´»è·ƒåº¦è´¦æˆ·æ•°é‡
                low_activity = sum(1 for periods in period_stats.values() 
                                 if periods < self.config.period_thresholds['low_activity'])
                high_activity = total_accounts - low_activity
                
                st.write(f"\nğŸ² å½©ç§ '{lottery}' è´¦æˆ·ç»Ÿè®¡:")
                st.write(f"  æ€»è´¦æˆ·æ•°: {total_accounts}")
                st.write(f"  æ€»è®°å½•æ•°: {total_records}")
                st.write(f"  æœ€å¤§æŠ•æ³¨æœŸæ•°: {max_periods}")
                st.write(f"  æœ€å°æŠ•æ³¨æœŸæ•°: {min_periods}")
                st.write(f"  å¹³å‡æŠ•æ³¨æœŸæ•°: {avg_periods:.1f}")
                st.write(f"  å¹³å‡è®°å½•æ•°: {avg_records:.1f}")
                st.write(f"  ä½æ´»è·ƒè´¦æˆ·(<{self.config.period_thresholds['low_activity']}æœŸ): {low_activity}ä¸ª")
                st.write(f"  é«˜æ´»è·ƒè´¦æˆ·(â‰¥{self.config.period_thresholds['low_activity']}æœŸ): {high_activity}ä¸ª")
    
    def display_detailed_account_stats(self):
        """æ˜¾ç¤ºè¯¦ç»†è´¦æˆ·ç»Ÿè®¡ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        st.write("\nğŸ” è¯¦ç»†è´¦æˆ·ç»Ÿè®¡ï¼ˆå‰20ä¸ªè´¦æˆ·ï¼‰:")
        
        for lottery, period_stats in self.account_period_stats_by_lottery.items():
            st.write(f"\nğŸ¯ å½©ç§ '{lottery}':")
            
            # æŒ‰è®°å½•æ•°æ’åºï¼Œæ˜¾ç¤ºå‰20ä¸ªè´¦æˆ·
            record_stats = self.account_record_stats_by_lottery[lottery]
            sorted_accounts = sorted(record_stats.items(), key=lambda x: x[1], reverse=True)[:20]
            
            for account, record_count in sorted_accounts:
                period_count = period_stats.get(account, 0)
                st.write(f"  è´¦æˆ·: {account} | è®°å½•æ•°: {record_count} | æœŸæ•°: {period_count}")
    
    def display_account_period_distribution_by_lottery(self):
        """æŒ‰å½©ç§æ˜¾ç¤ºè´¦æˆ·æŠ•æ³¨æœŸæ•°åˆ†å¸ƒ"""
        if not self.account_period_stats_by_lottery:
            return
        
        # å®šä¹‰åˆ†å¸ƒåŒºé—´
        bins = [0, 3, 5, 10, 20, 30, 50, 100, 1000]
        bin_labels = ['1-3æœŸ', '4-5æœŸ', '6-10æœŸ', '11-20æœŸ', '21-30æœŸ', '31-50æœŸ', '51-100æœŸ', '100+æœŸ']
        
        for lottery, account_stats in self.account_period_stats_by_lottery.items():
            periods = list(account_stats.values())
            
            distribution = {}
            for i in range(len(bins) - 1):
                count = sum(1 for p in periods if bins[i] <= p < bins[i+1])
                if count > 0:
                    distribution[bin_labels[i]] = count
            
            if distribution:
                st.write(f"\nğŸ“ˆ å½©ç§ '{lottery}' è´¦æˆ·æŠ•æ³¨æœŸæ•°åˆ†å¸ƒ:")
                for range_label, count in distribution.items():
                    percentage = (count / len(periods)) * 100
                    st.write(f"  {range_label}: {count}ä¸ªè´¦æˆ· ({percentage:.1f}%)")
    
    def extract_bet_amount(self, amount_text):
        """ä»å¤æ‚æ–‡æœ¬ä¸­æå–æŠ•æ³¨é‡‘é¢"""
        try:
            if pd.isna(amount_text):
                return 0
            
            text = str(amount_text).strip()
            
            # å…ˆå°è¯•ç›´æ¥è½¬æ¢
            try:
                cleaned_text = text.replace(',', '').replace('ï¼Œ', '')
                amount = float(cleaned_text)
                if amount >= self.config.min_amount:
                    return amount
            except:
                pass
            
            # å¤šç§é‡‘é¢æå–æ¨¡å¼
            patterns = [
                r'æŠ•æ³¨[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'æŠ•æ³¨\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'é‡‘é¢[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'(\d+[,ï¼Œ]?\d*\.?\d*)\s*å…ƒ',
                r'ï¿¥\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'Â¥\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'(\d+[,ï¼Œ]?\d*\.?\d*)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text)
                if match:
                    amount_str = match.group(1).replace(',', '').replace('ï¼Œ', '')
                    try:
                        amount = float(amount_str)
                        if amount >= self.config.min_amount:
                            return amount
                    except:
                        continue
            
            return 0
        except Exception as e:
            logger.warning(f"é‡‘é¢æå–å¤±è´¥: {amount_text}, é”™è¯¯: {e}")
            return 0
    
    def extract_direction_from_content(self, content):
        """ä»å†…å®¹åˆ—æå–æŠ•æ³¨æ–¹å‘"""
        try:
            if pd.isna(content):
                return ""
            
            content_str = str(content).strip().lower()
            
            for direction, patterns in self.config.direction_patterns.items():
                for pattern in patterns:
                    if pattern.lower() in content_str:
                        return direction
            
            return ""
        except Exception as e:
            logger.warning(f"æ–¹å‘æå–å¤±è´¥: {content}, é”™è¯¯: {e}")
            return ""
    
    def detect_all_wash_trades(self):
        """æ£€æµ‹æ‰€æœ‰ç±»å‹çš„å¯¹åˆ·äº¤æ˜“"""
        if not self.data_processed or self.df_valid is None or len(self.df_valid) == 0:
            st.error("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ç”¨äºæ£€æµ‹")
            return []
        
        st.write(f"\n=== å¼€å§‹å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ (2-{self.config.max_accounts_in_group}ä¸ªè´¦æˆ·) ===")
        
        # æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨
        df_filtered = self.exclude_multi_direction_accounts(self.df_valid)
        
        if len(df_filtered) == 0:
            st.error("âŒ è¿‡æ»¤åæ— æœ‰æ•ˆæ•°æ®")
            return []
        
        all_patterns = []
        
        # æ£€æµ‹ä¸åŒè´¦æˆ·æ•°é‡çš„å¯¹åˆ·
        for account_count in range(2, self.config.max_accounts_in_group + 1):
            st.write(f"\nğŸ” æ£€æµ‹{account_count}ä¸ªè´¦æˆ·å¯¹åˆ·...")
            patterns = self.detect_n_account_patterns(df_filtered, account_count)
            all_patterns.extend(patterns)
            st.write(f"  å‘ç° {len(patterns)} ä¸ª{account_count}è´¦æˆ·å¯¹åˆ·ç»„")
        
        return all_patterns
    
    def exclude_multi_direction_accounts(self, df_valid):
        """æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨"""
        st.write("æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨...")
        multi_direction_accounts = set()
        
        account_period_groups = df_valid.groupby(['æœŸå·', 'ä¼šå‘˜è´¦å·'])
        for (period, account), group in account_period_groups:
            directions = group['æŠ•æ³¨æ–¹å‘'].unique()
            if len(directions) > 1:
                multi_direction_accounts.add((period, account))
        
        df_filtered = df_valid.copy()
        mask = df_filtered.apply(
            lambda row: (row['æœŸå·'], row['ä¼šå‘˜è´¦å·']) not in multi_direction_accounts, 
            axis=1
        )
        df_filtered = df_filtered[mask]
        
        st.write(f"è¿‡æ»¤åè®°å½•æ•°: {len(df_filtered)}")
        return df_filtered
    
    def detect_n_account_patterns(self, df_filtered, n_accounts):
        """æ£€æµ‹Nä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼"""
        wash_records = []
        
        # æŒ‰æœŸå·å’Œå½©ç§åˆ†ç»„
        period_groups = df_filtered.groupby(['æœŸå·', 'å½©ç§'])
        
        for (period, lottery), period_data in period_groups:
            period_accounts = period_data['ä¼šå‘˜è´¦å·'].unique()
            
            if len(period_accounts) < n_accounts:
                continue
            
            for account_group in combinations(period_accounts, n_accounts):
                group_data = period_data[period_data['ä¼šå‘˜è´¦å·'].isin(account_group)]
                if len(group_data) != n_accounts:
                    continue
                
                # æ£€æŸ¥æ–¹å‘ä¸€è‡´æ€§
                result = self._check_direction_consistency(group_data)
                if not result['valid']:
                    continue
                
                opposite_type = result['opposite_type']
                dir1, dir2 = opposite_type.split('-')
                
                # è®¡ç®—ä¸¤ä¸ªæ–¹å‘çš„æ€»é‡‘é¢
                dir1_total = group_data[group_data['æŠ•æ³¨æ–¹å‘'] == dir1]['æŠ•æ³¨é‡‘é¢'].sum()
                dir2_total = group_data[group_data['æŠ•æ³¨æ–¹å‘'] == dir2]['æŠ•æ³¨é‡‘é¢'].sum()
                
                if dir1_total == 0 or dir2_total == 0:
                    continue
                
                similarity = min(dir1_total, dir2_total) / max(dir1_total, dir2_total)
                
                if similarity >= self.config.amount_similarity_threshold:
                    direction_counts = group_data['æŠ•æ³¨æ–¹å‘'].value_counts()
                    dir1_count = direction_counts.get(dir1, 0)
                    dir2_count = direction_counts.get(dir2, 0)
                    
                    record = {
                        'æœŸå·': period,
                        'å½©ç§': lottery,
                        'è´¦æˆ·ç»„': list(account_group),
                        'æ–¹å‘ç»„': group_data['æŠ•æ³¨æ–¹å‘'].tolist(),
                        'é‡‘é¢ç»„': group_data['æŠ•æ³¨é‡‘é¢'].tolist(),
                        'æ€»é‡‘é¢': dir1_total + dir2_total,
                        'ç›¸ä¼¼åº¦': similarity,
                        'è´¦æˆ·æ•°é‡': n_accounts,
                        'æ¨¡å¼': f"{dir1}({dir1_count}ä¸ª) vs {dir2}({dir2_count}ä¸ª)",
                        'å¯¹ç«‹ç±»å‹': opposite_type
                    }
                    
                    wash_records.append(record)
        
        return self.find_continuous_patterns_corrected(wash_records)
    
    def _check_direction_consistency(self, group_data):
        """æ£€æŸ¥æ–¹å‘ä¸€è‡´æ€§"""
        direction_counts = group_data['æŠ•æ³¨æ–¹å‘'].value_counts()
        directions = set(direction_counts.index)
        
        for opposites in self.config.opposite_groups:
            if directions.issubset(opposites):
                opposite_type = f"{list(opposites)[0]}-{list(opposites)[1]}"
                return {
                    'valid': True,
                    'opposite_type': opposite_type,
                    'directions': directions
                }
        
        return {'valid': False}
    
    def get_account_group_activity_level(self, account_group, lottery):
        """è·å–è´¦æˆ·ç»„åœ¨ç‰¹å®šå½©ç§çš„æ´»è·ƒåº¦æ°´å¹³"""
        if lottery not in self.account_period_stats_by_lottery:
            return 'unknown'
        
        lottery_stats = self.account_period_stats_by_lottery[lottery]
        
        # è®¡ç®—è´¦æˆ·ç»„ä¸­åœ¨æŒ‡å®šå½©ç§çš„æœ€å°æŠ•æ³¨æœŸæ•°
        min_periods = min(lottery_stats.get(account, 0) for account in account_group)
        
        if min_periods < self.config.period_thresholds['low_activity']:
            return 'low'
        else:
            return 'high'
    
    def get_required_min_periods(self, account_group, lottery):
        """æ ¹æ®è´¦æˆ·ç»„åœ¨ç‰¹å®šå½©ç§çš„æ´»è·ƒåº¦è·å–æ‰€éœ€çš„æœ€å°å¯¹åˆ·æœŸæ•°"""
        activity_level = self.get_account_group_activity_level(account_group, lottery)
        
        if activity_level == 'low':
            return self.config.period_thresholds['min_periods_low']
        else:
            return self.config.period_thresholds['min_periods_high']
    
    def find_continuous_patterns_corrected(self, wash_records):
        """ä¿®å¤çš„è¿ç»­å¯¹åˆ·æ¨¡å¼æ£€æµ‹ - æŒ‰å½©ç§è®¡ç®—è´¦æˆ·æ´»è·ƒåº¦"""
        if not wash_records:
            return []
        
        # æŒ‰è´¦æˆ·ç»„å’Œå½©ç§åˆ†ç»„
        account_group_patterns = defaultdict(list)
        for record in wash_records:
            account_group_key = (tuple(sorted(record['è´¦æˆ·ç»„'])), record['å½©ç§'])
            account_group_patterns[account_group_key].append(record)
        
        continuous_patterns = []
        
        for (account_group, lottery), records in account_group_patterns.items():
            # æŒ‰æœŸå·æ’åº
            sorted_records = sorted(records, key=lambda x: x['æœŸå·'])
            
            # ä¿®æ”¹ï¼šæ ¹æ®è´¦æˆ·åœ¨ç‰¹å®šå½©ç§çš„æ´»è·ƒåº¦ç¡®å®šæœ€å°å¯¹åˆ·æœŸæ•°è¦æ±‚
            required_min_periods = self.get_required_min_periods(account_group, lottery)
            activity_level = self.get_account_group_activity_level(account_group, lottery)
            
            # åº”ç”¨æ–°çš„é˜ˆå€¼è§„åˆ™
            if len(sorted_records) >= required_min_periods:
                # ç»Ÿè®¡æ€»é‡‘é¢å’Œå¹³å‡ç›¸ä¼¼åº¦
                total_investment = sum(r['æ€»é‡‘é¢'] for r in sorted_records)
                avg_similarity = np.mean([r['ç›¸ä¼¼åº¦'] for r in sorted_records])
                
                # åˆ†æå¯¹ç«‹ç±»å‹åˆ†å¸ƒ
                opposite_type_counts = defaultdict(int)
                for record in sorted_records:
                    opposite_type_counts[record['å¯¹ç«‹ç±»å‹']] += 1
                
                # åˆ†ææ¨¡å¼åˆ†å¸ƒ
                patterns = [r['æ¨¡å¼'] for r in sorted_records]
                pattern_count = defaultdict(int)
                for pattern in patterns:
                    pattern_count[pattern] += 1
                
                # ä¸»è¦å¯¹ç«‹ç±»å‹
                main_opposite_type = max(opposite_type_counts.items(), key=lambda x: x[1])[0]
                
                # è·å–è´¦æˆ·ç»„åœ¨æŒ‡å®šå½©ç§çš„æŠ•æ³¨æœŸæ•°ä¿¡æ¯
                lottery_stats = self.account_period_stats_by_lottery.get(lottery, {})
                record_stats = self.account_record_stats_by_lottery.get(lottery, {})
                account_periods_info = []
                for account in account_group:
                    periods = lottery_stats.get(account, 0)
                    records_count = record_stats.get(account, 0)
                    account_periods_info.append(f"{account}({periods}æœŸ/{records_count}è®°å½•)")
                
                continuous_patterns.append({
                    'è´¦æˆ·ç»„': list(account_group),
                    'å½©ç§': lottery,
                    'è´¦æˆ·æ•°é‡': len(account_group),
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': main_opposite_type,
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': dict(opposite_type_counts),
                    'æ€»æœŸæ•°': len(sorted_records),
                    'æ€»æŠ•æ³¨é‡‘é¢': total_investment,
                    'å¹³å‡ç›¸ä¼¼åº¦': avg_similarity,
                    'æ¨¡å¼åˆ†å¸ƒ': dict(pattern_count),
                    'è¯¦ç»†è®°å½•': sorted_records,
                    # ä¿®æ”¹å­—æ®µï¼šæŒ‰å½©ç§è®¡ç®—
                    'è´¦æˆ·æ´»è·ƒåº¦': activity_level,
                    'è´¦æˆ·æŠ•æ³¨æœŸæ•°': account_periods_info,
                    'æœ€å°æŠ•æ³¨æœŸæ•°': min(lottery_stats.get(account, 0) for account in account_group),
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': required_min_periods
                })
                
                st.write(f"  ğŸ¯ å‘ç°å¯¹åˆ·ç»„: {len(account_group)}è´¦æˆ·ç»„[{activity_level}æ´»è·ƒ] å½©ç§:{lottery} æ€»{len(sorted_records)}æœŸ(è¦æ±‚â‰¥{required_min_periods}æœŸ) æ€»é‡‘é¢:{total_investment:.2f}")
        
        return continuous_patterns
    
    def display_detailed_results(self, patterns):
        """æ˜¾ç¤ºè¯¦ç»†æ£€æµ‹ç»“æœ - å°†ç»Ÿè®¡æ”¾åˆ°æœ€å"""
        st.write("\n" + "="*80)
        st.write("ğŸ¯ å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹æœ€ç»ˆç»“æœ")
        st.write("="*80)
        
        if not patterns:
            st.error("âŒ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„è¿ç»­å¯¹åˆ·æ¨¡å¼")
            return
        
        # æŒ‰å½©ç§åˆ†ç»„
        patterns_by_lottery = defaultdict(list)
        for pattern in patterns:
            patterns_by_lottery[pattern['å½©ç§']].append(pattern)
        
        # å…ˆæ˜¾ç¤ºè¯¦ç»†å¯¹åˆ·ç»„ä¿¡æ¯
        for lottery, lottery_patterns in patterns_by_lottery.items():
            st.write(f"\n{'='*60}")
            st.write(f"ğŸ² å½©ç§: {lottery} (å‘ç°{len(lottery_patterns)}ç»„)")
            st.write(f"{'='*60}")
            
            # æŒ‰è´¦æˆ·æ•°é‡åˆ†ç»„
            patterns_by_count = defaultdict(list)
            for pattern in lottery_patterns:
                patterns_by_count[pattern['è´¦æˆ·æ•°é‡']].append(pattern)
            
            for account_count in sorted(patterns_by_count.keys(), reverse=True):
                group_patterns = patterns_by_count[account_count]
                st.write(f"\nğŸ‘¥ {account_count} ä¸ªè´¦æˆ·å¯¹åˆ·ç»„ (å‘ç°{len(group_patterns)}ç»„)")
                
                for i, pattern in enumerate(group_patterns, 1):
                    st.write(f"\nğŸ” å¯¹åˆ·ç»„ {i}:")
                    
                    # ç®€åŒ–çš„è§†è§‰æ ‡è¯†ï¼šè´¦æˆ·ç»„
                    st.write(f"   ğŸ”¥ è´¦æˆ·ç»„: {' â†” '.join(pattern['è´¦æˆ·ç»„'])}")
                    
                    # æ–°å¢ï¼šæ˜¾ç¤ºè´¦æˆ·æ´»è·ƒåº¦ä¿¡æ¯ï¼ˆæŒ‰å½©ç§ï¼‰
                    activity_icon = "ğŸŸ¡" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'low' else "ğŸ”´"
                    st.write(f"   {activity_icon} æ´»è·ƒåº¦: {pattern['è´¦æˆ·æ´»è·ƒåº¦']}æ´»è·ƒ (åœ¨è¯¥å½©ç§æœ€å°æŠ•æ³¨æœŸæ•°: {pattern['æœ€å°æŠ•æ³¨æœŸæ•°']}æœŸ)")
                    st.write(f"   ğŸ“Š è´¦æˆ·åœ¨è¯¥å½©ç§æŠ•æ³¨æœŸæ•°/è®°å½•æ•°: {', '.join(pattern['è´¦æˆ·æŠ•æ³¨æœŸæ•°'])}")
                    
                    # ç®€åŒ–çš„è§†è§‰æ ‡è¯†ï¼šå½©ç§
                    st.write(f"   ğŸ¯ å½©ç§: {pattern['å½©ç§']}")
                    
                    st.write(f"   ä¸»è¦å¯¹ç«‹ç±»å‹: {pattern['ä¸»è¦å¯¹ç«‹ç±»å‹']}")
                    st.write(f"   å¯¹ç«‹ç±»å‹åˆ†å¸ƒ: {pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ']}")
                    st.write(f"   æ€»æœŸæ•°: {pattern['æ€»æœŸæ•°']} æœŸ (è¦æ±‚â‰¥{pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°']}æœŸ)")
                    st.write(f"   æ€»æŠ•æ³¨é‡‘é¢: {pattern['æ€»æŠ•æ³¨é‡‘é¢']:.2f} å…ƒ")
                    
                    # ç®€åŒ–çš„è§†è§‰æ ‡è¯†ï¼šå¹³å‡é‡‘é¢åŒ¹é…
                    similarity_percent = pattern['å¹³å‡ç›¸ä¼¼åº¦'] * 100
                    if similarity_percent >= 95:
                        symbol = "ğŸ’¯"  # 100%åŒ¹é…
                        color_indicator = "ğŸŸ¢"  # ç»¿è‰²é«˜åŒ¹é…
                    elif similarity_percent >= 90:
                        symbol = "âœ…"  # é«˜åŒ¹é…
                        color_indicator = "ğŸŸ¡"  # é»„è‰²ä¸­ç­‰åŒ¹é…
                    else:
                        symbol = "âš ï¸"  # è­¦å‘Š
                        color_indicator = "ğŸ”´"  # çº¢è‰²ä½åŒ¹é…
                    
                    st.write(f"   {symbol} å¹³å‡é‡‘é¢åŒ¹é…: {pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%} {color_indicator}")
                    
                    st.write(f"   æ¨¡å¼åˆ†å¸ƒ: {pattern['æ¨¡å¼åˆ†å¸ƒ']}")
                    
                    st.write(f"   è¯¦ç»†è®°å½•:")
                    for j, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                        st.write(f"     {j}. æœŸå·: {record['æœŸå·']}")
                        st.write(f"         å½©ç§: {record['å½©ç§']}")
                        st.write(f"         å¯¹ç«‹ç±»å‹: {record['å¯¹ç«‹ç±»å‹']}")
                        st.write(f"         æ¨¡å¼: {record['æ¨¡å¼']}")
                        account_directions = list(zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„']))
                        st.write(f"         è´¦æˆ·æ–¹å‘: {account_directions}")
                        st.write(f"         åŒ¹é…åº¦: {record['ç›¸ä¼¼åº¦']:.2%}")
        
        # æœ€åæ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
        self.display_summary_statistics(patterns)
    
    def display_summary_statistics(self, patterns):
        """æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡ - æ”¾åœ¨æœ€å"""
        if not patterns:
            return
            
        st.write(f"\n{'='*80}")
        st.write("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        st.write(f"{'='*80}")
        
        total_groups = len(patterns)
        total_accounts = sum(p['è´¦æˆ·æ•°é‡'] for p in patterns)
        total_periods = sum(p['æ€»æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        # æŒ‰è´¦æˆ·æ•°é‡ç»Ÿè®¡
        account_count_stats = defaultdict(int)
        for pattern in patterns:
            account_count_stats[pattern['è´¦æˆ·æ•°é‡']] += 1
        
        # æŒ‰å½©ç§ç»Ÿè®¡
        lottery_stats = defaultdict(int)
        for pattern in patterns:
            lottery_stats[pattern['å½©ç§']] += 1
        
        # æ–°å¢ï¼šæŒ‰æ´»è·ƒåº¦ç»Ÿè®¡
        activity_stats = defaultdict(int)
        for pattern in patterns:
            activity_stats[pattern['è´¦æˆ·æ´»è·ƒåº¦']] += 1
        
        st.write(f"\nğŸ¯ æ£€æµ‹ç»“æœæ±‡æ€»:")
        st.write(f"   å¯¹åˆ·ç»„æ•°: {total_groups} ç»„")
        st.write(f"   æ¶‰åŠè´¦æˆ·: {total_accounts} ä¸ª")
        st.write(f"   æ€»å¯¹åˆ·æœŸæ•°: {total_periods} æœŸ")
        st.write(f"   æ€»æ¶‰åŠé‡‘é¢: {total_amount:.2f} å…ƒ")
        
        st.write(f"\nğŸ‘¥ æŒ‰è´¦æˆ·æ•°é‡åˆ†å¸ƒ:")
        for account_count, count in sorted(account_count_stats.items()):
            st.write(f"   {account_count}ä¸ªè´¦æˆ·ç»„: {count} ç»„")
        
        st.write(f"\nğŸ² æŒ‰å½©ç§åˆ†å¸ƒ:")
        for lottery, count in lottery_stats.items():
            st.write(f"   {lottery}: {count} ç»„")
        
        st.write(f"\nğŸ“ˆ æŒ‰æ´»è·ƒåº¦åˆ†å¸ƒ:")
        for activity, count in activity_stats.items():
            st.write(f"   {activity}æ´»è·ƒè´¦æˆ·ç»„: {count} ç»„")
        
        st.write(f"\nğŸ’° é‡‘é¢ç»Ÿè®¡:")
        avg_amount_per_group = total_amount / total_groups if total_groups > 0 else 0
        avg_periods_per_group = total_periods / total_groups if total_groups > 0 else 0
        st.write(f"   å¹³å‡æ¯ç»„é‡‘é¢: {avg_amount_per_group:.2f} å…ƒ")
        st.write(f"   å¹³å‡æ¯æœŸé‡‘é¢: {total_amount/total_periods:.2f} å…ƒ" if total_periods > 0 else "   å¹³å‡æ¯æœŸé‡‘é¢: 0 å…ƒ")
        st.write(f"   å¹³å‡æ¯ç»„æœŸæ•°: {avg_periods_per_group:.1f} æœŸ")
        
        # æ–°å¢ï¼šæ˜¾ç¤ºé˜ˆå€¼é…ç½®ä¿¡æ¯
        st.write(f"\nâš™ï¸ æ£€æµ‹é˜ˆå€¼é…ç½®:")
        st.write(f"   ä½æ´»è·ƒåº¦è´¦æˆ·é˜ˆå€¼: <{self.config.period_thresholds['low_activity']}æœŸ")
        st.write(f"   ä½æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°: â‰¥{self.config.period_thresholds['min_periods_low']}æœŸ")
        st.write(f"   é«˜æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°: â‰¥{self.config.period_thresholds['min_periods_high']}æœŸ")
        st.write(f"   ğŸ“ æ³¨æ„: æ´»è·ƒåº¦æŒ‰å½©ç§å•ç‹¬è®¡ç®—ï¼Œæ˜¾ç¤ºæ ¼å¼ä¸º'æœŸæ•°/è®°å½•æ•°'")
    
    def export_to_excel(self, patterns, filename):
        """å¯¼å‡ºæ£€æµ‹ç»“æœåˆ°Excelæ–‡ä»¶"""
        if not patterns:
            st.error("âŒ æ²¡æœ‰å¯¹åˆ·æ•°æ®å¯å¯¼å‡º")
            return None
        
        st.write(f"\nğŸ“Š æ­£åœ¨ç”ŸæˆExcelæŠ¥å‘Š...")
        
        # å‡†å¤‡å¯¼å‡ºæ•°æ®
        export_data = []
        
        for group_idx, pattern in enumerate(patterns, 1):
            for record_idx, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                # æ ¼å¼åŒ–è´¦æˆ·æ–¹å‘ä¿¡æ¯
                account_directions = []
                for account, direction, amount in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„']):
                    account_directions.append(f"{account}({direction}:{amount})")
                
                export_data.append({
                    'å¯¹åˆ·ç»„ç¼–å·': group_idx,
                    'è´¦æˆ·ç»„': ' â†” '.join(pattern['è´¦æˆ·ç»„']),
                    'å½©ç§': pattern['å½©ç§'],
                    'è´¦æˆ·æ•°é‡': pattern['è´¦æˆ·æ•°é‡'],
                    'è´¦æˆ·æ´»è·ƒåº¦': pattern['è´¦æˆ·æ´»è·ƒåº¦'],
                    'æœ€å°æŠ•æ³¨æœŸæ•°': pattern['æœ€å°æŠ•æ³¨æœŸæ•°'],
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°'],
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': pattern['ä¸»è¦å¯¹ç«‹ç±»å‹'],
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': str(pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ']),
                    'æ€»æœŸæ•°': pattern['æ€»æœŸæ•°'],
                    'æ€»æŠ•æ³¨é‡‘é¢': pattern['æ€»æŠ•æ³¨é‡‘é¢'],
                    'å¹³å‡ç›¸ä¼¼åº¦': f"{pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}",
                    'æ¨¡å¼åˆ†å¸ƒ': str(pattern['æ¨¡å¼åˆ†å¸ƒ']),
                    'æœŸå·': record['æœŸå·'],
                    'å¯¹ç«‹ç±»å‹': record['å¯¹ç«‹ç±»å‹'],
                    'æ¨¡å¼': record['æ¨¡å¼'],
                    'é‡‘é¢': record['æ€»é‡‘é¢'],
                    'åŒ¹é…åº¦': f"{record['ç›¸ä¼¼åº¦']:.2%}",
                    'è´¦æˆ·æ–¹å‘': ' | '.join(account_directions)
                })
        
        # åˆ›å»ºDataFrame
        df_export = pd.DataFrame(export_data)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        export_filename = f"å¯¹åˆ·æ£€æµ‹æŠ¥å‘Š_å¤šæ ¼å¼å…¼å®¹ç‰ˆ_{timestamp}.xlsx"
        
        # å¯¼å‡ºåˆ°Excel
        try:
            # åˆ›å»ºExcelå†™å…¥å¯¹è±¡
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # ä¸»è¡¨ - è¯¦ç»†è®°å½•
                df_export.to_excel(writer, sheet_name='è¯¦ç»†è®°å½•', index=False)
                
                # æ±‡æ€»è¡¨ - å¯¹åˆ·ç»„ç»Ÿè®¡
                summary_data = []
                for group_idx, pattern in enumerate(patterns, 1):
                    summary_data.append({
                        'å¯¹åˆ·ç»„ç¼–å·': group_idx,
                        'è´¦æˆ·ç»„': ' â†” '.join(pattern['è´¦æˆ·ç»„']),
                        'å½©ç§': pattern['å½©ç§'],
                        'è´¦æˆ·æ•°é‡': pattern['è´¦æˆ·æ•°é‡'],
                        'è´¦æˆ·æ´»è·ƒåº¦': pattern['è´¦æˆ·æ´»è·ƒåº¦'],
                        'æœ€å°æŠ•æ³¨æœŸæ•°': pattern['æœ€å°æŠ•æ³¨æœŸæ•°'],
                        'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°'],
                        'ä¸»è¦å¯¹ç«‹ç±»å‹': pattern['ä¸»è¦å¯¹ç«‹ç±»å‹'],
                        'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': str(pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ']),
                        'æ€»æœŸæ•°': pattern['æ€»æœŸæ•°'],
                        'æ€»æŠ•æ³¨é‡‘é¢': pattern['æ€»æŠ•æ³¨é‡‘é¢'],
                        'å¹³å‡ç›¸ä¼¼åº¦': f"{pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}",
                        'æ¨¡å¼åˆ†å¸ƒ': str(pattern['æ¨¡å¼åˆ†å¸ƒ'])
                    })
                
                df_summary = pd.DataFrame(summary_data)
                df_summary.to_excel(writer, sheet_name='å¯¹åˆ·ç»„æ±‡æ€»', index=False)
                
                # ç»Ÿè®¡è¡¨ - æ€»ä½“ç»Ÿè®¡
                stats_data = [{
                    'å¯¹åˆ·ç»„æ•°': len(patterns),
                    'æ¶‰åŠè´¦æˆ·æ•°': sum(p['è´¦æˆ·æ•°é‡'] for p in patterns),
                    'æ€»å¯¹åˆ·æœŸæ•°': sum(p['æ€»æœŸæ•°'] for p in patterns),
                    'æ€»æ¶‰åŠé‡‘é¢': sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns),
                    'å¹³å‡æ¯ç»„é‡‘é¢': sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns) / len(patterns) if patterns else 0,
                    'å¹³å‡æ¯æœŸé‡‘é¢': sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns) / sum(p['æ€»æœŸæ•°'] for p in patterns) if patterns else 0,
                    'ä½æ´»è·ƒåº¦è´¦æˆ·é˜ˆå€¼': self.config.period_thresholds['low_activity'],
                    'ä½æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°': self.config.period_thresholds['min_periods_low'],
                    'é«˜æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°': self.config.period_thresholds['min_periods_high'],
                    'æ´»è·ƒåº¦è®¡ç®—æ–¹å¼': 'æŒ‰å½©ç§å•ç‹¬è®¡ç®—',
                    'åˆ—åæ˜ å°„': str(self.column_mapping_used),
                    'æ£€æµ‹æ—¶é—´': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                }]
                
                df_stats = pd.DataFrame(stats_data)
                df_stats.to_excel(writer, sheet_name='æ€»ä½“ç»Ÿè®¡', index=False)
            
            output.seek(0)
            st.success(f"âœ… ExcelæŠ¥å‘Šå·²ç”Ÿæˆ: {export_filename}")
            st.write(f"ğŸ“‹ åŒ…å« {len(patterns)} ä¸ªå¯¹åˆ·ç»„çš„è¯¦ç»†æ•°æ®")
            
            return output, export_filename
            
        except Exception as e:
            st.error(f"âŒ å¯¼å‡ºExcelå¤±è´¥: {str(e)}")
            return None, None

def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ¯ å¿«ä¸‰å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿï¼ˆå¤šæ ¼å¼å…¼å®¹ç‰ˆï¼‰")
    st.markdown("---")
    
    # ä¾§è¾¹æ é…ç½®
    st.sidebar.header("âš™ï¸ æ£€æµ‹å‚æ•°é…ç½®")
    
    min_amount = st.sidebar.number_input("æœ€å°æŠ•æ³¨é‡‘é¢", value=10, min_value=1, help="ä½äºæ­¤é‡‘é¢çš„è®°å½•å°†è¢«è¿‡æ»¤")
    similarity_threshold = st.sidebar.slider("é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼", 0.8, 1.0, 0.9, 0.01, help="å¯¹ç«‹æ–¹å‘é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼")
    max_accounts = st.sidebar.slider("æœ€å¤§æ£€æµ‹è´¦æˆ·æ•°", 2, 8, 5, help="æ£€æµ‹çš„æœ€å¤§è´¦æˆ·ç»„åˆæ•°é‡")
    
    # æ´»è·ƒåº¦é˜ˆå€¼é…ç½®
    st.sidebar.subheader("æ´»è·ƒåº¦é˜ˆå€¼é…ç½®")
    low_activity_threshold = st.sidebar.number_input("ä½æ´»è·ƒåº¦è´¦æˆ·é˜ˆå€¼(æœŸ)", value=10, min_value=1, help="ä½äºæ­¤æœŸæ•°çš„è´¦æˆ·è§†ä¸ºä½æ´»è·ƒåº¦")
    min_periods_low = st.sidebar.number_input("ä½æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=3, min_value=1, help="ä½æ´»è·ƒåº¦è´¦æˆ·æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°")
    min_periods_high = st.sidebar.number_input("é«˜æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=5, min_value=1, help="é«˜æ´»è·ƒåº¦è´¦æˆ·æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°")
    
    # æ–‡ä»¶ä¸Šä¼ 
    st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
    uploaded_file = st.file_uploader(
        "è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶ (æ”¯æŒ .xlsx, .xls, .csv)", 
        type=['xlsx', 'xls', 'csv'],
        help="è¯·ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—ï¼šä¼šå‘˜è´¦å·ã€æœŸå·ã€å†…å®¹ã€é‡‘é¢"
    )
    
    if uploaded_file is not None:
        try:
            # æ›´æ–°é…ç½®å‚æ•°
            config = Config()
            config.min_amount = min_amount
            config.amount_similarity_threshold = similarity_threshold
            config.max_accounts_in_group = max_accounts
            config.period_thresholds = {
                'low_activity': low_activity_threshold,
                'min_periods_low': min_periods_low,
                'min_periods_high': min_periods_high
            }
            
            detector = WashTradeDetector(config)
            
            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            st.success(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
            
            # è§£ææ•°æ®
            with st.spinner("ğŸ”„ æ­£åœ¨è§£ææ•°æ®..."):
                df, filename = detector.upload_and_process(uploaded_file)
                if df is not None:
                    df_valid = detector.parse_column_data(df)
                    
                    if len(df_valid) > 0:
                        st.success("âœ… æ•°æ®è§£æå®Œæˆ")
                        
                        # æ£€æµ‹å¯¹åˆ·äº¤æ˜“
                        if st.button("ğŸš€ å¼€å§‹æ£€æµ‹å¯¹åˆ·äº¤æ˜“", type="primary"):
                            with st.spinner("ğŸ” æ­£åœ¨æ£€æµ‹å¯¹åˆ·äº¤æ˜“..."):
                                patterns = detector.detect_all_wash_trades()
                            
                            # æ˜¾ç¤ºç»“æœ
                            if patterns:
                                st.success(f"âœ… æ£€æµ‹å®Œæˆï¼å‘ç° {len(patterns)} ä¸ªå¯¹åˆ·ç»„")
                                
                                # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                                detector.display_detailed_results(patterns)
                                
                                # å¯¼å‡ºExcelæŠ¥å‘Š
                                excel_output, export_filename = detector.export_to_excel(patterns, filename)
                                
                                if excel_output is not None:
                                    st.download_button(
                                        label="ğŸ“¥ ä¸‹è½½æ£€æµ‹æŠ¥å‘Š",
                                        data=excel_output,
                                        file_name=export_filename,
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )
                            else:
                                st.warning("âš ï¸ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„å¯¹åˆ·è¡Œä¸º")
                    else:
                        st.error("âŒ æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
            
        except Exception as e:
            st.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
            st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½è¯´æ˜
        
        **ğŸ¯ æ£€æµ‹é€»è¾‘ï¼š**
        - æ£€æµ‹2-5ä¸ªè´¦æˆ·ä¹‹é—´çš„å¯¹åˆ·è¡Œä¸º
        - æ”¯æŒå¤§-å°ã€å•-åŒç­‰å¯¹ç«‹æŠ•æ³¨æ–¹å‘
        - é‡‘é¢åŒ¹é…åº¦ â‰¥ 90%
        - æ ¹æ®è´¦æˆ·æ´»è·ƒåº¦è‡ªé€‚åº”é˜ˆå€¼
        
        **ğŸ“Š æ´»è·ƒåº¦åˆ¤å®šï¼š**
        - **ä½æ´»è·ƒåº¦è´¦æˆ·**ï¼šæŠ•æ³¨æœŸæ•° < é…ç½®é˜ˆå€¼ï¼Œè¦æ±‚ â‰¥ 3æœŸè¿ç»­å¯¹åˆ·
        - **é«˜æ´»è·ƒåº¦è´¦æˆ·**ï¼šæŠ•æ³¨æœŸæ•° â‰¥ é…ç½®é˜ˆå€¼ï¼Œè¦æ±‚ â‰¥ 5æœŸè¿ç»­å¯¹åˆ·
        
        **ğŸ“ æ•°æ®æ ¼å¼è¦æ±‚ï¼š**
        - å¿…é¡»åŒ…å«ï¼šä¼šå‘˜è´¦å·ã€æœŸå·ã€å†…å®¹ã€é‡‘é¢
        - å¯é€‰åŒ…å«ï¼šå½©ç§ï¼ˆå¦‚æ— åˆ™è‡ªåŠ¨æ·»åŠ é»˜è®¤å€¼ï¼‰
        - æ”¯æŒè‡ªåŠ¨åˆ—åæ˜ å°„
        
        **âš™ï¸ å‚æ•°é…ç½®ï¼š**
        - å¯åœ¨ä¾§è¾¹æ è°ƒæ•´æ£€æµ‹å‚æ•°
        - æ”¯æŒå®æ—¶é¢„è§ˆé…ç½®æ•ˆæœ
        """)
    
    # ç³»ç»Ÿä¿¡æ¯
    st.sidebar.markdown("---")
    st.sidebar.info("""
    **ç³»ç»Ÿä¿¡æ¯**
    - ç‰ˆæœ¬: 2.0
    - æ›´æ–°: 2024
    - ä½œè€…: å¿«ä¸‰æ£€æµ‹ç³»ç»Ÿ
    """)

if __name__ == "__main__":
    main()
