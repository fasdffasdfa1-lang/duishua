import pandas as pd
import numpy as np
import streamlit as st
import io
import re
import logging
from collections import defaultdict
from datetime import datetime
from itertools import combinations
import warnings
import traceback
import hashlib
from functools import lru_cache

# é…ç½®æ—¥å¿—å’Œè­¦å‘Š
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('MultiAccountWashTrade')

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== é…ç½®ç±» - å¢å¼ºç‰ˆï¼Œæ–°å¢3Dç³»åˆ—å’Œä½ç½®ç²¾åº¦ ====================
class Config:
    """é…ç½®å‚æ•°ç±» - å¢å¼ºç‰ˆ"""
    def __init__(self):
        self.min_amount = 10
        self.amount_similarity_threshold = 0.8
        self.min_continuous_periods = 3
        self.max_accounts_in_group = 5
        self.supported_file_types = ['.xlsx', '.xls', '.csv']
        
        # å¢å¼ºçš„åˆ—åæ˜ å°„é…ç½®
        self.column_mappings = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
        
        # å¢å¼ºï¼šæ ¹æ®æ‚¨çš„è¦æ±‚è°ƒæ•´å¯¹åˆ·æœŸæ•°é˜ˆå€¼
        self.period_thresholds = {
            'low_activity': 10,           # ä½æ´»è·ƒåº¦ä¸Šé™ï¼ˆæ€»æŠ•æ³¨æœŸæ•°1-10ï¼‰
            'medium_activity_low': 11,    # ä¸­æ´»è·ƒåº¦ä¸‹é™ï¼ˆæ€»æŠ•æ³¨æœŸæ•°11-50ï¼‰
            'medium_activity_high': 50,   # ä¸­æ´»è·ƒåº¦ä¸Šé™
            'high_activity_low': 51,      # é«˜æ´»è·ƒåº¦ä¸‹é™ï¼ˆæ€»æŠ•æ³¨æœŸæ•°51-100ï¼‰
            'high_activity_high': 100,    # é«˜æ´»è·ƒåº¦ä¸Šé™
            'min_periods_low': 3,         # ä½æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
            'min_periods_medium': 5,      # ä¸­æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
            'min_periods_high': 8,        # é«˜æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
            'min_periods_very_high': 11   # æé«˜æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
        }
        
        # æ‰©å±•ï¼šæ ¹æ®è´¦æˆ·æ•°é‡è°ƒæ•´åŒ¹é…åº¦é˜ˆå€¼
        self.account_count_similarity_thresholds = {
            2: 0.8,    # 2ä¸ªè´¦æˆ·ï¼š80%åŒ¹é…åº¦
            3: 0.85,   # 3ä¸ªè´¦æˆ·ï¼š85%åŒ¹é…åº¦  
            4: 0.9,    # 4ä¸ªè´¦æˆ·ï¼š90%åŒ¹é…åº¦
            5: 0.95    # 5ä¸ªè´¦æˆ·ï¼š95%åŒ¹é…åº¦
        }
        
        # æ–°å¢ï¼šè´¦æˆ·æœŸæ•°å·®å¼‚é˜ˆå€¼
        self.account_period_diff_threshold = 150  # è´¦æˆ·æ€»æŠ•æ³¨æœŸæ•°æœ€å¤§å·®å¼‚é˜ˆå€¼
        
        # æ‰©å±•ï¼šå¢åŠ é¾™è™æ–¹å‘æ¨¡å¼ï¼Œå¹¶æ·»åŠ è´¨åˆæ–¹å‘ï¼Œå¢å¼ºä½ç½®ç²¾åº¦
        self.direction_patterns = {
            'å°': ['ä¸¤é¢-å°', 'å’Œå€¼-å°', 'å°', 'small', 'xia'],
            'å¤§': ['ä¸¤é¢-å¤§', 'å’Œå€¼-å¤§', 'å¤§', 'big', 'da'], 
            'å•': ['ä¸¤é¢-å•', 'å’Œå€¼-å•', 'å•', 'odd', 'dan'],
            'åŒ': ['ä¸¤é¢-åŒ', 'å’Œå€¼-åŒ', 'åŒ', 'even', 'shuang'],
            'é¾™': ['é¾™', 'long', 'é¾', 'dragon'],
            'è™': ['è™', 'hu', 'tiger'],
            'è´¨': ['è´¨', 'è´¨æ•°', 'prime', 'zhi', 'è³ª', 'è³ªæ•¸'],
            'åˆ': ['åˆ', 'åˆæ•°', 'composite', 'he', 'åˆæ•¸']
        }
        
        # æ‰©å±•ï¼šå¢åŠ é¾™è™å¯¹ç«‹ç»„ï¼Œå¹¶æ·»åŠ è´¨åˆå¯¹ç«‹ç»„
        self.opposite_groups = [{'å¤§', 'å°'}, {'å•', 'åŒ'}, {'é¾™', 'è™'}, {'è´¨', 'åˆ'}]
        
        # å¢å¼ºï¼šä½ç½®å…³é”®è¯æ˜ å°„ - æ‰©å±•æ›´å¤šä½ç½®å…³é”®è¯
        self.position_keywords = {
            'PK10': {
                'å† å†›': ['å† å†›', 'ç¬¬1å', 'ç¬¬ä¸€å', 'å‰ä¸€', 'å†  å†›', 'å† ã€€å†›', '1st', 'ç¬¬ä¸€å', '1å'],
                'äºšå†›': ['äºšå†›', 'ç¬¬2å', 'ç¬¬äºŒå', 'äºš å†›', 'äºšã€€å†›', '2nd', 'ç¬¬äºŒå', '2å'],
                'ç¬¬ä¸‰å': ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›', '3rd', 'ç¬¬ä¸‰å', '3å'],
                'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å', '4th', 'ç¬¬å››å', '4å'],
                'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å', '5th', 'ç¬¬äº”å', '5å'],
                'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å', '6th', 'ç¬¬å…­å', '6å'],
                'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th', 'ç¬¬ä¸ƒå', '7å'],
                'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å', '8th', 'ç¬¬å…«å', '8å'],
                'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å', '9th', 'ç¬¬ä¹å', '9å'],
                'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å', '10th', 'ç¬¬åå', '10å']
            },
            '3D': {
                'ç™¾ä½': ['ç™¾ä½', 'ç™¾', 'ç™¾ä½èƒ†', 'ç™¾ä½å®šä½èƒ†', 'baiwei', 'bai'],
                'åä½': ['åä½', 'å', 'åä½èƒ†', 'åä½å®šä½èƒ†', 'shiwei', 'shi'],
                'ä¸ªä½': ['ä¸ªä½', 'ä¸ª', 'ä¸ªä½èƒ†', 'ä¸ªä½å®šä½èƒ†', 'gewei', 'ge']
            },
            'SSC': {
                'ç¬¬1çƒ': ['ç¬¬1çƒ', 'ä¸‡ä½', 'ç¬¬ä¸€ä½', '1çƒ', 'ball1', 'ç¬¬ä¸€çƒ', 'ä¸‡ä½å®šä½èƒ†'],
                'ç¬¬2çƒ': ['ç¬¬2çƒ', 'åƒä½', 'ç¬¬äºŒä½', '2çƒ', 'ball2', 'ç¬¬äºŒçƒ', 'åƒä½å®šä½èƒ†'],
                'ç¬¬3çƒ': ['ç¬¬3çƒ', 'ç™¾ä½', 'ç¬¬ä¸‰ä½', '3çƒ', 'ball3', 'ç¬¬ä¸‰çƒ', 'ç™¾ä½å®šä½èƒ†'],
                'ç¬¬4çƒ': ['ç¬¬4çƒ', 'åä½', 'ç¬¬å››ä½', '4çƒ', 'ball4', 'ç¬¬å››çƒ', 'åä½å®šä½èƒ†'],
                'ç¬¬5çƒ': ['ç¬¬5çƒ', 'ä¸ªä½', 'ç¬¬äº”ä½', '5çƒ', 'ball5', 'ç¬¬äº”çƒ', 'ä¸ªä½å®šä½èƒ†']
            },
            'K3': {
                'å’Œå€¼': ['å’Œå€¼', 'æ€»å’Œ', 'å’Œæ•°', 'ç‚¹æ•°', 'hezhi', 'sum'],
                'ä¸‰å†›': ['ä¸‰å†›', 'ç‹¬èƒ†', 'å•ç ', 'sanjun', 'single'],
                'äºŒä¸åŒå·': ['äºŒä¸åŒå·', 'äºŒä¸åŒ', 'äºŒä¸åŒ', 'two_diff'],
                'ä¸‰ä¸åŒå·': ['ä¸‰ä¸åŒå·', 'ä¸‰ä¸åŒ', 'ä¸‰ä¸åŒ', 'three_diff']
            },
            'LHC': {
                'ç‰¹ç ': ['ç‰¹ç ', 'ç‰¹è‚–', 'ç‰¹ç A', 'ç‰¹ç B', 'ç‰¹ç å•åŒ', 'ç‰¹ç å¤§å°', 'tema', 'special'],
                'æ­£ç ': ['æ­£ç ', 'æ­£ç‰¹', 'æ­£ç 1-6', 'æ­£ç ç‰¹', 'zhengma', 'normal'],
                'å¹³ç‰¹': ['å¹³ç‰¹', 'å¹³ç‰¹è‚–', 'å¹³ç‰¹å°¾', 'pingte', 'flat_special'],
                'è¿è‚–': ['è¿è‚–', 'äºŒè‚–', 'ä¸‰è‚–', 'å››è‚–', 'äº”è‚–', 'lianxiao', 'continuous']
            }
        }

# ==================== æ•°æ®å¤„ç†å™¨ç±» - å¢å¼ºç‰ˆ ====================
class DataProcessor:
    def __init__(self):
        self.required_columns = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹', 'é‡‘é¢']
        self.column_mapping = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
    
    def smart_column_identification(self, df_columns):
        """æ™ºèƒ½åˆ—è¯†åˆ«"""
        identified_columns = {}
        actual_columns = [str(col).strip() for col in df_columns]
        
        with st.expander("ğŸ” åˆ—åè¯†åˆ«è¯¦æƒ…", expanded=False):
            st.info(f"æ£€æµ‹åˆ°çš„åˆ—å: {actual_columns}")
            
            for standard_col, possible_names in self.column_mapping.items():
                found = False
                for actual_col in actual_columns:
                    actual_col_lower = actual_col.lower().replace(' ', '').replace('_', '').replace('-', '')
                    
                    for possible_name in possible_names:
                        possible_name_lower = possible_name.lower().replace(' ', '').replace('_', '').replace('-', '')
                        
                        if standard_col == 'ä¼šå‘˜è´¦å·':
                            account_keywords = ['ä¼šå‘˜', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·', 'ç©å®¶', 'id']
                            if any(keyword in actual_col_lower for keyword in account_keywords):
                                identified_columns[actual_col] = standard_col
                                st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                                found = True
                                break
                        else:
                            if (possible_name_lower in actual_col_lower or 
                                actual_col_lower in possible_name_lower or
                                len(set(possible_name_lower) & set(actual_col_lower)) / len(possible_name_lower) > 0.7):
                                identified_columns[actual_col] = standard_col
                                st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                                found = True
                                break
                    
                    if found:
                        break
                
                if not found:
                    st.warning(f"âš ï¸ æœªè¯†åˆ«åˆ° {standard_col} å¯¹åº”çš„åˆ—å")
        
        return identified_columns
    
    def find_data_start(self, df):
        """æ™ºèƒ½æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®"""
        for row_idx in range(min(20, len(df))):
            for col_idx in range(min(10, len(df.columns))):
                cell_value = str(df.iloc[row_idx, col_idx])
                if pd.notna(cell_value) and any(keyword in cell_value for keyword in ['ä¼šå‘˜', 'è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•', 'å†…å®¹', 'è®¢å•', 'ç”¨æˆ·']):
                    return row_idx, col_idx
        return 0, 0
    
    def validate_data_quality(self, df):
        """æ•°æ®è´¨é‡éªŒè¯"""
        logger.info("æ­£åœ¨è¿›è¡Œæ•°æ®è´¨é‡éªŒè¯...")
        issues = []
        
        # æ£€æŸ¥å¿…è¦åˆ—
        missing_cols = [col for col in self.required_columns if col not in df.columns]
        if missing_cols:
            issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        
        # æ£€æŸ¥ç©ºå€¼
        for col in self.required_columns:
            if col in df.columns:
                null_count = df[col].isnull().sum()
                if null_count > 0:
                    issues.append(f"åˆ— '{col}' æœ‰ {null_count} ä¸ªç©ºå€¼")
        
        # ç‰¹åˆ«æ£€æŸ¥ä¼šå‘˜è´¦å·çš„å®Œæ•´æ€§
        if 'ä¼šå‘˜è´¦å·' in df.columns:
            truncated_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(r'\.\.\.|â€¦', na=False)]
            if len(truncated_accounts) > 0:
                issues.append(f"å‘ç° {len(truncated_accounts)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„ä¼šå‘˜è´¦å·")
            
            account_lengths = df['ä¼šå‘˜è´¦å·'].str.len()
            if account_lengths.max() > 50:
                issues.append("å‘ç°å¼‚å¸¸é•¿åº¦çš„ä¼šå‘˜è´¦å·")
            
            unique_accounts = df['ä¼šå‘˜è´¦å·'].unique()[:5]
            sample_info = " | ".join([f"'{acc}'" for acc in unique_accounts])
            st.info(f"ä¼šå‘˜è´¦å·æ ¼å¼æ ·æœ¬: {sample_info}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if 'æœŸå·' in df.columns:
            df['æœŸå·'] = df['æœŸå·'].astype(str).str.replace(r'\.0$', '', regex=True)
            invalid_periods = df[~df['æœŸå·'].str.match(r'^[\dA-Za-z]+$')]
            if len(invalid_periods) > 0:
                issues.append(f"å‘ç° {len(invalid_periods)} æ¡æ— æ•ˆæœŸå·è®°å½•")
        
        # æ£€æŸ¥é‡å¤æ•°æ®
        duplicate_count = df.duplicated().sum()
        if duplicate_count > 0:
            issues.append(f"å‘ç° {duplicate_count} æ¡é‡å¤è®°å½•")
        
        if issues:
            with st.expander("âš ï¸ æ•°æ®è´¨é‡é—®é¢˜", expanded=True):
                for issue in issues:
                    st.warning(f"  - {issue}")
        else:
            st.success("âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
        
        return issues
    
    def clean_data(self, uploaded_file):
        """æ•°æ®æ¸…æ´—ä¸»å‡½æ•°"""
        try:
            df_temp = pd.read_excel(uploaded_file, header=None, nrows=50)
            st.info(f"åŸå§‹æ•°æ®ç»´åº¦: {df_temp.shape}")
            
            start_row, start_col = self.find_data_start(df_temp)
            st.info(f"æ•°æ®èµ·å§‹ä½ç½®: ç¬¬{start_row+1}è¡Œ, ç¬¬{start_col+1}åˆ—")
            
            df_clean = pd.read_excel(
                uploaded_file, 
                header=start_row,
                skiprows=range(start_row + 1) if start_row > 0 else None,
                dtype=str,
                na_filter=False,
                keep_default_na=False
            )
            
            if start_col > 0:
                df_clean = df_clean.iloc[:, start_col:]
            
            st.info(f"æ¸…ç†åæ•°æ®ç»´åº¦: {df_clean.shape}")
            
            column_mapping = self.smart_column_identification(df_clean.columns)
            if column_mapping:
                df_clean = df_clean.rename(columns=column_mapping)
                st.success("âœ… åˆ—åè¯†åˆ«å®Œæˆ!")
            
            missing_columns = [col for col in self.required_columns if col not in df_clean.columns]
            if missing_columns and len(df_clean.columns) >= 4:
                st.warning("è‡ªåŠ¨æ˜ å°„åˆ—å...")
                manual_mapping = {}
                col_names = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'å†…å®¹', 'ç©æ³•', 'é‡‘é¢']
                for i, col_name in enumerate(col_names):
                    if i < len(df_clean.columns):
                        manual_mapping[df_clean.columns[i]] = col_name
                
                df_clean = df_clean.rename(columns=manual_mapping)
                st.info(f"æ‰‹åŠ¨é‡å‘½ååçš„åˆ—: {list(df_clean.columns)}")
            
            initial_count = len(df_clean)
            df_clean = df_clean.dropna(subset=[col for col in self.required_columns if col in df_clean.columns])
            df_clean = df_clean.dropna(axis=1, how='all')
            
            for col in self.required_columns:
                if col in df_clean.columns:
                    if col == 'ä¼šå‘˜è´¦å·':
                        df_clean[col] = df_clean[col].apply(
                            lambda x: str(x) if pd.notna(x) else ''
                        )
                    else:
                        df_clean[col] = df_clean[col].astype(str).str.strip()
            
            if 'æœŸå·' in df_clean.columns:
                df_clean['æœŸå·'] = df_clean['æœŸå·'].str.replace(r'\.0$', '', regex=True)
            
            self.validate_data_quality(df_clean)
            
            st.success(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆ: {initial_count} -> {len(df_clean)} æ¡è®°å½•")
            
            st.info(f"ğŸ“Š å”¯ä¸€ä¼šå‘˜è´¦å·æ•°: {df_clean['ä¼šå‘˜è´¦å·'].nunique()}")
            
            if 'å½©ç§' in df_clean.columns:
                lottery_dist = df_clean['å½©ç§'].value_counts()
                with st.expander("ğŸ¯ å½©ç§åˆ†å¸ƒ", expanded=False):
                    st.dataframe(lottery_dist.reset_index().rename(columns={'index': 'å½©ç§', 'å½©ç§': 'æ•°é‡'}))
            
            return df_clean
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            logger.error(f"æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            return None

# ==================== å½©ç§è¯†åˆ«å™¨ - å¢å¼ºç‰ˆï¼Œæ–°å¢3Dç³»åˆ— ====================
LOTTERY_CONFIGS = {
    'PK10': {
        'lotteries': [
            'åˆ†åˆ†PKæ‹¾', 'ä¸‰åˆ†PKæ‹¾', 'äº”åˆ†PKæ‹¾', 'æ–°å¹¸è¿é£è‰‡', 'æ¾³æ´²å¹¸è¿10',
            'ä¸€åˆ†PK10', 'å®¾æœPK10', 'æé€Ÿé£è‰‡', 'æ¾³æ´²é£è‰‡', 'å¹¸è¿èµ›è½¦',
            'åˆ†åˆ†èµ›è½¦', 'åŒ—äº¬PK10', 'æ—§åŒ—äº¬PK10', 'æé€Ÿèµ›è½¦', 'å¹¸è¿èµ›è»Š', 
            'åŒ—äº¬èµ›è½¦', 'æé€ŸPK10', 'å¹¸è¿PK10', 'èµ›è½¦', 'èµ›è»Š'
        ],
        'min_number': 1,
        'max_number': 10,
        'gyh_min': 3,
        'gyh_max': 19,
        'position_names': ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                          'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
    },
    'K3': {
        'lotteries': [
            'åˆ†åˆ†å¿«ä¸‰', 'ä¸‰åˆ†å¿«3', 'äº”åˆ†å¿«3', 'æ¾³æ´²å¿«ä¸‰', 'å®¾æœå¿«ä¸‰',
            '1åˆ†å¿«ä¸‰', '3åˆ†å¿«ä¸‰', '5åˆ†å¿«ä¸‰', '10åˆ†å¿«ä¸‰', 'åŠ å·å¿«ä¸‰',
            'å¹¸è¿å¿«ä¸‰', 'å¤§å‘å¿«ä¸‰', 'å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 
            'æ¾³é—¨å¿«ä¸‰', 'é¦™æ¸¯å¿«ä¸‰', 'æ±Ÿè‹å¿«ä¸‰'
        ],
        'min_number': 1,
        'max_number': 6,
        'hezhi_min': 3,
        'hezhi_max': 18
    },
    'LHC': {
        'lotteries': [
            'æ–°æ¾³é—¨å…­åˆå½©', 'æ¾³é—¨å…­åˆå½©', 'é¦™æ¸¯å…­åˆå½©', 'ä¸€åˆ†å…­åˆå½©',
            'äº”åˆ†å…­åˆå½©', 'ä¸‰åˆ†å…­åˆå½©', 'é¦™æ¸¯â‘¥åˆå½©', 'åˆ†åˆ†å…­åˆå½©',
            'å¿«ä¹6åˆå½©', 'æ¸¯â‘¥åˆå½©', 'å°æ¹¾å¤§ä¹é€', 'å…­åˆ', 'lhc', 'å…­åˆå½©',
            'â‘¥åˆ', '6åˆ', 'å¤§å‘å…­åˆå½©'
        ],
        'min_number': 1,
        'max_number': 49
    },
    'SSC': {
        'lotteries': [
            'åˆ†åˆ†æ—¶æ—¶å½©', 'ä¸‰åˆ†æ—¶æ—¶å½©', 'äº”åˆ†æ—¶æ—¶å½©', 'å®¾æœæ—¶æ—¶å½©',
            '1åˆ†æ—¶æ—¶å½©', '3åˆ†æ—¶æ—¶å½©', '5åˆ†æ—¶æ—¶å½©', 'æ—§é‡åº†æ—¶æ—¶å½©',
            'å¹¸è¿æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©', 'æ–°ç–†æ—¶æ—¶å½©', 'å¤©æ´¥æ—¶æ—¶å½©',
            'é‡åº†æ—¶æ—¶å½©', 'ä¸Šæµ·æ—¶æ—¶å½©', 'å¹¿ä¸œæ—¶æ—¶å½©', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©'
        ],
        'min_number': 0,
        'max_number': 9
    },
    # æ–°å¢ï¼š3Dç³»åˆ—å½©ç§é…ç½®
    '3D': {
        'lotteries': [
            'æ’åˆ—ä¸‰', 'æ’åˆ—3', 'å¹¸è¿æ’åˆ—3', 'ä¸€åˆ†æ’åˆ—3', 'äºŒåˆ†æ’åˆ—3', 'ä¸‰åˆ†æ’åˆ—3', 
            'äº”åˆ†æ’åˆ—3', 'ååˆ†æ’åˆ—3', 'å¤§å‘æ’åˆ—3', 'å¥½è¿æ’åˆ—3', 'ç¦å½©3D', 'æé€Ÿ3D',
            'æé€Ÿæ’åˆ—3', 'å¹¸è¿3D', 'ä¸€åˆ†3D', 'äºŒåˆ†3D', 'ä¸‰åˆ†3D', 'äº”åˆ†3D', 
            'ååˆ†3D', 'å¤§å‘3D', 'å¥½è¿3D'
        ],
        'min_number': 0,
        'max_number': 9,
        'position_names': ['ç™¾ä½', 'åä½', 'ä¸ªä½']
    }
}

class LotteryIdentifier:
    def __init__(self):
        self.lottery_configs = LOTTERY_CONFIGS
        self.general_keywords = {
            'PK10': ['pk10', 'pkæ‹¾', 'é£è‰‡', 'èµ›è½¦', 'èµ›è»Š', 'å¹¸è¿10', 'åŒ—äº¬èµ›è½¦', 'æé€Ÿèµ›è½¦'],
            'K3': ['å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 'éª°å®', 'ä¸‰å†›'],
            'LHC': ['å…­åˆ', 'lhc', 'å…­åˆå½©', 'â‘¥åˆ', '6åˆ', 'ç‰¹ç ', 'å¹³ç‰¹', 'è¿è‚–'],
            'SSC': ['æ—¶æ—¶å½©', 'ssc', 'åˆ†åˆ†å½©', 'æ™‚æ™‚å½©', 'é‡åº†æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©'],
            # æ–°å¢ï¼š3Dç³»åˆ—å…³é”®è¯
            '3D': ['æ’åˆ—ä¸‰', 'æ’åˆ—3', 'ç¦å½©3d', '3d', 'æé€Ÿ3d', 'æ’åˆ—', 'p3', 'pä¸‰']
        }
        
        self.lottery_aliases = {
            'åˆ†åˆ†PKæ‹¾': 'PK10', 'ä¸‰åˆ†PKæ‹¾': 'PK10', 'äº”åˆ†PKæ‹¾': 'PK10',
            'æ–°å¹¸è¿é£è‰‡': 'PK10', 'æ¾³æ´²å¹¸è¿10': 'PK10', 'ä¸€åˆ†PK10': 'PK10',
            'å®¾æœPK10': 'PK10', 'æé€Ÿé£è‰‡': 'PK10', 'æ¾³æ´²é£è‰‡': 'PK10',
            'å¹¸è¿èµ›è½¦': 'PK10', 'åˆ†åˆ†èµ›è½¦': 'PK10', 'åŒ—äº¬PK10': 'PK10',
            'æ—§åŒ—äº¬PK10': 'PK10', 'æé€Ÿèµ›è½¦': 'PK10', 'å¹¸è¿èµ›è»Š': 'PK10',
            'åŒ—äº¬èµ›è½¦': 'PK10', 'æé€ŸPK10': 'PK10', 'å¹¸è¿PK10': 'PK10',
            'åˆ†åˆ†å¿«ä¸‰': 'K3', 'ä¸‰åˆ†å¿«3': 'K3', 'äº”åˆ†å¿«3': 'K3', 'æ¾³æ´²å¿«ä¸‰': 'K3',
            'å®¾æœå¿«ä¸‰': 'K3', '1åˆ†å¿«ä¸‰': 'K3', '3åˆ†å¿«ä¸‰': 'K3', '5åˆ†å¿«ä¸‰': 'K3',
            '10åˆ†å¿«ä¸‰': 'K3', 'åŠ å·å¿«ä¸‰': 'K3', 'å¹¸è¿å¿«ä¸‰': 'K3', 'å¤§å‘å¿«ä¸‰': 'K3',
            'æ¾³é—¨å¿«ä¸‰': 'K3', 'é¦™æ¸¯å¿«ä¸‰': 'K3', 'æ±Ÿè‹å¿«ä¸‰': 'K3',
            'æ–°æ¾³é—¨å…­åˆå½©': 'LHC', 'æ¾³é—¨å…­åˆå½©': 'LHC', 'é¦™æ¸¯å…­åˆå½©': 'LHC',
            'ä¸€åˆ†å…­åˆå½©': 'LHC', 'äº”åˆ†å…­åˆå½©': 'LHC', 'ä¸‰åˆ†å…­åˆå½©': 'LHC',
            'é¦™æ¸¯â‘¥åˆå½©': 'LHC', 'åˆ†åˆ†å…­åˆå½©': 'LHC', 'å¿«ä¹6åˆå½©': 'LHC',
            'æ¸¯â‘¥åˆå½©': 'LHC', 'å°æ¹¾å¤§ä¹é€': 'LHC', 'å¤§å‘å…­åˆå½©': 'LHC',
            'åˆ†åˆ†æ—¶æ—¶å½©': 'SSC', 'ä¸‰åˆ†æ—¶æ—¶å½©': 'SSC', 'äº”åˆ†æ—¶æ—¶å½©': 'SSC',
            'å®¾æœæ—¶æ—¶å½©': 'SSC', '1åˆ†æ—¶æ—¶å½©': 'SSC', '3åˆ†æ—¶æ—¶å½©': 'SSC',
            '5åˆ†æ—¶æ—¶å½©': 'SSC', 'æ—§é‡åº†æ—¶æ—¶å½©': 'SSC', 'å¹¸è¿æ—¶æ—¶å½©': 'SSC',
            'è…¾è®¯åˆ†åˆ†å½©': 'SSC', 'æ–°ç–†æ—¶æ—¶å½©': 'SSC', 'å¤©æ´¥æ—¶æ—¶å½©': 'SSC',
            'é‡åº†æ—¶æ—¶å½©': 'SSC', 'ä¸Šæµ·æ—¶æ—¶å½©': 'SSC', 'å¹¿ä¸œæ—¶æ—¶å½©': 'SSC',
            # æ–°å¢ï¼š3Dç³»åˆ—åˆ«å
            'æ’åˆ—ä¸‰': '3D', 'æ’åˆ—3': '3D', 'å¹¸è¿æ’åˆ—3': '3D', 'ä¸€åˆ†æ’åˆ—3': '3D',
            'äºŒåˆ†æ’åˆ—3': '3D', 'ä¸‰åˆ†æ’åˆ—3': '3D', 'äº”åˆ†æ’åˆ—3': '3D', 'ååˆ†æ’åˆ—3': '3D',
            'å¤§å‘æ’åˆ—3': '3D', 'å¥½è¿æ’åˆ—3': '3D', 'ç¦å½©3D': '3D', 'æé€Ÿ3D': '3D',
            'æé€Ÿæ’åˆ—3': '3D', 'å¹¸è¿3D': '3D', 'ä¸€åˆ†3D': '3D', 'äºŒåˆ†3D': '3D',
            'ä¸‰åˆ†3D': '3D', 'äº”åˆ†3D': '3D', 'ååˆ†3D': '3D', 'å¤§å‘3D': '3D', 'å¥½è¿3D': '3D'
        }

    def identify_lottery_type(self, lottery_name):
        """å½©ç§ç±»å‹è¯†åˆ«"""
        lottery_str = str(lottery_name).strip()
        
        if lottery_str in self.lottery_aliases:
            return self.lottery_aliases[lottery_str]
        
        for lottery_type, config in self.lottery_configs.items():
            for lottery in config['lotteries']:
                if lottery in lottery_str:
                    return lottery_type
        
        lottery_lower = lottery_str.lower()
        
        for lottery_type, keywords in self.general_keywords.items():
            for keyword in keywords:
                if keyword.lower() in lottery_lower:
                    return lottery_type
        
        return lottery_str

# ==================== ç©æ³•åˆ†ç±»å™¨ - å¢å¼ºç‰ˆï¼Œå€Ÿé‰´ç¬¬ä¸€ä¸ªä»£ç çš„è¯¦ç»†æ˜ å°„ ====================
class PlayCategoryNormalizer:
    def __init__(self):
        self.category_mapping = self._create_category_mapping()
    
    def _create_category_mapping(self):
        """åˆ›å»ºç©æ³•åˆ†ç±»æ˜ å°„ - å€Ÿé‰´ç¬¬ä¸€ä¸ªä»£ç çš„è¯¦ç»†æ˜ å°„"""
        mapping = {
            # å¿«ä¸‰ç©æ³•
            'å’Œå€¼': 'å’Œå€¼', 'å’Œå€¼_å¤§å°å•åŒ': 'å’Œå€¼', 'ä¸¤é¢': 'ä¸¤é¢',
            'äºŒä¸åŒå·': 'äºŒä¸åŒå·', 'ä¸‰ä¸åŒå·': 'ä¸‰ä¸åŒå·', 'ç‹¬èƒ†': 'ç‹¬èƒ†',
            'ç‚¹æ•°': 'å’Œå€¼', 'ä¸‰å†›': 'ç‹¬èƒ†', 'ä¸‰è»': 'ç‹¬èƒ†',
            
            # å…­åˆå½©ç©æ³•
            'ç‰¹ç ': 'ç‰¹ç ', 'æ­£1ç‰¹': 'æ­£1ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹': 'æ­£1ç‰¹',
            'æ­£2ç‰¹': 'æ­£2ç‰¹', 'æ­£ç ç‰¹_æ­£äºŒç‰¹': 'æ­£2ç‰¹', 'æ­£3ç‰¹': 'æ­£3ç‰¹',
            'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹', 'æ­£4ç‰¹': 'æ­£4ç‰¹', 'æ­£ç ç‰¹_æ­£å››ç‰¹': 'æ­£4ç‰¹',
            'æ­£5ç‰¹': 'æ­£5ç‰¹', 'æ­£ç ç‰¹_æ­£äº”ç‰¹': 'æ­£5ç‰¹', 'æ­£6ç‰¹': 'æ­£6ç‰¹',
            'æ­£ç ç‰¹_æ­£å…­ç‰¹': 'æ­£6ç‰¹', 'æ­£ç ': 'æ­£ç ', 'æ­£ç‰¹': 'æ­£ç‰¹',
            'å°¾æ•°': 'å°¾æ•°', 'ç‰¹è‚–': 'ç‰¹è‚–', 'å¹³ç‰¹': 'å¹³ç‰¹', 'ä¸€è‚–': 'ä¸€è‚–',
            'è¿è‚–': 'è¿è‚–', 'è¿å°¾': 'è¿å°¾', 'é¾™è™': 'é¾™è™', 'äº”è¡Œ': 'äº”è¡Œ',
            'è‰²æ³¢': 'è‰²æ³¢', 'åŠæ³¢': 'åŠæ³¢',
            
            # 3Dç³»åˆ—ç©æ³•
            'ä¸¤é¢': 'ä¸¤é¢', 'å¤§å°å•åŒ': 'ä¸¤é¢', 'ç™¾ä½': 'ç™¾ä½', 'åä½': 'åä½', 
            'ä¸ªä½': 'ä¸ªä½', 'ç™¾å': 'ç™¾å', 'ç™¾ä¸ª': 'ç™¾ä¸ª', 'åä¸ª': 'åä¸ª',
            'ç™¾åä¸ª': 'ç™¾åä¸ª', 'å®šä½èƒ†': 'å®šä½èƒ†', 'å®šä½èƒ†_ç™¾ä½': 'å®šä½èƒ†_ç™¾ä½',
            'å®šä½èƒ†_åä½': 'å®šä½èƒ†_åä½', 'å®šä½èƒ†_ä¸ªä½': 'å®šä½èƒ†_ä¸ªä½',
            
            # æ—¶æ—¶å½©ç©æ³•
            'æ–—ç‰›': 'æ–—ç‰›', '1-5çƒ': '1-5çƒ', 'ç¬¬1çƒ': 'ç¬¬1çƒ', 'ç¬¬2çƒ': 'ç¬¬2çƒ',
            'ç¬¬3çƒ': 'ç¬¬3çƒ', 'ç¬¬4çƒ': 'ç¬¬4çƒ', 'ç¬¬5çƒ': 'ç¬¬5çƒ', 'æ€»å’Œ': 'æ€»å’Œ',
            'æ­£ç ': 'æ­£ç ', 'å®šä½èƒ†': 'å®šä½èƒ†',
            
            # PKæ‹¾/èµ›è½¦ç©æ³•
            'å‰ä¸€': 'å† å†›', 'å®šä½èƒ†': 'å®šä½èƒ†', '1-5å': '1-5å', '6-10å': '6-10å',
            'å† å†›': 'å† å†›', 'äºšå†›': 'äºšå†›', 'å­£å†›': 'ç¬¬ä¸‰å', 'ç¬¬3å': 'ç¬¬ä¸‰å',
            'ç¬¬4å': 'ç¬¬å››å', 'ç¬¬5å': 'ç¬¬äº”å', 'ç¬¬6å': 'ç¬¬å…­å',
            'ç¬¬7å': 'ç¬¬ä¸ƒå', 'ç¬¬8å': 'ç¬¬å…«å', 'ç¬¬9å': 'ç¬¬ä¹å',
            'ç¬¬10å': 'ç¬¬åå', 'åŒé¢': 'ä¸¤é¢', 'å† äºšå’Œ': 'å† äºšå’Œ'
        }
        return mapping
    
    def normalize_category(self, category):
        """ç»Ÿä¸€ç©æ³•åˆ†ç±»åç§° - å¢å¼ºç‰ˆ"""
        category_str = str(category).strip()
        
        # ç›´æ¥æ˜ å°„
        if category_str in self.category_mapping:
            return self.category_mapping[category_str]
        
        # å…³é”®è¯åŒ¹é…
        for key, value in self.category_mapping.items():
            if key in category_str:
                return value
        
        # æ™ºèƒ½åŒ¹é…
        category_lower = category_str.lower()
        
        # PK10/èµ›è½¦æ™ºèƒ½åŒ¹é…
        if any(word in category_lower for word in ['å† å†›', 'ç¬¬ä¸€å', 'ç¬¬1å', '1st']):
            return 'å† å†›'
        elif any(word in category_lower for word in ['äºšå†›', 'ç¬¬äºŒå', 'ç¬¬2å', '2nd']):
            return 'äºšå†›'
        elif any(word in category_lower for word in ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›', '3rd']):
            return 'ç¬¬ä¸‰å'
        elif any(word in category_lower for word in ['ç¬¬å››å', 'ç¬¬4å', '4th']):
            return 'ç¬¬å››å'
        elif any(word in category_lower for word in ['ç¬¬äº”å', 'ç¬¬5å', '5th']):
            return 'ç¬¬äº”å'
        elif any(word in category_lower for word in ['ç¬¬å…­å', 'ç¬¬6å', '6th']):
            return 'ç¬¬å…­å'
        elif any(word in category_lower for word in ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th']):
            return 'ç¬¬ä¸ƒå'
        elif any(word in category_lower for word in ['ç¬¬å…«å', 'ç¬¬8å', '8th']):
            return 'ç¬¬å…«å'
        elif any(word in category_lower for word in ['ç¬¬ä¹å', 'ç¬¬9å', '9th']):
            return 'ç¬¬ä¹å'
        elif any(word in category_lower for word in ['ç¬¬åå', 'ç¬¬10å', '10th']):
            return 'ç¬¬åå'
        
        # 3Dç³»åˆ—æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ç™¾ä½']):
            return 'ç™¾ä½'
        elif any(word in category_lower for word in ['åä½']):
            return 'åä½'
        elif any(word in category_lower for word in ['ä¸ªä½']):
            return 'ä¸ªä½'
        
        # æ—¶æ—¶å½©æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ç¬¬1çƒ', 'ä¸‡ä½']):
            return 'ç¬¬1çƒ'
        elif any(word in category_lower for word in ['ç¬¬2çƒ', 'åƒä½']):
            return 'ç¬¬2çƒ'
        elif any(word in category_lower for word in ['ç¬¬3çƒ', 'ç™¾ä½']):
            return 'ç¬¬3çƒ'
        elif any(word in category_lower for word in ['ç¬¬4çƒ', 'åä½']):
            return 'ç¬¬4çƒ'
        elif any(word in category_lower for word in ['ç¬¬5çƒ', 'ä¸ªä½']):
            return 'ç¬¬5çƒ'
        
        return category_str

# ==================== å†…å®¹è§£æå™¨ - å€Ÿé‰´ç¬¬ä¸€ä¸ªä»£ç çš„è¯¦ç»†è§£æé€»è¾‘ ====================
class ContentParser:
    """ä»ç¬¬ä¸€ä¸ªä»£ç å€Ÿé‰´çš„æŠ•æ³¨å†…å®¹è§£æå™¨"""

    @staticmethod
    def parse_pk10_vertical_format(content):
        """
        è§£æPK10ç«–çº¿åˆ†éš”çš„å®šä½èƒ†æ ¼å¼
        æ ¼å¼ï¼šå·ç 1,å·ç 2|å·ç 3|å·ç 4,å·ç 5|å·ç 6|å·ç 7,å·ç 8,å·ç 9|å·ç 10
        """
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                        'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
            
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    numbers = []
                    if ',' in part_clean:
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£æPK10ç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)

    @staticmethod
    def parse_3d_vertical_format(content):
        """
        è§£æ3Dç«–çº¿åˆ†éš”çš„å®šä½èƒ†æ ¼å¼
        æ ¼å¼ï¼šå·ç 1,å·ç 2|å·ç 3|å·ç 4,å·ç 5,å·ç 6
        """
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            positions = ['ç™¾ä½', 'åä½', 'ä¸ªä½']
            
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    numbers = []
                    if ',' in part_clean:
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£æ3Dç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)

    @staticmethod
    def parse_positional_bets(content, position_keywords=None):
        """
        è§£æä½ç½®æŠ•æ³¨å†…å®¹
        æ ¼å¼ï¼šä½ç½®1-æŠ•æ³¨é¡¹1,æŠ•æ³¨é¡¹2,ä½ç½®2-æŠ•æ³¨é¡¹1,æŠ•æ³¨é¡¹2,...
        """
        content_str = str(content).strip()
        bets_by_position = defaultdict(list)
        
        if not content_str:
            return bets_by_position
        
        parts = [part.strip() for part in content_str.split(',')]
        
        current_position = None
        
        for part in parts:
            is_position = False
            if position_keywords:
                for keyword in position_keywords:
                    if keyword in part and '-' in part:
                        is_position = True
                        break
            
            if '-' in part and (is_position or position_keywords is None):
                try:
                    position_part, bet_value = part.split('-', 1)
                    current_position = position_part.strip()
                    bets_by_position[current_position].append(bet_value.strip())
                except ValueError:
                    if current_position:
                        bets_by_position[current_position].append(part)
            elif current_position:
                bets_by_position[current_position].append(part)
            else:
                bets_by_position['æœªçŸ¥ä½ç½®'].append(part)
        
        return bets_by_position

# ==================== å¢å¼ºçš„å¯¹åˆ·æ£€æµ‹å™¨ - å®Œå–„ä½ç½®åˆ¤æ–­é€»è¾‘ ====================
class WashTradeDetector:
    def __init__(self, config=None):
        self.config = config or Config()
        self.data_processor = DataProcessor()
        self.lottery_identifier = LotteryIdentifier()
        self.play_normalizer = PlayCategoryNormalizer()
        self.content_parser = ContentParser()  # æ–°å¢å†…å®¹è§£æå™¨
        
        self.data_processed = False
        self.df_valid = None
        self.export_data = []
        
        # æŒ‰å½©ç§å­˜å‚¨è´¦æˆ·ç»Ÿè®¡
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        self.performance_stats = {}
    
    def upload_and_process(self, uploaded_file):
        """ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶"""
        try:
            if uploaded_file is None:
                st.error("âŒ æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
                return None, None
            
            filename = uploaded_file.name
            logger.info(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {filename}")
            
            if not any(filename.endswith(ext) for ext in self.config.supported_file_types):
                st.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
                return None, None
            
            with st.spinner("ğŸ”„ æ­£åœ¨æ¸…æ´—æ•°æ®..."):
                df_clean = self.data_processor.clean_data(uploaded_file)
            
            if df_clean is not None and len(df_clean) > 0:
                df_enhanced = self.enhance_data_processing(df_clean)
                return df_enhanced, filename
            else:
                return None, None
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            return None, None
    
    def enhance_data_processing(self, df_clean):
        """å¢å¼ºçš„æ•°æ®å¤„ç†æµç¨‹"""
        try:
            # å½©ç§è¯†åˆ«
            if 'å½©ç§' in df_clean.columns:
                df_clean['åŸå§‹å½©ç§'] = df_clean['å½©ç§']
                df_clean['å½©ç§ç±»å‹'] = df_clean['å½©ç§'].apply(self.lottery_identifier.identify_lottery_type)
            
            # ç©æ³•åˆ†ç±»ç»Ÿä¸€
            if 'ç©æ³•' in df_clean.columns:
                df_clean['ç©æ³•åˆ†ç±»'] = df_clean['ç©æ³•'].apply(self.play_normalizer.normalize_category)
            
            # è®¡ç®—è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
            self.calculate_account_total_periods_by_lottery(df_clean)
            
            # æå–æŠ•æ³¨é‡‘é¢å’Œæ–¹å‘ - å¢å¼ºç‰ˆï¼Œæ·»åŠ ä½ç½®ç²¾åº¦
            df_clean['æŠ•æ³¨é‡‘é¢'] = df_clean['é‡‘é¢'].apply(lambda x: self.extract_bet_amount_safe(x))
            
            # ä¿®æ”¹ï¼šä¼ å…¥ç©æ³•åˆ†ç±»ä¿¡æ¯è¿›è¡Œä½ç½®åˆ¤æ–­
            df_clean['æŠ•æ³¨æ–¹å‘'] = df_clean.apply(
                lambda row: self.enhanced_extract_direction_with_position(
                    row['å†…å®¹'], 
                    row['ç©æ³•åˆ†ç±»'],  # æ–°å¢ç©æ³•åˆ†ç±»å‚æ•°
                    row['å½©ç§ç±»å‹']
                ), 
                axis=1
            )
            
            # è¿‡æ»¤æœ‰æ•ˆè®°å½•
            df_valid = df_clean[
                (df_clean['æŠ•æ³¨æ–¹å‘'] != '') & 
                (df_clean['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
            ].copy()
            
            if len(df_valid) == 0:
                st.error("âŒ è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆè®°å½•")
                return pd.DataFrame()
            
            self.data_processed = True
            self.df_valid = df_valid
            
            return df_valid
            
        except Exception as e:
            logger.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            st.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def extract_bet_amount_safe(self, amount_text):
        """å®‰å…¨æå–æŠ•æ³¨é‡‘é¢"""
        try:
            if pd.isna(amount_text):
                return 0
            
            text = str(amount_text).strip()
            
            # ç›´æ¥è½¬æ¢
            try:
                cleaned_text = text.replace(',', '').replace('ï¼Œ', '').replace(' ', '')
                if re.match(r'^-?\d+(\.\d+)?$', cleaned_text):
                    amount = float(cleaned_text)
                    if amount >= self.config.min_amount:
                        return amount
            except:
                pass
            
            # æ¨¡å¼åŒ¹é…
            patterns = [
                r'æŠ•æ³¨[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'ä¸‹æ³¨[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'é‡‘é¢[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'æ€»é¢[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'(\d+[,ï¼Œ]?\d*\.?\d*)\s*å…ƒ',
                r'ï¿¥\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'Â¥\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'[\$ï¿¥Â¥]?\s*(\d+[,ï¼Œ]?\d*\.?\d+)',
                r'(\d+[,ï¼Œ]?\d*\.?\d+)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text)
                if match:
                    amount_str = match.group(1).replace(',', '').replace('ï¼Œ', '').replace(' ', '')
                    try:
                        amount = float(amount_str)
                        if amount >= self.config.min_amount:
                            return amount
                    except:
                        continue
            
            return 0
            
        except Exception as e:
            logger.warning(f"é‡‘é¢æå–å¤±è´¥: {amount_text}, é”™è¯¯: {e}")
            return 0
    
    def enhanced_extract_direction_with_position(self, content, play_category, lottery_type):
        """å¢å¼ºçš„æŠ•æ³¨æ–¹å‘æå– - åŒæ—¶åˆ©ç”¨ç©æ³•å’Œå†…å®¹è¿›è¡Œä½ç½®åˆ¤æ–­"""
        try:
            if pd.isna(content):
                return ""
            
            content_str = str(content).strip()
            play_category_str = str(play_category).strip() if play_category else ""
            
            # é¦–å…ˆæå–ä½ç½®ä¿¡æ¯ - ä¿®æ”¹ï¼šåŒæ—¶ä¼ å…¥ç©æ³•å’Œå†…å®¹
            position = self._extract_position_from_content_and_play(content_str, play_category_str, lottery_type)
            
            # æå–æ–¹å‘ä¿¡æ¯
            direction = self._extract_direction_from_content(content_str)
            
            if not direction:
                return ""
            
            # å¦‚æœæœ‰ä½ç½®ä¿¡æ¯ï¼Œç»„åˆæˆ"ä½ç½®-æ–¹å‘"æ ¼å¼
            if position and position != 'æœªçŸ¥ä½ç½®':
                return f"{position}-{direction}"
            else:
                return direction
            
        except Exception as e:
            logger.warning(f"æ–¹å‘æå–å¤±è´¥: {content}, ç©æ³•: {play_category}, é”™è¯¯: {e}")
            return ""
    
    def _extract_position_from_content_and_play(self, content, play_category, lottery_type):
        """ä»å†…å®¹å’Œç©æ³•ä¸­æå–ä½ç½®ä¿¡æ¯ - å®Œæ•´çš„åŒé‡åˆ¤æ–­é€»è¾‘"""
        content_str = str(content).strip()
        play_str = str(play_category).strip()
        
        # æ ¹æ®å½©ç§ç±»å‹è·å–ä½ç½®å…³é”®è¯
        position_keywords = self.config.position_keywords.get(lottery_type, {})
        
        # 1. é¦–å…ˆä»ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½®ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
        play_position = self._extract_position_from_text(play_str, position_keywords, "ç©æ³•")
        if play_position and play_position != 'æœªçŸ¥ä½ç½®':
            logger.info(f"ä»ç©æ³•è¯†åˆ«ä½ç½®: {play_str} -> {play_position}")
            return play_position
        
        # 2. ä»å†…å®¹ä¸­æå–ä½ç½®ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰
        content_position = self._extract_position_from_text(content_str, position_keywords, "å†…å®¹")
        if content_position and content_position != 'æœªçŸ¥ä½ç½®':
            logger.info(f"ä»å†…å®¹è¯†åˆ«ä½ç½®: {content_str} -> {content_position}")
            return content_position
        
        # 3. ç‰¹æ®Šå¤„ç†ç«–çº¿æ ¼å¼ï¼ˆä½ä¼˜å…ˆçº§ï¼‰
        vertical_position = self._extract_position_from_vertical_format(content_str, lottery_type)
        if vertical_position and vertical_position != 'æœªçŸ¥ä½ç½®':
            logger.info(f"ä»ç«–çº¿æ ¼å¼è¯†åˆ«ä½ç½®: {content_str} -> {vertical_position}")
            return vertical_position
        
        # 4. æ£€æŸ¥æ˜¯å¦æœ‰ä½ç½®-æ–¹å‘çš„ç»„åˆæ ¼å¼
        combined_position = self._extract_position_from_combined_format(content_str, position_keywords)
        if combined_position and combined_position != 'æœªçŸ¥ä½ç½®':
            logger.info(f"ä»ç»„åˆæ ¼å¼è¯†åˆ«ä½ç½®: {content_str} -> {combined_position}")
            return combined_position
        
        return 'æœªçŸ¥ä½ç½®'
    
    def _extract_position_from_text(self, text, position_keywords, source_type):
        """ä»æ–‡æœ¬ä¸­æå–ä½ç½®ä¿¡æ¯"""
        if not text:
            return 'æœªçŸ¥ä½ç½®'
        
        text_lower = text.lower()
        
        # ç²¾ç¡®åŒ¹é…ï¼šå®Œæ•´ä½ç½®åç§°
        for position, keywords in position_keywords.items():
            for keyword in keywords:
                keyword_lower = keyword.lower()
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯ï¼ˆè€ƒè™‘è¾¹ç•Œæƒ…å†µï¼‰
                if (keyword_lower == text_lower or 
                    f" {keyword_lower} " in f" {text_lower} " or
                    text_lower.startswith(keyword_lower + "-") or
                    text_lower.endswith("-" + keyword_lower)):
                    return position
        
        # æ¨¡ç³ŠåŒ¹é…ï¼šåŒ…å«å…³é”®è¯
        for position, keywords in position_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    return position
        
        return 'æœªçŸ¥ä½ç½®'
    
    def _extract_position_from_vertical_format(self, content, lottery_type):
        """ä»ç«–çº¿æ ¼å¼ä¸­æå–ä½ç½®ä¿¡æ¯"""
        if '|' not in content:
            return 'æœªçŸ¥ä½ç½®'
        
        try:
            if lottery_type == 'PK10':
                bets_by_position = self.content_parser.parse_pk10_vertical_format(content)
                for position in bets_by_position:
                    if bets_by_position[position]:
                        return position
            elif lottery_type == '3D':
                bets_by_position = self.content_parser.parse_3d_vertical_format(content)
                for position in bets_by_position:
                    if bets_by_position[position]:
                        return position
        except Exception as e:
            logger.warning(f"ç«–çº¿æ ¼å¼è§£æå¤±è´¥: {content}, é”™è¯¯: {str(e)}")
        
        return 'æœªçŸ¥ä½ç½®'
    
    def _extract_position_from_combined_format(self, content, position_keywords):
        """ä»ä½ç½®-æ–¹å‘ç»„åˆæ ¼å¼ä¸­æå–ä½ç½®"""
        if '-' not in content:
            return 'æœªçŸ¥ä½ç½®'
        
        parts = content.split('-')
        if len(parts) >= 2:
            position_part = parts[0].strip()
            return self._extract_position_from_text(position_part, position_keywords, "ç»„åˆæ ¼å¼")
        
        return 'æœªçŸ¥ä½ç½®'
    
    def _extract_direction_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–æ–¹å‘ä¿¡æ¯"""
        content_str = str(content).strip().lower()
        
        for direction, patterns in self.config.direction_patterns.items():
            for pattern in patterns:
                pattern_lower = pattern.lower()
                # ç²¾ç¡®åŒ¹é…æ–¹å‘å…³é”®è¯
                if (pattern_lower == content_str or 
                    f" {pattern_lower} " in f" {content_str} " or
                    content_str.startswith(pattern_lower + "-") or
                    content_str.endswith("-" + pattern_lower) or
                    pattern_lower in content_str):
                    return direction
        
        # ç‰¹æ®Šå¤„ç†ï¼šå’Œå€¼ç›¸å…³çš„æ–¹å‘
        if 'å’Œå€¼' in content_str or 'å’Œæ•°' in content_str or 'æ€»å’Œ' in content_str:
            for direction in ['å¤§', 'å°', 'å•', 'åŒ', 'è´¨', 'åˆ']:
                if direction in content_str:
                    return direction
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–¹å‘åœ¨å†…å®¹ä¸­æ˜ç¡®å‡ºç°
        direction_keywords = ['å¤§', 'å°', 'å•', 'åŒ', 'é¾™', 'è™', 'è´¨', 'åˆ']
        for direction in direction_keywords:
            if direction in content_str:
                return direction
        
        return ""
    
    def calculate_account_total_periods_by_lottery(self, df):
        """æŒ‰å½©ç§è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°ç»Ÿè®¡"""
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        
        lottery_col = 'åŸå§‹å½©ç§' if 'åŸå§‹å½©ç§' in df.columns else 'å½©ç§'
        
        for lottery in df[lottery_col].unique():
            df_lottery = df[df[lottery_col] == lottery]
            
            period_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·')['æœŸå·'].nunique().to_dict()
            self.account_total_periods_by_lottery[lottery] = period_counts
            
            record_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·').size().to_dict()
            self.account_record_stats_by_lottery[lottery] = record_counts
    
    def detect_all_wash_trades(self):
        """æ£€æµ‹æ‰€æœ‰ç±»å‹çš„å¯¹åˆ·äº¤æ˜“"""
        if not self.data_processed or self.df_valid is None or len(self.df_valid) == 0:
            st.error("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ç”¨äºæ£€æµ‹")
            return []
        
        self.performance_stats = {
            'start_time': datetime.now(),
            'total_records': len(self.df_valid),
            'total_periods': self.df_valid['æœŸå·'].nunique(),
            'total_accounts': self.df_valid['ä¼šå‘˜è´¦å·'].nunique()
        }
        
        df_filtered = self.exclude_multi_direction_accounts(self.df_valid)
        
        if len(df_filtered) == 0:
            st.error("âŒ è¿‡æ»¤åæ— æœ‰æ•ˆæ•°æ®")
            return []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_patterns = []
        total_steps = self.config.max_accounts_in_group - 1
        
        for account_count in range(2, self.config.max_accounts_in_group + 1):
            status_text.text(f"ğŸ” æ£€æµ‹{account_count}ä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼...")
            patterns = self.detect_n_account_patterns_optimized(df_filtered, account_count)
            all_patterns.extend(patterns)
            
            progress = (account_count - 1) / total_steps
            progress_bar.progress(progress)
        
        progress_bar.progress(1.0)
        status_text.text("âœ… æ£€æµ‹å®Œæˆ")
        
        self.performance_stats['end_time'] = datetime.now()
        self.performance_stats['detection_time'] = (
            self.performance_stats['end_time'] - self.performance_stats['start_time']
        ).total_seconds()
        self.performance_stats['total_patterns'] = len(all_patterns)
        
        self.display_performance_stats()
        
        return all_patterns
    
    def detect_n_account_patterns_optimized(self, df_filtered, n_accounts):
        """ä¼˜åŒ–ç‰ˆçš„Nä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼æ£€æµ‹"""
        wash_records = []
        
        period_groups = df_filtered.groupby(['æœŸå·', 'åŸå§‹å½©ç§'])
        
        valid_direction_combinations = self._get_valid_direction_combinations(n_accounts)
        
        batch_size = 100
        period_keys = list(period_groups.groups.keys())
        
        for i in range(0, len(period_keys), batch_size):
            batch_keys = period_keys[i:i+batch_size]
            
            for period_key in batch_keys:
                period_data = period_groups.get_group(period_key)
                period_accounts = period_data['ä¼šå‘˜è´¦å·'].unique()
                
                if len(period_accounts) < n_accounts:
                    continue
                
                batch_patterns = self._detect_combinations_for_period(
                    period_data, period_accounts, n_accounts, valid_direction_combinations
                )
                wash_records.extend(batch_patterns)
        
        return self.find_continuous_patterns_optimized(wash_records)
    
    def _get_valid_direction_combinations(self, n_accounts):
        """è·å–æœ‰æ•ˆçš„æ–¹å‘ç»„åˆ - å¢å¼ºç‰ˆï¼Œæ”¯æŒä½ç½®ç²¾åº¦"""
        valid_combinations = []
        
        # å¯¹äº2ä¸ªè´¦æˆ·ï¼šæ ‡å‡†çš„å¯¹ç«‹ç»„ï¼ˆåŒ…æ‹¬å¸¦ä½ç½®çš„å¯¹ç«‹ç»„ï¼‰
        if n_accounts == 2:
            # æ— ä½ç½®çš„å¯¹ç«‹ç»„
            for opposites in self.config.opposite_groups:
                dir1, dir2 = list(opposites)
                valid_combinations.append({
                    'directions': [dir1, dir2],
                    'dir1_count': 1,
                    'dir2_count': 1,
                    'opposite_type': f"{dir1}-{dir2}"
                })
            
            # å¸¦ä½ç½®çš„å¯¹ç«‹ç»„ - åŠ¨æ€ç”Ÿæˆ
            positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                        'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå',
                        'ç™¾ä½', 'åä½', 'ä¸ªä½', 'ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ']
            
            for position in positions:
                for opposites in self.config.opposite_groups:
                    dir1, dir2 = list(opposites)
                    valid_combinations.append({
                        'directions': [f"{position}-{dir1}", f"{position}-{dir2}"],
                        'dir1_count': 1,
                        'dir2_count': 1,
                        'opposite_type': f"{position}-{dir1} vs {position}-{dir2}"
                    })
        
        # å¯¹äº3ä¸ªåŠä»¥ä¸Šè´¦æˆ·ï¼šå…è®¸å¤šç§åˆ†å¸ƒ
        else:
            for opposites in self.config.opposite_groups:
                dir1, dir2 = list(opposites)
                
                for i in range(1, n_accounts):
                    j = n_accounts - i
                    valid_combinations.append({
                        'directions': [dir1] * i + [dir2] * j,
                        'dir1_count': i,
                        'dir2_count': j,
                        'opposite_type': f"{dir1}-{dir2}"
                    })
        
        return valid_combinations
    
    def _detect_combinations_for_period(self, period_data, period_accounts, n_accounts, valid_combinations):
        """ä¸ºå•ä¸ªæœŸå·æ£€æµ‹ç»„åˆ - æ·»åŠ è´¦æˆ·æœŸæ•°å·®å¼‚æ£€æŸ¥"""
        patterns = []
        
        # è·å–å½“å‰å½©ç§
        lottery = period_data['åŸå§‹å½©ç§'].iloc[0] if 'åŸå§‹å½©ç§' in period_data.columns else period_data['å½©ç§'].iloc[0]
        
        # æ„å»ºè´¦æˆ·ä¿¡æ¯å­—å…¸
        account_info = {}
        for _, row in period_data.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            direction = row['æŠ•æ³¨æ–¹å‘']
            amount = row['æŠ•æ³¨é‡‘é¢']
            
            if account not in account_info:
                account_info[account] = []
            account_info[account].append({
                'direction': direction,
                'amount': amount
            })
        
        # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„è´¦æˆ·ç»„åˆ
        for account_group in combinations(period_accounts, n_accounts):
            # æ–°å¢ï¼šæ£€æŸ¥è´¦æˆ·æœŸæ•°å·®å¼‚
            if not self._check_account_period_difference(account_group, lottery):
                continue
            
            group_directions = []
            group_amounts = []
            
            for account in account_group:
                if account in account_info:
                    if account_info[account]:
                        first_bet = account_info[account][0]
                        group_directions.append(first_bet['direction'])
                        group_amounts.append(first_bet['amount'])
            
            if len(group_directions) != n_accounts:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æœ‰æ•ˆçš„æ–¹å‘ç»„åˆ
            for combo in valid_combinations:
                target_directions = combo['directions']
                
                actual_directions_sorted = sorted(group_directions)
                target_directions_sorted = sorted(target_directions)
                
                if actual_directions_sorted == target_directions_sorted:
                    # è®¡ç®—ä¸¤ä¸ªæ–¹å‘çš„æ€»é‡‘é¢
                    dir1_total = 0
                    dir2_total = 0
                    dir1 = combo['directions'][0]  # å–ç¬¬ä¸€ä¸ªæ–¹å‘ä½œä¸ºå‚è€ƒ
                    
                    for direction, amount in zip(group_directions, group_amounts):
                        if direction == dir1:
                            dir1_total += amount
                        else:
                            dir2_total += amount
                    
                    # æ£€æŸ¥é‡‘é¢ç›¸ä¼¼åº¦ - æ ¹æ®è´¦æˆ·æ•°é‡ä½¿ç”¨ä¸åŒçš„é˜ˆå€¼
                    similarity_threshold = self.config.account_count_similarity_thresholds.get(
                        n_accounts, self.config.amount_similarity_threshold
                    )
                    
                    if dir1_total > 0 and dir2_total > 0:
                        similarity = min(dir1_total, dir2_total) / max(dir1_total, dir2_total)
                        
                        if similarity >= similarity_threshold:
                            lottery_type = period_data['å½©ç§ç±»å‹'].iloc[0] if 'å½©ç§ç±»å‹' in period_data.columns else 'æœªçŸ¥'
                            
                            record = {
                                'æœŸå·': period_data['æœŸå·'].iloc[0],
                                'å½©ç§': lottery,
                                'å½©ç§ç±»å‹': lottery_type,
                                'è´¦æˆ·ç»„': list(account_group),
                                'æ–¹å‘ç»„': group_directions,
                                'é‡‘é¢ç»„': group_amounts,
                                'æ€»é‡‘é¢': dir1_total + dir2_total,
                                'ç›¸ä¼¼åº¦': similarity,
                                'è´¦æˆ·æ•°é‡': n_accounts,
                                'æ¨¡å¼': f"{combo['opposite_type'].split('-')[0]}({combo['dir1_count']}ä¸ª) vs {combo['opposite_type'].split('-')[1]}({combo['dir2_count']}ä¸ª)",
                                'å¯¹ç«‹ç±»å‹': combo['opposite_type']
                            }
                            
                            patterns.append(record)
        
        return patterns
    
    def _check_account_period_difference(self, account_group, lottery):
        """æ£€æŸ¥è´¦æˆ·ç»„å†…è´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°å·®å¼‚æ˜¯å¦åœ¨é˜ˆå€¼å†…"""
        if lottery not in self.account_total_periods_by_lottery:
            return True  # å¦‚æœæ²¡æœ‰è¯¥å½©ç§çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œé»˜è®¤å…è®¸ç»„åˆ
        
        total_periods_stats = self.account_total_periods_by_lottery[lottery]
        
        # è·å–è´¦æˆ·ç»„å†…æ¯ä¸ªè´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°
        account_periods = []
        for account in account_group:
            if account in total_periods_stats:
                account_periods.append(total_periods_stats[account])
            else:
                # å¦‚æœæŸä¸ªè´¦æˆ·æ²¡æœ‰ç»Ÿè®¡ä¿¡æ¯ï¼Œæ— æ³•æ¯”è¾ƒï¼Œé»˜è®¤å…è®¸ç»„åˆ
                return True
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªè´¦æˆ·æœ‰æœŸæ•°ä¿¡æ¯ï¼Œæ— æ³•æ¯”è¾ƒï¼Œé»˜è®¤å…è®¸ç»„åˆ
        if len(account_periods) < 2:
            return True
        
        # è®¡ç®—æœ€å¤§å’Œæœ€å°æœŸæ•°å·®å¼‚
        max_period = max(account_periods)
        min_period = min(account_periods)
        period_diff = max_period - min_period
        
        # å¦‚æœæœŸæ•°å·®å¼‚è¶…è¿‡é˜ˆå€¼ï¼Œä¸å…è®¸ç»„åˆ
        if period_diff > self.config.account_period_diff_threshold:
            logger.info(f"è·³è¿‡è´¦æˆ·ç»„ {account_group}ï¼ŒæœŸæ•°å·®å¼‚ {period_diff} > {self.config.account_period_diff_threshold}")
            return False
        
        return True
    
    def find_continuous_patterns_optimized(self, wash_records):
        """ä¼˜åŒ–ç‰ˆçš„è¿ç»­å¯¹åˆ·æ¨¡å¼æ£€æµ‹ - ä¿®æ”¹é˜ˆå€¼é€»è¾‘"""
        if not wash_records:
            return []
        
        account_group_patterns = defaultdict(list)
        for record in wash_records:
            account_group_key = (tuple(sorted(record['è´¦æˆ·ç»„'])), record['å½©ç§'])
            account_group_patterns[account_group_key].append(record)
        
        continuous_patterns = []
        
        for (account_group, lottery), records in account_group_patterns.items():
            sorted_records = sorted(records, key=lambda x: x['æœŸå·'])
            
            # ä¿®æ”¹ï¼šæ ¹æ®æ–°çš„é˜ˆå€¼è¦æ±‚ç¡®å®šæœ€å°å¯¹åˆ·æœŸæ•°
            required_min_periods = self.get_required_min_periods(account_group, lottery)
            
            if len(sorted_records) >= required_min_periods:
                total_investment = sum(r['æ€»é‡‘é¢'] for r in sorted_records)
                similarities = [r['ç›¸ä¼¼åº¦'] for r in sorted_records]
                avg_similarity = np.mean(similarities) if similarities else 0
                
                opposite_type_counts = defaultdict(int)
                for record in sorted_records:
                    opposite_type_counts[record['å¯¹ç«‹ç±»å‹']] += 1
                
                pattern_count = defaultdict(int)
                for record in sorted_records:
                    pattern_count[record['æ¨¡å¼']] += 1
                
                main_opposite_type = max(opposite_type_counts.items(), key=lambda x: x[1])[0]
                
                # è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
                account_stats_info = []
                total_periods_stats = self.account_total_periods_by_lottery.get(lottery, {})
                record_stats = self.account_record_stats_by_lottery.get(lottery, {})
                
                for account in account_group:
                    total_periods = total_periods_stats.get(account, 0)
                    records_count = record_stats.get(account, 0)
                    account_stats_info.append(f"{account}({total_periods}æœŸ/{records_count}è®°å½•)")
                
                activity_level = self.get_account_group_activity_level(account_group, lottery)
                
                continuous_patterns.append({
                    'è´¦æˆ·ç»„': list(account_group),
                    'å½©ç§': lottery,
                    'å½©ç§ç±»å‹': records[0]['å½©ç§ç±»å‹'] if records else 'æœªçŸ¥',
                    'è´¦æˆ·æ•°é‡': len(account_group),
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': main_opposite_type,
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': dict(opposite_type_counts),
                    'å¯¹åˆ·æœŸæ•°': len(sorted_records),
                    'æ€»æŠ•æ³¨é‡‘é¢': total_investment,
                    'å¹³å‡ç›¸ä¼¼åº¦': avg_similarity,
                    'æ¨¡å¼åˆ†å¸ƒ': dict(pattern_count),
                    'è¯¦ç»†è®°å½•': sorted_records,
                    'è´¦æˆ·æ´»è·ƒåº¦': activity_level,
                    'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': account_stats_info,
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': required_min_periods
                })
        
        return continuous_patterns

    def exclude_multi_direction_accounts(self, df_valid):
        """æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨"""
        multi_direction_mask = (
            df_valid.groupby(['æœŸå·', 'ä¼šå‘˜è´¦å·'])['æŠ•æ³¨æ–¹å‘']
            .transform('nunique') > 1
        )
        
        df_filtered = df_valid[~multi_direction_mask].copy()
        
        return df_filtered
    
    def get_account_group_activity_level(self, account_group, lottery):
        """ä¿®æ”¹ï¼šæ ¹æ®æ–°çš„æ´»è·ƒåº¦é˜ˆå€¼è·å–æ´»è·ƒåº¦æ°´å¹³"""
        if lottery not in self.account_total_periods_by_lottery:
            return 'unknown'
        
        total_periods_stats = self.account_total_periods_by_lottery[lottery]
        
        # è®¡ç®—è´¦æˆ·ç»„ä¸­åœ¨æŒ‡å®šå½©ç§çš„æœ€å°æ€»æŠ•æ³¨æœŸæ•°
        min_total_periods = min(total_periods_stats.get(account, 0) for account in account_group)
        
        # ä¿®æ”¹ï¼šæŒ‰ç…§æ–°çš„æ´»è·ƒåº¦é˜ˆå€¼
        if min_total_periods <= self.config.period_thresholds['low_activity']:
            return 'low'        # æ€»æŠ•æ³¨æœŸæ•°1-10
        elif min_total_periods <= self.config.period_thresholds['medium_activity_high']:
            return 'medium'     # æ€»æŠ•æ³¨æœŸæ•°11-50
        elif min_total_periods <= self.config.period_thresholds['high_activity_high']:
            return 'high'       # æ€»æŠ•æ³¨æœŸæ•°51-100
        else:
            return 'very_high'  # æ€»æŠ•æ³¨æœŸæ•°100ä»¥ä¸Š
    
    def get_required_min_periods(self, account_group, lottery):
        """ä¿®æ”¹ï¼šæ ¹æ®æ–°çš„æ´»è·ƒåº¦é˜ˆå€¼è·å–æ‰€éœ€çš„æœ€å°å¯¹åˆ·æœŸæ•°"""
        activity_level = self.get_account_group_activity_level(account_group, lottery)
        
        if activity_level == 'low':
            return self.config.period_thresholds['min_periods_low']      # 3æœŸ
        elif activity_level == 'medium':
            return self.config.period_thresholds['min_periods_medium']   # 5æœŸ
        elif activity_level == 'high':
            return self.config.period_thresholds['min_periods_high']     # 8æœŸ
        else:
            return self.config.period_thresholds['min_periods_very_high'] # 11æœŸ
    
    def display_performance_stats(self):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
        if not self.performance_stats:
            return
        
        with st.expander("ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡", expanded=False):
            st.write(f"**æ•°æ®å¤„ç†ç»Ÿè®¡:**")
            st.write(f"- æ€»è®°å½•æ•°: {self.performance_stats['total_records']:,}")
            st.write(f"- æ€»æœŸå·æ•°: {self.performance_stats['total_periods']:,}")
            st.write(f"- æ€»è´¦æˆ·æ•°: {self.performance_stats['total_accounts']:,}")
            
            if 'detection_time' in self.performance_stats:
                st.write(f"**æ£€æµ‹æ€§èƒ½:**")
                st.write(f"- æ£€æµ‹æ—¶é—´: {self.performance_stats['detection_time']:.2f} ç§’")
                st.write(f"- å‘ç°æ¨¡å¼: {self.performance_stats['total_patterns']} ä¸ª")
    
    def display_detailed_results(self, patterns):
        """æ˜¾ç¤ºè¯¦ç»†æ£€æµ‹ç»“æœ"""
        st.write("\n" + "="*60)
        st.write("ğŸ¯ å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç»“æœ")
        st.write("="*60)
        
        if not patterns:
            st.error("âŒ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„è¿ç»­å¯¹åˆ·æ¨¡å¼")
            return
        
        patterns_by_lottery = defaultdict(list)
        for pattern in patterns:
            lottery_key = pattern['å½©ç§']
            patterns_by_lottery[lottery_key].append(pattern)
        
        for lottery, lottery_patterns in patterns_by_lottery.items():
            with st.expander(f"ğŸ² å½©ç§ï¼š{lottery}ï¼ˆå‘ç°{len(lottery_patterns)}ç»„ï¼‰", expanded=True):
                for i, pattern in enumerate(lottery_patterns, 1):
                    st.markdown(f"**å¯¹åˆ·ç»„ {i}:** {' â†” '.join(pattern['è´¦æˆ·ç»„'])}")
                    
                    activity_icon = "ğŸŸ¢" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'low' else "ğŸŸ¡" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'medium' else "ğŸŸ " if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'high' else "ğŸ”´"
                    st.markdown(f"**æ´»è·ƒåº¦:** {activity_icon} {pattern['è´¦æˆ·æ´»è·ƒåº¦']} | **å½©ç§:** {pattern['å½©ç§']} | **ä¸»è¦ç±»å‹:** {pattern['ä¸»è¦å¯¹ç«‹ç±»å‹']}")
                    
                    st.markdown(f"**è´¦æˆ·åœ¨è¯¥å½©ç§æŠ•æ³¨æœŸæ•°/è®°å½•æ•°:** {', '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯'])}")
                    st.markdown(f"**å¯¹åˆ·æœŸæ•°:** {pattern['å¯¹åˆ·æœŸæ•°']}æœŸ (è¦æ±‚â‰¥{pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°']}æœŸ)")
                    st.markdown(f"**æ€»é‡‘é¢:** {pattern['æ€»æŠ•æ³¨é‡‘é¢']:.2f}å…ƒ | **å¹³å‡åŒ¹é…:** {pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}")
                    
                    st.markdown("**è¯¦ç»†è®°å½•:**")
                    for j, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                        account_directions = []
                        for account, direction, amount in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„']):
                            account_directions.append(f"{account}({direction}:{amount})")
                        
                        st.markdown(f"{j}. **æœŸå·:** {record['æœŸå·']} | **æ¨¡å¼:** {record['æ¨¡å¼']} | **æ–¹å‘:** {' â†” '.join(account_directions)} | **åŒ¹é…åº¦:** {record['ç›¸ä¼¼åº¦']:.2%}")
                    
                    if i < len(lottery_patterns):
                        st.markdown("---")
        
        self.display_summary_statistics(patterns)
    
    def display_summary_statistics(self, patterns):
        """æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡"""
        if not patterns:
            return
            
        st.write(f"\n{'='*60}")
        st.write("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        st.write(f"{'='*60}")
        
        total_groups = len(patterns)
        total_accounts = sum(p['è´¦æˆ·æ•°é‡'] for p in patterns)
        total_wash_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        account_count_stats = defaultdict(int)
        for pattern in patterns:
            account_count_stats[pattern['è´¦æˆ·æ•°é‡']] += 1
        
        lottery_stats = defaultdict(int)
        for pattern in patterns:
            lottery_stats[pattern['å½©ç§']] += 1
        
        activity_stats = defaultdict(int)
        for pattern in patterns:
            activity_stats[pattern['è´¦æˆ·æ´»è·ƒåº¦']] += 1
        
        opposite_type_stats = defaultdict(int)
        for pattern in patterns:
            for opposite_type, count in pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ'].items():
                opposite_type_stats[opposite_type] += count
        
        st.write(f"**ğŸ¯ æ£€æµ‹ç»“æœæ±‡æ€»:**")
        st.write(f"- å¯¹åˆ·ç»„æ•°: {total_groups} ç»„")
        st.write(f"- æ¶‰åŠè´¦æˆ·: {total_accounts} ä¸ª")
        st.write(f"- æ€»å¯¹åˆ·æœŸæ•°: {total_wash_periods} æœŸ")
        st.write(f"- æ€»æ¶‰åŠé‡‘é¢: {total_amount:.2f} å…ƒ")
        
        st.write(f"**ğŸ‘¥ æŒ‰è´¦æˆ·æ•°é‡åˆ†å¸ƒ:**")
        for account_count, count in sorted(account_count_stats.items()):
            st.write(f"- {account_count}ä¸ªè´¦æˆ·ç»„: {count} ç»„")
        
        st.write(f"**ğŸ² æŒ‰å½©ç§åˆ†å¸ƒ:**")
        for lottery, count in lottery_stats.items():
            st.write(f"- {lottery}: {count} ç»„")
            
        st.write(f"**ğŸ“ˆ æŒ‰æ´»è·ƒåº¦åˆ†å¸ƒ:**")
        for activity, count in activity_stats.items():
            st.write(f"- {activity}æ´»è·ƒåº¦: {count} ç»„")
            
        st.write(f"**ğŸ¯ æŒ‰å¯¹ç«‹ç±»å‹åˆ†å¸ƒ:**")
        for opposite_type, count in opposite_type_stats.items():
            st.write(f"- {opposite_type}: {count} æœŸå¯¹åˆ·")

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ¯ æ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    with st.sidebar:
        st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
        uploaded_file = st.file_uploader(
            "è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶", 
            type=['xlsx', 'xls', 'csv'],
            help="è¯·ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—ï¼šä¼šå‘˜è´¦å·ã€æœŸå·ã€å†…å®¹ã€é‡‘é¢"
        )
    
    if uploaded_file is not None:
        try:
            # é…ç½®å‚æ•°
            st.sidebar.header("âš™ï¸ æ£€æµ‹å‚æ•°é…ç½®")
            
            min_amount = st.sidebar.number_input("æœ€å°æŠ•æ³¨é‡‘é¢", value=10, min_value=1, help="ä½äºæ­¤é‡‘é¢çš„è®°å½•å°†è¢«è¿‡æ»¤")
            base_similarity_threshold = st.sidebar.slider("åŸºç¡€é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼", 0.8, 1.0, 0.8, 0.01, help="2ä¸ªè´¦æˆ·çš„åŸºç¡€åŒ¹é…åº¦é˜ˆå€¼")
            max_accounts = st.sidebar.slider("æœ€å¤§æ£€æµ‹è´¦æˆ·æ•°", 2, 8, 5, help="æ£€æµ‹çš„æœ€å¤§è´¦æˆ·ç»„åˆæ•°é‡")
            
            # æ–°å¢ï¼šè´¦æˆ·æœŸæ•°å·®å¼‚é˜ˆå€¼é…ç½®
            period_diff_threshold = st.sidebar.number_input(
                "è´¦æˆ·æœŸæ•°æœ€å¤§å·®å¼‚é˜ˆå€¼", 
                value=150, 
                min_value=0, 
                max_value=1000,
                help="è´¦æˆ·æ€»æŠ•æ³¨æœŸæ•°æœ€å¤§å…è®¸å·®å¼‚ï¼Œè¶…è¿‡æ­¤å€¼ä¸è¿›è¡Œç»„åˆæ£€æµ‹"
            )
            
            # æ´»è·ƒåº¦é˜ˆå€¼é…ç½®
            st.sidebar.subheader("ğŸ“Š æ´»è·ƒåº¦é˜ˆå€¼é…ç½®")
            st.sidebar.markdown("**æ–°é˜ˆå€¼è®¾ç½®:**")
            st.sidebar.markdown("- **1-10æœŸ:** è¦æ±‚â‰¥3æœŸè¿ç»­å¯¹åˆ·")
            st.sidebar.markdown("- **11-50æœŸ:** è¦æ±‚â‰¥5æœŸè¿ç»­å¯¹åˆ·")  
            st.sidebar.markdown("- **51-100æœŸ:** è¦æ±‚â‰¥8æœŸè¿ç»­å¯¹åˆ·")
            st.sidebar.markdown("- **100æœŸä»¥ä¸Š:** è¦æ±‚â‰¥11æœŸè¿ç»­å¯¹åˆ·")
            
            # å¤šè´¦æˆ·åŒ¹é…åº¦é…ç½®
            st.sidebar.subheader("ğŸ¯ å¤šè´¦æˆ·åŒ¹é…åº¦é…ç½®")
            st.sidebar.markdown("**è´¦æˆ·æ•°é‡ vs åŒ¹é…åº¦è¦æ±‚:**")
            st.sidebar.markdown("- **2ä¸ªè´¦æˆ·:** 80%åŒ¹é…åº¦")
            st.sidebar.markdown("- **3ä¸ªè´¦æˆ·:** 85%åŒ¹é…åº¦")  
            st.sidebar.markdown("- **4ä¸ªè´¦æˆ·:** 90%åŒ¹é…åº¦")
            st.sidebar.markdown("- **5ä¸ªè´¦æˆ·:** 95%åŒ¹é…åº¦")
            
            # æ›´æ–°é…ç½®å‚æ•°
            config = Config()
            config.min_amount = min_amount
            config.amount_similarity_threshold = base_similarity_threshold
            config.max_accounts_in_group = max_accounts
            config.account_period_diff_threshold = period_diff_threshold
            
            # è®¾ç½®å¤šè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼
            config.account_count_similarity_thresholds = {
                2: base_similarity_threshold,
                3: max(base_similarity_threshold + 0.05, 0.85),
                4: max(base_similarity_threshold + 0.1, 0.9),
                5: max(base_similarity_threshold + 0.15, 0.95)
            }
            
            detector = WashTradeDetector(config)
            
            st.success(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
            
            with st.spinner("ğŸ”„ æ­£åœ¨è§£ææ•°æ®..."):
                df_enhanced, filename = detector.upload_and_process(uploaded_file)
                
                if df_enhanced is not None and len(df_enhanced) > 0:
                    st.success("âœ… æ•°æ®è§£æå®Œæˆ")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æœ‰æ•ˆè®°å½•æ•°", f"{len(df_enhanced):,}")
                    with col2:
                        st.metric("å”¯ä¸€æœŸå·æ•°", f"{df_enhanced['æœŸå·'].nunique():,}")
                    with col3:
                        st.metric("å”¯ä¸€è´¦æˆ·æ•°", f"{df_enhanced['ä¼šå‘˜è´¦å·'].nunique():,}")
                    with col4:
                        if 'å½©ç§ç±»å‹' in df_enhanced.columns:
                            st.metric("å½©ç§ç±»å‹æ•°", f"{df_enhanced['å½©ç§ç±»å‹'].nunique()}")
                    
                    with st.expander("ğŸ“Š æ•°æ®è¯¦æƒ…", expanded=False):
                        tab1, tab2, tab3 = st.tabs(["æ•°æ®æ¦‚è§ˆ", "å½©ç§åˆ†å¸ƒ", "ä½ç½®åˆ¤æ–­è¯¦æƒ…"])
                        
                        with tab1:
                            st.dataframe(df_enhanced.head(100), use_container_width=True)
                            
                        with tab2:
                            if 'å½©ç§ç±»å‹' in df_enhanced.columns:
                                lottery_type_stats = df_enhanced['å½©ç§ç±»å‹'].value_counts()
                                st.bar_chart(lottery_type_stats)
                        
                        with tab3:
                            # æ˜¾ç¤ºä½ç½®åˆ¤æ–­çš„è¯¦ç»†åˆ†æ
                            if 'æŠ•æ³¨æ–¹å‘' in df_enhanced.columns:
                                position_analysis = df_enhanced[['ç©æ³•åˆ†ç±»', 'å†…å®¹', 'æŠ•æ³¨æ–¹å‘']].copy()
                                position_analysis['ä½ç½®æ¥æº'] = position_analysis.apply(
                                    lambda row: "ç©æ³•" if '-' in row['æŠ•æ³¨æ–¹å‘'] and row['ç©æ³•åˆ†ç±»'] in row['æŠ•æ³¨æ–¹å‘'] else 
                                               "å†…å®¹" if '-' in row['æŠ•æ³¨æ–¹å‘'] else "æ— ä½ç½®", 
                                    axis=1
                                )
                                st.dataframe(position_analysis.head(50), use_container_width=True)
                                
                                # ä½ç½®æ¥æºç»Ÿè®¡
                                source_stats = position_analysis['ä½ç½®æ¥æº'].value_counts()
                                st.write("**ä½ç½®åˆ¤æ–­æ¥æºç»Ÿè®¡:**")
                                for source, count in source_stats.items():
                                    st.write(f"- {source}: {count} æ¡è®°å½•")
                    
                    st.info("ğŸš€ è‡ªåŠ¨å¼€å§‹æ£€æµ‹å¯¹åˆ·äº¤æ˜“...")
                    with st.spinner("ğŸ” æ­£åœ¨æ£€æµ‹å¯¹åˆ·äº¤æ˜“..."):
                        patterns = detector.detect_all_wash_trades()
                    
                    if patterns:
                        st.success(f"âœ… æ£€æµ‹å®Œæˆï¼å‘ç° {len(patterns)} ä¸ªå¯¹åˆ·ç»„")
                        detector.display_detailed_results(patterns)
                    else:
                        st.warning("âš ï¸ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„å¯¹åˆ·è¡Œä¸º")
                else:
                    st.error("âŒ æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
            
        except Exception as e:
            st.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
            st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("ğŸ” æ™ºèƒ½æ£€æµ‹")
            st.markdown("""
            - å¤šè´¦æˆ·å¯¹åˆ·æ¨¡å¼è¯†åˆ«
            - æ™ºèƒ½é‡‘é¢åŒ¹é…åˆ†æ
            - æ´»è·ƒåº¦è‡ªé€‚åº”é˜ˆå€¼
            - å®æ—¶è¿›åº¦ç›‘æ§
            """)
        
        with col2:
            st.subheader("ğŸ“Š ä¸“ä¸šåˆ†æ")
            st.markdown("""
            - å®Œæ•´å½©ç§æ”¯æŒï¼ˆæ–°å¢3Dç³»åˆ—ï¼‰
            - ç©æ³•åˆ†ç±»æ ‡å‡†åŒ–
            - æ•°æ®è´¨é‡éªŒè¯
            - è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
            """)
        
        with col3:
            st.subheader("ğŸš€ é«˜æ•ˆå¤„ç†")
            st.markdown("""
            - å¤§æ•°æ®é‡ä¼˜åŒ–
            - å¹¶è¡Œæ£€æµ‹ç®—æ³•
            - ä¸€é”®å¯¼å‡ºç»“æœ
            - å®æ—¶æ€§èƒ½ç›‘æ§
            """)
    
    with st.expander("ğŸ“– ç³»ç»Ÿä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½è¯´æ˜

        **ğŸ¯ æ£€æµ‹é€»è¾‘ï¼š**
        - **æ€»æŠ•æ³¨æœŸæ•°**ï¼šè´¦æˆ·åœ¨ç‰¹å®šå½©ç§ä¸­çš„æ‰€æœ‰æœŸå·æŠ•æ³¨æ¬¡æ•°
        - **å¯¹åˆ·æœŸæ•°**ï¼šè´¦æˆ·ç»„å®é™…å‘ç”Ÿå¯¹åˆ·è¡Œä¸ºçš„æœŸæ•°
        - æ ¹æ®**æ€»æŠ•æ³¨æœŸæ•°**åˆ¤å®šè´¦æˆ·æ´»è·ƒåº¦ï¼Œè®¾ç½®ä¸åŒçš„**å¯¹åˆ·æœŸæ•°**é˜ˆå€¼

        **ğŸ“Š æ–°æ´»è·ƒåº¦åˆ¤å®šï¼š**
        - **1-10æœŸ**ï¼šè¦æ±‚â‰¥3æœŸè¿ç»­å¯¹åˆ·
        - **11-50æœŸ**ï¼šè¦æ±‚â‰¥5æœŸè¿ç»­å¯¹åˆ·  
        - **51-100æœŸ**ï¼šè¦æ±‚â‰¥8æœŸè¿ç»­å¯¹åˆ·
        - **100æœŸä»¥ä¸Š**ï¼šè¦æ±‚â‰¥11æœŸè¿ç»­å¯¹åˆ·

        **ğŸ¯ å¤šè´¦æˆ·åŒ¹é…åº¦è¦æ±‚ï¼š**
        - **2ä¸ªè´¦æˆ·**ï¼š80%åŒ¹é…åº¦
        - **3ä¸ªè´¦æˆ·**ï¼š85%åŒ¹é…åº¦  
        - **4ä¸ªè´¦æˆ·**ï¼š90%åŒ¹é…åº¦
        - **5ä¸ªè´¦æˆ·**ï¼š95%åŒ¹é…åº¦

        **ğŸ”„ è´¦æˆ·æœŸæ•°å·®å¼‚æ£€æŸ¥ï¼š**
        - é¿å…æœŸæ•°å·®å¼‚è¿‡å¤§çš„è´¦æˆ·ç»„åˆ
        - é»˜è®¤é˜ˆå€¼ï¼š150æœŸ
        - å¯è‡ªå®šä¹‰è°ƒæ•´é˜ˆå€¼

        **ğŸ² ä½ç½®åˆ¤æ–­å¢å¼ºï¼š**
        - **åŒé‡åˆ¤æ–­æœºåˆ¶**ï¼šåŒæ—¶åˆ©ç”¨ç©æ³•å’Œå†…å®¹è¿›è¡Œä½ç½®åˆ¤æ–­
        - **ä¼˜å…ˆçº§é¡ºåº**ï¼šç©æ³•åˆ†ç±» > æŠ•æ³¨å†…å®¹ > ç«–çº¿æ ¼å¼ > ç»„åˆæ ¼å¼
        - **ç²¾ç¡®åŒ¹é…**ï¼šæ”¯æŒå®Œæ•´ä½ç½®åç§°å’Œå…³é”®è¯åŒ¹é…
        - **å¤šæ ¼å¼æ”¯æŒ**ï¼šPK10ç«–çº¿æ ¼å¼ã€3Dç«–çº¿æ ¼å¼ã€ä½ç½®-æ–¹å‘ç»„åˆæ ¼å¼

        **âš¡ è‡ªåŠ¨æ£€æµ‹ï¼š**
        - æ•°æ®ä¸Šä¼ åè‡ªåŠ¨å¼€å§‹å¤„ç†å’Œåˆ†æ
        - æ— éœ€æ‰‹åŠ¨ç‚¹å‡»å¼€å§‹æ£€æµ‹æŒ‰é’®
        """)

if __name__ == "__main__":
    main()
