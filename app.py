import pandas as pd
import numpy as np
import streamlit as st
import io
import re
import logging
import zipfile
import openpyxl
from openpyxl.styles import Font, Alignment
from collections import defaultdict
from datetime import datetime
from itertools import combinations
import warnings
import traceback
import hashlib
from functools import lru_cache

# é…ç½®æ—¥å¿—å’Œè­¦å‘Š
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('MultiAccountWashTrade')

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== é…ç½®ç±» ====================
class Config:
    def __init__(self):
        self.min_amount = 10
        self.amount_similarity_threshold = 0.8
        self.min_continuous_periods = 3
        self.max_accounts_in_group = 5
        self.supported_file_types = ['.xlsx', '.xls', '.csv']
        
        # åˆ—åæ˜ å°„é…ç½®
        self.column_mappings = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
        
        # æ´»è·ƒåº¦é˜ˆå€¼é…ç½®
        self.period_thresholds = {
            'low_activity': 10,
            'medium_activity_low': 11,
            'medium_activity_high': 50,
            'high_activity_low': 51,
            'high_activity_high': 100,
            'min_periods_low': 3,
            'min_periods_medium': 5,
            'min_periods_high': 8,
            'min_periods_very_high': 11
        }
        
        # å¤šè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼
        self.account_count_similarity_thresholds = {
            2: 0.8,
            3: 0.85,
            4: 0.9,
            5: 0.95
        }
        
        # è´¦æˆ·æœŸæ•°å·®å¼‚é˜ˆå€¼
        self.account_period_diff_threshold = 101
        
        # æ–¹å‘æ¨¡å¼
        self.base_direction_patterns = {
            'å°': ['ä¸¤é¢-å°', 'å’Œå€¼-å°', 'å°', 'small', 'xia', 'xiao', 'å’Œå€¼å°', 'æ€»å’Œ-å°', 'æ€»å’Œå°', 'å’Œå€¼_å°', 'æ€»å’Œ_å°'],
            'å¤§': ['ä¸¤é¢-å¤§', 'å’Œå€¼-å¤§', 'å¤§', 'big', 'da', 'large', 'å’Œå€¼å¤§', 'æ€»å’Œ-å¤§', 'æ€»å’Œå¤§', 'å’Œå€¼_å¤§', 'æ€»å’Œ_å¤§'], 
            'å•': ['ä¸¤é¢-å•', 'å’Œå€¼-å•', 'å•', 'odd', 'dan', 'å¥‡æ•°', 'å’Œå€¼å•', 'æ€»å’Œ-å•', 'æ€»å’Œå•', 'å’Œå€¼_å•', 'æ€»å’Œ_å•'],
            'åŒ': ['ä¸¤é¢-åŒ', 'å’Œå€¼-åŒ', 'åŒ', 'even', 'shuang', 'å¶æ•°', 'å’Œå€¼åŒ', 'æ€»å’Œ-åŒ', 'æ€»å’ŒåŒ', 'å’Œå€¼_åŒ', 'æ€»å’Œ_åŒ'],
            'é¾™': ['é¾™', 'long', 'dragon', 'é¾', 'é¾è™-é¾™', 'é¾™è™-é¾™', 'é¾è™_é¾™'],
            'è™': ['è™', 'hu', 'tiger', 'é¾è™-è™', 'é¾™è™-è™', 'é¾è™_è™'],
            'è´¨': ['è´¨', 'è´¨æ•°', 'prime', 'zhi', 'è³ª', 'è³ªæ•¸', 'ç´ æ•°'],
            'åˆ': ['åˆ', 'åˆæ•°', 'composite', 'he', 'åˆæ•¸', 'åˆæˆæ•°'],
        }
        
        # å¢å¼ºæ–¹å‘æ¨¡å¼
        self.enhanced_direction_patterns = {
            'ç‰¹å°': ['ç‰¹å°', 'æå°', 'æœ€å°', 'ç‰¹å°å•', 'ç‰¹å°åŒ', 'ç‰¹ç -å°', 'ç‰¹ç å°', 'ç‰¹ç _å°'],
            'ç‰¹å¤§': ['ç‰¹å¤§', 'æå¤§', 'æœ€å¤§', 'ç‰¹å•å¤§', 'ç‰¹åŒå¤§', 'ç‰¹ç -å¤§', 'ç‰¹ç å¤§', 'ç‰¹ç _å¤§'],
            'ç‰¹å•': ['ç‰¹å•', 'ç‰¹ç -å•', 'ç‰¹ç å•', 'ç‰¹ç _å•'],
            'ç‰¹åŒ': ['ç‰¹åŒ', 'ç‰¹ç -åŒ', 'ç‰¹ç åŒ', 'ç‰¹ç _åŒ'],
            'æ€»å’Œå°': ['æ€»å’Œå°', 'å’Œå°', 'æ€»å’Œ-å°', 'å’Œå€¼å°', 'å’Œå€¼-å°', 'å† äºšå’Œå°', 'å† äºšå’Œ-å°'],
            'æ€»å’Œå¤§': ['æ€»å’Œå¤§', 'å’Œå¤§', 'æ€»å’Œ-å¤§', 'å’Œå€¼å¤§', 'å’Œå€¼-å¤§', 'å† äºšå’Œå¤§', 'å† äºšå’Œ-å¤§'],
            'æ€»å’Œå•': ['æ€»å’Œå•', 'å’Œå•', 'æ€»å’Œ-å•', 'å’Œå€¼å•', 'å’Œå€¼-å•', 'å† äºšå’Œå•', 'å† äºšå’Œ-å•'],
            'æ€»å’ŒåŒ': ['æ€»å’ŒåŒ', 'å’ŒåŒ', 'æ€»å’Œ-åŒ', 'å’Œå€¼åŒ', 'å’Œå€¼-åŒ', 'å† äºšå’ŒåŒ', 'å† äºšå’Œ-åŒ'],
            
            'å¤§å•': ['å¤§å•', 'å•å¤§', 'big-odd', 'å¤§-å•', 'å•-å¤§'],
            'å¤§åŒ': ['å¤§åŒ', 'åŒå¤§', 'big-even', 'å¤§-åŒ', 'åŒ-å¤§'],
            'å°å•': ['å°å•', 'å•å°', 'small-odd', 'å°-å•', 'å•-å°'],
            'å°åŒ': ['å°åŒ', 'åŒå°', 'small-even', 'å°-åŒ', 'åŒ-å°'],
            
            'å¤©è‚–': ['å¤©è‚–', 'å¤©è‚–', 'å¤©', 'å¤©ç”Ÿè‚–', 'å¤©è‚–ç '],
            'åœ°è‚–': ['åœ°è‚–', 'åœ°è‚–', 'åœ°', 'åœ°ç”Ÿè‚–', 'åœ°è‚–ç '],
            'å®¶è‚–': ['å®¶è‚–', 'å®¶ç¦½', 'å®¶è‚–', 'å®¶', 'å®¶ç¦½è‚–', 'å®¶ç”Ÿè‚–'],
            'é‡è‚–': ['é‡è‚–', 'é‡å…½', 'é‡è‚–', 'é‡', 'é‡å…½è‚–', 'é‡ç”Ÿè‚–'],
            'å°¾å¤§': ['å°¾å¤§', 'å°¾å¤§', 'å¤§å°¾', 'å°¾æ•°å¤§', 'å°¾æ•¸å¤§'],
            'å°¾å°': ['å°¾å°', 'å°¾å°', 'å°å°¾', 'å°¾æ•°å°', 'å°¾æ•¸å°'],

            'å°¾å¤§': ['å°¾å¤§', 'å°¾å¤§', 'å¤§å°¾', 'å°¾æ•°å¤§', 'å°¾æ•¸å¤§', 'ç‰¹ç ä¸¤é¢-å°¾å¤§'],
            'å°¾å°': ['å°¾å°', 'å°¾å°', 'å°å°¾', 'å°¾æ•°å°', 'å°¾æ•¸å°', 'ç‰¹ç ä¸¤é¢-å°¾å°'],
            'ç‰¹å¤§': ['ç‰¹å¤§', 'æå¤§', 'æœ€å¤§', 'ç‰¹å•å¤§', 'ç‰¹åŒå¤§', 'ç‰¹ç -å¤§', 'ç‰¹ç å¤§', 'ç‰¹ç _å¤§', 'ç‰¹ç ä¸¤é¢-ç‰¹å¤§'],
            'ç‰¹å°': ['ç‰¹å°', 'æå°', 'æœ€å°', 'ç‰¹å°å•', 'ç‰¹å°åŒ', 'ç‰¹ç -å°', 'ç‰¹ç å°', 'ç‰¹ç _å°', 'ç‰¹ç ä¸¤é¢-ç‰¹å°'],
            'ç‰¹å•': ['ç‰¹å•', 'ç‰¹ç -å•', 'ç‰¹ç å•', 'ç‰¹ç _å•', 'ç‰¹ç ä¸¤é¢-ç‰¹å•'],
            'ç‰¹åŒ': ['ç‰¹åŒ', 'ç‰¹ç -åŒ', 'ç‰¹ç åŒ', 'ç‰¹ç _åŒ', 'ç‰¹ç ä¸¤é¢-ç‰¹åŒ'],
            
            'å¤§': ['å¤§', 'big', 'large', 'da', 'ç‰¹ç ä¸¤é¢-å¤§'],
            'å°': ['å°', 'small', 'xiao', 'ç‰¹ç ä¸¤é¢-å°'], 
            'å•': ['å•', 'odd', 'dan', 'å¥‡', 'ç‰¹ç ä¸¤é¢-å•'],
            'åŒ': ['åŒ', 'even', 'shuang', 'å¶', 'ç‰¹ç ä¸¤é¢-åŒ'],
            
            'æ­£1ç‰¹-å¤§': ['æ­£1ç‰¹-å¤§', 'æ­£ä¸€ç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹-å¤§', 'æ­£1ç‰¹å¤§', 'æ­£ä¸€ç‰¹å¤§', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹-å¤§'],
            'æ­£1ç‰¹-å°': ['æ­£1ç‰¹-å°', 'æ­£ä¸€ç‰¹-å°', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹-å°', 'æ­£1ç‰¹å°', 'æ­£ä¸€ç‰¹å°', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹-å°'],
            'æ­£1ç‰¹-å•': ['æ­£1ç‰¹-å•', 'æ­£ä¸€ç‰¹-å•', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹-å•', 'æ­£1ç‰¹å•', 'æ­£ä¸€ç‰¹å•', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹-å•'],
            'æ­£1ç‰¹-åŒ': ['æ­£1ç‰¹-åŒ', 'æ­£ä¸€ç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹-åŒ', 'æ­£1ç‰¹åŒ', 'æ­£ä¸€ç‰¹åŒ', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹-åŒ'],
            
            'æ­£2ç‰¹-å¤§': ['æ­£2ç‰¹-å¤§', 'æ­£äºŒç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£äºŒç‰¹-å¤§', 'æ­£2ç‰¹å¤§', 'æ­£äºŒç‰¹å¤§', 'æ­£ç ç‰¹-æ­£äºŒç‰¹-å¤§'],
            'æ­£2ç‰¹-å°': ['æ­£2ç‰¹-å°', 'æ­£äºŒç‰¹-å°', 'æ­£ç ç‰¹_æ­£äºŒç‰¹-å°', 'æ­£2ç‰¹å°', 'æ­£äºŒç‰¹å°', 'æ­£ç ç‰¹-æ­£äºŒç‰¹-å°'],
            'æ­£2ç‰¹-å•': ['æ­£2ç‰¹-å•', 'æ­£äºŒç‰¹-å•', 'æ­£ç ç‰¹_æ­£äºŒç‰¹-å•', 'æ­£2ç‰¹å•', 'æ­£äºŒç‰¹å•', 'æ­£ç ç‰¹-æ­£äºŒç‰¹-å•'],
            'æ­£2ç‰¹-åŒ': ['æ­£2ç‰¹-åŒ', 'æ­£äºŒç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£äºŒç‰¹-åŒ', 'æ­£2ç‰¹åŒ', 'æ­£äºŒç‰¹åŒ', 'æ­£ç ç‰¹-æ­£äºŒç‰¹-åŒ'],
            
            'æ­£3ç‰¹-å¤§': ['æ­£3ç‰¹-å¤§', 'æ­£ä¸‰ç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹-å¤§', 'æ­£3ç‰¹å¤§', 'æ­£ä¸‰ç‰¹å¤§', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹-å¤§'],
            'æ­£3ç‰¹-å°': ['æ­£3ç‰¹-å°', 'æ­£ä¸‰ç‰¹-å°', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹-å°', 'æ­£3ç‰¹å°', 'æ­£ä¸‰ç‰¹å°', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹-å°'],
            'æ­£3ç‰¹-å•': ['æ­£3ç‰¹-å•', 'æ­£ä¸‰ç‰¹-å•', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹-å•', 'æ­£3ç‰¹å•', 'æ­£ä¸‰ç‰¹å•', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹-å•'],
            'æ­£3ç‰¹-åŒ': ['æ­£3ç‰¹-åŒ', 'æ­£ä¸‰ç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹-åŒ', 'æ­£3ç‰¹åŒ', 'æ­£ä¸‰ç‰¹åŒ', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹-åŒ'],
            
            'æ­£4ç‰¹-å¤§': ['æ­£4ç‰¹-å¤§', 'æ­£å››ç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£å››ç‰¹-å¤§', 'æ­£4ç‰¹å¤§', 'æ­£å››ç‰¹å¤§', 'æ­£ç ç‰¹-æ­£å››ç‰¹-å¤§'],
            'æ­£4ç‰¹-å°': ['æ­£4ç‰¹-å°', 'æ­£å››ç‰¹-å°', 'æ­£ç ç‰¹_æ­£å››ç‰¹-å°', 'æ­£4ç‰¹å°', 'æ­£å››ç‰¹å°', 'æ­£ç ç‰¹-æ­£å››ç‰¹-å°'],
            'æ­£4ç‰¹-å•': ['æ­£4ç‰¹-å•', 'æ­£å››ç‰¹-å•', 'æ­£ç ç‰¹_æ­£å››ç‰¹-å•', 'æ­£4ç‰¹å•', 'æ­£å››ç‰¹å•', 'æ­£ç ç‰¹-æ­£å››ç‰¹-å•'],
            'æ­£4ç‰¹-åŒ': ['æ­£4ç‰¹-åŒ', 'æ­£å››ç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£å››ç‰¹-åŒ', 'æ­£4ç‰¹åŒ', 'æ­£å››ç‰¹åŒ', 'æ­£ç ç‰¹-æ­£å››ç‰¹-åŒ'],
            
            'æ­£5ç‰¹-å¤§': ['æ­£5ç‰¹-å¤§', 'æ­£äº”ç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£äº”ç‰¹-å¤§', 'æ­£5ç‰¹å¤§', 'æ­£äº”ç‰¹å¤§', 'æ­£ç ç‰¹-æ­£äº”ç‰¹-å¤§'],
            'æ­£5ç‰¹-å°': ['æ­£5ç‰¹-å°', 'æ­£äº”ç‰¹-å°', 'æ­£ç ç‰¹_æ­£äº”ç‰¹-å°', 'æ­£5ç‰¹å°', 'æ­£äº”ç‰¹å°', 'æ­£ç ç‰¹-æ­£äº”ç‰¹-å°'],
            'æ­£5ç‰¹-å•': ['æ­£5ç‰¹-å•', 'æ­£äº”ç‰¹-å•', 'æ­£ç ç‰¹_æ­£äº”ç‰¹-å•', 'æ­£5ç‰¹å•', 'æ­£äº”ç‰¹å•', 'æ­£ç ç‰¹-æ­£äº”ç‰¹-å•'],
            'æ­£5ç‰¹-åŒ': ['æ­£5ç‰¹-åŒ', 'æ­£äº”ç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£äº”ç‰¹-åŒ', 'æ­£5ç‰¹åŒ', 'æ­£äº”ç‰¹åŒ', 'æ­£ç ç‰¹-æ­£äº”ç‰¹-åŒ'],
            
            'æ­£6ç‰¹-å¤§': ['æ­£6ç‰¹-å¤§', 'æ­£å…­ç‰¹-å¤§', 'æ­£ç ç‰¹_æ­£å…­ç‰¹-å¤§', 'æ­£6ç‰¹å¤§', 'æ­£å…­ç‰¹å¤§', 'æ­£ç ç‰¹-æ­£å…­ç‰¹-å¤§'],
            'æ­£6ç‰¹-å°': ['æ­£6ç‰¹-å°', 'æ­£å…­ç‰¹-å°', 'æ­£ç ç‰¹_æ­£å…­ç‰¹-å°', 'æ­£6ç‰¹å°', 'æ­£å…­ç‰¹å°', 'æ­£ç ç‰¹-æ­£å…­ç‰¹-å°'],
            'æ­£6ç‰¹-å•': ['æ­£6ç‰¹-å•', 'æ­£å…­ç‰¹-å•', 'æ­£ç ç‰¹_æ­£å…­ç‰¹-å•', 'æ­£6ç‰¹å•', 'æ­£å…­ç‰¹å•', 'æ­£ç ç‰¹-æ­£å…­ç‰¹-å•'],
            'æ­£6ç‰¹-åŒ': ['æ­£6ç‰¹-åŒ', 'æ­£å…­ç‰¹-åŒ', 'æ­£ç ç‰¹_æ­£å…­ç‰¹-åŒ', 'æ­£6ç‰¹åŒ', 'æ­£å…­ç‰¹åŒ', 'æ­£ç ç‰¹-æ­£å…­ç‰¹-åŒ'],
            
            'æ­£1-å¤§': ['æ­£1-å¤§', 'æ­£ç 1-å¤§', 'æ­£ä¸€-å¤§', 'æ­£ç _æ­£ä¸€-å¤§', 'æ­£ç 1å¤§', 'æ­£ä¸€å¤§'],
            'æ­£1-å°': ['æ­£1-å°', 'æ­£ç 1-å°', 'æ­£ä¸€-å°', 'æ­£ç _æ­£ä¸€-å°', 'æ­£ç 1å°', 'æ­£ä¸€å°'],
            'æ­£1-å•': ['æ­£1-å•', 'æ­£ç 1-å•', 'æ­£ä¸€-å•', 'æ­£ç _æ­£ä¸€-å•', 'æ­£ç 1å•', 'æ­£ä¸€å•'],
            'æ­£1-åŒ': ['æ­£1-åŒ', 'æ­£ç 1-åŒ', 'æ­£ä¸€-åŒ', 'æ­£ç _æ­£ä¸€-åŒ', 'æ­£ç 1åŒ', 'æ­£ä¸€åŒ'],
            
            'æ­£2-å¤§': ['æ­£2-å¤§', 'æ­£ç 2-å¤§', 'æ­£äºŒ-å¤§', 'æ­£ç _æ­£äºŒ-å¤§', 'æ­£ç 2å¤§', 'æ­£äºŒå¤§'],
            'æ­£2-å°': ['æ­£2-å°', 'æ­£ç 2-å°', 'æ­£äºŒ-å°', 'æ­£ç _æ­£äºŒ-å°', 'æ­£ç 2å°', 'æ­£äºŒå°'],
            'æ­£2-å•': ['æ­£2-å•', 'æ­£ç 2-å•', 'æ­£äºŒ-å•', 'æ­£ç _æ­£äºŒ-å•', 'æ­£ç 2å•', 'æ­£äºŒå•'],
            'æ­£2-åŒ': ['æ­£2-åŒ', 'æ­£ç 2-åŒ', 'æ­£äºŒ-åŒ', 'æ­£ç _æ­£äºŒ-åŒ', 'æ­£ç 2åŒ', 'æ­£äºŒåŒ'],
            
            'æ­£3-å¤§': ['æ­£3-å¤§', 'æ­£ç 3-å¤§', 'æ­£ä¸‰-å¤§', 'æ­£ç _æ­£ä¸‰-å¤§', 'æ­£ç 3å¤§', 'æ­£ä¸‰å¤§'],
            'æ­£3-å°': ['æ­£3-å°', 'æ­£ç 3-å°', 'æ­£ä¸‰-å°', 'æ­£ç _æ­£ä¸‰-å°', 'æ­£ç 3å°', 'æ­£ä¸‰å°'],
            'æ­£3-å•': ['æ­£3-å•', 'æ­£ç 3-å•', 'æ­£ä¸‰-å•', 'æ­£ç _æ­£ä¸‰-å•', 'æ­£ç 3å•', 'æ­£ä¸‰å•'],
            'æ­£3-åŒ': ['æ­£3-åŒ', 'æ­£ç 3-åŒ', 'æ­£ä¸‰-åŒ', 'æ­£ç _æ­£ä¸‰-åŒ', 'æ­£ç 3åŒ', 'æ­£ä¸‰åŒ'],
            
            'æ­£4-å¤§': ['æ­£4-å¤§', 'æ­£ç 4-å¤§', 'æ­£å››-å¤§', 'æ­£ç _æ­£å››-å¤§', 'æ­£ç 4å¤§', 'æ­£å››å¤§'],
            'æ­£4-å°': ['æ­£4-å°', 'æ­£ç 4-å°', 'æ­£å››-å°', 'æ­£ç _æ­£å››-å°', 'æ­£ç 4å°', 'æ­£å››å°'],
            'æ­£4-å•': ['æ­£4-å•', 'æ­£ç 4-å•', 'æ­£å››-å•', 'æ­£ç _æ­£å››-å•', 'æ­£ç 4å•', 'æ­£å››å•'],
            'æ­£4-åŒ': ['æ­£4-åŒ', 'æ­£ç 4-åŒ', 'æ­£å››-åŒ', 'æ­£ç _æ­£å››-åŒ', 'æ­£ç 4åŒ', 'æ­£å››åŒ'],
            
            'æ­£5-å¤§': ['æ­£5-å¤§', 'æ­£ç 5-å¤§', 'æ­£äº”-å¤§', 'æ­£ç _æ­£äº”-å¤§', 'æ­£ç 5å¤§', 'æ­£äº”å¤§'],
            'æ­£5-å°': ['æ­£5-å°', 'æ­£ç 5-å°', 'æ­£äº”-å°', 'æ­£ç _æ­£äº”-å°', 'æ­£ç 5å°', 'æ­£äº”å°'],
            'æ­£5-å•': ['æ­£5-å•', 'æ­£ç 5-å•', 'æ­£äº”-å•', 'æ­£ç _æ­£äº”-å•', 'æ­£ç 5å•', 'æ­£äº”å•'],
            'æ­£5-åŒ': ['æ­£5-åŒ', 'æ­£ç 5-åŒ', 'æ­£äº”-åŒ', 'æ­£ç _æ­£äº”-åŒ', 'æ­£ç 5åŒ', 'æ­£äº”åŒ'],
            
            'æ­£6-å¤§': ['æ­£6-å¤§', 'æ­£ç 6-å¤§', 'æ­£å…­-å¤§', 'æ­£ç _æ­£å…­-å¤§', 'æ­£ç 6å¤§', 'æ­£å…­å¤§'],
            'æ­£6-å°': ['æ­£6-å°', 'æ­£ç 6-å°', 'æ­£å…­-å°', 'æ­£ç _æ­£å…­-å°', 'æ­£ç 6å°', 'æ­£å…­å°'],
            'æ­£6-å•': ['æ­£6-å•', 'æ­£ç 6-å•', 'æ­£å…­-å•', 'æ­£ç _æ­£å…­-å•', 'æ­£ç 6å•', 'æ­£å…­å•'],
            'æ­£6-åŒ': ['æ­£6-åŒ', 'æ­£ç 6-åŒ', 'æ­£å…­-åŒ', 'æ­£ç _æ­£å…­-åŒ', 'æ­£ç 6åŒ', 'æ­£å…­åŒ'],
        }
        
        # åˆå¹¶æ–¹å‘æ¨¡å¼
        self.direction_patterns = {**self.base_direction_patterns, **self.enhanced_direction_patterns}
        
        # å¯¹ç«‹ç»„é…ç½®
        self.opposite_groups = [
            {'å¤§', 'å°'}, {'å•', 'åŒ'}, {'é¾™', 'è™'}, {'è´¨', 'åˆ'},
            {'ç‰¹å¤§', 'ç‰¹å°'}, {'ç‰¹å•', 'ç‰¹åŒ'}, 
            {'æ€»å’Œå¤§', 'æ€»å’Œå°'}, {'æ€»å’Œå•', 'æ€»å’ŒåŒ'},
            {'å¤§å•', 'å°åŒ'}, {'å¤§åŒ', 'å°å•'},
            {'å¤©è‚–', 'åœ°è‚–'}, {'å®¶è‚–', 'é‡è‚–'}, {'å°¾å¤§', 'å°¾å°'},
            
            {'æ­£1ç‰¹-å¤§', 'æ­£1ç‰¹-å°'}, {'æ­£1ç‰¹-å•', 'æ­£1ç‰¹-åŒ'},
            {'æ­£2ç‰¹-å¤§', 'æ­£2ç‰¹-å°'}, {'æ­£2ç‰¹-å•', 'æ­£2ç‰¹-åŒ'},
            {'æ­£3ç‰¹-å¤§', 'æ­£3ç‰¹-å°'}, {'æ­£3ç‰¹-å•', 'æ­£3ç‰¹-åŒ'},
            {'æ­£4ç‰¹-å¤§', 'æ­£4ç‰¹-å°'}, {'æ­£4ç‰¹-å•', 'æ­£4ç‰¹-åŒ'},
            {'æ­£5ç‰¹-å¤§', 'æ­£5ç‰¹-å°'}, {'æ­£5ç‰¹-å•', 'æ­£5ç‰¹-åŒ'},
            {'æ­£6ç‰¹-å¤§', 'æ­£6ç‰¹-å°'}, {'æ­£6ç‰¹-å•', 'æ­£6ç‰¹-åŒ'},
            
            {'æ­£1-å¤§', 'æ­£1-å°'}, {'æ­£1-å•', 'æ­£1-åŒ'},
            {'æ­£2-å¤§', 'æ­£2-å°'}, {'æ­£2-å•', 'æ­£2-åŒ'},
            {'æ­£3-å¤§', 'æ­£3-å°'}, {'æ­£3-å•', 'æ­£3-åŒ'},
            {'æ­£4-å¤§', 'æ­£4-å°'}, {'æ­£4-å•', 'æ­£4-åŒ'},
            {'æ­£5-å¤§', 'æ­£5-å°'}, {'æ­£5-å•', 'æ­£5-åŒ'},
            {'æ­£6-å¤§', 'æ­£6-å°'}, {'æ­£6-å•', 'æ­£6-åŒ'},
            
            {'å°¾å¤§', 'å°¾å°'},
            {'ç‰¹å¤§', 'ç‰¹å°'},
            {'ç‰¹å•', 'ç‰¹åŒ'},
            {'ç‰¹ç ä¸¤é¢-å°¾å¤§', 'ç‰¹ç ä¸¤é¢-å°¾å°'},
            {'ç‰¹ç ä¸¤é¢-ç‰¹å¤§', 'ç‰¹ç ä¸¤é¢-ç‰¹å°'},
            {'ç‰¹ç ä¸¤é¢-ç‰¹å•', 'ç‰¹ç ä¸¤é¢-ç‰¹åŒ'},
        ]
        
        # ä½ç½®å…³é”®è¯æ˜ å°„
        self.position_keywords = {
            'PK10': {
                'å† å†›': ['å† å†›', 'ç¬¬1å', 'ç¬¬ä¸€å', 'å‰ä¸€', 'å†  å†›', 'å† ã€€å†›'],
                'äºšå†›': ['äºšå†›', 'ç¬¬2å', 'ç¬¬äºŒå', 'äºš å†›', 'äºšã€€å†›'],
                'å­£å†›': ['å­£å†›', 'ç¬¬3å', 'ç¬¬ä¸‰å', 'å­£ å†›', 'å­£ã€€å†›'],
                'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å'],
                'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å'],
                'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å'],
                'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å'],
                'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å'],
                'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å'],
                'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å']
            },
            '3D': {
                'ç™¾ä½': ['ç™¾ä½', 'å®šä½_ç™¾ä½', 'ç™¾ä½å®šä½'],
                'åä½': ['åä½', 'å®šä½_åä½', 'åä½å®šä½'],
                'ä¸ªä½': ['ä¸ªä½', 'å®šä½_ä¸ªä½', 'ä¸ªä½å®šä½']
            },
            'SSC': {
                'ç¬¬1çƒ': ['ç¬¬1çƒ', 'ä¸‡ä½', 'ç¬¬ä¸€ä½', 'å®šä½_ä¸‡ä½', 'ä¸‡ä½å®šä½'],
                'ç¬¬2çƒ': ['ç¬¬2çƒ', 'åƒä½', 'ç¬¬äºŒä½', 'å®šä½_åƒä½', 'åƒä½å®šä½'],
                'ç¬¬3çƒ': ['ç¬¬3çƒ', 'ç™¾ä½', 'ç¬¬ä¸‰ä½', 'å®šä½_ç™¾ä½', 'ç™¾ä½å®šä½'],
                'ç¬¬4çƒ': ['ç¬¬4çƒ', 'åä½', 'ç¬¬å››ä½', 'å®šä½_åä½', 'åä½å®šä½'],
                'ç¬¬5çƒ': ['ç¬¬5çƒ', 'ä¸ªä½', 'ç¬¬äº”ä½', 'å®šä½_ä¸ªä½', 'ä¸ªä½å®šä½']
            },
            'LHC': {
                'ç‰¹ç ': ['ç‰¹ç ', 'ç‰¹è‚–', 'æ­£ç ç‰¹', 'ç‰¹ç A', 'ç‰¹ç B'],
                'æ­£1ç‰¹': ['æ­£1ç‰¹', 'æ­£ä¸€ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹'],
                'æ­£2ç‰¹': ['æ­£2ç‰¹', 'æ­£äºŒç‰¹', 'æ­£ç ç‰¹_æ­£äºŒç‰¹', 'æ­£ç ç‰¹-æ­£äºŒç‰¹'],
                'æ­£3ç‰¹': ['æ­£3ç‰¹', 'æ­£ä¸‰ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹'],
                'æ­£4ç‰¹': ['æ­£4ç‰¹', 'æ­£å››ç‰¹', 'æ­£ç ç‰¹_æ­£å››ç‰¹', 'æ­£ç ç‰¹-æ­£å››ç‰¹'],
                'æ­£5ç‰¹': ['æ­£5ç‰¹', 'æ­£äº”ç‰¹', 'æ­£ç ç‰¹_æ­£äº”ç‰¹', 'æ­£ç ç‰¹-æ­£äº”ç‰¹'],
                'æ­£6ç‰¹': ['æ­£6ç‰¹', 'æ­£å…­ç‰¹', 'æ­£ç ç‰¹_æ­£å…­ç‰¹', 'æ­£ç ç‰¹-æ­£å…­ç‰¹'],
                'æ­£1': ['æ­£1', 'æ­£ä¸€', 'æ­£ç 1', 'æ­£ç _æ­£ä¸€'],
                'æ­£2': ['æ­£2', 'æ­£äºŒ', 'æ­£ç 2', 'æ­£ç _æ­£äºŒ'],
                'æ­£3': ['æ­£3', 'æ­£ä¸‰', 'æ­£ç 3', 'æ­£ç _æ­£ä¸‰'],
                'æ­£4': ['æ­£4', 'æ­£å››', 'æ­£ç 4', 'æ­£ç _æ­£å››'],
                'æ­£5': ['æ­£5', 'æ­£äº”', 'æ­£ç 5', 'æ­£ç _æ­£äº”'],
                'æ­£6': ['æ­£6', 'æ­£å…­', 'æ­£ç 6', 'æ­£ç _æ­£å…­'],
                'å¹³ç‰¹': ['å¹³ç‰¹', 'å¹³ç‰¹è‚–', 'å¹³ç '],
                'è¿è‚–': ['è¿è‚–', 'äºŒè¿è‚–', 'ä¸‰è¿è‚–', 'å››è¿è‚–'],
                'è¿å°¾': ['è¿å°¾', 'äºŒè¿å°¾', 'ä¸‰è¿å°¾', 'å››è¿å°¾'],
                'è‰²æ³¢': ['è‰²æ³¢', 'çº¢æ³¢', 'è“æ³¢', 'ç»¿æ³¢'],
                'äº”è¡Œ': ['äº”è¡Œ', 'é‡‘', 'æœ¨', 'æ°´', 'ç«', 'åœŸ']
            }
        }

        # é‡‘é¢é˜ˆå€¼é…ç½®
        self.amount_threshold = {
            'max_amount_ratio': 10,
            'enable_threshold_filter': True
        }

# ==================== æ•°æ®å¤„ç†å™¨ç±» ====================
class DataProcessor:
    def __init__(self):
        self.required_columns = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹', 'é‡‘é¢']
        self.column_mapping = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID', 'ç”¨æˆ·åç§°', 'ç©å®¶åç§°'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°', 'å½©ç³»', 'æ¸¸æˆåç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·', 'å¼€å¥–æœŸå·', 'å¥–æœŸå·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»', 'ç©æ³•åç§°', 'æŠ•æ³¨æ–¹å¼'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯', 'å·ç ', 'é€‰å·'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼', 'å•æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é’±', 'å…ƒ']
        }
        
        self.similarity_threshold = 0.7
    
    def smart_column_identification(self, df_columns):
        """æ™ºèƒ½åˆ—è¯†åˆ«"""
        identified_columns = {}
        actual_columns = [str(col).strip() for col in df_columns]
        
        # åˆ é™¤å±•å¼€å™¨å’Œæ‰€æœ‰æ—¥å¿—è¾“å‡º
        for standard_col, possible_names in self.column_mapping.items():
            found = False
            for actual_col in actual_columns:
                actual_col_lower = actual_col.lower().replace(' ', '').replace('_', '').replace('-', '')
                
                for possible_name in possible_names:
                    possible_name_lower = possible_name.lower().replace(' ', '').replace('_', '').replace('-', '')
                    
                    set1 = set(possible_name_lower)
                    set2 = set(actual_col_lower)
                    intersection = set1 & set2
                    
                    similarity_score = len(intersection) / len(set1) if set1 else 0
                    
                    if (possible_name_lower in actual_col_lower or 
                        actual_col_lower in possible_name_lower or
                        similarity_score >= self.similarity_threshold):
                        
                        identified_columns[actual_col] = standard_col
                        found = True
                        break
                
                if found:
                    break
        
        return identified_columns
    
    def find_data_start(self, df):
        """æ™ºèƒ½æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®"""
        for row_idx in range(min(20, len(df))):
            for col_idx in range(min(10, len(df.columns))):
                cell_value = str(df.iloc[row_idx, col_idx])
                if pd.notna(cell_value) and any(keyword in cell_value for keyword in ['ä¼šå‘˜', 'è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•', 'å†…å®¹', 'è®¢å•', 'ç”¨æˆ·']):
                    return row_idx, col_idx
        return 0, 0
    
    def validate_data_quality(self, df):
        """æ•°æ®è´¨é‡éªŒè¯"""
        logger.info("æ­£åœ¨è¿›è¡Œæ•°æ®è´¨é‡éªŒè¯...")
        issues = []
        
        # æ£€æŸ¥å¿…è¦åˆ—
        missing_cols = [col for col in self.required_columns if col not in df.columns]
        if missing_cols:
            issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        
        # æ£€æŸ¥ç©ºå€¼
        for col in self.required_columns:
            if col in df.columns:
                null_count = df[col].isnull().sum()
                if null_count > 0:
                    issues.append(f"åˆ— '{col}' æœ‰ {null_count} ä¸ªç©ºå€¼")

        # æ£€æŸ¥é‡å¤æ•°æ®
        duplicate_count = df.duplicated().sum()
        if duplicate_count > 0:
            issues.append(f"å‘ç° {duplicate_count} æ¡é‡å¤è®°å½•")

        return issues
    
    def clean_data(self, uploaded_file):
        """æ•°æ®æ¸…æ´—ä¸»å‡½æ•°"""
        try:
            df_temp = pd.read_excel(uploaded_file, header=None, nrows=50)
            
            start_row, start_col = self.find_data_start(df_temp)
            
            df_clean = pd.read_excel(
                uploaded_file, 
                header=start_row,
                skiprows=range(start_row + 1) if start_row > 0 else None,
                dtype=str,
                na_filter=False,
                keep_default_na=False
            )
            
            if start_col > 0:
                df_clean = df_clean.iloc[:, start_col:]
            
            column_mapping = self.smart_column_identification(df_clean.columns)
            if column_mapping:
                df_clean = df_clean.rename(columns=column_mapping)
            
            missing_columns = [col for col in self.required_columns if col not in df_clean.columns]
            if missing_columns and len(df_clean.columns) >= 4:
                manual_mapping = {}
                col_names = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'å†…å®¹', 'ç©æ³•', 'é‡‘é¢']
                for i, col_name in enumerate(col_names):
                    if i < len(df_clean.columns):
                        manual_mapping[df_clean.columns[i]] = col_name
                
                df_clean = df_clean.rename(columns=manual_mapping)
            
            initial_count = len(df_clean)
            df_clean = df_clean.dropna(subset=[col for col in self.required_columns if col in df_clean.columns])
            df_clean = df_clean.dropna(axis=1, how='all')
            
            for col in self.required_columns:
                if col in df_clean.columns:
                    if col == 'ä¼šå‘˜è´¦å·':
                        df_clean[col] = df_clean[col].apply(
                            lambda x: str(x) if pd.notna(x) else ''
                        )
                    else:
                        df_clean[col] = df_clean[col].astype(str).str.strip()
            
            if 'æœŸå·' in df_clean.columns:
                df_clean['æœŸå·'] = df_clean['æœŸå·'].str.replace(r'\.0$', '', regex=True)
            
            if 'é‡‘é¢' in df_clean.columns:
                df_clean['é‡‘é¢'] = df_clean['é‡‘é¢'].apply(self.preprocess_amount_column)
            
            if 'å†…å®¹' in df_clean.columns:
                df_clean['å†…å®¹'] = df_clean['å†…å®¹'].apply(self.preprocess_content_column)
            
            self.validate_data_quality(df_clean)
            
            return df_clean
                
        except Exception as e:
            st.error(f"âŒ æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            logger.error(f"æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            return None
    
    def preprocess_amount_column(self, amount_text):
        """é¢„å¤„ç†é‡‘é¢åˆ—æ ¼å¼"""
        if pd.isna(amount_text):
            return amount_text
        
        text = str(amount_text).strip()
        
        if 'æŠ•æ³¨ï¼š' in text and 'æŠµç”¨ï¼š' in text:
            try:
                bet_part = text.split('æŠ•æ³¨ï¼š')[1].split('æŠµç”¨ï¼š')[0].strip()
                return f"æŠ•æ³¨ï¼š{bet_part}"
            except:
                return text
        
        return text
    
    def preprocess_content_column(self, content_text):
        """é¢„å¤„ç†å†…å®¹åˆ—æ ¼å¼"""
        if pd.isna(content_text):
            return content_text
        
        text = str(content_text).strip()
        
        if 'ç‰¹ç ä¸¤é¢-' in text:
            text = text.replace('ç‰¹ç ä¸¤é¢ - ', 'ç‰¹ç ä¸¤é¢-')
            text = text.replace('ç‰¹ç ä¸¤é¢- ', 'ç‰¹ç ä¸¤é¢-')
            return text
        
        return text

# ==================== å½©ç§è¯†åˆ«å™¨ ====================
LOTTERY_CONFIGS = {
    'PK10': {
        'lotteries': [
            'åˆ†åˆ†PKæ‹¾', 'ä¸‰åˆ†PKæ‹¾', 'äº”åˆ†PKæ‹¾', 'æ–°å¹¸è¿é£è‰‡', 'æ¾³æ´²å¹¸è¿10',
            'ä¸€åˆ†PK10', 'å®¾æœPK10', 'æé€Ÿé£è‰‡', 'æ¾³æ´²é£è‰‡', 'å¹¸è¿èµ›è½¦',
            'åˆ†åˆ†èµ›è½¦', 'åŒ—äº¬PK10', 'æ—§åŒ—äº¬PK10', 'æé€Ÿèµ›è½¦', 'å¹¸è¿èµ›è»Š', 
            'åŒ—äº¬èµ›è½¦', 'æé€ŸPK10', 'å¹¸è¿PK10', 'èµ›è½¦', 'èµ›è»Š'
        ],
        'min_number': 1,
        'max_number': 10,
        'gyh_min': 3,
        'gyh_max': 19,
        'position_names': ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                          'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
    },
    'K3': {
        'lotteries': [
            'åˆ†åˆ†å¿«ä¸‰', 'ä¸‰åˆ†å¿«3', 'äº”åˆ†å¿«3', 'æ¾³æ´²å¿«ä¸‰', 'å®¾æœå¿«ä¸‰',
            '1åˆ†å¿«ä¸‰', '3åˆ†å¿«ä¸‰', '5åˆ†å¿«ä¸‰', '10åˆ†å¿«ä¸‰', 'åŠ å·å¿«ä¸‰',
            'å¹¸è¿å¿«ä¸‰', 'å¤§å‘å¿«ä¸‰', 'å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 
            'æ¾³é—¨å¿«ä¸‰', 'é¦™æ¸¯å¿«ä¸‰', 'æ±Ÿè‹å¿«ä¸‰'
        ],
        'min_number': 1,
        'max_number': 6,
        'hezhi_min': 3,
        'hezhi_max': 18
    },
    'LHC': {
        'lotteries': [
            'æ–°æ¾³é—¨å…­åˆå½©', 'æ¾³é—¨å…­åˆå½©', 'é¦™æ¸¯å…­åˆå½©', 'ä¸€åˆ†å…­åˆå½©',
            'äº”åˆ†å…­åˆå½©', 'ä¸‰åˆ†å…­åˆå½©', 'é¦™æ¸¯â‘¥åˆå½©', 'åˆ†åˆ†å…­åˆå½©',
            'å¿«ä¹6åˆå½©', 'æ¸¯â‘¥åˆå½©', 'å°æ¹¾å¤§ä¹é€', 'å…­åˆ', 'lhc', 'å…­åˆå½©',
            'â‘¥åˆ', '6åˆ', 'å¤§å‘å…­åˆå½©'
        ],
        'min_number': 1,
        'max_number': 49
    },
    'SSC': {
        'lotteries': [
            'åˆ†åˆ†æ—¶æ—¶å½©', 'ä¸‰åˆ†æ—¶æ—¶å½©', 'äº”åˆ†æ—¶æ—¶å½©', 'å®¾æœæ—¶æ—¶å½©',
            '1åˆ†æ—¶æ—¶å½©', '3åˆ†æ—¶æ—¶å½©', '5åˆ†æ—¶æ—¶å½©', 'æ—§é‡åº†æ—¶æ—¶å½©',
            'å¹¸è¿æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©', 'æ–°ç–†æ—¶æ—¶å½©', 'å¤©æ´¥æ—¶æ—¶å½©',
            'é‡åº†æ—¶æ—¶å½©', 'ä¸Šæµ·æ—¶æ—¶å½©', 'å¹¿ä¸œæ—¶æ—¶å½©', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©'
        ],
        'min_number': 0,
        'max_number': 9
    },
    '3D': {
        'lotteries': [
            'æ’åˆ—ä¸‰', 'æ’åˆ—3', 'å¹¸è¿æ’åˆ—3', 'ä¸€åˆ†æ’åˆ—3', 'äºŒåˆ†æ’åˆ—3', 'ä¸‰åˆ†æ’åˆ—3', 
            'äº”åˆ†æ’åˆ—3', 'ååˆ†æ’åˆ—3', 'å¤§å‘æ’åˆ—3', 'å¥½è¿æ’åˆ—3', 'ç¦å½©3D', 'æé€Ÿ3D',
            'æé€Ÿæ’åˆ—3', 'å¹¸è¿3D', 'ä¸€åˆ†3D', 'äºŒåˆ†3D', 'ä¸‰åˆ†3D', 'äº”åˆ†3D', 
            'ååˆ†3D', 'å¤§å‘3D', 'å¥½è¿3D'
        ],
        'min_number': 0,
        'max_number': 9,
        'position_names': ['ç™¾ä½', 'åä½', 'ä¸ªä½']
    }
}

class LotteryIdentifier:
    def __init__(self):
        self.lottery_configs = LOTTERY_CONFIGS
        self.general_keywords = {
            'PK10': ['pk10', 'pkæ‹¾', 'é£è‰‡', 'èµ›è½¦', 'èµ›è»Š', 'å¹¸è¿10', 'åŒ—äº¬èµ›è½¦', 'æé€Ÿèµ›è½¦'],
            'K3': ['å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 'éª°å®', 'ä¸‰å†›'],
            'LHC': ['å…­åˆ', 'lhc', 'å…­åˆå½©', 'â‘¥åˆ', '6åˆ', 'ç‰¹ç ', 'å¹³ç‰¹', 'è¿è‚–'],
            'SSC': ['æ—¶æ—¶å½©', 'ssc', 'åˆ†åˆ†å½©', 'æ™‚æ™‚å½©', 'é‡åº†æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©'],
            '3D': ['æ’åˆ—ä¸‰', 'æ’åˆ—3', 'ç¦å½©3d', '3d', 'æé€Ÿ3d', 'æ’åˆ—', 'p3', 'pä¸‰']
        }
        
        self.lottery_aliases = {
            'åˆ†åˆ†PKæ‹¾': 'PK10', 'ä¸‰åˆ†PKæ‹¾': 'PK10', 'äº”åˆ†PKæ‹¾': 'PK10',
            'æ–°å¹¸è¿é£è‰‡': 'PK10', 'æ¾³æ´²å¹¸è¿10': 'PK10', 'ä¸€åˆ†PK10': 'PK10',
            'å®¾æœPK10': 'PK10', 'æé€Ÿé£è‰‡': 'PK10', 'æ¾³æ´²é£è‰‡': 'PK10',
            'å¹¸è¿èµ›è½¦': 'PK10', 'åˆ†åˆ†èµ›è½¦': 'PK10', 'åŒ—äº¬PK10': 'PK10',
            'æ—§åŒ—äº¬PK10': 'PK10', 'æé€Ÿèµ›è½¦': 'PK10', 'å¹¸è¿èµ›è»Š': 'PK10',
            'åŒ—äº¬èµ›è½¦': 'PK10', 'æé€ŸPK10': 'PK10', 'å¹¸è¿PK10': 'PK10',
            'åˆ†åˆ†å¿«ä¸‰': 'K3', 'ä¸‰åˆ†å¿«3': 'K3', 'äº”åˆ†å¿«3': 'K3', 'æ¾³æ´²å¿«ä¸‰': 'K3',
            'å®¾æœå¿«ä¸‰': 'K3', '1åˆ†å¿«ä¸‰': 'K3', '3åˆ†å¿«ä¸‰': 'K3', '5åˆ†å¿«ä¸‰': 'K3',
            '10åˆ†å¿«ä¸‰': 'K3', 'åŠ å·å¿«ä¸‰': 'K3', 'å¹¸è¿å¿«ä¸‰': 'K3', 'å¤§å‘å¿«ä¸‰': 'K3',
            'æ¾³é—¨å¿«ä¸‰': 'K3', 'é¦™æ¸¯å¿«ä¸‰': 'K3', 'æ±Ÿè‹å¿«ä¸‰': 'K3',
            'æ–°æ¾³é—¨å…­åˆå½©': 'LHC', 'æ¾³é—¨å…­åˆå½©': 'LHC', 'é¦™æ¸¯å…­åˆå½©': 'LHC',
            'ä¸€åˆ†å…­åˆå½©': 'LHC', 'äº”åˆ†å…­åˆå½©': 'LHC', 'ä¸‰åˆ†å…­åˆå½©': 'LHC',
            'é¦™æ¸¯â‘¥åˆå½©': 'LHC', 'åˆ†åˆ†å…­åˆå½©': 'LHC', 'å¿«ä¹6åˆå½©': 'LHC',
            'æ¸¯â‘¥åˆå½©': 'LHC', 'å°æ¹¾å¤§ä¹é€': 'LHC', 'å¤§å‘å…­åˆå½©': 'LHC',
            'åˆ†åˆ†æ—¶æ—¶å½©': 'SSC', 'ä¸‰åˆ†æ—¶æ—¶å½©': 'SSC', 'äº”åˆ†æ—¶æ—¶å½©': 'SSC',
            'å®¾æœæ—¶æ—¶å½©': 'SSC', '1åˆ†æ—¶æ—¶å½©': 'SSC', '3åˆ†æ—¶æ—¶å½©': 'SSC',
            '5åˆ†æ—¶æ—¶å½©': 'SSC', 'æ—§é‡åº†æ—¶æ—¶å½©': 'SSC', 'å¹¸è¿æ—¶æ—¶å½©': 'SSC',
            'è…¾è®¯åˆ†åˆ†å½©': 'SSC', 'æ–°ç–†æ—¶æ—¶å½©': 'SSC', 'å¤©æ´¥æ—¶æ—¶å½©': 'SSC',
            'é‡åº†æ—¶æ—¶å½©': 'SSC', 'ä¸Šæµ·æ—¶æ—¶å½©': 'SSC', 'å¹¿ä¸œæ—¶æ—¶å½©': 'SSC',
            'æ’åˆ—ä¸‰': '3D', 'æ’åˆ—3': '3D', 'å¹¸è¿æ’åˆ—3': '3D', 'ä¸€åˆ†æ’åˆ—3': '3D',
            'äºŒåˆ†æ’åˆ—3': '3D', 'ä¸‰åˆ†æ’åˆ—3': '3D', 'äº”åˆ†æ’åˆ—3': '3D', 'ååˆ†æ’åˆ—3': '3D',
            'å¤§å‘æ’åˆ—3': '3D', 'å¥½è¿æ’åˆ—3': '3D', 'ç¦å½©3D': '3D', 'æé€Ÿ3D': '3D',
            'æé€Ÿæ’åˆ—3': '3D', 'å¹¸è¿3D': '3D', 'ä¸€åˆ†3D': '3D', 'äºŒåˆ†3D': '3D',
            'ä¸‰åˆ†3D': '3D', 'äº”åˆ†3D': '3D', 'ååˆ†3D': '3D', 'å¤§å‘3D': '3D', 'å¥½è¿3D': '3D'
        }

    def identify_lottery_type(self, lottery_name):
        """å½©ç§ç±»å‹è¯†åˆ«"""
        lottery_str = str(lottery_name).strip()
        
        if lottery_str in self.lottery_aliases:
            return self.lottery_aliases[lottery_str]
        
        for lottery_type, config in self.lottery_configs.items():
            for lottery in config['lotteries']:
                if lottery in lottery_str:
                    return lottery_type
        
        lottery_lower = lottery_str.lower()
        
        for lottery_type, keywords in self.general_keywords.items():
            for keyword in keywords:
                if keyword.lower() in lottery_lower:
                    return lottery_type
        
        return lottery_str

# ==================== ç©æ³•åˆ†ç±»å™¨ ====================
class PlayCategoryNormalizer:
    def __init__(self):
        self.category_mapping = self._create_category_mapping()
    
    def _create_category_mapping(self):
        """åˆ›å»ºç©æ³•åˆ†ç±»æ˜ å°„"""
        mapping = {
            'å’Œå€¼': 'å’Œå€¼', 'å’Œå€¼_å¤§å°å•åŒ': 'å’Œå€¼', 'ä¸¤é¢': 'ä¸¤é¢',
            'äºŒä¸åŒå·': 'äºŒä¸åŒå·', 'ä¸‰ä¸åŒå·': 'ä¸‰ä¸åŒå·', 'ç‹¬èƒ†': 'ç‹¬èƒ†',
            'ç‚¹æ•°': 'å’Œå€¼', 'ä¸‰å†›': 'ç‹¬èƒ†', 'ä¸‰è»': 'ç‹¬èƒ†',
            
            'ç‰¹ç ': 'ç‰¹ç ', 'æ­£1ç‰¹': 'æ­£1ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹': 'æ­£1ç‰¹',
            'æ­£2ç‰¹': 'æ­£2ç‰¹', 'æ­£ç ç‰¹_æ­£äºŒç‰¹': 'æ­£2ç‰¹', 'æ­£3ç‰¹': 'æ­£3ç‰¹',
            'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹', 'æ­£4ç‰¹': 'æ­£4ç‰¹', 'æ­£ç ç‰¹_æ­£å››ç‰¹': 'æ­£4ç‰¹',
            'æ­£5ç‰¹': 'æ­£5ç‰¹', 'æ­£ç ç‰¹_æ­£äº”ç‰¹': 'æ­£5ç‰¹', 'æ­£6ç‰¹': 'æ­£6ç‰¹',
            'æ­£ç ç‰¹_æ­£å…­ç‰¹': 'æ­£6ç‰¹', 'æ­£ç ': 'æ­£ç ', 'æ­£ç‰¹': 'æ­£ç‰¹',
            'å°¾æ•°': 'å°¾æ•°', 'ç‰¹è‚–': 'ç‰¹è‚–', 'å¹³ç‰¹': 'å¹³ç‰¹', 'ä¸€è‚–': 'ä¸€è‚–',
            'è¿è‚–': 'è¿è‚–', 'è¿å°¾': 'è¿å°¾', 'é¾™è™': 'é¾™è™', 'äº”è¡Œ': 'äº”è¡Œ',
            'è‰²æ³¢': 'è‰²æ³¢', 'åŠæ³¢': 'åŠæ³¢', 'å¤©è‚–': 'å¤©è‚–', 'åœ°è‚–': 'åœ°è‚–',
            'å®¶è‚–': 'å®¶è‚–', 'é‡è‚–': 'é‡è‚–',
    
            'æ­£1ç‰¹': 'æ­£1ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹': 'æ­£1ç‰¹', 'æ­£ç ç‰¹-æ­£ä¸€ç‰¹': 'æ­£1ç‰¹',
            'æ­£2ç‰¹': 'æ­£2ç‰¹', 'æ­£ç ç‰¹_æ­£äºŒç‰¹': 'æ­£2ç‰¹', 'æ­£ç ç‰¹-æ­£äºŒç‰¹': 'æ­£2ç‰¹',
            'æ­£3ç‰¹': 'æ­£3ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹', 'æ­£ç ç‰¹-æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹',
            'æ­£4ç‰¹': 'æ­£4ç‰¹', 'æ­£ç ç‰¹_æ­£å››ç‰¹': 'æ­£4ç‰¹', 'æ­£ç ç‰¹-æ­£å››ç‰¹': 'æ­£4ç‰¹',
            'æ­£5ç‰¹': 'æ­£5ç‰¹', 'æ­£ç ç‰¹_æ­£äº”ç‰¹': 'æ­£5ç‰¹', 'æ­£ç ç‰¹-æ­£äº”ç‰¹': 'æ­£5ç‰¹',
            'æ­£6ç‰¹': 'æ­£6ç‰¹', 'æ­£ç ç‰¹_æ­£å…­ç‰¹': 'æ­£6ç‰¹', 'æ­£ç ç‰¹-æ­£å…­ç‰¹': 'æ­£6ç‰¹',
            
            'æ­£1': 'æ­£1', 'æ­£ç 1': 'æ­£1', 'æ­£ç _æ­£ä¸€': 'æ­£1',
            'æ­£2': 'æ­£2', 'æ­£ç 2': 'æ­£2', 'æ­£ç _æ­£äºŒ': 'æ­£2',
            'æ­£3': 'æ­£3', 'æ­£ç 3': 'æ­£3', 'æ­£ç _æ­£ä¸‰': 'æ­£3',
            'æ­£4': 'æ­£4', 'æ­£ç 4': 'æ­£4', 'æ­£ç _æ­£å››': 'æ­£4',
            'æ­£5': 'æ­£5', 'æ­£ç 5': 'æ­£5', 'æ­£ç _æ­£äº”': 'æ­£5',
            'æ­£6': 'æ­£6', 'æ­£ç 6': 'æ­£6', 'æ­£ç _æ­£å…­': 'æ­£6',
            
            'ä¸¤é¢': 'ä¸¤é¢', 'å¤§å°å•åŒ': 'ä¸¤é¢', 'ç™¾ä½': 'ç™¾ä½', 'åä½': 'åä½', 
            'ä¸ªä½': 'ä¸ªä½', 'ç™¾å': 'ç™¾å', 'ç™¾ä¸ª': 'ç™¾ä¸ª', 'åä¸ª': 'åä¸ª',
            'ç™¾åä¸ª': 'ç™¾åä¸ª', 'å®šä½èƒ†': 'å®šä½èƒ†', 'å®šä½èƒ†_ç™¾ä½': 'å®šä½èƒ†_ç™¾ä½',
            'å®šä½èƒ†_åä½': 'å®šä½èƒ†_åä½', 'å®šä½èƒ†_ä¸ªä½': 'å®šä½èƒ†_ä¸ªä½',
            
            'æ–—ç‰›': 'æ–—ç‰›', '1-5çƒ': '1-5çƒ', 'ç¬¬1çƒ': 'ç¬¬1çƒ', 'ç¬¬2çƒ': 'ç¬¬2çƒ',
            'ç¬¬3çƒ': 'ç¬¬3çƒ', 'ç¬¬4çƒ': 'ç¬¬4çƒ', 'ç¬¬5çƒ': 'ç¬¬5çƒ', 'æ€»å’Œ': 'æ€»å’Œ',
            'æ­£ç ': 'æ­£ç ', 'å®šä½èƒ†': 'å®šä½èƒ†',
            
            'å‰ä¸€': 'å† å†›', 'å®šä½èƒ†': 'å®šä½èƒ†', '1-5å': '1-5å', '6-10å': '6-10å',
            'å† å†›': 'å† å†›', 'äºšå†›': 'äºšå†›', 'å­£å†›': 'ç¬¬ä¸‰å', 'ç¬¬3å': 'ç¬¬ä¸‰å',
            'ç¬¬ä¸‰å': 'ç¬¬ä¸‰å', 'ç¬¬4å': 'ç¬¬å››å', 'ç¬¬å››å': 'ç¬¬å››å',
            'ç¬¬5å': 'ç¬¬äº”å', 'ç¬¬äº”å': 'ç¬¬äº”å', 'ç¬¬6å': 'ç¬¬å…­å', 'ç¬¬å…­å': 'ç¬¬å…­å',
            'ç¬¬7å': 'ç¬¬ä¸ƒå', 'ç¬¬ä¸ƒå': 'ç¬¬ä¸ƒå', 'ç¬¬8å': 'ç¬¬å…«å', 'ç¬¬å…«å': 'ç¬¬å…«å',
            'ç¬¬9å': 'ç¬¬ä¹å', 'ç¬¬ä¹å': 'ç¬¬ä¹å', 'ç¬¬10å': 'ç¬¬åå', 'ç¬¬åå': 'ç¬¬åå',
            'åŒé¢': 'ä¸¤é¢', 'å† äºšå’Œ': 'å† äºšå’Œ',
            
            '1-5å': '1-5å',
            '6-10å': '6-10å', 
            '1-5åå®šä½èƒ†': '1-5å',
            '6-10åå®šä½èƒ†': '6-10å',
            'å‰ä¸€': 'å† å†›',
            'å‰äºŒ': 'äºšå†›', 
            'å‰ä¸‰': 'ç¬¬ä¸‰å',
            'å‰å››': 'ç¬¬å››å',
            'å‰äº”': 'ç¬¬äº”å',
            'å®šä½èƒ†': 'å®šä½èƒ†'
        }
        return mapping
    
    def normalize_category(self, category):
        """ç»Ÿä¸€ç©æ³•åˆ†ç±»åç§°"""
        category_str = str(category).strip()
        
        if category_str in self.category_mapping:
            return self.category_mapping[category_str]
        
        for key, value in self.category_mapping.items():
            if key in category_str:
                return value
        
        category_lower = category_str.lower()
        
        pk10_position_mapping = {
            'å† å†›': ['å† å†›', 'ç¬¬ä¸€å', 'ç¬¬1å', '1st', 'å‰ä¸€'],
            'äºšå†›': ['äºšå†›', 'ç¬¬äºŒå', 'ç¬¬2å', '2nd', 'å‰äºŒ'], 
            'ç¬¬ä¸‰å': ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›', '3rd', 'å‰ä¸‰'],
            'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å', '4th', 'å‰å››'],
            'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å', '5th', 'å‰äº”'],
            'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å', '6th'],
            'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th'],
            'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å', '8th'],
            'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å', '9th'],
            'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å', '10th']
        }
        
        for position, keywords in pk10_position_mapping.items():
            for keyword in keywords:
                if keyword in category_lower:
                    return position
        
        if any(word in category_lower for word in ['ç™¾ä½']):
            return 'ç™¾ä½'
        if any(word in category_lower for word in ['åä½']):
            return 'åä½'
        if any(word in category_lower for word in ['ä¸ªä½']):
            return 'ä¸ªä½'
        
        if any(word in category_lower for word in ['ç¬¬1çƒ', 'ä¸‡ä½']):
            return 'ç¬¬1çƒ'
        if any(word in category_lower for word in ['ç¬¬2çƒ', 'åƒä½']):
            return 'ç¬¬2çƒ'
        if any(word in category_lower for word in ['ç¬¬3çƒ', 'ç™¾ä½']):
            return 'ç¬¬3çƒ'
        if any(word in category_lower for word in ['ç¬¬4çƒ', 'åä½']):
            return 'ç¬¬4çƒ'
        if any(word in category_lower for word in ['ç¬¬5çƒ', 'ä¸ªä½']):
            return 'ç¬¬5çƒ'
        
        if any(word in category_lower for word in ['å¤©è‚–']):
            return 'å¤©è‚–'
        if any(word in category_lower for word in ['åœ°è‚–']):
            return 'åœ°è‚–'
        if any(word in category_lower for word in ['å®¶è‚–', 'å®¶ç¦½']):
            return 'å®¶è‚–'
        if any(word in category_lower for word in ['é‡è‚–', 'é‡å…½']):
            return 'é‡è‚–'
    
        if any(word in category_lower for word in ['æ­£1ç‰¹', 'æ­£ä¸€ç‰¹']):
            return 'æ­£1ç‰¹'
        if any(word in category_lower for word in ['æ­£2ç‰¹', 'æ­£äºŒç‰¹']):
            return 'æ­£2ç‰¹'
        if any(word in category_lower for word in ['æ­£3ç‰¹', 'æ­£ä¸‰ç‰¹']):
            return 'æ­£3ç‰¹'
        if any(word in category_lower for word in ['æ­£4ç‰¹', 'æ­£å››ç‰¹']):
            return 'æ­£4ç‰¹'
        if any(word in category_lower for word in ['æ­£5ç‰¹', 'æ­£äº”ç‰¹']):
            return 'æ­£5ç‰¹'
        if any(word in category_lower for word in ['æ­£6ç‰¹', 'æ­£å…­ç‰¹']):
            return 'æ­£6ç‰¹'
        
        if any(word in category_lower for word in ['æ­£1', 'æ­£ä¸€']):
            return 'æ­£1'
        if any(word in category_lower for word in ['æ­£2', 'æ­£äºŒ']):
            return 'æ­£2'
        if any(word in category_lower for word in ['æ­£3', 'æ­£ä¸‰']):
            return 'æ­£3'
        if any(word in category_lower for word in ['æ­£4', 'æ­£å››']):
            return 'æ­£4'
        if any(word in category_lower for word in ['æ­£5', 'æ­£äº”']):
            return 'æ­£5'
        if any(word in category_lower for word in ['æ­£6', 'æ­£å…­']):
            return 'æ­£6'
        
        return category_str

# ==================== å†…å®¹è§£æå™¨ ====================
class ContentParser:
    """å†…å®¹è§£æå™¨ - å…¨é¢å¢å¼ºç‰ˆï¼Œæ”¯æŒæ•°å­—ã€æ–¹å‘ã€å¤æ‚æ ¼å¼"""

    @staticmethod
    def extract_basic_directions(content, config):
        """æå–åŸºç¡€æ–¹å‘"""
        content_str = str(content).strip()
        directions = []
        
        if not content_str:
            return directions
        
        content_lower = content_str.lower()
        
        for direction, patterns in config.direction_patterns.items():
            for pattern in patterns:
                pattern_lower = pattern.lower()
                if (pattern_lower == content_lower or 
                    pattern_lower in content_lower or 
                    content_lower in pattern_lower):
                    directions.append(direction)
                    break
        
        return directions

    @staticmethod
    def enhanced_extract_directions(content, config):
        """å…¨é¢å¢å¼ºç‰ˆæ–¹å‘æå–"""
        try:
            if pd.isna(content):
                return []
            
            content_str = str(content).strip()
            
            # 1. é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯"ç‰¹ç ä¸¤é¢-"å¼€å¤´
            if 'ç‰¹ç ä¸¤é¢-' in content_str:
                direction_part = content_str.split('ç‰¹ç ä¸¤é¢-')[-1].strip()
                for direction, patterns in config.direction_patterns.items():
                    for pattern in patterns:
                        if direction_part == pattern or direction_part in pattern:
                            return [direction]
            
            # 2. LHCç‰¹æ®Šæ¨¡å¼å¤„ç†
            lhc_special_patterns = {
                'ç‰¹ç ä¸¤é¢-å°¾å¤§': 'å°¾å¤§',
                'ç‰¹ç ä¸¤é¢-å°¾å°': 'å°¾å°', 
                'ç‰¹ç ä¸¤é¢-ç‰¹å¤§': 'ç‰¹å¤§',
                'ç‰¹ç ä¸¤é¢-ç‰¹å°': 'ç‰¹å°',
                'ç‰¹ç ä¸¤é¢-ç‰¹å•': 'ç‰¹å•',
                'ç‰¹ç ä¸¤é¢-ç‰¹åŒ': 'ç‰¹åŒ',
                'ç‰¹ç ä¸¤é¢-å¤§': 'å¤§',
                'ç‰¹ç ä¸¤é¢-å°': 'å°',
                'ç‰¹ç ä¸¤é¢-å•': 'å•',
                'ç‰¹ç ä¸¤é¢-åŒ': 'åŒ'
            }
            
            for pattern, direction in lhc_special_patterns.items():
                if pattern in content_str:
                    return [direction]
            
            # 3. é¢„å¤„ç†å†…å®¹
            content_clean = ContentParser.preprocess_content(content_str)
            
            # 4. å¤šå±‚çº§æ–¹å‘æå–
            directions = set()
            
            # 4.1 ç²¾ç¡®åŒ¹é…
            for direction, patterns in config.direction_patterns.items():
                for pattern in patterns:
                    if pattern == content_clean:
                        directions.add(direction)
                        break
            
            # 4.2 éƒ¨åˆ†åŒ¹é…
            if not directions:
                for direction, patterns in config.direction_patterns.items():
                    for pattern in patterns:
                        if pattern in content_clean:
                            directions.add(direction)
            
            # 4.3 æ™ºèƒ½LHCä½ç½®æå–
            if not directions:
                directions = ContentParser.smart_lhc_position_extraction(content_clean, config)
            
            # 5. æå–æ•°å­—ï¼ˆå¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–¹å‘ï¼‰
            if not directions:
                numbers = ContentParser.extract_all_numbers(content_str)
                if numbers:
                    if len(numbers) > 1:
                        unique_numbers = sorted(set(numbers))
                        return [f"å¤šæ•°å­—-{','.join(unique_numbers)}"]
                    else:
                        return [f"æ•°å­—-{numbers[0]}"]
            
            return list(directions)
                
        except Exception as e:
            logger.warning(f"æ–¹å‘æå–å¤±è´¥: {content}, é”™è¯¯: {e}")
            return []

    @staticmethod
    def extract_all_numbers(content):
        """æå–æ‰€æœ‰æ•°å­—"""
        try:
            if pd.isna(content):
                return []
            
            content_str = str(content).strip()
            numbers = re.findall(r'\b\d{1,2}\b', content_str)
            
            valid_numbers = []
            for num in numbers:
                if num.isdigit():
                    num_int = int(num)
                    if 1 <= num_int <= 49:
                        valid_numbers.append(num)
            
            return list(set(valid_numbers))
        except:
            return []

    @staticmethod
    def parse_complex_content(content, play_category):
        """è§£æå¤æ‚å†…å®¹æ ¼å¼"""
        try:
            if pd.isna(content):
                return {'type': 'unknown', 'value': ''}
            
            content_str = str(content).strip()
            
            # å¤„ç†ä½ç½®-æ–¹å‘-æ•°å­—æ ¼å¼ï¼šç¬¬ä¸‰å-06,ç¬¬å››å-06,...
            if ',' in content_str and any(pos in content_str for pos in ['å† å†›', 'äºšå†›', 'ç¬¬']):
                items = content_str.split(',')
                positions = []
                values = []
                
                for item in items:
                    item_clean = item.strip()
                    if '-' in item_clean:
                        parts = item_clean.split('-')
                        if len(parts) >= 2:
                            position = parts[0].strip()
                            value = parts[1].strip()
                            
                            positions.append(position)
                            values.append(value)
                
                if len(set(values)) == 1:
                    return {
                        'type': 'multiple_positions', 
                        'value': values[0], 
                        'positions': positions,
                        'values': values
                    }
                else:
                    return {
                        'type': 'mixed_positions',
                        'value': 'æ··åˆ',
                        'positions': positions,
                        'values': values
                    }
            
            # å¤„ç†å•ä¸ªä½ç½®-å€¼æ ¼å¼
            if '-' in content_str:
                parts = content_str.split('-')
                if len(parts) >= 2:
                    position = parts[0].strip()
                    value = parts[1].strip()
                    
                    return {
                        'type': 'single_position',
                        'position': position,
                        'value': value
                    }
            
            # æå–æ•°å­—
            numbers = ContentParser.extract_all_numbers(content_str)
            if numbers:
                return {'type': 'number', 'value': numbers[0], 'values': numbers}
            
            return {'type': 'raw', 'value': content_str}
            
        except Exception as e:
            logger.warning(f"å¤æ‚å†…å®¹è§£æå¤±è´¥: {content}, é”™è¯¯: {e}")
            return {'type': 'error', 'value': content_str}

    @staticmethod
    def preprocess_content(content):
        """å†…å®¹é¢„å¤„ç†"""
        content_str = str(content).strip()
        
        # æ›¿æ¢ä¸­æ–‡æ ‡ç‚¹ä¸ºè‹±æ–‡æ ‡ç‚¹
        content_str = content_str.replace('ï¼Œ', ',').replace('ï¼›', ';').replace('ï¼š', ':')
        
        # å‹ç¼©å¤šä½™ç©ºæ ¼
        content_str = re.sub(r'\s+', ' ', content_str).strip()
        
        # ç§»é™¤æ‹¬å·
        content_str = re.sub(r'[\(\)ï¼ˆï¼‰ã€ã€‘]', '', content_str)
        
        return content_str

    @staticmethod
    def multi_level_direction_extraction(content, config):
        """å¤šå±‚çº§æ–¹å‘æå–"""
        directions = set()
        
        for direction, patterns in config.direction_patterns.items():
            for pattern in patterns:
                if pattern == content:
                    directions.add(direction)
                    break
        
        if not directions:
            for direction, patterns in config.direction_patterns.items():
                for pattern in patterns:
                    if pattern in content:
                        directions.add(direction)
        
        if not directions:
            directions = ContentParser.smart_lhc_position_extraction(content, config)
        
        return list(directions)

    @staticmethod
    def smart_lhc_position_extraction(content, config):
        """æ™ºèƒ½å…­åˆå½©ä½ç½®æå–"""
        directions = set()
        content_lower = content.lower()
        
        lhc_position_map = {
            'æ­£1ç‰¹': ['æ­£1ç‰¹', 'æ­£ä¸€ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹'],
            'æ­£2ç‰¹': ['æ­£2ç‰¹', 'æ­£äºŒç‰¹', 'æ­£ç ç‰¹_æ­£äºŒç‰¹'], 
            'æ­£3ç‰¹': ['æ­£3ç‰¹', 'æ­£ä¸‰ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹'],
            'æ­£4ç‰¹': ['æ­£4ç‰¹', 'æ­£å››ç‰¹', 'æ­£ç ç‰¹_æ­£å››ç‰¹'],
            'æ­£5ç‰¹': ['æ­£5ç‰¹', 'æ­£äº”ç‰¹', 'æ­£ç ç‰¹_æ­£äº”ç‰¹'],
            'æ­£6ç‰¹': ['æ­£6ç‰¹', 'æ­£å…­ç‰¹', 'æ­£ç ç‰¹_æ­£å…­ç‰¹'],
            'æ­£1': ['æ­£1', 'æ­£ä¸€', 'æ­£ç 1', 'æ­£ç _æ­£ä¸€'],
            'æ­£2': ['æ­£2', 'æ­£äºŒ', 'æ­£ç 2', 'æ­£ç _æ­£äºŒ'],
            'æ­£3': ['æ­£3', 'æ­£ä¸‰', 'æ­£ç 3', 'æ­£ç _æ­£ä¸‰'],
            'æ­£4': ['æ­£4', 'æ­£å››', 'æ­£ç 4', 'æ­£ç _æ­£å››'],
            'æ­£5': ['æ­£5', 'æ­£äº”', 'æ­£ç 5', 'æ­£ç _æ­£äº”'],
            'æ­£6': ['æ­£6', 'æ­£å…­', 'æ­£ç 6', 'æ­£ç _æ­£å…­']
        }
        
        base_directions = {
            'å¤§': ['å¤§', 'big', 'large', 'da'],
            'å°': ['å°', 'small', 'xiao'],
            'å•': ['å•', 'odd', 'dan', 'å¥‡'],
            'åŒ': ['åŒ', 'even', 'shuang', 'å¶']
        }
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ä½ç½®-æ–¹å‘ç»„åˆ
        for position, keywords in lhc_position_map.items():
            for keyword in keywords:
                if keyword in content_lower:
                    for direction, dir_keywords in base_directions.items():
                        for dir_keyword in dir_keywords:
                            if dir_keyword in content_lower:
                                combined_direction = f"{position}-{direction}"
                                directions.add(combined_direction)
                                break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç»„åˆï¼ŒæŸ¥æ‰¾åŸºç¡€æ–¹å‘
        if not directions:
            for direction, keywords in base_directions.items():
                for keyword in keywords:
                    if (keyword in content_lower and 
                        (len(keyword) > 1 or 
                         (len(keyword) == 1 and 
                          (content_lower == keyword or 
                           f" {keyword} " in f" {content_lower} " or
                           content_lower.startswith(keyword + ' ') or
                           content_lower.endswith(' ' + keyword))))):
                        directions.add(direction)
                        break
        
        return directions

    @staticmethod
    def prioritize_directions(directions, content, play_category):
        """æ–¹å‘ä¼˜å…ˆçº§æ’åº"""
        if not directions:
            return ""
        
        if len(directions) == 1:
            return directions[0]
        
        content_lower = content.lower()
        play_lower = play_category.lower() if play_category else ""
        
        priority_scores = {}
        
        for direction in directions:
            score = 0
            
            # ç²¾ç¡®åŒ¹é…å¾—åˆ†æœ€é«˜
            if direction == content_lower:
                score += 100
            
            # ç©æ³•åˆ†ç±»ä¼˜å…ˆçº§
            if any(word in play_lower for word in ['ä¸¤é¢', 'å’Œå€¼', 'å¤§å°å•åŒ']):
                score += 50
            
            # ç‰¹æ®Šæ¨¡å¼ä¼˜å…ˆçº§
            if 'æ€»' in content_lower and 'æ€»å’Œ' in direction:
                score += 30
            elif 'ç‰¹' in content_lower and 'ç‰¹' in direction:
                score += 30
            
            # åŸºç¡€æ–¹å‘ä¼˜å…ˆçº§
            if direction in ['å¤§', 'å°', 'å•', 'åŒ']:
                score += 20
            
            priority_scores[direction] = score
        
        return max(priority_scores.items(), key=lambda x: x[1])[0]

    @staticmethod
    def extract_position_from_play_category(play_category, lottery_type, config):
        """ä»ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½®ä¿¡æ¯"""
        play_str = str(play_category).strip()
        
        if not play_str:
            return 'æœªçŸ¥ä½ç½®'
        
        position_keywords = config.position_keywords.get(lottery_type, {})
        
        for position, keywords in position_keywords.items():
            for keyword in keywords:
                if keyword in play_str:
                    return position
        
        # LHCç‰¹æ®Šå¤„ç†
        if lottery_type == 'LHC':
            if 'æ­£ç ç‰¹' in play_str or 'æ­£ç‰¹' in play_str:
                return 'ç‰¹ç '
            elif 'æ­£ç ' in play_str and 'ç‰¹' not in play_str:
                return 'æ­£ç '
        
        return 'æœªçŸ¥ä½ç½®'

    @staticmethod
    def parse_pk10_vertical_format(content):
        """è§£æPK10ç«–çº¿åˆ†éš”æ ¼å¼"""
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                        'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
            
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    numbers = []
                    if ',' in part_clean:
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£æPK10ç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)
    
    @staticmethod
    def parse_3d_vertical_format(content):
        """è§£æ3Dç«–çº¿åˆ†éš”æ ¼å¼"""
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            positions = ['ç™¾ä½', 'åä½', 'ä¸ªä½']
            
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    numbers = []
                    if ',' in part_clean:
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£æ3Dç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)

# ==================== PKæ‹¾åºåˆ—ä½ç½®æ£€æµ‹å™¨ ====================
class PK10SequenceDetector:
    """PKæ‹¾åºåˆ—ä½ç½®æ£€æµ‹å™¨"""
    
    def __init__(self, config=None):
        self.config = config or Config()
        self.content_parser = ContentParser()

        self.play_category_to_positions = {
            '1-5å': ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å'],
            '6-10å': ['ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå'],
            'å† å†›': ['å† å†›'],
            'äºšå†›': ['äºšå†›'], 
            'ç¬¬ä¸‰å': ['ç¬¬ä¸‰å'],
            'ç¬¬å››å': ['ç¬¬å››å'],
            'ç¬¬äº”å': ['ç¬¬äº”å'],
            'ç¬¬å…­å': ['ç¬¬å…­å'],
            'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå'],
            'ç¬¬å…«å': ['ç¬¬å…«å'],
            'ç¬¬ä¹å': ['ç¬¬ä¹å'],
            'ç¬¬åå': ['ç¬¬åå'],
            'å®šä½èƒ†': ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                     'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
        }
        
        self.direction_mapping = {
            'å¤§': ['å¤§', 'big', 'large', 'da'],
            'å°': ['å°', 'small', 'xiao'], 
            'å•': ['å•', 'odd', 'dan', 'å¥‡'],
            'åŒ': ['åŒ', 'even', 'shuang', 'å¶'],
            'é¾™': ['é¾™', 'long', 'dragon'],
            'è™': ['è™', 'hu', 'tiger']
        }
        
        self.pk10_positions = [
            'å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å',
            'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå'
        ]
        
    def extract_pk10_bet_content(self, content, play_category):
        """æå–PK10æŠ•æ³¨å†…å®¹"""
        try:
            if pd.isna(content):
                return None
            
            content_str = str(content).strip()
            
            if ',' in content_str and any(pos in content_str for pos in self.pk10_positions):
                return self._parse_comma_separated_format(content_str)
            
            directions = self.content_parser.enhanced_extract_directions(content_str, self.config)
            if directions:
                return directions[0]
            
            return None
            
        except Exception as e:
            logger.warning(f"PK10å†…å®¹æå–å¤±è´¥: {content}, é”™è¯¯: {e}")
            return None
    
    def _parse_comma_separated_format(self, content):
        """è§£æé€—å·åˆ†éš”çš„ä½ç½®-æ–¹å‘æ ¼å¼"""
        try:
            items = content.split(',')
            directions_found = set()
            
            for item in items:
                item_clean = item.strip()
                if '-' in item_clean:
                    direction_part = item_clean.split('-')[-1].strip()
                    
                    for direction, keywords in self.direction_mapping.items():
                        for keyword in keywords:
                            if direction_part == keyword or direction_part in keyword:
                                directions_found.add(direction)
                                break
            
            if len(directions_found) == 1:
                return list(directions_found)[0]
            
            return None
            
        except Exception as e:
            logger.debug(f"é€—å·åˆ†éš”æ ¼å¼è§£æå¤±è´¥: {content}, é”™è¯¯: {e}")
            return None
    
    def get_positions_from_play_category(self, play_category):
        """ä»ç©æ³•åˆ†ç±»è·å–å¯¹åº”çš„ä½ç½®åˆ—è¡¨"""
        play_str = str(play_category).strip()
        return self.play_category_to_positions.get(play_str, [])
    
    def _detect_incomplete_position_collaboration(self, period_data, period):
        """æ£€æµ‹ä¸å®Œæ•´ä½ç½®çš„åä½œæ¨¡å¼"""
        patterns = []
        
        # æ£€æŸ¥1-5åæŠ•æ³¨
        play_1_5 = period_data[period_data['ç©æ³•åˆ†ç±»'] == '1-5å']
        play_6_10 = period_data[period_data['ç©æ³•åˆ†ç±»'] == '6-10å']
        
        if len(play_1_5) == 0 or len(play_6_10) == 0:
            return patterns
        
        # åˆ†ææ¯ä¸ªè´¦æˆ·çš„æŠ•æ³¨å†…å®¹
        account_bets = defaultdict(lambda: {'1_5_bets': [], '6_10_bets': []})
        
        for _, row in period_data.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            play_category = row['ç©æ³•åˆ†ç±»']
            content = row['å†…å®¹']
            direction = row.get('æŠ•æ³¨æ–¹å‘', '')
            amount = row.get('æŠ•æ³¨é‡‘é¢', 0)
            
            if play_category == '1-5å':
                account_bets[account]['1_5_bets'].append({
                    'content': content,
                    'direction': direction,
                    'amount': amount
                })
            elif play_category == '6-10å':
                account_bets[account]['6_10_bets'].append({
                    'content': content,
                    'direction': direction,
                    'amount': amount
                })
        
        # æŸ¥æ‰¾å¯èƒ½çš„ä¸å®Œæ•´åä½œ
        accounts = list(account_bets.keys())
        for i in range(len(accounts)):
            for j in range(i+1, len(accounts)):
                acc1 = accounts[i]
                acc2 = accounts[j]
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å…¸å‹çš„"ä½ æŠ•1-5åï¼Œæˆ‘æŠ•6-10å"æ¨¡å¼
                bets1 = account_bets[acc1]
                bets2 = account_bets[acc2]
                
                # æƒ…å†µ1ï¼šacc1æŠ•1-5åï¼Œacc2æŠ•6-10å
                if len(bets1['1_5_bets']) > 0 and len(bets2['6_10_bets']) > 0:
                    # æ£€æŸ¥æŠ•æ³¨æ–¹å‘æ˜¯å¦ç›¸åŒ
                    direction1 = bets1['1_5_bets'][0]['direction']
                    direction2 = bets2['6_10_bets'][0]['direction']
                    
                    if direction1 and direction2 and direction1 == direction2:
                        # æ£€æŸ¥æŠ•æ³¨å†…å®¹æ˜¯å¦åŒ¹é…
                        content1 = bets1['1_5_bets'][0]['content']
                        content2 = bets2['6_10_bets'][0]['content']
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºç®€å•æŠ•æ³¨ï¼ˆå¦‚åªæŠ•å† å†›ï¼‰
                        if 'å† å†›-' in content1 and len(content1.split(',')) == 1:
                            pattern_type = 'å† å†›å•ç‚¹åä½œ'
                        else:
                            # åˆ†ææŠ•æ³¨çš„è¯¦ç»†ä½ç½®
                            positions_1_5 = self._extract_positions_from_content(content1)
                            positions_6_10 = self._extract_positions_from_content(content2)
                            
                            pattern_type = f'éƒ¨åˆ†ä½ç½®åä½œ({len(positions_1_5)}ä¸ª1-5å, {len(positions_6_10)}ä¸ª6-10å)'
                        
                        amounts = [
                            sum(b['amount'] for b in bets1['1_5_bets']),
                            sum(b['amount'] for b in bets2['6_10_bets'])
                        ]
                        
                        patterns.append({
                            'æœŸå·': period,
                            'å½©ç§': 'PK10',
                            'å½©ç§ç±»å‹': 'PK10',
                            'è´¦æˆ·ç»„': [acc1, acc2],
                            'æ–¹å‘ç»„': [direction1, direction2],
                            'é‡‘é¢ç»„': amounts,
                            'æ€»é‡‘é¢': sum(amounts),
                            'ç›¸ä¼¼åº¦': 1.0,
                            'è´¦æˆ·æ•°é‡': 2,
                            'æ¨¡å¼': f'PK10-{pattern_type}-{direction1.replace("æ•°å­—-", "")}',
                            'å¯¹ç«‹ç±»å‹': f'{pattern_type}-{direction1}',
                            'æ£€æµ‹ç±»å‹': 'PK10åºåˆ—ä½ç½®'
                        })
                
                # æƒ…å†µ2ï¼šacc2æŠ•1-5åï¼Œacc1æŠ•6-10å
                if len(bets2['1_5_bets']) > 0 and len(bets1['6_10_bets']) > 0:
                    # ç±»ä¼¼ä¸Šé¢çš„é€»è¾‘ï¼Œåªæ˜¯è´¦æˆ·é¡ºåºç›¸å
                    direction1 = bets2['1_5_bets'][0]['direction']
                    direction2 = bets1['6_10_bets'][0]['direction']
                    
                    if direction1 and direction2 and direction1 == direction2:
                        amounts = [
                            sum(b['amount'] for b in bets2['1_5_bets']),
                            sum(b['amount'] for b in bets1['6_10_bets'])
                        ]
                        
                        patterns.append({
                            'æœŸå·': period,
                            'å½©ç§': 'PK10',
                            'å½©ç§ç±»å‹': 'PK10',
                            'è´¦æˆ·ç»„': [acc2, acc1],
                            'æ–¹å‘ç»„': [direction1, direction2],
                            'é‡‘é¢ç»„': amounts,
                            'æ€»é‡‘é¢': sum(amounts),
                            'ç›¸ä¼¼åº¦': 1.0,
                            'è´¦æˆ·æ•°é‡': 2,
                            'æ¨¡å¼': f'PK10-éƒ¨åˆ†ä½ç½®åä½œ-{direction1.replace("æ•°å­—-", "")}',
                            'å¯¹ç«‹ç±»å‹': f'éƒ¨åˆ†ä½ç½®åä½œ-{direction1}',
                            'æ£€æµ‹ç±»å‹': 'PK10åºåˆ—ä½ç½®'
                        })
        
        return patterns
    
    def _extract_positions_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–ä½ç½®ä¿¡æ¯"""
        positions = []
        content_str = str(content)
        
        position_keywords = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å',
                            'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
        
        for position in position_keywords:
            if position in content_str:
                positions.append(position)
        
        return positions
    
    def detect_sequence_coverage(self, df_pk10):
        """æ£€æµ‹åºåˆ—è¦†ç›–æ¨¡å¼"""
        sequence_patterns = []
        
        period_groups = df_pk10.groupby('æœŸå·')
        
        for period, period_data in period_groups:
            position_account_content = defaultdict(lambda: defaultdict(list))
            
            for _, row in period_data.iterrows():
                account = row['ä¼šå‘˜è´¦å·']
                play_category = row.get('ç©æ³•åˆ†ç±»', '')
                content = row['å†…å®¹']
                amount = row.get('æŠ•æ³¨é‡‘é¢', 0)
                
                positions_from_play = self.get_positions_from_play_category(play_category)
                positions_from_content = self._extract_positions_from_content(content)
                
                all_positions = list(set(positions_from_play + positions_from_content))
                if not all_positions:
                    position = self.content_parser.extract_position_from_play_category(
                        play_category, 'PK10', self.config
                    )
                    if position in self.pk10_positions:
                        all_positions = [position]
                
                bet_content = self.extract_pk10_bet_content(content, play_category)
                if bet_content is None:
                    continue
                
                for position in all_positions:
                    if position in self.pk10_positions:
                        position_account_content[position][account].append({
                            'content': bet_content,
                            'amount': amount,
                            'original_content': content,
                            'play_category': play_category,
                            'positions_covered': all_positions
                        })
            
            patterns = self._find_sequence_coverage_patterns(
                position_account_content, period
            )
            sequence_patterns.extend(patterns)
        
        return sequence_patterns
    
    def _find_sequence_coverage_patterns(self, position_account_content, period):
        """æŸ¥æ‰¾åºåˆ—è¦†ç›–æ¨¡å¼"""
        patterns = []
        
        all_accounts = set()
        account_bet_contents = defaultdict(set)
        
        for position, account_data in position_account_content.items():
            for account, bets in account_data.items():
                all_accounts.add(account)
                for bet in bets:
                    account_bet_contents[account].add(str(bet['content']))
        
        common_content_groups = defaultdict(list)
        
        for account, contents in account_bet_contents.items():
            for content in contents:
                common_content_groups[content].append(account)
        
        for bet_content, accounts in common_content_groups.items():
            if len(accounts) < 2:
                continue
            
            if len(accounts) >= 2:
                for account_group in combinations(accounts, 2):
                    coverage_result = self._check_position_coverage(
                        position_account_content, list(account_group), bet_content
                    )
                    if coverage_result['covered']:
                        pattern = self._create_sequence_pattern(
                            period, list(account_group), bet_content, coverage_result
                        )
                        patterns.append(pattern)
            
            if len(accounts) >= 3:
                for account_group in combinations(accounts, 3):
                    coverage_result = self._check_position_coverage(
                        position_account_content, list(account_group), bet_content
                    )
                    if coverage_result['covered']:
                        pattern = self._create_sequence_pattern(
                            period, list(account_group), bet_content, coverage_result
                        )
                        patterns.append(pattern)
        
        return patterns
    
    def _check_position_coverage(self, position_account_content, accounts, target_content):
        """æ£€æŸ¥è´¦æˆ·ç»„æ˜¯å¦è¦†ç›–äº†åä¸ªä½ç½®ä¸”æŠ•æ³¨å†…å®¹ç›¸åŒ"""
        covered_positions = set()
        position_details = {}
        total_amount = 0
        
        for position in self.pk10_positions:
            if position not in position_account_content:
                continue
            
            position_covered = False
            position_accounts = []
            position_amounts = []
            
            for account in accounts:
                if account in position_account_content[position]:
                    account_bets = position_account_content[position][account]
                    for bet in account_bets:
                        bet_content_str = str(bet['content'])
                        if bet_content_str == target_content:
                            position_covered = True
                            position_accounts.append(account)
                            position_amounts.append(bet['amount'])
                            total_amount += bet['amount']
                            break
            
            if position_covered:
                covered_positions.add(position)
                position_details[position] = {
                    'accounts': position_accounts,
                    'amounts': position_amounts
                }
        
        return {
            'covered': len(covered_positions) == len(self.pk10_positions),
            'covered_positions': covered_positions,
            'position_details': position_details,
            'total_amount': total_amount
        }
    
    def _create_sequence_pattern(self, period, accounts, bet_content, coverage_result):
        """åˆ›å»ºåºåˆ—è¦†ç›–æ¨¡å¼è®°å½•"""
        coverage_ratio = len(coverage_result['covered_positions']) / len(self.pk10_positions)
        
        detailed_records = []
        for position in self.pk10_positions:
            if position in coverage_result['position_details']:
                details = coverage_result['position_details'][position]
                record = {
                    'position': position,
                    'accounts': details['accounts'],
                    'amounts': details['amounts'],
                    'bet_content': bet_content
                }
                detailed_records.append(record)
        
        account_count = len(accounts)
        if account_count == 2:
            pattern_desc = f'PK10åä½ç½®å…¨è¦†ç›–-{bet_content}(2è´¦æˆ·åä½œ)'
        elif account_count == 3:
            pattern_desc = f'PK10åä½ç½®å…¨è¦†ç›–-{bet_content}(3è´¦æˆ·åä½œ)'
        else:
            pattern_desc = f'PK10åä½ç½®å…¨è¦†ç›–-{bet_content}({account_count}è´¦æˆ·åä½œ)'
        
        return {
            'æœŸå·': period,
            'å½©ç§': 'PK10',
            'å½©ç§ç±»å‹': 'PK10',
            'è´¦æˆ·ç»„': accounts,
            'è´¦æˆ·æ•°é‡': account_count,
            'æŠ•æ³¨å†…å®¹': bet_content,
            'è¦†ç›–ä½ç½®æ•°': len(coverage_result['covered_positions']),
            'æ€»ä½ç½®æ•°': len(self.pk10_positions),
            'è¦†ç›–åº¦': coverage_ratio,
            'æ€»æŠ•æ³¨é‡‘é¢': coverage_result['total_amount'],
            'ä½ç½®è¯¦æƒ…': detailed_records,
            'æ¨¡å¼ç±»å‹': 'åºåˆ—è¦†ç›–',
            'æ¨¡å¼æè¿°': pattern_desc
        }

    def _extract_direction_from_data(self, data):
        """ä»æ•°æ®ä¸­æå–ä¸»è¦æŠ•æ³¨æ–¹å‘"""
        try:
            if len(data) == 0:
                return None
            
            if 'æŠ•æ³¨æ–¹å‘' not in data.columns:
                return None
            
            direction = data.iloc[0]['æŠ•æ³¨æ–¹å‘']
            return direction
            
        except Exception as e:
            return None
    
    def _extract_number_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–æ•°å­—"""
        try:
            if pd.isna(content):
                return None
            
            content_str = str(content).strip()
            
            if '-' in content_str:
                parts = content_str.split('-')
                if len(parts) >= 2:
                    number_part = parts[-1].strip()
                    if number_part.isdigit():
                        return number_part
            
            numbers = re.findall(r'\d+', content_str)
            if numbers:
                return numbers[0]
            
            return None
        except:
            return None
    
    def _parse_pk10_content_enhanced(self, data):
        """å¢å¼ºç‰ˆPK10å†…å®¹è§£æ"""
        if len(data) == 0:
            return None
        
        sample_row = data.iloc[0]
        content = sample_row['å†…å®¹']
        
        parsed_content = self.content_parser.parse_complex_content(content, '')
        
        content_type = parsed_content.get('type', 'unknown')
        
        if content_type == 'number':
            return f"æ•°å­—-{parsed_content['value']}"
        elif content_type == 'single_position':
            value = parsed_content['value']
            if value.isdigit():
                return f"æ•°å­—-{value}"
            return value
        elif content_type == 'multiple_positions':
            value = parsed_content['value']
            if value.isdigit():
                return f"æ•°å­—-{value}"
            return value
        elif content_type == 'raw':
            directions = self.content_parser.enhanced_extract_directions(content, self.config)
            if directions:
                return directions[0]
            
            numbers = self.content_parser.extract_all_numbers(content)
            if numbers:
                return f"æ•°å­—-{numbers[0]}"
            
            return content
        else:
            return str(content)

# ==================== å¯¹åˆ·æ£€æµ‹å™¨ç±» ====================
class WashTradeDetector:
    def __init__(self, config=None):
        self.config = config or Config()
        self.data_processor = DataProcessor()
        self.lottery_identifier = LotteryIdentifier()
        self.play_normalizer = PlayCategoryNormalizer()
        self.content_parser = ContentParser()
        
        self.data_processed = False
        self.df_valid = None
        self.export_data = []
        self.pk10_sequence_detector = PK10SequenceDetector(config)
        
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        self.performance_stats = {}

    def filter_accounts_by_amount_balance(self, account_group, directions, amounts):
        """æ ¹æ®ç»„å†…é‡‘é¢å¹³è¡¡æ€§è¿‡æ»¤è´¦æˆ·"""
        if not self.config.amount_threshold['enable_threshold_filter']:
            return account_group, directions, amounts
        
        if not amounts or len(amounts) < 2:
            return account_group, directions, amounts
        
        max_amount = max(amounts)
        min_amount = min(amounts)
        
        amount_ratio = max_amount / min_amount if min_amount > 0 else float('inf')
        
        max_allowed_ratio = self.config.amount_threshold['max_amount_ratio']
        if amount_ratio > max_allowed_ratio:
            min_required = max_amount / max_allowed_ratio
            valid_indices = [i for i, amount in enumerate(amounts) if amount >= min_required]
            
            if len(valid_indices) >= 2:
                filtered_accounts = [account_group[i] for i in valid_indices]
                filtered_directions = [directions[i] for i in valid_indices]
                filtered_amounts = [amounts[i] for i in valid_indices]
                
                logger.info(f"é‡‘é¢å¹³è¡¡è¿‡æ»¤: {len(account_group)} -> {len(filtered_accounts)} ä¸ªè´¦æˆ· (åŸæ¯”ä¾‹: {amount_ratio:.1f}å€)")
                
                return filtered_accounts, filtered_directions, filtered_amounts
            else:
                return [], [], []
        
        return account_group, directions, amounts

    def upload_and_process(self, uploaded_file):
        """ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶"""
        try:
            if uploaded_file is None:
                st.error("âŒ æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
                return None, None
            
            filename = uploaded_file.name
            logger.info(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {filename}")
            
            if not any(filename.endswith(ext) for ext in self.config.supported_file_types):
                st.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
                return None, None
            
            with st.spinner("ğŸ”„ æ­£åœ¨æ¸…æ´—æ•°æ®..."):
                df_clean = self.data_processor.clean_data(uploaded_file)
            
            if df_clean is not None and len(df_clean) > 0:
                df_enhanced = self.enhance_data_processing(df_clean)
                return df_enhanced, filename
            else:
                return None, None
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            return None, None
    
    def enhance_data_processing(self, df_clean):
        """æ•°æ®å¤„ç†æµç¨‹"""
        try:
            if 'å½©ç§' in df_clean.columns:
                df_clean['åŸå§‹å½©ç§'] = df_clean['å½©ç§']
                df_clean['å½©ç§ç±»å‹'] = df_clean['å½©ç§'].apply(self.lottery_identifier.identify_lottery_type)
            
            if 'ç©æ³•' in df_clean.columns:
                df_clean['ç©æ³•åˆ†ç±»'] = df_clean['ç©æ³•'].apply(self.play_normalizer.normalize_category)
            else:
                df_clean['ç©æ³•åˆ†ç±»'] = ''
            
            df_clean['æŠ•æ³¨é‡‘é¢'] = df_clean['é‡‘é¢'].apply(
                lambda x: self.extract_bet_amount_safe(str(x))
            )
            
            df_clean['æŠ•æ³¨æ–¹å‘'] = df_clean.apply(
                lambda row: self.enhanced_extract_direction_with_position(
                    row['å†…å®¹'], 
                    row.get('ç©æ³•åˆ†ç±»', ''), 
                    row.get('å½©ç§ç±»å‹', 'æœªçŸ¥')
                ), 
                axis=1
            )
            
            df_valid = df_clean[
                (df_clean['æŠ•æ³¨æ–¹å‘'] != '') & 
                (df_clean['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
            ].copy()
            
            self.data_processed = True
            self.df_valid = df_valid
            
            self.calculate_account_total_periods_by_lottery(df_valid)
            
            return df_valid
                
        except Exception as e:
            logger.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            st.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            return pd.DataFrame()

    def extract_bet_amount_safe(self, amount_text):
        """å®‰å…¨æå–æŠ•æ³¨é‡‘é¢"""
        try:
            if pd.isna(amount_text):
                return 0
            
            text = str(amount_text).strip()
            
            if 'æŠ•æ³¨ï¼š' in text and 'æŠµç”¨ï¼š' in text:
                try:
                    bet_part = text.split('æŠ•æ³¨ï¼š')[1].split('æŠµç”¨ï¼š')[0].strip()
                    amount = float(bet_part.replace(',', ''))
                    if amount >= self.config.min_amount:
                        return amount
                except (ValueError, IndexError) as e:
                    logger.debug(f"ç‰¹æ®Šæ ¼å¼é‡‘é¢æå–å¤±è´¥: {text}, é”™è¯¯: {e}")
            
            if text.startswith('æŠ•æ³¨ï¼š'):
                try:
                    bet_part = text.replace('æŠ•æ³¨ï¼š', '').strip()
                    bet_part_clean = re.split(r'[^\d.]', bet_part)[0]
                    amount = float(bet_part_clean)
                    if amount >= self.config.min_amount:
                        return amount
                except (ValueError, IndexError) as e:
                    logger.debug(f"ç®€åŒ–æ ¼å¼é‡‘é¢æå–å¤±è´¥: {text}, é”™è¯¯: {e}")
            
            if 'æŠ•æ³¨:' in text:
                try:
                    bet_part = text.split('æŠ•æ³¨:')[1].split()[0].strip()
                    amount = float(bet_part.replace(',', ''))
                    if amount >= self.config.min_amount:
                        return amount
                except (ValueError, IndexError) as e:
                    logger.debug(f"ä¸­æ–‡å†’å·æ ¼å¼é‡‘é¢æå–å¤±è´¥: {text}, é”™è¯¯: {e}")
            
            if 'E' in text or 'e' in text:
                try:
                    amount = float(text)
                    if amount >= self.config.min_amount:
                        return amount
                except:
                    pass
            
            try:
                cleaned_text = re.sub(r'[^\d.-]', '', text)
                if cleaned_text and cleaned_text != '-':
                    amount = float(cleaned_text)
                    if amount >= self.config.min_amount:
                        return amount
            except:
                pass
            
            patterns = [
                r'æŠ•æ³¨[:ï¼š]?\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'ä¸‹æ³¨[:ï¼š]?\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'é‡‘é¢[:ï¼š]?\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'æ€»é¢[:ï¼š]?\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'([-]?\d+[,ï¼Œ]?\d*\.?\d*)\s*å…ƒ',
                r'ï¿¥\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'Â¥\s*([-]?\d+[,ï¼Œ]?\d*\.?\d*)',
                r'[\$ï¿¥Â¥]?\s*([-]?\d+[,ï¼Œ]?\d*\.?\d+)',
                r'([-]?\d+[,ï¼Œ]?\d*\.?\d+)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text)
                if match:
                    amount_str = match.group(1).replace(',', '').replace('ï¼Œ', '').replace(' ', '')
                    try:
                        amount = float(amount_str)
                        if amount >= self.config.min_amount:
                            return amount
                    except:
                        continue
            
            return 0
            
        except Exception as e:
            logger.warning(f"é‡‘é¢æå–å¤±è´¥: {amount_text}, é”™è¯¯: {e}")
            return 0
    
    def enhanced_extract_direction_with_position(self, content, play_category, lottery_type):
        """å…¨é¢ä¿®å¤æ–¹å‘æå– - æ”¯æŒæ‰€æœ‰æ ¼å¼"""
        try:
            if pd.isna(content):
                return ""
            
            content_str = str(content).strip()
            
            # å¦‚æœæ˜¯PK10ç±»å‹
            if lottery_type == 'PK10':
                # æ ¼å¼1: å† å†›-01,04,05ï¼ˆå¤šä¸ªæ•°å­—ï¼‰
                if '-' in content_str and ',' in content_str:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ä½ç½®-æ•°å­—æ ¼å¼
                    parts = content_str.split('-', 1)
                    if len(parts) >= 2:
                        number_part = parts[1].strip()
                        # æå–æ‰€æœ‰æ•°å­—
                        numbers = re.findall(r'\b\d{1,2}\b', number_part)
                        if numbers:
                            unique_numbers = sorted(set(numbers))
                            if len(unique_numbers) > 1:
                                return f"å¤šæ•°å­—-{','.join(unique_numbers)}"
                            elif len(unique_numbers) == 1:
                                return f"æ•°å­—-{unique_numbers[0]}"
                
                # æ ¼å¼2: å† å†›-åŒï¼ˆæ–¹å‘ï¼‰
                if '-' in content_str:
                    parts = content_str.split('-', 1)
                    if len(parts) >= 2:
                        value_part = parts[1].strip()
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–¹å‘ï¼ˆå¤§å°å•åŒç­‰ï¼‰
                        directions = self.content_parser.enhanced_extract_directions(value_part, self.config)
                        if directions:
                            return directions[0]  # å–ç¬¬ä¸€ä¸ªæ–¹å‘
            
            # é€šç”¨æ•°å­—æå–
            numbers = re.findall(r'\b\d{1,2}\b', content_str)
            if numbers:
                unique_numbers = sorted(set(numbers))
                if len(unique_numbers) > 1:
                    return f"å¤šæ•°å­—-{','.join(unique_numbers)}"
                elif len(unique_numbers) == 1:
                    return f"æ•°å­—-{unique_numbers[0]}"
            
            # é€šç”¨æ–¹å‘æå–
            directions = self.content_parser.enhanced_extract_directions(content_str, self.config)
            if directions:
                return directions[0]  # å–ç¬¬ä¸€ä¸ªæ–¹å‘
            
            return ""
                
        except Exception as e:
            logger.warning(f"æ–¹å‘æå–å¤±è´¥: {content}, é”™è¯¯: {e}")
            return ""
    
    def _select_primary_direction(self, directions, content):
        """é€‰æ‹©ä¸»è¦æ–¹å‘"""
        if not directions:
            return ""
        
        if len(directions) == 1:
            return directions[0]
        
        content_str = str(content)
        
        priority_rules = [
            lambda d: any(keyword in content_str for keyword in ['æ€»å’Œ', 'æ€»']) and d in directions,
            lambda d: 'ç‰¹' in content_str and d in directions,
            lambda d: any(keyword in content_str for keyword in ['å’Œå€¼', 'å’Œ']) and d in directions,
            lambda d: 'ä¸¤é¢' in content_str and d in directions,
            lambda d: d in directions
        ]
        
        for rule in priority_rules:
            matching_directions = [d for d in directions if rule(d)]
            if matching_directions:
                return matching_directions[0]
        
        return directions[0]
    
    def _extract_position_from_content(self, content, lottery_type):
        """ä»å†…å®¹ä¸­æå–ä½ç½®ä¿¡æ¯"""
        content_str = str(content).strip()
        
        position_keywords = self.config.position_keywords.get(lottery_type, {})
        
        for position, keywords in position_keywords.items():
            for keyword in keywords:
                if keyword in content_str:
                    return position
        
        if '|' in content_str:
            if lottery_type == 'PK10':
                bets_by_position = self.content_parser.parse_pk10_vertical_format(content_str)
                for position in bets_by_position:
                    if bets_by_position[position]:
                        return position
            elif lottery_type == '3D':
                bets_by_position = self.content_parser.parse_3d_vertical_format(content_str)
                for position in bets_by_position:
                    if bets_by_position[position]:
                        return position
        
        return 'æœªçŸ¥ä½ç½®'
    
    def calculate_account_total_periods_by_lottery(self, df):
        """ä¿®å¤è´¦æˆ·æœŸæ•°ç»Ÿè®¡æ–¹æ³•"""
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        
        data_source = self.df_valid if hasattr(self, 'df_valid') and self.df_valid is not None else df
        
        lottery_col = 'å½©ç§'
        
        for lottery in data_source[lottery_col].unique():
            df_lottery = data_source[data_source[lottery_col] == lottery]
            
            period_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·')['æœŸå·'].nunique().to_dict()
            self.account_total_periods_by_lottery[lottery] = period_counts
            
            record_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·').size().to_dict()
            self.account_record_stats_by_lottery[lottery] = record_counts
    
    def detect_all_wash_trades(self):
        """ä¿®å¤çš„ä¸»æ£€æµ‹æ–¹æ³•"""
        if not self.data_processed or self.df_valid is None or len(self.df_valid) == 0:
            st.error("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ç”¨äºæ£€æµ‹")
            return []
        
        df_filtered = self.exclude_multi_direction_accounts(self.df_valid)
        
        if len(df_filtered) == 0:
            st.error("âŒ è¿‡æ»¤åæ— æœ‰æ•ˆæ•°æ®")
            return []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_patterns = []
        total_steps = self.config.max_accounts_in_group + 1
        
        for account_count in range(2, self.config.max_accounts_in_group + 1):
            status_text.text(f"ğŸ” æ£€æµ‹{account_count}ä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼...")
            patterns = self.detect_n_account_patterns_optimized(df_filtered, account_count)
            all_patterns.extend(patterns)
            
            progress = (account_count - 1) / total_steps
            progress_bar.progress(progress)
        
        status_text.text(f"ğŸ” æ£€æµ‹PK10åºåˆ—ä½ç½®æ¨¡å¼...")
        pk10_patterns = self.detect_pk10_sequence_patterns(df_filtered)
        all_patterns.extend(pk10_patterns)
        
        progress_bar.progress(1.0)
        # åˆ é™¤æˆ–æ³¨é‡Šæ‰æ£€æµ‹å®Œæˆæç¤º
        # status_text.text("âœ… æ£€æµ‹å®Œæˆ")
        status_text.text("")  # æ¸…ç©ºçŠ¶æ€æ–‡æœ¬
        
        return all_patterns
    
    def detect_n_account_patterns_optimized(self, df_filtered, n_accounts):
        """Nä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼æ£€æµ‹"""
        wash_records = []
        
        period_groups = df_filtered.groupby(['æœŸå·', 'åŸå§‹å½©ç§'])
        
        valid_direction_combinations = self._get_valid_direction_combinations(n_accounts)
        
        batch_size = 100
        period_keys = list(period_groups.groups.keys())
        
        for i in range(0, len(period_keys), batch_size):
            batch_keys = period_keys[i:i+batch_size]
            
            for period_key in batch_keys:
                period_data = period_groups.get_group(period_key)
                period_accounts = period_data['ä¼šå‘˜è´¦å·'].unique()
                
                if len(period_accounts) < n_accounts:
                    continue
                
                batch_patterns = self._detect_combinations_for_period(
                    period_data, period_accounts, n_accounts, valid_direction_combinations
                )
                wash_records.extend(batch_patterns)
        
        return self.find_continuous_patterns_optimized(wash_records)

    def detect_pk10_sequence_patterns(self, df_filtered):
        """PK10åºåˆ—ä½ç½®æ¨¡å¼æ£€æµ‹ - ä¿æŒæ‰€æœ‰æ£€æµ‹é€»è¾‘"""
        try:
            if hasattr(self, 'df_valid') and self.df_valid is not None:
                df_pk10 = self.df_valid[
                    (self.df_valid['å½©ç§ç±»å‹'] == 'PK10') & 
                    (self.df_valid['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
                ].copy()
            else:
                df_pk10 = df_filtered[
                    (df_filtered['å½©ç§ç±»å‹'] == 'PK10') & 
                    (df_filtered['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
                ].copy()
            
            if len(df_pk10) == 0:
                return []
            
            sequence_patterns = []
            period_groups = df_pk10.groupby('æœŸå·')
            
            for period, period_data in period_groups:
                if len(period_data) > 0:
                    if 'åŸå§‹å½©ç§' in period_data.columns:
                        specific_lottery = period_data['åŸå§‹å½©ç§'].iloc[0]
                    else:
                        specific_lottery = period_data['å½©ç§'].iloc[0]
                else:
                    specific_lottery = 'PK10'
                
                # è°ƒç”¨æ‰€æœ‰æ£€æµ‹æ–¹æ³•ï¼Œä¸é™åˆ¶
                patterns_1 = self._detect_1_5_6_10_collaboration(period_data, period, specific_lottery)
                sequence_patterns.extend(patterns_1)
                
                patterns_2 = self._detect_single_position_full_coverage(period_data, period, specific_lottery)
                sequence_patterns.extend(patterns_2)
                
                patterns_3 = self._detect_vertical_format_collaboration(period_data, period, specific_lottery)
                sequence_patterns.extend(patterns_3)
            
            # ä½¿ç”¨ä¿®å¤åçš„è¿ç»­æ¨¡å¼æ£€æµ‹æ–¹æ³•ï¼Œå®ƒä¼šè¿›è¡Œé€‚å½“çš„å»é‡
            continuous_patterns = self.find_continuous_patterns_optimized(sequence_patterns)
            
            return continuous_patterns
                    
        except Exception as e:
            logger.error(f"PK10åºåˆ—æ£€æµ‹å¤±è´¥: {str(e)}")
            return []
    
    def _get_valid_direction_combinations(self, n_accounts):
        """æœ‰æ•ˆæ–¹å‘ç»„åˆç”Ÿæˆ"""
        valid_combinations = []
        
        for opposites in self.config.opposite_groups:
            opposite_list = list(opposites)
            
            if n_accounts == 2:
                if len(opposite_list) == 2:
                    dir1, dir2 = opposite_list
                    valid_combinations.append({
                        'directions': [dir1, dir2],
                        'dir1_count': 1,
                        'dir2_count': 1,
                        'opposite_type': f"{dir1}-{dir2}",
                        'combination_type': 'basic'
                    })
            else:
                for i in range(1, n_accounts):
                    j = n_accounts - i
                    if len(opposite_list) == 2:
                        dir1, dir2 = opposite_list
                        valid_combinations.append({
                            'directions': [dir1] * i + [dir2] * j,
                            'dir1_count': i,
                            'dir2_count': j,
                            'opposite_type': f"{dir1}-{dir2}",
                            'combination_type': 'basic'
                        })
        
        multi_number_combinations = [
            ['å¤šæ•°å­—-01,04,05', 'å¤šæ•°å­—-01,04,05'],
            ['å¤šæ•°å­—-01,04,05', 'å¤šæ•°å­—-01,04,05'],
        ]
        
        for combo in multi_number_combinations:
            if n_accounts == len(combo):
                valid_combinations.append({
                    'directions': combo,
                    'dir1_count': n_accounts,
                    'dir2_count': 0,
                    'opposite_type': f"åä½œè¦†ç›–-å¤šæ•°å­—",
                    'combination_type': 'multi_number'
                })
        
        return valid_combinations
    
    def _detect_combinations_for_period(self, period_data, period_accounts, n_accounts, valid_combinations):
        """ä¸ºå•ä¸ªæœŸå·æ£€æµ‹ç»„åˆ"""
        patterns = []
        detected_combinations = set()
        
        # ç¡®ä¿lottery_typeæœ‰é»˜è®¤å€¼
        lottery_type = 'æœªçŸ¥'
        
        # å°è¯•ä»ä¸åŒåˆ—è·å–å½©ç§ç±»å‹
        if len(period_data) > 0:
            if 'å½©ç§ç±»å‹' in period_data.columns:
                lottery_type = period_data['å½©ç§ç±»å‹'].iloc[0]
            elif 'åŸå§‹å½©ç§' in period_data.columns:
                # ä»åŸå§‹å½©ç§æ¨æ–­ç±»å‹
                lottery_name = period_data['åŸå§‹å½©ç§'].iloc[0]
                lottery_type = self.lottery_identifier.identify_lottery_type(lottery_name)
            elif 'å½©ç§' in period_data.columns:
                lottery_name = period_data['å½©ç§'].iloc[0]
                lottery_type = self.lottery_identifier.identify_lottery_type(lottery_name)
        
        lottery = period_data['åŸå§‹å½©ç§'].iloc[0] if 'åŸå§‹å½©ç§' in period_data.columns else period_data['å½©ç§'].iloc[0]
        
        current_period = period_data['æœŸå·'].iloc[0]
        
        account_info = {}
        for _, row in period_data.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            direction = row['æŠ•æ³¨æ–¹å‘']
            amount = row['æŠ•æ³¨é‡‘é¢']
            
            if account not in account_info:
                account_info[account] = []
            account_info[account].append({
                'direction': direction,
                'amount': amount
            })
        
        for account_group in combinations(period_accounts, n_accounts):
            if not self._check_account_period_difference(account_group, lottery):
                continue
            
            group_directions = []
            group_amounts = []
            
            for account in account_group:
                if account in account_info and account_info[account]:
                    first_bet = account_info[account][0]
                    group_directions.append(first_bet['direction'])
                    group_amounts.append(first_bet['amount'])
            
            if len(group_directions) != n_accounts:
                continue
            
            filtered_account_group, filtered_directions, filtered_amounts = self.filter_accounts_by_amount_balance(
                account_group, group_directions, group_amounts
            )
            
            if len(filtered_account_group) < 2:
                continue
            
            account_group = filtered_account_group
            group_directions = filtered_directions
            group_amounts = filtered_amounts
            n_accounts = len(account_group)
    
            combination_key = (
                tuple(sorted(account_group)), 
                tuple(sorted(group_directions)),
                tuple(sorted(group_amounts))
            )
            
            if combination_key in detected_combinations:
                continue
            
            for combo in valid_combinations:
                target_directions = combo['directions']
                
                actual_directions_sorted = sorted(group_directions)
                target_directions_sorted = sorted(target_directions)
                
                if actual_directions_sorted == target_directions_sorted:
                    detected_combinations.add(combination_key)
                    
                    dir1_total = 0
                    dir2_total = 0
                    dir1 = combo['directions'][0]
                    
                    for direction, amount in zip(group_directions, group_amounts):
                        if direction == dir1:
                            dir1_total += amount
                        else:
                            dir2_total += amount
                    
                    similarity_threshold = self.config.account_count_similarity_thresholds.get(
                        n_accounts, self.config.amount_similarity_threshold
                    )
                    
                    if dir1_total > 0 and dir2_total > 0:
                        similarity = min(dir1_total, dir2_total) / max(dir1_total, dir2_total)
                        
                        if similarity >= similarity_threshold:
                            # ä½¿ç”¨å·²ç»å®šä¹‰å¥½çš„lottery_type
                            if ' vs ' in combo['opposite_type']:
                                pattern_parts = combo['opposite_type'].split(' vs ')
                                if len(pattern_parts) == 2:
                                    dir1_part = pattern_parts[0].split('-')
                                    dir2_part = pattern_parts[1].split('-')
                                    if len(dir1_part) == 2 and len(dir2_part) == 2:
                                        pattern_str = f"{dir1_part[0]}-{dir1_part[1]}({combo['dir1_count']}ä¸ª) vs {dir2_part[0]}-{dir2_part[1]}({combo['dir2_count']}ä¸ª)"
                                    else:
                                        pattern_str = f"{pattern_parts[0]}({combo['dir1_count']}ä¸ª) vs {pattern_parts[1]}({combo['dir2_count']}ä¸ª)"
                                else:
                                    pattern_str = combo['opposite_type']
                            else:
                                opposite_parts = combo['opposite_type'].split('-')
                                if len(opposite_parts) == 2:
                                    pattern_str = f"{opposite_parts[0]}({combo['dir1_count']}ä¸ª) vs {opposite_parts[1]}({combo['dir2_count']}ä¸ª)"
                                else:
                                    pattern_str = combo['opposite_type']
                            
                            record = {
                                'æœŸå·': period_data['æœŸå·'].iloc[0],
                                'å½©ç§': lottery,
                                'å½©ç§ç±»å‹': lottery_type,
                                'è´¦æˆ·ç»„': list(account_group),
                                'æ–¹å‘ç»„': group_directions,
                                'é‡‘é¢ç»„': group_amounts,
                                'æ€»é‡‘é¢': dir1_total + dir2_total,
                                'ç›¸ä¼¼åº¦': similarity,
                                'è´¦æˆ·æ•°é‡': n_accounts,
                                'æ¨¡å¼': pattern_str,
                                'å¯¹ç«‹ç±»å‹': combo['opposite_type']
                            }
                            
                            patterns.append(record)
                            break
        
        return patterns
    
    def _check_account_period_difference(self, account_group, lottery):
        """æ£€æŸ¥è´¦æˆ·ç»„å†…è´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°å·®å¼‚æ˜¯å¦åœ¨é˜ˆå€¼å†…"""
        if lottery not in self.account_total_periods_by_lottery:
            return True
        
        total_periods_stats = self.account_total_periods_by_lottery[lottery]
        
        account_periods = []
        for account in account_group:
            if account in total_periods_stats:
                account_periods.append(total_periods_stats[account])
            else:
                return True
        
        if len(account_periods) < 2:
            return True
        
        max_period = max(account_periods)
        min_period = min(account_periods)
        period_diff = max_period - min_period
        
        if period_diff > self.config.account_period_diff_threshold:
            logger.info(f"è·³è¿‡è´¦æˆ·ç»„ {account_group}ï¼ŒæœŸæ•°å·®å¼‚ {period_diff} > {self.config.account_period_diff_threshold}")
            return False
        
        return True
    
    def find_continuous_patterns_optimized(self, wash_records):
        """è¿ç»­å¯¹åˆ·æ¨¡å¼æ£€æµ‹ - ä¿®å¤è¿‡åº¦è¿‡æ»¤é—®é¢˜"""
        if not wash_records:
            return []
        
        account_group_patterns = defaultdict(list)
        
        # ç®€å•çš„å»é‡ï¼šç¡®ä¿åŒä¸€æœŸå·ã€åŒä¸€è´¦æˆ·ç»„ã€åŒä¸€æ–¹å‘ä¸ä¼šé‡å¤
        seen_keys = set()
        unique_records = []
        
        for record in wash_records:
            # åˆ›å»ºå”¯ä¸€æ ‡è¯†é”®
            key = (
                record['æœŸå·'],
                tuple(sorted(record['è´¦æˆ·ç»„'])),
                tuple(sorted(record['æ–¹å‘ç»„']))
            )
            
            if key not in seen_keys:
                seen_keys.add(key)
                unique_records.append(record)
        
        # ä½¿ç”¨å»é‡åçš„è®°å½•è¿›è¡Œåˆ†ç»„
        for record in unique_records:
            # ä¸å†è¿‡åº¦è¿‡æ»¤PK10åºåˆ—ä½ç½®æ£€æµ‹
            # å³ä½¿æ˜¯æ™®é€šåä½œï¼Œä¹Ÿå…è®¸æ˜¾ç¤º
            account_group_key = (tuple(sorted(record['è´¦æˆ·ç»„'])), record['å½©ç§'])
            account_group_patterns[account_group_key].append(record)
        
        continuous_patterns = []
        
        for account_group_key, records in account_group_patterns.items():
            # å¯¹æ¯ä¸ªç»„çš„è®°å½•æŒ‰æœŸå·æ’åº
            sorted_records = sorted(records, key=lambda x: x['æœŸå·'])
            
            if isinstance(account_group_key, tuple) and len(account_group_key) > 0:
                if isinstance(account_group_key[0], tuple):
                    account_group = list(account_group_key[0])
                    lottery = account_group_key[1]
                else:
                    account_group = list(account_group_key)
                    lottery = records[0]['å½©ç§'] if records else 'æœªçŸ¥'
            else:
                continue
            
            # æ ¹æ®æ£€æµ‹ç±»å‹è®¾ç½®ä¸åŒçš„æœ€å°æœŸæ•°è¦æ±‚
            if records and 'æ£€æµ‹ç±»å‹' in records[0]:
                if records[0]['æ£€æµ‹ç±»å‹'] == 'PK10åºåˆ—ä½ç½®':
                    required_min_periods = 3  # PK10å®Œæ•´åä½œè¦æ±‚è‡³å°‘3æœŸ
                else:
                    required_min_periods = self.get_required_min_periods(account_group, lottery)
            else:
                required_min_periods = self.get_required_min_periods(account_group, lottery)
            
            if len(sorted_records) >= required_min_periods:
                # ç¡®ä¿è¯¦ç»†è®°å½•ä¹Ÿæ˜¯å”¯ä¸€çš„ï¼ˆæŒ‰æœŸå·å»é‡ï¼‰
                seen_periods = set()
                unique_detailed_records = []
                
                for record in sorted_records:
                    period = record['æœŸå·']
                    if period not in seen_periods:
                        seen_periods.add(period)
                        unique_detailed_records.append(record)
                
                total_investment = sum(r['æ€»é‡‘é¢'] for r in unique_detailed_records)
                similarities = [r['ç›¸ä¼¼åº¦'] for r in unique_detailed_records if 'ç›¸ä¼¼åº¦' in r]
                avg_similarity = np.mean(similarities) if similarities else 1.0
                
                opposite_type_counts = defaultdict(int)
                for record in unique_detailed_records:
                    opposite_type = record.get('å¯¹ç«‹ç±»å‹', 'åä½œæ¨¡å¼')
                    opposite_type_counts[opposite_type] += 1
                
                pattern_count = defaultdict(int)
                for record in unique_detailed_records:
                    pattern = record.get('æ¨¡å¼', 'PK10åä½œ')
                    pattern_count[pattern] += 1
                
                main_opposite_type = max(opposite_type_counts.items(), key=lambda x: x[1])[0] if opposite_type_counts else 'åä½œæ¨¡å¼'
                
                account_stats_info = []
                for account in account_group:
                    if hasattr(self, 'df_valid') and self.df_valid is not None:
                        account_data = self.df_valid[
                            (self.df_valid['ä¼šå‘˜è´¦å·'] == account) & 
                            (self.df_valid['å½©ç§'] == lottery)
                        ]
                        total_periods = account_data['æœŸå·'].nunique()
                        records_count = len(account_data)
                    else:
                        total_periods_stats = self.account_total_periods_by_lottery.get(lottery, {})
                        record_stats = self.account_record_stats_by_lottery.get(lottery, {})
                        total_periods = total_periods_stats.get(account, 0)
                        records_count = record_stats.get(account, 0)
                    
                    account_stats_info.append(f"{account}({total_periods}æœŸ/{records_count}è®°å½•)")
                
                activity_level = self.get_account_group_activity_level(account_group, lottery)
                
                continuous_pattern = {
                    'è´¦æˆ·ç»„': account_group,
                    'å½©ç§': lottery,
                    'å½©ç§ç±»å‹': records[0]['å½©ç§ç±»å‹'] if records else 'PK10',
                    'è´¦æˆ·æ•°é‡': len(account_group),
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': main_opposite_type,
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': dict(opposite_type_counts),
                    'å¯¹åˆ·æœŸæ•°': len(unique_detailed_records),
                    'æ€»æŠ•æ³¨é‡‘é¢': total_investment,
                    'å¹³å‡ç›¸ä¼¼åº¦': avg_similarity,
                    'æ¨¡å¼åˆ†å¸ƒ': dict(pattern_count),
                    'è¯¦ç»†è®°å½•': unique_detailed_records,
                    'è´¦æˆ·æ´»è·ƒåº¦': activity_level,
                    'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': account_stats_info,
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': required_min_periods,
                    'æ£€æµ‹ç±»å‹': records[0].get('æ£€æµ‹ç±»å‹', 'PK10åºåˆ—ä½ç½®'),
                    'å®Œæ•´è¦†ç›–æœŸæ•°': len(unique_detailed_records),
                    'æ€»æ£€æµ‹æœŸæ•°': len(sorted_records)
                }
                
                continuous_patterns.append(continuous_pattern)
        
        return continuous_patterns

    def _detect_single_position_full_coverage(self, period_data, period, specific_lottery='PK10'):
        """ä¿®å¤å•ä¸ªä½ç½®å…¨è¦†ç›–æ£€æµ‹ - ç¡®ä¿èƒ½æ£€æµ‹æ‰€æœ‰æ–¹å‘ç±»å‹"""
        patterns = []
        
        pk10_positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                         'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
        
        account_position_bets = defaultdict(lambda: defaultdict(list))
        
        for _, row in period_data.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            play_category = row.get('ç©æ³•åˆ†ç±»', '')
            content = row['å†…å®¹']
            amount = row.get('æŠ•æ³¨é‡‘é¢', 0)
            direction = row.get('æŠ•æ³¨æ–¹å‘', '')
            
            position = self._extract_position_from_play_category(play_category)
            if position not in pk10_positions:
                continue
            
            # å¦‚æœæ–¹å‘ä¸ºç©ºï¼Œå°è¯•é‡æ–°æå–
            if not direction:
                direction = self.enhanced_extract_direction_with_position(content, play_category, 'PK10')
                if not direction:
                    continue
            
            account_position_bets[account][position].append({
                'direction': direction,
                'amount': amount,
                'original_content': content
            })
        
        # æ‰¾å‡ºæ‰€æœ‰è´¦æˆ·
        all_accounts = list(account_position_bets.keys())
        if len(all_accounts) < 2:
            return patterns
        
        # æ£€æŸ¥ä¸¤ä¸ªè´¦æˆ·æ˜¯å¦èƒ½è¦†ç›–åä¸ªä½ç½®
        for i in range(len(all_accounts)):
            for j in range(i+1, len(all_accounts)):
                account1 = all_accounts[i]
                account2 = all_accounts[j]
                
                # æ£€æŸ¥ä¸¤ä¸ªè´¦æˆ·çš„æŠ•æ³¨æ–¹å‘æ˜¯å¦åœ¨æ‰€æœ‰ä½ç½®ä¸Šä¸€è‡´
                common_directions = set()
                all_positions_covered = True
                
                # è·Ÿè¸ªæ¯ä¸ªä½ç½®çš„æ–¹å‘
                position_directions = {}
                
                for position in pk10_positions:
                    account1_bets = account_position_bets[account1].get(position, [])
                    account2_bets = account_position_bets[account2].get(position, [])
                    
                    if not account1_bets and not account2_bets:
                        # è¿™ä¸ªä½ç½®ä¸¤ä¸ªè´¦æˆ·éƒ½æ²¡æŠ•æ³¨
                        all_positions_covered = False
                        break
                    
                    # ç¡®å®šè¿™ä¸ªä½ç½®çš„æŠ•æ³¨æ–¹å‘
                    position_direction = None
                    
                    if account1_bets and account2_bets:
                        # ä¸¤ä¸ªè´¦æˆ·éƒ½åœ¨è¿™ä¸ªä½ç½®æŠ•æ³¨ï¼Œæ£€æŸ¥æ–¹å‘æ˜¯å¦ç›¸åŒ
                        direction1 = account1_bets[0]['direction']
                        direction2 = account2_bets[0]['direction']
                        
                        if direction1 == direction2:
                            position_direction = direction1
                            common_directions.add(direction1)
                        else:
                            # æ–¹å‘ä¸åŒï¼Œä¸æ„æˆå¯¹åˆ·
                            all_positions_covered = False
                            break
                    elif account1_bets:
                        # åªæœ‰è´¦æˆ·1æŠ•æ³¨
                        position_direction = account1_bets[0]['direction']
                        common_directions.add(position_direction)
                    else:
                        # åªæœ‰è´¦æˆ·2æŠ•æ³¨
                        position_direction = account2_bets[0]['direction']
                        common_directions.add(position_direction)
                    
                    position_directions[position] = position_direction
                
                # å¦‚æœè¦†ç›–äº†æ‰€æœ‰ä½ç½®ä¸”æŠ•æ³¨æ–¹å‘ä¸€è‡´ï¼ˆæˆ–åªæœ‰ä¸€ä¸ªæ–¹å‘ï¼‰
                if all_positions_covered and len(common_directions) == 1:
                    common_direction = list(common_directions)[0]
                    
                    # è®¡ç®—é‡‘é¢
                    account1_amount = 0
                    account2_amount = 0
                    
                    for position in pk10_positions:
                        if position in account_position_bets[account1]:
                            account1_amount += sum(bet['amount'] for bet in account_position_bets[account1][position])
                        if position in account_position_bets[account2]:
                            account2_amount += sum(bet['amount'] for bet in account_position_bets[account2][position])
                    
                    total_amount = account1_amount + account2_amount
                    
                    # ç”Ÿæˆæ¨¡å¼æè¿°
                    if common_direction.startswith('å¤šæ•°å­—-'):
                        numbers = common_direction.replace('å¤šæ•°å­—-', '')
                        pattern_desc = f'PK10åä½ç½®å…¨è¦†ç›–-å¤šæ•°å­—{numbers}'
                    elif common_direction.startswith('æ•°å­—-'):
                        number = common_direction.replace('æ•°å­—-', '')
                        pattern_desc = f'PK10åä½ç½®å…¨è¦†ç›–-æ•°å­—{number}'
                    else:
                        pattern_desc = f'PK10åä½ç½®å…¨è¦†ç›–-{common_direction}'
                    
                    pattern = {
                        'æœŸå·': period,
                        'å½©ç§': specific_lottery,
                        'å½©ç§ç±»å‹': 'PK10',
                        'è´¦æˆ·ç»„': [account1, account2],
                        'æ–¹å‘ç»„': [common_direction, common_direction],
                        'é‡‘é¢ç»„': [account1_amount, account2_amount],
                        'æ€»é‡‘é¢': total_amount,
                        'ç›¸ä¼¼åº¦': 1.0,
                        'è´¦æˆ·æ•°é‡': 2,
                        'æ¨¡å¼': pattern_desc,
                        'å¯¹ç«‹ç±»å‹': f'å…¨è¦†ç›–åä½œ-{common_direction}',
                        'æ£€æµ‹ç±»å‹': 'PK10åºåˆ—ä½ç½®',
                        'ä½ç½®æ–¹å‘è¯¦æƒ…': position_directions
                    }
                    
                    patterns.append(pattern)
        
        return patterns

    def _check_individual_position_coverage(self, account_position_bets, account1, account2, period):
        """æ£€æŸ¥ä¸¤ä¸ªè´¦æˆ·çš„å•ä¸ªä½ç½®æ³¨å•åä½œ"""
        result = {
            'covered': False,
            'patterns': []
        }
        
        position_coverage = {}
        common_directions = set()
        
        for position in self.pk10_positions:
            account1_bets = account_position_bets[account1].get(position, [])
            account2_bets = account_position_bets[account2].get(position, [])
            
            if not account1_bets or not account2_bets:
                continue
            
            account1_content = account1_bets[0]['content']
            account2_content = account2_bets[0]['content']
            
            if account1_content == account2_content:
                position_coverage[position] = {
                    'content': account1_content,
                    'account1_amount': sum(bet['amount'] for bet in account1_bets),
                    'account2_amount': sum(bet['amount'] for bet in account2_bets)
                }
                common_directions.add(account1_content)
        
        if len(position_coverage) == len(self.pk10_positions) and len(common_directions) == 1:
            common_direction = list(common_directions)[0]
            total_amount = sum(pos_info['account1_amount'] + pos_info['account2_amount'] 
                              for pos_info in position_coverage.values())
            
            account1_positions = []
            account2_positions = []
            for position in self.pk10_positions:
                if account_position_bets[account1].get(position):
                    account1_positions.append(position)
                if account_position_bets[account2].get(position):
                    account2_positions.append(position)
            
            pattern = {
                'æœŸå·': period,
                'å½©ç§': 'PK10',
                'å½©ç§ç±»å‹': 'PK10',
                'è´¦æˆ·ç»„': [account1, account2],
                'æ–¹å‘ç»„': [common_direction, common_direction],
                'é‡‘é¢ç»„': [
                    sum(account_position_bets[account1][pos][0]['amount'] for pos in account1_positions),
                    sum(account_position_bets[account2][pos][0]['amount'] for pos in account2_positions)
                ],
                'æ€»é‡‘é¢': total_amount,
                'ç›¸ä¼¼åº¦': 1.0,
                'è´¦æˆ·æ•°é‡': 2,
                'æ¨¡å¼': f'PK10åä½ç½®å…¨è¦†ç›–-{common_direction}',
                'å¯¹ç«‹ç±»å‹': f'å…¨è¦†ç›–åä½œ-{common_direction}',
                'æ£€æµ‹ç±»å‹': 'PK10åºåˆ—ä½ç½®',
                'ä½ç½®åˆ†é…': {
                    account1: account1_positions,
                    account2: account2_positions
                }
            }
            
            result['covered'] = True
            result['patterns'].append(pattern)
        
        return result
    
    def _extract_position_from_play_category(self, play_category):
        """ä»ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½®ä¿¡æ¯ - å¢å¼ºç‰ˆ"""
        play_str = str(play_category).strip()
        
        position_mapping = {
            # å† å†›
            'å† å†›': 'å† å†›',
            'ç¬¬1å': 'å† å†›',
            'ç¬¬ä¸€å': 'å† å†›',
            'å‰ä¸€': 'å† å†›',
            'å†  å†›': 'å† å†›',
            'å† ã€€å†›': 'å† å†›',
            
            # äºšå†›
            'äºšå†›': 'äºšå†›',
            'ç¬¬2å': 'äºšå†›',
            'ç¬¬äºŒå': 'äºšå†›',
            'å‰äºŒ': 'äºšå†›',
            'äºš å†›': 'äºšå†›',
            'äºšã€€å†›': 'äºšå†›',
            
            # ç¬¬ä¸‰å
            'å­£å†›': 'ç¬¬ä¸‰å',
            'ç¬¬3å': 'ç¬¬ä¸‰å',
            'ç¬¬ä¸‰å': 'ç¬¬ä¸‰å',
            'å‰ä¸‰': 'ç¬¬ä¸‰å',
            
            # ç¬¬å››å
            'ç¬¬4å': 'ç¬¬å››å',
            'ç¬¬å››å': 'ç¬¬å››å',
            'å‰å››': 'ç¬¬å››å',
            
            # ç¬¬äº”å
            'ç¬¬5å': 'ç¬¬äº”å',
            'ç¬¬äº”å': 'ç¬¬äº”å',
            'å‰äº”': 'ç¬¬äº”å',
            
            # ç¬¬å…­å
            'ç¬¬6å': 'ç¬¬å…­å',
            'ç¬¬å…­å': 'ç¬¬å…­å',
            
            # ç¬¬ä¸ƒå
            'ç¬¬7å': 'ç¬¬ä¸ƒå',
            'ç¬¬ä¸ƒå': 'ç¬¬ä¸ƒå',
            
            # ç¬¬å…«å
            'ç¬¬8å': 'ç¬¬å…«å',
            'ç¬¬å…«å': 'ç¬¬å…«å',
            
            # ç¬¬ä¹å
            'ç¬¬9å': 'ç¬¬ä¹å',
            'ç¬¬ä¹å': 'ç¬¬ä¹å',
            
            # ç¬¬åå
            'ç¬¬10å': 'ç¬¬åå',
            'ç¬¬åå': 'ç¬¬åå'
        }
        
        for key, position in position_mapping.items():
            if key in play_str:
                return position
        
        return ''
    
    def _detect_1_5_6_10_collaboration(self, period_data, period, specific_lottery='PK10'):
        """ä¿®å¤ç‰ˆï¼šæ£€æµ‹1-5åå’Œ6-10åçš„åä½œæ¨¡å¼ - ä¿æŒåŸæœ‰é€»è¾‘ï¼Œä¸é¢å¤–é™åˆ¶"""
        patterns = []
        
        play_1_5 = period_data[period_data['ç©æ³•åˆ†ç±»'] == '1-5å']
        play_6_10 = period_data[period_data['ç©æ³•åˆ†ç±»'] == '6-10å']
        
        if len(play_1_5) == 0 or len(play_6_10) == 0:
            return patterns
        
        # æŒ‰è´¦æˆ·åˆ†ç»„
        account_1_5_data = {}
        account_6_10_data = {}
        
        # å¤„ç†1-5åæ•°æ®
        for _, row in play_1_5.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            direction = row.get('æŠ•æ³¨æ–¹å‘', '')
            amount = row.get('æŠ•æ³¨é‡‘é¢', 0)
            content = row['å†…å®¹']
            
            if direction:
                account_1_5_data[account] = {
                    'direction': direction,
                    'amount': amount,
                    'content': content
                }
        
        # å¤„ç†6-10åæ•°æ®
        for _, row in play_6_10.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            direction = row.get('æŠ•æ³¨æ–¹å‘', '')
            amount = row.get('æŠ•æ³¨é‡‘é¢', 0)
            content = row['å†…å®¹']
            
            if direction:
                account_6_10_data[account] = {
                    'direction': direction,
                    'amount': amount,
                    'content': content
                }
        
        # æŸ¥æ‰¾åä½œæ¨¡å¼
        for acc1, data1 in account_1_5_data.items():
            for acc2, data2 in account_6_10_data.items():
                if acc1 == acc2:
                    continue
                
                # æ£€æŸ¥æŠ•æ³¨æ–¹å‘æ˜¯å¦ç›¸åŒ
                if data1['direction'] != data2['direction']:
                    continue
                
                # æ£€æŸ¥é‡‘é¢å¹³è¡¡
                max_ratio = self.config.amount_threshold.get('max_amount_ratio', 10)
                if max(data1['amount'], data2['amount']) / min(data1['amount'], data2['amount']) > max_ratio:
                    continue
                
                account_group = [acc1, acc2]
                directions = [data1['direction'], data2['direction']]
                amounts = [data1['amount'], data2['amount']]
                total_amount = data1['amount'] + data2['amount']
                
                # æå–æŠ•æ³¨å†…å®¹
                if data1['direction'].startswith('æ•°å­—-'):
                    numbers = data1['direction'].replace('æ•°å­—-', '')
                    pattern_desc = f'PK10åä½ç½®åä½œ-æ•°å­—{numbers}'
                elif data1['direction'].startswith('å¤šæ•°å­—-'):
                    numbers = data1['direction'].replace('å¤šæ•°å­—-', '')
                    pattern_desc = f'PK10åä½ç½®åä½œ-å¤šæ•°å­—{numbers}'
                else:
                    pattern_desc = f'PK10åä½ç½®åä½œ-{data1["direction"]}'
                
                record = {
                    'æœŸå·': period,
                    'å½©ç§': specific_lottery,
                    'å½©ç§ç±»å‹': 'PK10',
                    'è´¦æˆ·ç»„': account_group,
                    'æ–¹å‘ç»„': directions,
                    'é‡‘é¢ç»„': amounts,
                    'æ€»é‡‘é¢': total_amount,
                    'ç›¸ä¼¼åº¦': 1.0,
                    'è´¦æˆ·æ•°é‡': 2,
                    'æ¨¡å¼': pattern_desc,
                    'å¯¹ç«‹ç±»å‹': f'ä½ç½®åä½œ-{data1["direction"]}',
                    'æ£€æµ‹ç±»å‹': 'PK10åºåˆ—ä½ç½®'
                }
                
                patterns.append(record)
        
        return patterns

    def _detect_vertical_format_collaboration(self, period_data, period, specific_lottery='PK10'):
        """ä¿®å¤ç‰ˆï¼šæ£€æµ‹ç«–çº¿åˆ†éš”æ ¼å¼çš„åä½œæ¨¡å¼ - ä¿®å¤æ¼æ´ï¼Œä¿æŒåŸæœ‰èƒ½åŠ›"""
        patterns = []
        
        # æŸ¥æ‰¾ä½¿ç”¨ç«–çº¿åˆ†éš”çš„å†…å®¹
        vertical_bets = period_data[period_data['å†…å®¹'].str.contains('|', na=False, regex=False)]
        
        if len(vertical_bets) < 2:
            return patterns
        
        # æŒ‰è´¦æˆ·åˆ†ç»„
        account_bets = {}
        for _, row in vertical_bets.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            content = row['å†…å®¹']
            direction = row.get('æŠ•æ³¨æ–¹å‘', '')
            amount = row.get('æŠ•æ³¨é‡‘é¢', 0)
            play_category = row.get('ç©æ³•åˆ†ç±»', '')
            
            if account not in account_bets:
                account_bets[account] = []
            
            account_bets[account].append({
                'content': content,
                'direction': direction,
                'amount': amount,
                'play_category': play_category,
                'original_play': row.get('ç©æ³•', '')  # ä¿ç•™åŸå§‹ç©æ³•å­—æ®µ
            })
        
        # æ¯”è¾ƒè´¦æˆ·é—´çš„æŠ•æ³¨å†…å®¹
        accounts = list(account_bets.keys())
        if len(accounts) < 2:
            return patterns
        
        # å»é‡é›†åˆï¼Œé¿å…åŒä¸€æœŸå·é‡å¤æ£€æµ‹ç›¸åŒè´¦æˆ·å¯¹
        detected_pairs = set()
        
        for i in range(len(accounts)):
            for j in range(i+1, len(accounts)):
                acc1 = accounts[i]
                acc2 = accounts[j]
                
                bets1 = account_bets[acc1]
                bets2 = account_bets[acc2]
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åŒæ–¹å‘çš„å¯¹åˆ·
                for bet1 in bets1:
                    for bet2 in bets2:
                        if bet1['direction'] and bet2['direction'] and bet1['direction'] == bet2['direction']:
                            # åˆ›å»ºå»é‡é”®
                            pair_key = (period, tuple(sorted([acc1, acc2])), bet1['direction'])
                            if pair_key in detected_pairs:
                                continue
                            
                            detected_pairs.add(pair_key)
                            
                            # æ£€æŸ¥é‡‘é¢å¹³è¡¡
                            max_ratio = self.config.amount_threshold.get('max_amount_ratio', 10)
                            if max(bet1['amount'], bet2['amount']) / min(bet1['amount'], bet2['amount']) > max_ratio:
                                continue
                            
                            # è·å–ç©æ³•åˆ†ç±»
                            play1 = bet1['play_category']
                            play2 = bet2['play_category']
                            original_play1 = bet1.get('original_play', '')
                            original_play2 = bet2.get('original_play', '')
                            
                            # åˆ¤æ–­åä½œç±»å‹
                            play1_lower = play1.lower()
                            play2_lower = play2.lower()
                            
                            # åˆ¤æ–­æ˜¯å¦äº’è¡¥
                            is_complementary = False
                            if ('1-5' in play1_lower or 'ç¬¬1~5å' in play1_lower or 
                                any(pos in play1_lower for pos in ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å'])):
                                if ('6-10' in play2_lower or 'ç¬¬6~10å' in play2_lower or 
                                    any(pos in play2_lower for pos in ['ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå'])):
                                    is_complementary = True
                            
                            if ('6-10' in play1_lower or 'ç¬¬6~10å' in play1_lower or 
                                any(pos in play1_lower for pos in ['ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå'])):
                                if ('1-5' in play2_lower or 'ç¬¬1~5å' in play2_lower or 
                                    any(pos in play2_lower for pos in ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å'])):
                                    is_complementary = True
                            
                            # ç¡®å®šæ¨¡å¼ç±»å‹
                            if is_complementary:
                                pattern_type = 'PK10å®Œæ•´åä½œ'
                                detection_type = 'PK10åºåˆ—ä½ç½®'
                            else:
                                # å¦‚æœç©æ³•åˆ†ç±»ç›¸åŒï¼Œè¿›ä¸€æ­¥åˆ†ææ˜¯å¦å¯èƒ½æ˜¯å®Œæ•´åä½œçš„ä¸åŒå½¢å¼
                                # ä¾‹å¦‚ï¼šä¸¤ä¸ªè´¦æˆ·éƒ½æŠ•1-5åï¼Œä½†å®é™…ä¸Šæ˜¯åˆ†å¼€æŠ•æ³¨
                                # è¿™é‡Œæˆ‘ä»¬æ ‡è®°ä¸ºå¯ç–‘åä½œï¼Œè®©è¿ç»­æ¨¡å¼æ£€æµ‹æ¥è¿‡æ»¤
                                pattern_type = 'PK10ç«–çº¿æ ¼å¼åä½œ'
                                detection_type = 'PK10å¯ç–‘åä½œ'
                            
                            # è·å–æŠ•æ³¨ä½ç½®è¯¦æƒ…
                            position_detail1 = self._get_position_detail(play1, original_play1)
                            position_detail2 = self._get_position_detail(play2, original_play2)
                            
                            record = {
                                'æœŸå·': period,
                                'å½©ç§': specific_lottery,
                                'å½©ç§ç±»å‹': 'PK10',
                                'è´¦æˆ·ç»„': [acc1, acc2],
                                'æ–¹å‘ç»„': [bet1['direction'], bet2['direction']],
                                'ç©æ³•åˆ†ç±»': [play1, play2],  # ç®€åŒ–åçš„ç©æ³•åˆ†ç±»
                                'åŸå§‹ç©æ³•': [original_play1, original_play2],  # åŸå§‹ç©æ³•å­—æ®µ
                                'ä½ç½®è¯¦æƒ…': [position_detail1, position_detail2],  # ä½ç½®è¯¦æƒ…
                                'é‡‘é¢ç»„': [bet1['amount'], bet2['amount']],
                                'æ€»é‡‘é¢': bet1['amount'] + bet2['amount'],
                                'ç›¸ä¼¼åº¦': 1.0,
                                'è´¦æˆ·æ•°é‡': 2,
                                'æ¨¡å¼': f'{pattern_type}-{bet1["direction"]}',
                                'å¯¹ç«‹ç±»å‹': f'{pattern_type.replace("PK10", "")}-{bet1["direction"]}',
                                'æ£€æµ‹ç±»å‹': detection_type,
                                'æ˜¯å¦äº’è¡¥': is_complementary
                            }
                            
                            # å¦‚æœæ˜¯å®Œæ•´åä½œï¼Œæ·»åŠ ä½ç½®è¦†ç›–è¯¦æƒ…
                            if is_complementary:
                                if '1-5' in play1_lower or 'ç¬¬1~5å' in play1_lower:
                                    acc1_positions = '1-5å'
                                    acc2_positions = '6-10å'
                                else:
                                    acc1_positions = '6-10å'
                                    acc2_positions = '1-5å'
                                
                                record['ä½ç½®è¦†ç›–è¯¦æƒ…'] = {
                                    'è¦†ç›–ç±»å‹': 'å®Œæ•´è¦†ç›–',
                                    acc1: acc1_positions,
                                    acc2: acc2_positions
                                }
                            else:
                                record['ä½ç½®è¦†ç›–è¯¦æƒ…'] = {
                                    'è¦†ç›–ç±»å‹': 'éƒ¨åˆ†è¦†ç›–',
                                    acc1: position_detail1,
                                    acc2: position_detail2
                                }
                            
                            patterns.append(record)
        
        return patterns
    
    def _get_position_detail(self, play_category, original_play):
        """è·å–ä½ç½®è¯¦æƒ…"""
        play_str = str(play_category).lower()
        
        if '1-5' in play_str or 'ç¬¬1~5å' in play_str:
            return '1-5å'
        elif '6-10' in play_str or 'ç¬¬6~10å' in play_str:
            return '6-10å'
        elif 'å† å†›' in play_str:
            return 'å† å†›'
        elif 'äºšå†›' in play_str:
            return 'äºšå†›'
        elif 'ç¬¬ä¸‰å' in play_str or 'å­£å†›' in play_str:
            return 'ç¬¬ä¸‰å'
        elif 'ç¬¬å››å' in play_str:
            return 'ç¬¬å››å'
        elif 'ç¬¬äº”å' in play_str:
            return 'ç¬¬äº”å'
        elif 'ç¬¬å…­å' in play_str:
            return 'ç¬¬å…­å'
        elif 'ç¬¬ä¸ƒå' in play_str:
            return 'ç¬¬ä¸ƒå'
        elif 'ç¬¬å…«å' in play_str:
            return 'ç¬¬å…«å'
        elif 'ç¬¬ä¹å' in play_str:
            return 'ç¬¬ä¹å'
        elif 'ç¬¬åå' in play_str:
            return 'ç¬¬åå'
        else:
            # å°è¯•ä»åŸå§‹ç©æ³•ä¸­æå–
            original_str = str(original_play).lower()
            if 'å† å†›' in original_str:
                return 'å† å†›'
            elif 'äºšå†›' in original_str:
                return 'äºšå†›'
            elif 'ç¬¬3å' in original_str or 'å­£å†›' in original_str:
                return 'ç¬¬ä¸‰å'
            elif 'ç¬¬4å' in original_str:
                return 'ç¬¬å››å'
            elif 'ç¬¬5å' in original_str:
                return 'ç¬¬äº”å'
            elif 'ç¬¬6å' in original_str:
                return 'ç¬¬å…­å'
            elif 'ç¬¬7å' in original_str:
                return 'ç¬¬ä¸ƒå'
            elif 'ç¬¬8å' in original_str:
                return 'ç¬¬å…«å'
            elif 'ç¬¬9å' in original_str:
                return 'ç¬¬ä¹å'
            elif 'ç¬¬10å' in original_str:
                return 'ç¬¬åå'
            else:
                return play_category

    def find_continuous_sequence_patterns(self, sequence_patterns):
        """æŸ¥æ‰¾è¿ç»­çš„åºåˆ—æ¨¡å¼"""
        if not sequence_patterns:
            return []
        
        account_group_patterns = defaultdict(list)
        for pattern in sequence_patterns:
            key = (tuple(sorted(pattern['è´¦æˆ·ç»„'])), pattern['æŠ•æ³¨å†…å®¹'])
            account_group_patterns[key].append(pattern)
        
        continuous_patterns = []
        
        for (account_group, bet_content), records in account_group_patterns.items():
            sorted_records = sorted(records, key=lambda x: x['æœŸå·'])
            
            if len(sorted_records) >= 3:
                total_investment = sum(r['æ€»æŠ•æ³¨é‡‘é¢'] for r in sorted_records)
                coverage_ratios = [r['è¦†ç›–åº¦'] for r in sorted_records]
                avg_coverage = np.mean(coverage_ratios) if coverage_ratios else 0
                
                if avg_coverage >= 1.0:
                    account_count = len(account_group)
                    if account_count in [2, 3]:
                        continuous_patterns.append({
                            'è´¦æˆ·ç»„': list(account_group),
                            'è´¦æˆ·æ•°é‡': account_count,
                            'æŠ•æ³¨å†…å®¹': bet_content,
                            'å½©ç§': 'PK10',
                            'å½©ç§ç±»å‹': 'PK10',
                            'è¿ç»­æœŸæ•°': len(sorted_records),
                            'æ€»æŠ•æ³¨é‡‘é¢': total_investment,
                            'å¹³å‡è¦†ç›–åº¦': avg_coverage,
                            'è¯¦ç»†è®°å½•': sorted_records,
                            'æ¨¡å¼ç±»å‹': 'åºåˆ—è¦†ç›–',
                            'æ¨¡å¼æè¿°': f'PK10åä½ç½®å…¨è¦†ç›–-{bet_content}({account_count}è´¦æˆ·åä½œ)',
                            'æ£€æµ‹ç±»å‹': 'PK10åºåˆ—ä½ç½®'
                        })
        
        return continuous_patterns

    def display_pk10_sequence_results(self, patterns):
        """æ˜¾ç¤ºPK10åºåˆ—æ£€æµ‹ç»“æœ"""
        if not patterns:
            return
        
        st.subheader("ğŸ¯ PK10åºåˆ—ä½ç½®æ£€æµ‹ç»“æœ")
        
        total_groups = len(patterns)
        total_periods = sum(p['è¿ç»­æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        account_count_stats = defaultdict(int)
        for pattern in patterns:
            account_count_stats[pattern['è´¦æˆ·æ•°é‡']] += 1
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("åºåˆ—å¯¹åˆ·ç»„æ•°", total_groups)
        with col2:
            st.metric("æ€»å¯¹åˆ·æœŸæ•°", total_periods)
        with col3:
            st.metric("æ€»æ¶‰åŠé‡‘é¢", f"Â¥{total_amount:,.2f}")
        with col4:
            two_account = account_count_stats.get(2, 0)
            three_account = account_count_stats.get(3, 0)
            st.metric("è´¦æˆ·ç»„åˆ", f"2è´¦æˆ·:{two_account}ç»„ 3è´¦æˆ·:{three_account}ç»„")
        
        content_stats = defaultdict(int)
        for pattern in patterns:
            content_stats[pattern['æŠ•æ³¨å†…å®¹']] += 1
        
        st.write("**æŠ•æ³¨å†…å®¹åˆ†å¸ƒ:**")
        content_cols = st.columns(min(5, len(content_stats)))
        for i, (content, count) in enumerate(content_stats.items()):
            if i < len(content_cols):
                with content_cols[i]:
                    st.metric(f"{content}æ¨¡å¼", f"{count}ç»„")
        
        st.info("""
        **æ£€æµ‹æ¨¡å¼è¯´æ˜ï¼š**
        - **2è´¦æˆ·åä½œ**ï¼šä¸¤ä¸ªè´¦æˆ·å…±åŒè¦†ç›–PK10åä¸ªä½ç½®ï¼ŒæŠ•æ³¨ç›¸åŒå†…å®¹
        - **3è´¦æˆ·åä½œ**ï¼šä¸‰ä¸ªè´¦æˆ·å…±åŒè¦†ç›–PK10åä¸ªä½ç½®ï¼ŒæŠ•æ³¨ç›¸åŒå†…å®¹
        - **åä¸ªä½ç½®å…¨è¦†ç›–**ï¼šç¡®ä¿PK10çš„åä¸ªä½ç½®éƒ½è¢«ç›¸åŒå†…å®¹è¦†ç›–
        - **è¿ç»­å¤šæœŸå‡ºç°**ï¼šè¦æ±‚è‡³å°‘è¿ç»­3æœŸå‡ºç°ç›¸åŒæ¨¡å¼
        """)
        
        for i, pattern in enumerate(patterns, 1):
            st.markdown(f"**å¯¹åˆ·ç»„ {i}:** {' â†” '.join(pattern['è´¦æˆ·ç»„'])}")
            account_type = "2è´¦æˆ·åä½œ" if pattern['è´¦æˆ·æ•°é‡'] == 2 else "3è´¦æˆ·åä½œ"
            st.markdown(f"**æ¨¡å¼ç±»å‹:** {account_type} | **æŠ•æ³¨å†…å®¹:** {pattern['æŠ•æ³¨å†…å®¹']} | **è¿ç»­æœŸæ•°:** {pattern['è¿ç»­æœŸæ•°']}æœŸ")
            st.markdown(f"**æ€»é‡‘é¢:** Â¥{pattern['æ€»æŠ•æ³¨é‡‘é¢']:,.2f} | **å¹³å‡è¦†ç›–åº¦:** {pattern['å¹³å‡è¦†ç›–åº¦']:.1%}")
            
            st.markdown("**è¯¦ç»†è®°å½•:**")
            for j, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                position_coverage = []
                for pos_record in record['ä½ç½®è¯¦æƒ…']:
                    position_coverage.append(f"{pos_record['position']}({','.join(pos_record['accounts'])})")
                
                st.write(f"{j}. æœŸå·: {record['æœŸå·']} | è¦†ç›–ä½ç½®: {record['è¦†ç›–ä½ç½®æ•°']}/{record['æ€»ä½ç½®æ•°']} | é‡‘é¢: Â¥{record['æ€»æŠ•æ³¨é‡‘é¢']:,.2f}")
                st.write(f"   ä½ç½®åˆ†é…: {' | '.join(position_coverage)}")
            
            if i < len(patterns):
                st.markdown("---")

    def _calculate_detailed_account_stats(self, patterns):
        """å½»åº•ä¿®å¤çš„è´¦æˆ·ç»Ÿè®¡è®¡ç®—æ–¹æ³• - å»æ‰æ¶‰åŠå½©ç§åˆ—"""
        account_participation = defaultdict(lambda: {
            'groups': set(),
            'lotteries': set(),
            'wash_periods': set(),
            'lottery_wash_periods': defaultdict(set),  # æŒ‰å½©ç§è®°å½•å¯¹åˆ·æœŸæ•°
            'total_bet_amount': 0,
        })
        
        if not hasattr(self, 'df_valid') or self.df_valid is None:
            return []
        
        # æ”¶é›†è´¦æˆ·å‚ä¸ä¿¡æ¯
        for pattern in patterns:
            group_id = f"ç»„{len(account_participation) + 1}"
            lottery = pattern['å½©ç§']
            
            for account in pattern['è´¦æˆ·ç»„']:
                account_info = account_participation[account]
                account_info['groups'].add(group_id)
                account_info['lotteries'].add(lottery)
                
                # è®°å½•æ¯ä¸ªå½©ç§çš„å¯¹åˆ·æœŸæ•°
                for record in pattern['è¯¦ç»†è®°å½•']:
                    account_info['wash_periods'].add(record['æœŸå·'])
                    account_info['lottery_wash_periods'][lottery].add(record['æœŸå·'])
                
                # è®¡ç®—è¯¥è´¦æˆ·åœ¨è¿™ä¸ªæ¨¡å¼ä¸­çš„æ€»æŠ•æ³¨é‡‘é¢
                pattern_bet_amount = 0
                for record in pattern['è¯¦ç»†è®°å½•']:
                    for acc, amt in zip(record['è´¦æˆ·ç»„'], record['é‡‘é¢ç»„']):
                        if acc == account:
                            pattern_bet_amount += amt
                
                account_info['total_bet_amount'] += pattern_bet_amount
        
        # ç”Ÿæˆç»Ÿè®¡è®°å½•
        account_stats = []
        for account, info in account_participation.items():
            groups_count = len(info['groups'])
            wash_periods_count = len(info['wash_periods'])
            total_bet_amount = info['total_bet_amount']
            avg_period_amount = total_bet_amount / wash_periods_count if wash_periods_count > 0 else 0
            
            # è®¡ç®—å½©ç§æ€»æŠ•æ³¨æœŸæ•°
            lottery_total_periods = 0
            
            for detected_lottery in info['lotteries']:
                account_all_data = self.df_valid[self.df_valid['ä¼šå‘˜è´¦å·'] == account]
                
                if 'åŸå§‹å½©ç§' in self.df_valid.columns:
                    account_lottery_data = account_all_data[account_all_data['åŸå§‹å½©ç§'] == detected_lottery]
                else:
                    account_lottery_data = account_all_data[account_all_data['å½©ç§'] == detected_lottery]
                
                if len(account_lottery_data) == 0 and 'å½©ç§ç±»å‹' in self.df_valid.columns:
                    account_lottery_data = account_all_data[account_all_data['å½©ç§ç±»å‹'] == detected_lottery]
                
                if len(account_lottery_data) == 0:
                    account_lottery_data = account_all_data[account_all_data['å½©ç§'].str.contains(detected_lottery, na=False)]
                
                lottery_total_periods += account_lottery_data['æœŸå·'].nunique()
            
            # ç”Ÿæˆè¿è§„å½©ç§å­—ç¬¦ä¸²ï¼ˆå½©ç§ï¼ˆæœŸæ•°ï¼‰ï¼‰
            violation_lotteries = []
            for lottery, periods in info['lottery_wash_periods'].items():
                period_count = len(periods)
                violation_lotteries.append(f"{lottery}ï¼ˆ{period_count}æœŸï¼‰")
            
            violation_lotteries_str = "ï¼›".join(violation_lotteries)
            
            stat_record = {
                'è´¦æˆ·': account,
                'å‚ä¸ç»„åˆæ•°': groups_count,
                'å½©ç§æ€»æŠ•æ³¨æœŸæ•°': lottery_total_periods,
                'å®é™…å¯¹åˆ·æœŸæ•°': wash_periods_count,
                'è¿è§„å½©ç§ï¼ˆå½©ç§ï¼ˆæœŸæ•°ï¼‰ï¼‰': violation_lotteries_str,
                'æ€»æŠ•æ³¨é‡‘é¢': total_bet_amount,
                'å¹³å‡æ¯æœŸé‡‘é¢': avg_period_amount
            }
            
            account_stats.append(stat_record)
        
        return sorted(account_stats, key=lambda x: x['å‚ä¸ç»„åˆæ•°'], reverse=True)

    def exclude_multi_direction_accounts(self, df_valid):
        """æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨"""
        if 'ç©æ³•åˆ†ç±»' not in df_valid.columns:
            return df_valid
        
        pk10_positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                         'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
        
        single_position_mask = df_valid['ç©æ³•åˆ†ç±»'].isin(pk10_positions)
        
        single_position_data = df_valid[single_position_mask]
        other_data = df_valid[~single_position_mask]
        
        if len(other_data) > 0:
            if 'æŠ•æ³¨æ–¹å‘' in other_data.columns:
                multi_direction_mask = (
                    other_data.groupby(['æœŸå·', 'ä¼šå‘˜è´¦å·'])['æŠ•æ³¨æ–¹å‘']
                    .transform('nunique') > 1
                )
                other_data_filtered = other_data[~multi_direction_mask]
            else:
                other_data_filtered = other_data
        else:
            other_data_filtered = other_data
        
        df_filtered = pd.concat([single_position_data, other_data_filtered], ignore_index=True)
        
        return df_filtered
    
    def get_account_group_activity_level(self, account_group, lottery):
        """è·å–æ´»è·ƒåº¦æ°´å¹³"""
        if hasattr(self, 'df_valid') and self.df_valid is not None:
            min_total_periods = float('inf')
            
            for account in account_group:
                account_data = self.df_valid[
                    (self.df_valid['ä¼šå‘˜è´¦å·'] == account) & 
                    (self.df_valid['å½©ç§'] == lottery)
                ]
                periods = account_data['æœŸå·'].nunique()
                if periods < min_total_periods:
                    min_total_periods = periods
            
            if min_total_periods != float('inf'):
                return self._calculate_activity_level(min_total_periods)
        
        if lottery in self.account_total_periods_by_lottery:
            total_periods_stats = self.account_total_periods_by_lottery[lottery]
            
            account_periods = [total_periods_stats.get(account, 0) for account in account_group]
            if account_periods:
                min_total_periods = min(account_periods)
                return self._calculate_activity_level(min_total_periods)
        
        return 'unknown'
    
    def _calculate_activity_level(self, min_total_periods):
        """æ ¹æ®æœŸæ•°è®¡ç®—æ´»è·ƒåº¦æ°´å¹³"""
        if min_total_periods <= self.config.period_thresholds['low_activity']:
            return 'low'
        elif min_total_periods <= self.config.period_thresholds['medium_activity_high']:
            return 'medium'
        elif min_total_periods <= self.config.period_thresholds['high_activity_low']:
            return 'high'
        else:
            return 'very_high'
    
    def get_required_min_periods(self, account_group, lottery):
        """æ ¹æ®æ–°çš„æ´»è·ƒåº¦é˜ˆå€¼è·å–æ‰€éœ€çš„æœ€å°å¯¹åˆ·æœŸæ•°"""
        activity_level = self.get_account_group_activity_level(account_group, lottery)
        
        if activity_level == 'low':
            return self.config.period_thresholds['min_periods_low']
        elif activity_level == 'medium':
            return self.config.period_thresholds['min_periods_medium']
        elif activity_level == 'high':
            return self.config.period_thresholds['min_periods_high']
        else:
            return self.config.period_thresholds['min_periods_very_high']
    
    def display_performance_stats(self):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
        if not self.performance_stats:
            return
        
        with st.expander("ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡", expanded=False):
            st.write(f"**æ•°æ®å¤„ç†ç»Ÿè®¡:**")
            st.write(f"- æ€»è®°å½•æ•°: {self.performance_stats['total_records']:,}")
            st.write(f"- æ€»æœŸå·æ•°: {self.performance_stats['total_periods']:,}")
            st.write(f"- æ€»è´¦æˆ·æ•°: {self.performance_stats['total_accounts']:,}")
            
            if 'detection_time' in self.performance_stats:
                st.write(f"**æ£€æµ‹æ€§èƒ½:**")
                st.write(f"- æ£€æµ‹æ—¶é—´: {self.performance_stats['detection_time']:.2f} ç§’")
                st.write(f"- å‘ç°æ¨¡å¼: {self.performance_stats['total_patterns']} ä¸ª")

    def enhanced_analyze_opposite_patterns(self, patterns):
        """å¢å¼ºå¯¹ç«‹æ¨¡å¼åˆ†æ"""
        if not patterns:
            return {}
        
        analysis = {
            'total_groups': len(patterns),
            'opposite_type_stats': defaultdict(int),
            'position_stats': defaultdict(int),
            'combination_type_stats': defaultdict(int),
            'lottery_opposite_stats': defaultdict(lambda: defaultdict(int))
        }
        
        for pattern in patterns:
            main_opposite = pattern['ä¸»è¦å¯¹ç«‹ç±»å‹']
            analysis['opposite_type_stats'][main_opposite] += 1
            
            for record in pattern['è¯¦ç»†è®°å½•']:
                for direction in record['æ–¹å‘ç»„']:
                    if '-' in direction:
                        position = direction.split('-')[0]
                        analysis['position_stats'][position] += 1
            
            lottery = pattern['å½©ç§']
            analysis['lottery_opposite_stats'][lottery][main_opposite] += 1
        
        return analysis
    
    def display_enhanced_opposite_analysis(self, patterns):
        """æ˜¾ç¤ºå¢å¼ºçš„å¯¹ç«‹æ¨¡å¼åˆ†æ"""
        if not patterns:
            return
        
        analysis = self.enhanced_analyze_opposite_patterns(patterns)
        
        st.subheader("ğŸ¯ å¯¹ç«‹æ¨¡å¼æ·±åº¦åˆ†æ")
        
        with st.expander("ğŸ“Š å¯¹ç«‹ç±»å‹åˆ†å¸ƒ", expanded=True):
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ä¸»è¦å¯¹ç«‹ç±»å‹:**")
                for opposite_type, count in sorted(analysis['opposite_type_stats'].items(), key=lambda x: x[1], reverse=True)[:10]:
                    st.write(f"- {opposite_type}: {count}ç»„")
            
            with col2:
                st.write("**ä½ç½®åˆ†å¸ƒ:**")
                for position, count in sorted(analysis['position_stats'].items(), key=lambda x: x[1], reverse=True)[:10]:
                    st.write(f"- {position}: {count}æ¬¡")
        
        with st.expander("ğŸ² å½©ç§å¯¹ç«‹æ¨¡å¼åˆ†æ", expanded=False):
            for lottery, opposite_stats in analysis['lottery_opposite_stats'].items():
                st.write(f"**{lottery}:**")
                for opposite_type, count in sorted(opposite_stats.items(), key=lambda x: x[1], reverse=True)[:5]:
                    st.write(f"  - {opposite_type}: {count}ç»„")

    def diagnose_account_data(self, account, lottery):
        """è¯Šæ–­è´¦æˆ·æ•°æ®åŒ¹é…é—®é¢˜"""
        if not hasattr(self, 'df_valid') or self.df_valid is None:
            return "æ— æ•°æ®"
        
        account_data = self.df_valid[self.df_valid['ä¼šå‘˜è´¦å·'] == account]
        
        result = {
            'account': account,
            'total_records': len(account_data),
            'total_periods': account_data['æœŸå·'].nunique(),
            'available_columns': self.df_valid.columns.tolist(),
            'lottery_match_attempts': {}
        }
        
        if 'åŸå§‹å½©ç§' in self.df_valid.columns:
            original_match = account_data[account_data['åŸå§‹å½©ç§'] == lottery]
            result['lottery_match_attempts']['åŸå§‹å½©ç§ç²¾ç¡®åŒ¹é…'] = {
                'records': len(original_match),
                'periods': original_match['æœŸå·'].nunique()
            }
        
        if 'å½©ç§' in self.df_valid.columns:
            lottery_match = account_data[account_data['å½©ç§'] == lottery]
            result['lottery_match_attempts']['å½©ç§ç²¾ç¡®åŒ¹é…'] = {
                'records': len(lottery_match),
                'periods': lottery_match['æœŸå·'].nunique()
            }
        
        if 'å½©ç§ç±»å‹' in self.df_valid.columns:
            type_match = account_data[account_data['å½©ç§ç±»å‹'] == lottery]
            result['lottery_match_attempts']['å½©ç§ç±»å‹åŒ¹é…'] = {
                'records': len(type_match),
                'periods': type_match['æœŸå·'].nunique()
            }
        
        if 'å½©ç§' in account_data.columns:
            result['all_lotteries'] = account_data['å½©ç§'].unique().tolist()
        
        return result

    def display_detailed_results(self, patterns):
        """æ˜¾ç¤ºè¯¦ç»†æ£€æµ‹ç»“æœ - ä¿®å¤å½©ç§ç»Ÿè®¡"""
        if not patterns:
            st.error("âŒ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„è¿ç»­å¯¹åˆ·æ¨¡å¼")
            return
        
        # ========== æ€»ä½“ç»Ÿè®¡ ==========
        st.subheader("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        
        # ä¿®å¤å½©ç§ç»Ÿè®¡é€»è¾‘
        lottery_stats = defaultdict(int)
        for pattern in patterns:
            # ä½¿ç”¨patternä¸­çš„'å½©ç§'å­—æ®µ
            lottery = pattern.get('å½©ç§', 'æœªçŸ¥')
            lottery_stats[lottery] += 1
        
        # è®¡ç®—åŸºç¡€ç»Ÿè®¡
        total_groups = len(patterns)
        total_accounts = sum(p['è´¦æˆ·æ•°é‡'] for p in patterns)
        total_wash_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        # ç¬¬ä¸€è¡Œï¼šåŸºç¡€æ•°æ®ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»å¯¹åˆ·ç»„æ•°", f"{total_groups}")
        
        with col2:
            st.metric("æ¶‰åŠè´¦æˆ·æ•°", f"{total_accounts}")
        
        with col3:
            st.metric("æ€»å¯¹åˆ·æœŸæ•°", f"{total_wash_periods}")
        
        with col4:
            st.metric("æ€»æ¶‰åŠé‡‘é¢", f"Â¥{total_amount:,.2f}")
        
        # ========== å½©ç§ç±»å‹ç»Ÿè®¡ ==========
        st.subheader("ğŸ² å½©ç§ç±»å‹ç»Ÿè®¡")
        
        # æŒ‰æ•°é‡æ’åº
        sorted_lotteries = sorted(lottery_stats.items(), key=lambda x: x[1], reverse=True)
        
        if sorted_lotteries:
            # æ˜¾ç¤ºæ‰€æœ‰å½©ç§ï¼Œä¸åˆ†æŠ˜å 
            st.write("**å„å½©ç§å¯¹åˆ·ç»„æ•°:**")
            
            # è®¡ç®—æ¯è¡Œæ˜¾ç¤ºå¤šå°‘ä¸ª
            max_per_row = 6
            num_lotteries = len(sorted_lotteries)
            
            # å¦‚æœå½©ç§æ•°é‡å°‘ï¼Œæ˜¾ç¤ºåœ¨ä¸€è¡Œ
            if num_lotteries <= max_per_row:
                cols = st.columns(num_lotteries)
                for i, (lottery, count) in enumerate(sorted_lotteries):
                    with cols[i]:
                        display_name = lottery
                        if len(display_name) > 10:
                            display_name = display_name[:8] + "..."
                        
                        st.metric(
                            label=display_name,
                            value=f"{count}ç»„",
                            help=f"å®Œæ•´åç§°: {lottery}"
                        )
            else:
                # å¦‚æœå½©ç§æ•°é‡å¤šï¼Œåˆ†å¤šè¡Œæ˜¾ç¤º
                num_rows = (num_lotteries + max_per_row - 1) // max_per_row
                
                for row in range(num_rows):
                    start_idx = row * max_per_row
                    end_idx = min((row + 1) * max_per_row, num_lotteries)
                    row_lotteries = sorted_lotteries[start_idx:end_idx]
                    
                    # åˆ›å»ºè¿™ä¸€è¡Œçš„åˆ—
                    cols = st.columns(len(row_lotteries))
                    
                    for i, (lottery, count) in enumerate(row_lotteries):
                        with cols[i]:
                            display_name = lottery
                            if len(display_name) > 10:
                                display_name = display_name[:8] + "..."
                            
                            st.metric(
                                label=display_name,
                                value=f"{count}ç»„",
                                help=f"å®Œæ•´åç§°: {lottery}"
                            )
        
        # ========== å‚ä¸è´¦æˆ·è¯¦ç»†ç»Ÿè®¡ ==========
        st.subheader("ğŸ‘¥ å‚ä¸è´¦æˆ·è¯¦ç»†ç»Ÿè®¡")
        
        account_stats = self._calculate_detailed_account_stats(patterns)
        
        if account_stats:
            df_stats = pd.DataFrame(account_stats)
            
            # æ ¼å¼åŒ–é‡‘é¢åˆ—
            df_stats['æ€»æŠ•æ³¨é‡‘é¢'] = df_stats['æ€»æŠ•æ³¨é‡‘é¢'].apply(lambda x: f"Â¥{x:,.2f}")
            df_stats['å¹³å‡æ¯æœŸé‡‘é¢'] = df_stats['å¹³å‡æ¯æœŸé‡‘é¢'].apply(lambda x: f"Â¥{x:,.2f}")
            
            # æ–°çš„åˆ—é¡ºåºï¼ˆå»æ‰æ¶‰åŠå½©ç§ï¼‰
            desired_columns = ['è´¦æˆ·', 'å‚ä¸ç»„åˆæ•°', 'å½©ç§æ€»æŠ•æ³¨æœŸæ•°', 'å®é™…å¯¹åˆ·æœŸæ•°', 
                              'è¿è§„å½©ç§ï¼ˆå½©ç§ï¼ˆæœŸæ•°ï¼‰ï¼‰', 'æ€»æŠ•æ³¨é‡‘é¢', 'å¹³å‡æ¯æœŸé‡‘é¢']
            
            # åªä¿ç•™å­˜åœ¨çš„åˆ—
            available_columns = [col for col in desired_columns if col in df_stats.columns]
            df_stats = df_stats[available_columns]
            
            st.dataframe(
                df_stats,
                use_container_width=True,
                hide_index=True,
                height=min(400, len(df_stats) * 35 + 38)
            )
        
        # ========== è¯¦ç»†å¯¹åˆ·ç»„åˆ†æ ==========
        st.subheader("ğŸ” è¯¦ç»†å¯¹åˆ·ç»„åˆ†æ")
        
        patterns_by_lottery = defaultdict(list)
        for pattern in patterns:
            lottery = pattern['å½©ç§']
            patterns_by_lottery[lottery].append(pattern)
        
        for lottery, lottery_patterns in patterns_by_lottery.items():
            total_groups_in_lottery = len(lottery_patterns)
            
            lottery_icon = "ğŸ²"
            if 'å¿«ä¸‰' in lottery or 'K3' in lottery:
                lottery_icon = "ğŸ²"
            elif 'å…­åˆå½©' in lottery or 'LHC' in lottery:
                lottery_icon = "ğŸ°"
            elif 'PK10' in lottery or 'èµ›è½¦' in lottery:
                lottery_icon = "ğŸ"
            elif 'æ—¶æ—¶å½©' in lottery or 'SSC' in lottery:
                lottery_icon = "â°"
            elif '3D' in lottery or 'æ’åˆ—' in lottery:
                lottery_icon = "ğŸ”¢"
            
            with st.expander(f"{lottery_icon} å½©ç§ï¼š{lottery}ï¼ˆå‘ç°{total_groups_in_lottery}ç»„ï¼‰", expanded=True):
                for i, pattern in enumerate(lottery_patterns, 1):
                    self._display_single_pattern_by_lottery(pattern, i, lottery)
    
    def _display_single_pattern_by_lottery(self, pattern, index, lottery):
        """æŒ‰å½©ç§æ˜¾ç¤ºå•ä¸ªå¯¹åˆ·ç»„è¯¦æƒ… - æ˜¾ç¤ºæ‰€æœ‰æ¨¡å¼"""
        # ä¸å†è¿‡æ»¤ä»»ä½•æ¨¡å¼ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ£€æµ‹åˆ°çš„å¯¹åˆ·ç»„
        st.markdown(f"**å¯¹åˆ·ç»„ {index}:** {' â†” '.join(pattern['è´¦æˆ·ç»„'])}")
        
        activity_icon = "ğŸŸ¢" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'low' else "ğŸŸ¡" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'medium' else "ğŸŸ " if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'high' else "ğŸ”´"
        activity_text = {
            'low': 'ä½æ´»è·ƒåº¦', 
            'medium': 'ä¸­æ´»è·ƒåº¦', 
            'high': 'é«˜æ´»è·ƒåº¦', 
            'very_high': 'æé«˜æ´»è·ƒåº¦'
        }.get(pattern['è´¦æˆ·æ´»è·ƒåº¦'], pattern['è´¦æˆ·æ´»è·ƒåº¦'])
        
        main_type = pattern['ä¸»è¦å¯¹ç«‹ç±»å‹']
        if ' vs ' in main_type:
            main_type_parts = main_type.split(' vs ')
            if len(main_type_parts) == 2:
                dir1 = main_type_parts[0].split('(')[0] if '(' in main_type_parts[0] else main_type_parts[0]
                dir2 = main_type_parts[1].split('(')[0] if '(' in main_type_parts[1] else main_type_parts[1]
                display_type = f"{dir1}-{dir2}"
            else:
                display_type = main_type.split('(')[0] if '(' in main_type else main_type
        else:
            display_type = main_type.split('(')[0] if '(' in main_type else main_type
        
        st.markdown(f"**æ´»è·ƒåº¦:** {activity_icon} {activity_text} | **å½©ç§:** {lottery} | **ä¸»è¦ç±»å‹:** {display_type}")
        
        account_stats_info = []
        for account in pattern['è´¦æˆ·ç»„']:
            if hasattr(self, 'df_valid') and self.df_valid is not None:
                account_all_data = self.df_valid[self.df_valid['ä¼šå‘˜è´¦å·'] == account]
                
                account_lottery_data = pd.DataFrame()
                
                if 'åŸå§‹å½©ç§' in self.df_valid.columns:
                    account_lottery_data = account_all_data[account_all_data['åŸå§‹å½©ç§'] == lottery]
                
                if len(account_lottery_data) == 0 and 'å½©ç§' in self.df_valid.columns:
                    account_lottery_data = account_all_data[account_all_data['å½©ç§'] == lottery]
                
                if len(account_lottery_data) == 0 and 'å½©ç§ç±»å‹' in self.df_valid.columns:
                    account_lottery_data = account_all_data[account_all_data['å½©ç§ç±»å‹'] == lottery]
                
                if len(account_lottery_data) == 0:
                    account_lottery_data = account_all_data[account_all_data['å½©ç§'].str.contains(lottery, na=False)]
                
                total_periods = account_lottery_data['æœŸå·'].nunique()
                records_count = len(account_lottery_data)
                
                if total_periods == 0:
                    all_lotteries = account_all_data['å½©ç§'].unique() if 'å½©ç§' in account_all_data.columns else []
                    account_stats_info.append(f"{account}(0æœŸ/0è®°å½•) [å®é™…å½©ç§: {', '.join(all_lotteries[:3])}]")
                else:
                    account_stats_info.append(f"{account}({total_periods}æœŸ/{records_count}è®°å½•)")
            else:
                account_stats_info.append(f"{account}(æ•°æ®ä¸å¯ç”¨)")
        
        st.markdown(f"**è´¦æˆ·åœ¨è¯¥å½©ç§æŠ•æ³¨æœŸæ•°/æ€»è®°å½•æ•°:** {', '.join(account_stats_info)}")
        
        st.markdown(f"**å¯¹åˆ·æœŸæ•°:** {pattern['å¯¹åˆ·æœŸæ•°']}æœŸ (è¦æ±‚â‰¥{pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°']}æœŸ)")
        
        detect_type = pattern.get('æ£€æµ‹ç±»å‹', 'ä¼ ç»Ÿå¯¹åˆ·')
        if detect_type == 'PK10åºåˆ—ä½ç½®':
            st.markdown(f"**æ€»é‡‘é¢:** {pattern['æ€»æŠ•æ³¨é‡‘é¢']:.2f}å…ƒ")
        else:
            st.markdown(f"**æ€»é‡‘é¢:** {pattern['æ€»æŠ•æ³¨é‡‘é¢']:.2f}å…ƒ | **å¹³å‡åŒ¹é…:** {pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}")
        
        st.markdown("**è¯¦ç»†è®°å½•:**")
        
        # ç¡®ä¿è¯¦ç»†è®°å½•ä¸é‡å¤
        seen_periods = set()
        record_count = 0
        
        for record in pattern['è¯¦ç»†è®°å½•']:
            period = record['æœŸå·']
            if period in seen_periods:
                continue
            
            seen_periods.add(period)
            record_count += 1
            
            # è·å–ä½ç½®è¯¦æƒ…
            position_details = record.get('ä½ç½®è¯¦æƒ…', [])
            play_categories = record.get('ç©æ³•åˆ†ç±»', [])
            original_plays = record.get('åŸå§‹ç©æ³•', [])
            
            account_directions = []
            for idx, (account, direction, amount) in enumerate(zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„'])):
                if '-' in direction:
                    clean_direction = direction.split('-', 1)[1]
                else:
                    clean_direction = direction
                
                # æ˜¾ç¤ºä½ç½®è¯¦æƒ…
                if idx < len(position_details):
                    position = position_details[idx]
                    account_directions.append(f"{account}({position},{clean_direction}:Â¥{amount})")
                elif idx < len(play_categories):
                    # å¦‚æœæ²¡æœ‰ä½ç½®è¯¦æƒ…ï¼Œä½¿ç”¨ç©æ³•åˆ†ç±»
                    play_category = play_categories[idx]
                    if '1-5' in play_category or 'ç¬¬1~5å' in play_category:
                        position = '1-5å'
                    elif '6-10' in play_category or 'ç¬¬6~10å' in play_category:
                        position = '6-10å'
                    else:
                        position = play_category
                    account_directions.append(f"{account}({position},{clean_direction}:Â¥{amount})")
                else:
                    account_directions.append(f"{account}({clean_direction}:Â¥{amount})")
            
            # æ˜¾ç¤ºä½ç½®è¦†ç›–è¯¦æƒ…ï¼ˆå¦‚æœæœ‰ï¼‰
            coverage_text = ""
            if 'ä½ç½®è¦†ç›–è¯¦æƒ…' in record:
                coverage_info = []
                coverage_type = record['ä½ç½®è¦†ç›–è¯¦æƒ…'].get('è¦†ç›–ç±»å‹', '')
                
                for key, value in record['ä½ç½®è¦†ç›–è¯¦æƒ…'].items():
                    if key not in ['è¦†ç›–ç±»å‹'] and key in record['è´¦æˆ·ç»„']:
                        coverage_info.append(f"{key}:{value}")
                
                if coverage_info:
                    coverage_text = f" | ä½ç½®è¦†ç›–: {' | '.join(coverage_info)}"
                    if coverage_type:
                        coverage_text = f" | {coverage_type}: {' | '.join(coverage_info)}"
            
            # æ˜¾ç¤ºæ˜¯å¦äº’è¡¥
            complementary_text = ""
            if 'æ˜¯å¦äº’è¡¥' in record:
                complementary_text = " | äº’è¡¥: âœ“" if record['æ˜¯å¦äº’è¡¥'] else " | äº’è¡¥: âœ—"
            
            if detect_type == 'PK10åºåˆ—ä½ç½®':
                st.write(f"{record_count}. æœŸå·: {record['æœŸå·']} | æ–¹å‘: {' â†” '.join(account_directions)}{coverage_text}{complementary_text}")
            else:
                similarity_display = f"{record['ç›¸ä¼¼åº¦']:.2%}" if 'ç›¸ä¼¼åº¦' in record else "100.00%"
                st.write(f"{record_count}. æœŸå·: {record['æœŸå·']} | æ–¹å‘: {' â†” '.join(account_directions)} | åŒ¹é…åº¦: {similarity_display}{coverage_text}{complementary_text}")
        
        if index < len(pattern):
            st.markdown("---")

    def display_summary_statistics(self, patterns):
        """æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡"""
        if not patterns:
            return
            
        st.subheader("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        
        total_groups = len(patterns)
        total_accounts = sum(p['è´¦æˆ·æ•°é‡'] for p in patterns)
        total_wash_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        account_count_stats = defaultdict(int)
        for pattern in patterns:
            account_count_stats[pattern['è´¦æˆ·æ•°é‡']] += 1
        
        lottery_stats = defaultdict(int)
        for pattern in patterns:
            lottery_stats[pattern['å½©ç§']] += 1
        
        activity_stats = defaultdict(int)
        for pattern in patterns:
            activity_stats[pattern['è´¦æˆ·æ´»è·ƒåº¦']] += 1
        
        opposite_type_stats = defaultdict(int)
        for pattern in patterns:
            for opposite_type, count in pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ'].items():
                opposite_type_stats[opposite_type] += count
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»å¯¹åˆ·ç»„æ•°", total_groups)
        
        with col2:
            st.metric("æ¶‰åŠè´¦æˆ·æ•°", total_accounts)
        
        with col3:
            st.metric("æ€»å¯¹åˆ·æœŸæ•°", total_wash_periods)
        
        with col4:
            st.metric("æ€»æ¶‰åŠé‡‘é¢", f"Â¥{total_amount:,.2f}")
        
        st.subheader("ğŸ² å½©ç§ç±»å‹ç»Ÿè®¡")
        
        lottery_display_names = {
            'PK10': 'PK10/èµ›è½¦',
            'K3': 'å¿«ä¸‰',
            'LHC': 'å…­åˆå½©', 
            'SSC': 'æ—¶æ—¶å½©',
            '3D': '3Dç³»åˆ—'
        }
        
        lottery_cols = st.columns(min(5, len(lottery_stats)))
        
        for i, (lottery, count) in enumerate(lottery_stats.items()):
            if i < len(lottery_cols):
                with lottery_cols[i]:
                    display_name = lottery_display_names.get(lottery, lottery)
                    st.metric(
                        label=display_name,
                        value=f"{count}ç»„"
                    )
        
        col_left, col_right = st.columns(2)
        
        with col_left:
            st.subheader("ğŸ‘¥ è´¦æˆ·ç»„åˆåˆ†å¸ƒ")
            
            for account_count, group_count in sorted(account_count_stats.items()):
                account_type_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns if p['è´¦æˆ·æ•°é‡'] == account_count)
                st.write(f"- **{account_count}ç»„**: {group_count}ç»„ ({account_type_periods}æœŸ)")
        
        with col_right:
            st.subheader("ğŸ“ˆ æ´»è·ƒåº¦åˆ†å¸ƒ")
            
            activity_display_names = {
                'low': 'ä½æ´»è·ƒåº¦',
                'medium': 'ä¸­æ´»è·ƒåº¦',
                'high': 'é«˜æ´»è·ƒåº¦',
                'very_high': 'æé«˜æ´»è·ƒåº¦'
            }
            
            for activity, count in activity_stats.items():
                display_name = activity_display_names.get(activity, activity)
                activity_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns if p['è´¦æˆ·æ´»è·ƒåº¦'] == activity)
                st.write(f"- **{display_name}**: {count}ç»„ ({activity_periods}æœŸ)")
        
        st.subheader("ğŸ“ˆ å…³é”®æŒ‡æ ‡")
        
        avg_group_amount = total_amount / total_groups if total_groups > 0 else 0
        
        metric_col1, metric_col2, metric_col3 = st.columns(3)
        
        with metric_col1:
            st.metric("å¹³å‡æ¯ç»„é‡‘é¢", f"Â¥{avg_group_amount:,.2f}")
        
        with metric_col2:
            business_total = total_amount
            st.metric("ä¸šåŠ¡ç±»å‹æ€»é¢", f"Â¥{business_total:,.2f}")
        
        with metric_col3:
            st.metric("å‚ä¸æ€»è´¦æˆ·æ•°", total_accounts)
        
        st.subheader("ğŸ¯ ä¸»è¦å¯¹ç«‹ç±»å‹")
        
        top_opposites = sorted(opposite_type_stats.items(), key=lambda x: x[1], reverse=True)[:3]
        
        for opposite_type, count in top_opposites:
            if ' vs ' in opposite_type:
                display_type = opposite_type.replace(' vs ', '-')
            else:
                display_type = opposite_type
            st.write(f"- **{display_type}**: {count}æœŸ")

    def export_detection_results(self, patterns, export_format='excel'):
        """å¯¼å‡ºæ£€æµ‹ç»“æœ"""
        if not patterns:
            st.warning("âŒ æ²¡æœ‰æ£€æµ‹ç»“æœå¯ä¾›å¯¼å‡º")
            return None
        
        try:
            main_data = []
            detailed_data = []
            
            for i, pattern in enumerate(patterns, 1):
                main_record = {
                    'ç»„ID': f"ç»„{i}",
                    'è´¦æˆ·ç»„': ' â†” '.join(pattern['è´¦æˆ·ç»„']),
                    'å½©ç§': pattern['å½©ç§'],
                    'å½©ç§ç±»å‹': pattern['å½©ç§ç±»å‹'],
                    'è´¦æˆ·æ•°é‡': pattern['è´¦æˆ·æ•°é‡'],
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': pattern['ä¸»è¦å¯¹ç«‹ç±»å‹'],
                    'å¯¹åˆ·æœŸæ•°': pattern['å¯¹åˆ·æœŸæ•°'],
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°'],
                    'æ€»æŠ•æ³¨é‡‘é¢': pattern['æ€»æŠ•æ³¨é‡‘é¢'],
                    'å¹³å‡ç›¸ä¼¼åº¦': pattern['å¹³å‡ç›¸ä¼¼åº¦'],
                    'è´¦æˆ·æ´»è·ƒåº¦': pattern['è´¦æˆ·æ´»è·ƒåº¦'],
                    'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': '; '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯'])
                }
                main_data.append(main_record)
                
                for j, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                    detailed_record = {
                        'ç»„ID': f"ç»„{i}",
                        'è´¦æˆ·ç»„': ' â†” '.join(pattern['è´¦æˆ·ç»„']),
                        'æœŸå·': record['æœŸå·'],
                        'å½©ç§': record['å½©ç§'],
                        'å½©ç§ç±»å‹': record['å½©ç§ç±»å‹'],
                        'æ–¹å‘ç»„': ' â†” '.join([f"{acc}({dir})" for acc, dir in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'])]),
                        'é‡‘é¢ç»„': ' â†” '.join([f"Â¥{amt}" for amt in record['é‡‘é¢ç»„']]),
                        'æ€»é‡‘é¢': record['æ€»é‡‘é¢'],
                        'ç›¸ä¼¼åº¦': record['ç›¸ä¼¼åº¦'],
                        'è´¦æˆ·æ•°é‡': record['è´¦æˆ·æ•°é‡'],
                        'æ¨¡å¼': record['æ¨¡å¼'],
                        'å¯¹ç«‹ç±»å‹': record['å¯¹ç«‹ç±»å‹']
                    }
                    detailed_data.append(detailed_record)
            
            df_main = pd.DataFrame(main_data)
            df_detailed = pd.DataFrame(detailed_data)
            
            numeric_columns = ['æ€»æŠ•æ³¨é‡‘é¢', 'å¹³å‡ç›¸ä¼¼åº¦', 'æ€»é‡‘é¢', 'ç›¸ä¼¼åº¦']
            for col in numeric_columns:
                if col in df_main.columns:
                    df_main[col] = df_main[col].apply(lambda x: f"Â¥{x:,.2f}" if 'é‡‘é¢' in col else f"{x:.2%}")
                if col in df_detailed.columns:
                    df_detailed[col] = df_detailed[col].apply(lambda x: f"Â¥{x:,.2f}" if 'é‡‘é¢' in col else f"{x:.2%}")
            
            if export_format == 'excel':
                return self._export_to_excel(df_main, df_detailed)
            else:
                return self._export_to_csv(df_main, df_detailed)
                
        except Exception as e:
            logger.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            return None

    def _export_to_excel(self, df_main, df_detailed):
        """å¯¼å‡ºåˆ°Excelæ ¼å¼"""
        try:
            output = io.BytesIO()
            
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df_main.to_excel(writer, sheet_name='å¯¹åˆ·ç»„æ±‡æ€»', index=False)
                df_detailed.to_excel(writer, sheet_name='è¯¦ç»†è®°å½•', index=False)
                
                workbook = writer.book
                main_sheet = workbook['å¯¹åˆ·ç»„æ±‡æ€»']
                detailed_sheet = workbook['è¯¦ç»†è®°å½•']
                
                for sheet in [main_sheet, detailed_sheet]:
                    for column in sheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        adjusted_width = min(max_length + 2, 50)
                        sheet.column_dimensions[column_letter].width = adjusted_width
                
                main_sheet.insert_rows(0, 3)
                main_sheet['A1'] = "å¯¹åˆ·æ£€æµ‹ç»“æœæŠ¥å‘Š"
                main_sheet['A2'] = f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                main_sheet['A3'] = f"æ€»å¯¹åˆ·ç»„æ•°: {len(df_main)}"
                
                main_sheet.merge_cells('A1:L1')
                main_sheet.merge_cells('A2:L2')
                main_sheet.merge_cells('A3:L3')
                
                for cell in ['A1', 'A2', 'A3']:
                    main_sheet[cell].font = Font(bold=True, size=12)
                    main_sheet[cell].alignment = Alignment(horizontal='center')
            
            output.seek(0)
            return output
            
        except Exception as e:
            logger.error(f"Excelå¯¼å‡ºå¤±è´¥: {str(e)}")
            raise e

    def _export_to_csv(self, df_main, df_detailed):
        """å¯¼å‡ºåˆ°CSVæ ¼å¼"""
        try:
            zip_buffer = io.BytesIO()
            
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                main_csv = df_main.to_csv(index=False, encoding='utf-8-sig')
                zip_file.writestr('å¯¹åˆ·ç»„æ±‡æ€».csv', main_csv)
                
                detailed_csv = df_detailed.to_csv(index=False, encoding='utf-8-sig')
                zip_file.writestr('è¯¦ç»†è®°å½•.csv', detailed_csv)
                
                readme_content = f"""å¯¹åˆ·æ£€æµ‹ç»“æœå¯¼å‡ºæ–‡ä»¶
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æ€»å¯¹åˆ·ç»„æ•°: {len(df_main)}

æ–‡ä»¶è¯´æ˜:
1. å¯¹åˆ·ç»„æ±‡æ€».csv - åŒ…å«æ‰€æœ‰å¯¹åˆ·ç»„çš„æ±‡æ€»ä¿¡æ¯
2. è¯¦ç»†è®°å½•.csv - åŒ…å«æ¯ä¸ªå¯¹åˆ·ç»„çš„è¯¦ç»†æœŸå·è®°å½•

æ£€æµ‹å‚æ•°:
- æœ€å°æŠ•æ³¨é‡‘é¢: {self.config.min_amount}å…ƒ
- åŸºç¡€åŒ¹é…åº¦é˜ˆå€¼: {self.config.amount_similarity_threshold:.0%}
- æœ€å¤§æ£€æµ‹è´¦æˆ·æ•°: {self.config.max_accounts_in_group}
"""
                zip_file.writestr('è¯´æ˜.txt', readme_content)
            
            zip_buffer.seek(0)
            return zip_buffer
            
        except Exception as e:
            logger.error(f"CSVå¯¼å‡ºå¤±è´¥: {str(e)}")
            raise e

    def display_export_buttons(self, patterns):
        """æ˜¾ç¤ºå¯¼å‡ºæŒ‰é’®"""
        if not patterns:
            return
        
        st.markdown("---")
        st.subheader("ğŸ“¤ å¯¼å‡ºæ£€æµ‹ç»“æœ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ“Š å¯¼å‡ºExcelæŠ¥å‘Š", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”ŸæˆExcelæŠ¥å‘Š..."):
                    excel_data = self.export_detection_results(patterns, 'excel')
                    if excel_data:
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½Excelæ–‡ä»¶",
                            data=excel_data,
                            file_name=f"å¯¹åˆ·æ£€æµ‹æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
        
        with col2:
            if st.button("ğŸ“„ å¯¼å‡ºCSVæ–‡ä»¶", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”ŸæˆCSVæ–‡ä»¶..."):
                    csv_data = self.export_detection_results(patterns, 'csv')
                    if csv_data:
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½CSVå‹ç¼©åŒ…",
                            data=csv_data,
                            file_name=f"å¯¹åˆ·æ£€æµ‹æŠ¥å‘Š_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                            mime="application/zip",
                            use_container_width=True
                        )
        
        st.info(f"ğŸ“Š å¯¼å‡ºå†…å®¹: {len(patterns)}ä¸ªå¯¹åˆ·ç»„, å…±{sum(len(p['è¯¦ç»†è®°å½•']) for p in patterns)}æ¡è¯¦ç»†è®°å½•")

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ¯ æ™ºèƒ½å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    with st.sidebar:
        st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æŠ•æ³¨æ•°æ®æ–‡ä»¶", 
            type=['xlsx', 'xls', 'csv'],
            help="è¯·ä¸Šä¼ åŒ…å«å½©ç¥¨æŠ•æ³¨æ•°æ®çš„Excelæˆ–CSVæ–‡ä»¶"
        )
        
        st.header("âš™ï¸ æ£€æµ‹å‚æ•°è®¾ç½®")
        
        min_amount = st.slider(
            "æœ€å°æŠ•æ³¨é‡‘é¢é˜ˆå€¼", 
            min_value=1, 
            max_value=50, 
            value=10,
            help="æŠ•æ³¨é‡‘é¢ä½äºæ­¤å€¼çš„è®°å½•å°†ä¸å‚ä¸æ£€æµ‹"
        )
        
        max_accounts = st.slider(
            "æœ€å¤§æ£€æµ‹è´¦æˆ·æ•°", 
            2, 8, 5, 
            help="æ£€æµ‹çš„æœ€å¤§è´¦æˆ·ç»„åˆæ•°é‡"
        )
        
        period_diff_threshold = st.slider(
            "è´¦æˆ·æœŸæ•°æœ€å¤§å·®å¼‚é˜ˆå€¼", 
            min_value=0, 
            max_value=500,
            value=101,
            help="è´¦æˆ·æ€»æŠ•æ³¨æœŸæ•°æœ€å¤§å…è®¸å·®å¼‚ï¼Œè¶…è¿‡æ­¤å€¼ä¸è¿›è¡Œç»„åˆæ£€æµ‹"
        )
        
        st.subheader("ğŸ’° é‡‘é¢å¹³è¡¡è®¾ç½®")
        
        enable_balance_filter = st.checkbox("å¯ç”¨é‡‘é¢å¹³è¡¡è¿‡æ»¤", value=True,
                                          help="ç¡®ä¿å¯¹åˆ·ç»„å†…è´¦æˆ·é‡‘é¢å·®è·ä¸è¶…è¿‡è®¾å®šå€æ•°")
        
        max_ratio = 10
        if enable_balance_filter:
            max_ratio = st.slider("æœ€å¤§é‡‘é¢å·®è·å€æ•°", 
                                 min_value=2, 
                                 max_value=20, 
                                 value=10, 
                                 step=1,
                                 help="ç»„å†…æœ€å¤§é‡‘é¢ä¸æœ€å°é‡‘é¢çš„å…è®¸å€æ•°ï¼ˆä¾‹å¦‚ï¼š10è¡¨ç¤º10å€å·®è·ï¼‰")
        
        st.subheader("ğŸ¯ å¤šè´¦æˆ·åŒ¹é…åº¦é…ç½®")
        
        st.markdown("**2ä¸ªè´¦æˆ·:**")
        similarity_2_accounts = st.slider(
            "2ä¸ªè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼", 
            min_value=0.5, max_value=1.0, value=0.8, step=0.01,
            help="2ä¸ªè´¦æˆ·å¯¹åˆ·çš„é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼"
        )
        
        st.markdown("**3ä¸ªè´¦æˆ·:**")
        similarity_3_accounts = st.slider(
            "3ä¸ªè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼", 
            min_value=0.5, max_value=1.0, value=0.85, step=0.01,
            help="3ä¸ªè´¦æˆ·å¯¹åˆ·çš„é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼"
        )
        
        st.markdown("**4ä¸ªè´¦æˆ·:**")
        similarity_4_accounts = st.slider(
            "4ä¸ªè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼", 
            min_value=0.5, max_value=1.0, value=0.9, step=0.01,
            help="4ä¸ªè´¦æˆ·å¯¹åˆ·çš„é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼"
        )
        
        st.markdown("**5ä¸ªè´¦æˆ·:**")
        similarity_5_accounts = st.slider(
            "5ä¸ªè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼", 
            min_value=0.5, max_value=1.0, value=0.95, step=0.01,
            help="5ä¸ªè´¦æˆ·å¯¹åˆ·çš„é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼"
        )
        
        st.subheader("ğŸ› ï¸ è¿ç»­å¯¹åˆ·é˜ˆå€¼é…ç½®")
        
        st.markdown("**ä½æ´»è·ƒåº¦(1-10æœŸ):**")
        min_periods_low = st.slider(
            "ä½æ´»è·ƒåº¦æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°", 
            min_value=1, max_value=10, value=3,
            help="æ€»æŠ•æ³¨æœŸæ•°1-10æœŸçš„è´¦æˆ·ï¼Œè¦æ±‚çš„æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°"
        )
        
        st.markdown("**ä¸­æ´»è·ƒåº¦(11-50æœŸ):**")
        min_periods_medium = st.slider(
            "ä¸­æ´»è·ƒåº¦æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°", 
            min_value=3, max_value=15, value=5,
            help="æ€»æŠ•æ³¨æœŸæ•°11-50æœŸçš„è´¦æˆ·ï¼Œè¦æ±‚çš„æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°"
        )
        
        st.markdown("**é«˜æ´»è·ƒåº¦(51-100æœŸ):**")
        min_periods_high = st.slider(
            "é«˜æ´»è·ƒåº¦æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°", 
            min_value=5, max_value=20, value=8,
            help="æ€»æŠ•æ³¨æœŸæ•°51-100æœŸçš„è´¦æˆ·ï¼Œè¦æ±‚çš„æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°"
        )
        
        st.markdown("**æé«˜æ´»è·ƒåº¦(100æœŸä»¥ä¸Š):**")
        min_periods_very_high = st.slider(
            "æé«˜æ´»è·ƒåº¦æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°", 
            min_value=8, max_value=30, value=11,
            help="æ€»æŠ•æ³¨æœŸæ•°100æœŸä»¥ä¸Šçš„è´¦æˆ·ï¼Œè¦æ±‚çš„æœ€å°è¿ç»­å¯¹åˆ·æœŸæ•°"
        )
    
    if uploaded_file is not None:
        try:
            config = Config()
            config.min_amount = min_amount
            config.max_accounts_in_group = max_accounts
            config.account_period_diff_threshold = period_diff_threshold
            
            config.amount_similarity_threshold = similarity_2_accounts
            
            config.amount_threshold = {
                'max_amount_ratio': max_ratio,
                'enable_threshold_filter': enable_balance_filter
            }
            
            config.account_count_similarity_thresholds = {
                2: similarity_2_accounts,
                3: similarity_3_accounts,
                4: similarity_4_accounts,
                5: similarity_5_accounts
            }
            
            config.period_thresholds.update({
                'min_periods_low': min_periods_low,
                'min_periods_medium': min_periods_medium,
                'min_periods_high': min_periods_high,
                'min_periods_very_high': min_periods_very_high
            })
            
            detector = WashTradeDetector(config)
            
            st.success(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
            
            with st.spinner("ğŸ”„ æ­£åœ¨è§£ææ•°æ®..."):
                df_enhanced, filename = detector.upload_and_process(uploaded_file)
                
                if df_enhanced is not None and len(df_enhanced) > 0:
                    with st.spinner("ğŸ” æ­£åœ¨æ£€æµ‹å¯¹åˆ·äº¤æ˜“..."):
                        patterns = detector.detect_all_wash_trades()
                    
                    if patterns:
                        detector.display_detailed_results(patterns)
                        detector.display_export_buttons(patterns)
                    else:
                        st.warning("âš ï¸ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„å¯¹åˆ·è¡Œä¸º")
                else:
                    st.error("âŒ æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
            
        except Exception as e:
            st.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("ğŸ” æ™ºèƒ½æ£€æµ‹")
            st.markdown("""
            - å¤šè´¦æˆ·å¯¹åˆ·æ¨¡å¼è¯†åˆ«
            - æ™ºèƒ½é‡‘é¢åŒ¹é…åˆ†æ
            - æ´»è·ƒåº¦è‡ªé€‚åº”é˜ˆå€¼
            - å®æ—¶è¿›åº¦ç›‘æ§
            """)
        
        with col2:
            st.subheader("ğŸ“Š ä¸“ä¸šåˆ†æ")
            st.markdown("""
            - å®Œæ•´å½©ç§æ”¯æŒ
            - ç©æ³•åˆ†ç±»æ ‡å‡†åŒ–
            - æ•°æ®è´¨é‡éªŒè¯
            - è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
            """)
        
        with col3:
            st.subheader("ğŸš€ é«˜æ•ˆå¤„ç†")
            st.markdown("""
            - å¤§æ•°æ®é‡ä¼˜åŒ–
            - å¹¶è¡Œæ£€æµ‹ç®—æ³•
            - ä¸€é”®å¯¼å‡ºç»“æœ
            - å®æ—¶æ€§èƒ½ç›‘æ§
            """)
    
    with st.expander("ğŸ“– ç³»ç»Ÿä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½è¯´æ˜

        **ğŸ¯ æ£€æµ‹é€»è¾‘ï¼š**
        - **é‡‘é¢è¿‡æ»¤**ï¼šæŠ•æ³¨é‡‘é¢ä½äºè®¾å®šé˜ˆå€¼ï¼ˆé»˜è®¤10å…ƒï¼‰çš„è®°å½•ä¸å‚ä¸æ£€æµ‹
        - **æ€»æŠ•æ³¨æœŸæ•°**ï¼šè´¦æˆ·åœ¨ç‰¹å®šå½©ç§ä¸­çš„æ‰€æœ‰æœŸå·æŠ•æ³¨æ¬¡æ•°
        - **å¯¹åˆ·æœŸæ•°**ï¼šè´¦æˆ·ç»„å®é™…å‘ç”Ÿå¯¹åˆ·è¡Œä¸ºçš„æœŸæ•°
        - æ ¹æ®**æ€»æŠ•æ³¨æœŸæ•°**åˆ¤å®šè´¦æˆ·æ´»è·ƒåº¦ï¼Œè®¾ç½®ä¸åŒçš„**å¯¹åˆ·æœŸæ•°**é˜ˆå€¼

        **ğŸ“Š æ´»è·ƒåº¦åˆ¤å®šï¼š**
        - **1-10æœŸ**ï¼šè¦æ±‚â‰¥3æœŸè¿ç»­å¯¹åˆ·
        - **11-50æœŸ**ï¼šè¦æ±‚â‰¥5æœŸè¿ç»­å¯¹åˆ·  
        - **51-100æœŸ**ï¼šè¦æ±‚â‰¥8æœŸè¿ç»­å¯¹åˆ·
        - **100æœŸä»¥ä¸Š**ï¼šè¦æ±‚â‰¥11æœŸè¿ç»­å¯¹åˆ·

        **ğŸ¯ å¤šè´¦æˆ·åŒ¹é…åº¦è¦æ±‚ï¼š**
        - **2ä¸ªè´¦æˆ·**ï¼š80%åŒ¹é…åº¦
        - **3ä¸ªè´¦æˆ·**ï¼š85%åŒ¹é…åº¦  
        - **4ä¸ªè´¦æˆ·**ï¼š90%åŒ¹é…åº¦
        - **5ä¸ªè´¦æˆ·**ï¼š95%åŒ¹é…åº¦

        **ğŸ”„ è´¦æˆ·æœŸæ•°å·®å¼‚æ£€æŸ¥ï¼š**
        - é¿å…æœŸæ•°å·®å¼‚è¿‡å¤§çš„è´¦æˆ·ç»„åˆ
        - é»˜è®¤é˜ˆå€¼ï¼š101æœŸ
        - å¯è‡ªå®šä¹‰è°ƒæ•´é˜ˆå€¼

        **âš¡ è‡ªåŠ¨æ£€æµ‹ï¼š**
        - æ•°æ®ä¸Šä¼ åè‡ªåŠ¨å¼€å§‹å¤„ç†å’Œåˆ†æ
        - æ— éœ€æ‰‹åŠ¨ç‚¹å‡»å¼€å§‹æ£€æµ‹æŒ‰é’®

        **ğŸ² æ–°å¢å…­åˆå½©æ£€æµ‹ï¼š**
        - **å¤©è‚– vs åœ°è‚–**ï¼šå¤©è‚–ä¸åœ°è‚–çš„å¯¹ç«‹æ£€æµ‹
        - **å®¶è‚– vs é‡è‚–**ï¼šå®¶ç¦½è‚–ä¸é‡å…½è‚–çš„å¯¹ç«‹æ£€æµ‹  
        - **å°¾å¤§ vs å°¾å°**ï¼šå°¾æ•°å¤§å°çš„å¯¹ç«‹æ£€æµ‹
        - **ç‰¹å¤§ vs ç‰¹å°**ï¼šç‰¹ç å¤§å°çš„å¯¹ç«‹æ£€æµ‹
        - **ç‰¹å• vs ç‰¹åŒ**ï¼šç‰¹ç å•åŒçš„å¯¹ç«‹æ£€æµ‹
        """)

if __name__ == "__main__":
    main()
