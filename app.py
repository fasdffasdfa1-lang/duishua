import pandas as pd
import numpy as np
import streamlit as st
import io
import re
import logging
from collections import defaultdict
from datetime import datetime
from itertools import combinations
import warnings
import traceback
import hashlib
from functools import lru_cache

# é…ç½®æ—¥å¿—å’Œè­¦å‘Š
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('MultiAccountWashTrade')

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== é…ç½®ç±» - ä¿®å¤ç‰ˆ ====================
class Config:
    """é…ç½®å‚æ•°ç±» - ä¿®å¤ç‰ˆï¼Œæ”¯æŒå˜å¼‚å½¢å¼ä½†æ˜ å°„åˆ°åŸºç¡€æ–¹å‘"""
    def __init__(self):
        self.min_amount = 10
        self.amount_similarity_threshold = 0.8
        self.min_continuous_periods = 3
        self.max_accounts_in_group = 5
        self.supported_file_types = ['.xlsx', '.xls', '.csv']
        
        # åˆ—åæ˜ å°„é…ç½®
        self.column_mappings = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
        
        # æ´»è·ƒåº¦é˜ˆå€¼é…ç½®
        self.period_thresholds = {
            'low_activity': 10,
            'medium_activity_low': 11,
            'medium_activity_high': 50,
            'high_activity_low': 51,
            'high_activity_high': 100,
            'min_periods_low': 3,
            'min_periods_medium': 5,
            'min_periods_high': 8,
            'min_periods_very_high': 11
        }
        
        # å¤šè´¦æˆ·åŒ¹é…åº¦é˜ˆå€¼
        self.account_count_similarity_thresholds = {
            2: 0.8,
            3: 0.85,
            4: 0.9,
            5: 0.95
        }
        
        # è´¦æˆ·æœŸæ•°å·®å¼‚é˜ˆå€¼
        self.account_period_diff_threshold = 150
        
        # ğŸ¯ å…³é”®ä¿®å¤ï¼šæ‰©å±•æ–¹å‘æ¨¡å¼ï¼Œä½†ä¿æŒå˜å¼‚å½¢å¼çš„ç‹¬ç«‹æ€§
        self.direction_patterns = {
            # æ ¸å¿ƒåŸºç¡€å¯¹ç«‹æ–¹å‘
            'å°': ['ä¸¤é¢-å°', 'å’Œå€¼-å°', 'å°', 'small', 'xia', 'xiao', 'x', 's', 'å°æ•°'],
            'å¤§': ['ä¸¤é¢-å¤§', 'å’Œå€¼-å¤§', 'å¤§', 'big', 'da', 'large', 'd', 'b', 'å¤§æ•°'],
            'å•': ['ä¸¤é¢-å•', 'å’Œå€¼-å•', 'å•', 'odd', 'dan', 'å¥‡æ•°', 'jd', 'o', 'å•æ•°'],
            'åŒ': ['ä¸¤é¢-åŒ', 'å’Œå€¼-åŒ', 'åŒ', 'even', 'shuang', 'å¶æ•°', 'sd', 'e', 'åŒæ•°'],
            'é¾™': ['é¾™', 'long', 'dragon', 'é¾', 'é¾è™-é¾™', 'l', 'd', 'long'],
            'è™': ['è™', 'hu', 'tiger', 'é¾è™-è™', 'h', 't', 'tiger'],
            
            # ğŸ¯ å®Œå–„ï¼šè´¨åˆå¯¹ç«‹
            'è´¨': ['è´¨', 'è´¨æ•°', 'prime', 'zhi', 'è³ª', 'è³ªæ•¸', 'p', 'z'],
            'åˆ': ['åˆ', 'åˆæ•°', 'composite', 'he', 'åˆæ•¸', 'c', 'h'],
            
            # ğŸ¯ å®Œå–„ï¼šå®¶é‡å¯¹ç«‹
            'å®¶': ['å®¶', 'å®¶ç¦½', 'å®¶ç•œ', 'å®¶åº­', 'jia', 'home'],
            'é‡': ['é‡', 'é‡å…½', 'é‡ç”Ÿ', 'é‡å¤–', 'ye', 'wild'],
            
            # ğŸ¯ å®Œå–„ï¼šç‰¹æ®Šå¯¹ç«‹å½¢å¼
            'ç‰¹å°': ['ç‰¹å°', 'æå°', 'æœ€å°', 'éå¸¸å°', 'tx', 'jx'],
            'ç‰¹å¤§': ['ç‰¹å¤§', 'æå¤§', 'æœ€å¤§', 'éå¸¸å¤§', 'td', 'jd'],
            'ç‰¹å•': ['ç‰¹å•', 'æå•', 'æœ€å•', 'éå¸¸å•'],
            'ç‰¹åŒ': ['ç‰¹åŒ', 'æåŒ', 'æœ€åŒ', 'éå¸¸åŒ'],
            'æ€»å’Œå°': ['æ€»å’Œå°', 'å’Œå°', 'æ€»å’Œ-å°', 'å’Œå€¼å°', 'zhex'],
            'æ€»å’Œå¤§': ['æ€»å’Œå¤§', 'å’Œå¤§', 'æ€»å’Œ-å¤§', 'å’Œå€¼å¤§', 'zhd'],
            'æ€»å’Œå•': ['æ€»å’Œå•', 'å’Œå•', 'æ€»å’Œ-å•', 'å’Œå€¼å•', 'zhdan'],
            'æ€»å’ŒåŒ': ['æ€»å’ŒåŒ', 'å’ŒåŒ', 'æ€»å’Œ-åŒ', 'å’Œå€¼åŒ', 'zhshuang'],
            
            # ğŸ¯ å®Œå–„ï¼šå¿«ä¸‰ç‰¹æ®Šå¯¹ç«‹
            'ä¸‰å†›å¤§': ['ä¸‰å†›å¤§', 'ä¸‰è»å¤§', 'å•ç å¤§', 'å¤§æ•°'],
            'ä¸‰å†›å°': ['ä¸‰å†›å°', 'ä¸‰è»å°', 'å•ç å°', 'å°æ•°'],
            'ä¸‰å†›å•': ['ä¸‰å†›å•', 'ä¸‰è»å•', 'å•ç å•', 'å•æ•°'], 
            'ä¸‰å†›åŒ': ['ä¸‰å†›åŒ', 'ä¸‰è»åŒ', 'å•ç åŒ', 'åŒæ•°'],
        }
        
        # ğŸ¯ ä¿®å¤ï¼šæ‰©å±•å¯¹ç«‹ç»„ï¼ŒåŒ…å«å˜å¼‚å½¢å¼
        self.opposite_groups = [
            # æ ¸å¿ƒåŸºç¡€å¯¹ç«‹ç»„
            {'å¤§', 'å°'}, 
            {'å•', 'åŒ'}, 
            {'é¾™', 'è™'},
            {'è´¨', 'åˆ'},
            {'å®¶', 'é‡'},
            
            # ğŸ¯ å®Œå–„ï¼šç‰¹æ®Šå½¢å¼å¯¹ç«‹ç»„
            {'ç‰¹å¤§', 'ç‰¹å°'},
            {'ç‰¹å•', 'ç‰¹åŒ'},
            {'æ€»å’Œå¤§', 'æ€»å’Œå°'},
            {'æ€»å’Œå•', 'æ€»å’ŒåŒ'},
            
            # ğŸ¯ å®Œå–„ï¼šå¿«ä¸‰å¯¹ç«‹ç»„
            {'ä¸‰å†›å¤§', 'ä¸‰å†›å°'},
            {'ä¸‰å†›å•', 'ä¸‰å†›åŒ'},
        ]
        
        # ä½ç½®å…³é”®è¯æ˜ å°„ - å¢å¼ºç‰ˆ
        self.position_keywords = {
            'PK10': {
                'å† å†›': ['å† å†›', 'ç¬¬1å', 'ç¬¬ä¸€å', 'å‰ä¸€', 'å†  å†›', 'å† ã€€å†›'],
                'äºšå†›': ['äºšå†›', 'ç¬¬2å', 'ç¬¬äºŒå', 'äºš å†›', 'äºšã€€å†›'],
                'å­£å†›': ['å­£å†›', 'ç¬¬3å', 'ç¬¬ä¸‰å', 'å­£ å†›', 'å­£ã€€å†›'],
                'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å'],
                'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å'],
                'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å'],
                'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å'],
                'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å'],
                'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å'],
                'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å']
            },
            '3D': {
                'ç™¾ä½': ['ç™¾ä½', 'å®šä½_ç™¾ä½', 'ç™¾ä½å®šä½'],
                'åä½': ['åä½', 'å®šä½_åä½', 'åä½å®šä½'],
                'ä¸ªä½': ['ä¸ªä½', 'å®šä½_ä¸ªä½', 'ä¸ªä½å®šä½']
            },
            'SSC': {
                'ç¬¬1çƒ': ['ç¬¬1çƒ', 'ä¸‡ä½', 'ç¬¬ä¸€ä½', 'å®šä½_ä¸‡ä½', 'ä¸‡ä½å®šä½'],
                'ç¬¬2çƒ': ['ç¬¬2çƒ', 'åƒä½', 'ç¬¬äºŒä½', 'å®šä½_åƒä½', 'åƒä½å®šä½'],
                'ç¬¬3çƒ': ['ç¬¬3çƒ', 'ç™¾ä½', 'ç¬¬ä¸‰ä½', 'å®šä½_ç™¾ä½', 'ç™¾ä½å®šä½'],
                'ç¬¬4çƒ': ['ç¬¬4çƒ', 'åä½', 'ç¬¬å››ä½', 'å®šä½_åä½', 'åä½å®šä½'],
                'ç¬¬5çƒ': ['ç¬¬5çƒ', 'ä¸ªä½', 'ç¬¬äº”ä½', 'å®šä½_ä¸ªä½', 'ä¸ªä½å®šä½']
            }
        }

# ==================== æ•°æ®å¤„ç†å™¨ç±» ====================
class DataProcessor:
    def __init__(self):
        self.required_columns = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹', 'é‡‘é¢']
        self.column_mapping = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID', 'ç”¨æˆ·åç§°', 'ç©å®¶åç§°'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°', 'å½©ç³»', 'æ¸¸æˆåç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·', 'å¼€å¥–æœŸå·', 'å¥–æœŸå·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»', 'ç©æ³•åç§°', 'æŠ•æ³¨æ–¹å¼'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯', 'å·ç ', 'é€‰å·'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼', 'å•æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é’±', 'å…ƒ']
        }
        
        self.similarity_threshold = 0.7

    def validate_data_format(self, df):
        """éªŒè¯æ•°æ®æ ¼å¼"""
        st.subheader("ğŸ” æ•°æ®æ ¼å¼éªŒè¯")
        
        issues = []
        
        # æ£€æŸ¥å¿…è¦åˆ—
        required_columns = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
        
        # æ£€æŸ¥æ•°æ®æ ·æœ¬
        st.write("æ•°æ®æ ·æœ¬:")
        st.dataframe(df.head(10))
        
        # æ£€æŸ¥åˆ—æ•°æ®ç±»å‹
        st.write("åˆ—æ•°æ®ç±»å‹:")
        col_types = df.dtypes.astype(str)
        st.write(col_types)
        
        # æ£€æŸ¥ç©ºå€¼
        st.write("ç©ºå€¼ç»Ÿè®¡:")
        null_stats = df.isnull().sum()
        st.write(null_stats)
        
        # æ£€æŸ¥å†…å®¹åˆ—æ˜¯å¦åŒ…å«æœ‰æ•ˆæ•°æ®
        if 'å†…å®¹' in df.columns:
            content_sample = df['å†…å®¹'].head(10).tolist()
            st.write("å†…å®¹åˆ—æ ·æœ¬:")
            for i, content in enumerate(content_sample, 1):
                st.write(f"{i}. {content}")
        
        if issues:
            st.error("âŒ æ•°æ®æ ¼å¼é—®é¢˜:")
            for issue in issues:
                st.error(f"- {issue}")
            return False
        
        st.success("âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡")
        return True
    
    def smart_column_identification(self, df_columns):
        """æ™ºèƒ½åˆ—è¯†åˆ« - å¢å¼ºç‰ˆ"""
        identified_columns = {}
        actual_columns = [str(col).strip() for col in df_columns]
        
        # ğŸ†• æ–°å¢ï¼šæ˜¾ç¤ºåŸå§‹åˆ—åå¸®åŠ©è°ƒè¯•
        st.info(f"ğŸ“‹ æ£€æµ‹åˆ°çš„åŸå§‹åˆ—å: {actual_columns}")
        
        for standard_col, possible_names in self.column_mapping.items():
            found = False
            for actual_col in actual_columns:
                actual_col_lower = actual_col.lower().replace(' ', '').replace('_', '').replace('-', '')
                
                for possible_name in possible_names:
                    possible_name_lower = possible_name.lower().replace(' ', '').replace('_', '').replace('-', '')
                    
                    # ğŸ†• å¢å¼ºåŒ¹é…æ¡ä»¶
                    if (possible_name_lower == actual_col_lower or 
                        possible_name_lower in actual_col_lower or 
                        actual_col_lower in possible_name_lower):
                        
                        identified_columns[actual_col] = standard_col
                        st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                        found = True
                        break
                
                if found:
                    break
            
            if not found:
                st.warning(f"âš ï¸ æœªè¯†åˆ«åˆ° {standard_col} å¯¹åº”çš„åˆ—å")
        
        return identified_columns
    
    # ========== ğŸ†• æ–°å¢è¿™ä¸ªæ–¹æ³• ==========
    def _calculate_string_similarity(self, str1, str2):
        """è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ - æ•´åˆç¬¬ä¸€å¥—ä»£ç ç®—æ³•"""
        if not str1 or not str2:
            return 0
        
        # ä½¿ç”¨é›†åˆäº¤é›†è®¡ç®—ç›¸ä¼¼åº¦
        set1 = set(str1)
        set2 = set(str2)
        intersection = set1 & set2
        
        if not set1:
            return 0
        
        return len(intersection) / len(set1)
    
    def find_data_start(self, df):
        """æ™ºèƒ½æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®"""
        for row_idx in range(min(20, len(df))):
            for col_idx in range(min(10, len(df.columns))):
                cell_value = str(df.iloc[row_idx, col_idx])
                if pd.notna(cell_value) and any(keyword in cell_value for keyword in ['ä¼šå‘˜', 'è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•', 'å†…å®¹', 'è®¢å•', 'ç”¨æˆ·']):
                    return row_idx, col_idx
        return 0, 0
    
    def validate_data_quality(self, df):
        """æ•°æ®è´¨é‡éªŒè¯"""
        logger.info("æ­£åœ¨è¿›è¡Œæ•°æ®è´¨é‡éªŒè¯...")
        issues = []
        
        # æ£€æŸ¥å¿…è¦åˆ—
        missing_cols = [col for col in self.required_columns if col not in df.columns]
        if missing_cols:
            issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        
        # æ£€æŸ¥ç©ºå€¼
        for col in self.required_columns:
            if col in df.columns:
                null_count = df[col].isnull().sum()
                if null_count > 0:
                    issues.append(f"åˆ— '{col}' æœ‰ {null_count} ä¸ªç©ºå€¼")

        if 'ä¼šå‘˜è´¦å·' in df.columns:
            # æ£€æŸ¥æˆªæ–­è´¦å·
            truncated_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(r'\.\.\.|â€¦', na=False)]
            if len(truncated_accounts) > 0:
                issues.append(f"å‘ç° {len(truncated_accounts)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„ä¼šå‘˜è´¦å·")
            
            # æ£€æŸ¥è´¦å·é•¿åº¦å¼‚å¸¸
            account_lengths = df['ä¼šå‘˜è´¦å·'].str.len()
            if account_lengths.max() > 50:
                issues.append("å‘ç°å¼‚å¸¸é•¿åº¦çš„ä¼šå‘˜è´¦å·")
            
            # æ˜¾ç¤ºè´¦å·æ ¼å¼æ ·æœ¬
            unique_accounts = df['ä¼šå‘˜è´¦å·'].unique()[:5]
            sample_info = " | ".join([f"'{acc}'" for acc in unique_accounts])
            st.info(f"ä¼šå‘˜è´¦å·æ ¼å¼æ ·æœ¬: {sample_info}")
        
        if 'æœŸå·' in df.columns:
            df['æœŸå·'] = df['æœŸå·'].astype(str).str.replace(r'\.0$', '', regex=True)
            invalid_periods = df[~df['æœŸå·'].str.match(r'^[\dA-Za-z]+$')]
            if len(invalid_periods) > 0:
                issues.append(f"å‘ç° {len(invalid_periods)} æ¡æ— æ•ˆæœŸå·è®°å½•")
        
        if 'å½©ç§' in df.columns:
            lottery_stats = df['å½©ç§'].value_counts()
            st.info(f"ğŸ² å½©ç§åˆ†å¸ƒ: å…±{len(lottery_stats)}ç§ï¼Œå‰5: {', '.join([f'{k}({v}æ¡)' for k,v in lottery_stats.head().items()])}")
        
        if hasattr(df, 'æŠ•æ³¨æ–¹å‘') and 'æŠ•æ³¨æ–¹å‘' in df.columns:
            direction_stats = df['æŠ•æ³¨æ–¹å‘'].value_counts().head(10)
            with st.expander("ğŸ¯ æŠ•æ³¨æ–¹å‘åˆ†å¸ƒTOP10", expanded=False):
                for direction, count in direction_stats.items():
                    st.write(f"  - {direction}: {count}æ¬¡")
        
        # ç‰¹åˆ«æ£€æŸ¥ä¼šå‘˜è´¦å·çš„å®Œæ•´æ€§
        if 'ä¼šå‘˜è´¦å·' in df.columns:
            truncated_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(r'\.\.\.|â€¦', na=False)]
            if len(truncated_accounts) > 0:
                issues.append(f"å‘ç° {len(truncated_accounts)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„ä¼šå‘˜è´¦å·")
            
            account_lengths = df['ä¼šå‘˜è´¦å·'].str.len()
            if account_lengths.max() > 50:
                issues.append("å‘ç°å¼‚å¸¸é•¿åº¦çš„ä¼šå‘˜è´¦å·")
            
            unique_accounts = df['ä¼šå‘˜è´¦å·'].unique()[:5]
            sample_info = " | ".join([f"'{acc}'" for acc in unique_accounts])
            st.info(f"ä¼šå‘˜è´¦å·æ ¼å¼æ ·æœ¬: {sample_info}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if 'æœŸå·' in df.columns:
            df['æœŸå·'] = df['æœŸå·'].astype(str).str.replace(r'\.0$', '', regex=True)
            invalid_periods = df[~df['æœŸå·'].str.match(r'^[\dA-Za-z]+$')]
            if len(invalid_periods) > 0:
                issues.append(f"å‘ç° {len(invalid_periods)} æ¡æ— æ•ˆæœŸå·è®°å½•")
        
        # æ£€æŸ¥é‡å¤æ•°æ®
        duplicate_count = df.duplicated().sum()
        if duplicate_count > 0:
            issues.append(f"å‘ç° {duplicate_count} æ¡é‡å¤è®°å½•")
        
        if issues:
            with st.expander("âš ï¸ æ•°æ®è´¨é‡é—®é¢˜", expanded=True):
                for issue in issues:
                    st.warning(f"  - {issue}")
        else:
            st.success("âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
        
        return issues
    
    def clean_data(self, uploaded_file):
        """æ•°æ®æ¸…æ´—ä¸»å‡½æ•° - å¢å¼ºè°ƒè¯•ç‰ˆ"""
        try:
            # ğŸ†• æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            st.info(f"ğŸ“ æ–‡ä»¶: {uploaded_file.name}")
            
            # è¯»å–åŸå§‹æ•°æ®
            df_temp = pd.read_excel(uploaded_file, header=None, nrows=50)
            st.info(f"åŸå§‹æ•°æ®ç»´åº¦: {df_temp.shape}")
            
            # ğŸ†• æ˜¾ç¤ºå‰å‡ è¡Œå¸®åŠ©è¯†åˆ«æ•°æ®ç»“æ„
            st.write("å‰5è¡ŒåŸå§‹æ•°æ®:")
            st.dataframe(df_temp.head(5))
            
            # æŸ¥æ‰¾æ•°æ®èµ·å§‹ä½ç½®
            start_row, start_col = self.find_data_start(df_temp)
            st.info(f"æ•°æ®èµ·å§‹ä½ç½®: ç¬¬{start_row+1}è¡Œ, ç¬¬{start_col+1}åˆ—")
            
            # è¯»å–æ¸…æ´—åçš„æ•°æ®
            df_clean = pd.read_excel(
                uploaded_file, 
                header=start_row,
                skiprows=range(start_row + 1) if start_row > 0 else None,
                dtype=str,
                na_filter=False
            )
            
            if start_col > 0:
                df_clean = df_clean.iloc[:, start_col:]
            
            st.info(f"æ¸…ç†åæ•°æ®ç»´åº¦: {df_clean.shape}")
            
            # ğŸ†• æ˜¾ç¤ºæ¸…ç†åçš„åˆ—å
            st.write("æ¸…ç†åçš„åˆ—å:", list(df_clean.columns))
            
            # æ™ºèƒ½åˆ—è¯†åˆ«
            column_mapping = self.smart_column_identification(df_clean.columns)
            if column_mapping:
                df_clean = df_clean.rename(columns=column_mapping)
                st.success("âœ… åˆ—åè¯†åˆ«å®Œæˆ!")
            
            # ğŸ†• æ£€æŸ¥å¿…è¦åˆ—
            missing_columns = [col for col in self.required_columns if col not in df_clean.columns]
            if missing_columns:
                st.error(f"âŒ ä»ç„¶ç¼ºå°‘åˆ—: {missing_columns}")
                st.info("å°è¯•æ‰‹åŠ¨æ˜ å°„...")
                
                # æ‰‹åŠ¨æ˜ å°„é€»è¾‘
                if len(df_clean.columns) >= len(self.required_columns):
                    manual_map = {}
                    st.write("è¯·æ‰‹åŠ¨é€‰æ‹©åˆ—æ˜ å°„:")
                    
                    for i, req_col in enumerate(self.required_columns):
                        if i < len(df_clean.columns):
                            manual_map[df_clean.columns[i]] = req_col
                            st.write(f"  {df_clean.columns[i]} -> {req_col}")
                    
                    df_clean = df_clean.rename(columns=manual_map)
            
            # ç»§ç»­åŸæœ‰å¤„ç†é€»è¾‘...
            # ...
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            return None

# ==================== å½©ç§è¯†åˆ«å™¨ ====================
LOTTERY_CONFIGS = {
    'PK10': {
        'lotteries': [
            'åˆ†åˆ†PKæ‹¾', 'ä¸‰åˆ†PKæ‹¾', 'äº”åˆ†PKæ‹¾', 'æ–°å¹¸è¿é£è‰‡', 'æ¾³æ´²å¹¸è¿10',
            'ä¸€åˆ†PK10', 'å®¾æœPK10', 'æé€Ÿé£è‰‡', 'æ¾³æ´²é£è‰‡', 'å¹¸è¿èµ›è½¦',
            'åˆ†åˆ†èµ›è½¦', 'åŒ—äº¬PK10', 'æ—§åŒ—äº¬PK10', 'æé€Ÿèµ›è½¦', 'å¹¸è¿èµ›è»Š', 
            'åŒ—äº¬èµ›è½¦', 'æé€ŸPK10', 'å¹¸è¿PK10', 'èµ›è½¦', 'èµ›è»Š'
        ],
        'min_number': 1,
        'max_number': 10,
        'gyh_min': 3,
        'gyh_max': 19,
        'position_names': ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                          'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
    },
    'K3': {
        'lotteries': [
            'åˆ†åˆ†å¿«ä¸‰', 'ä¸‰åˆ†å¿«3', 'äº”åˆ†å¿«3', 'æ¾³æ´²å¿«ä¸‰', 'å®¾æœå¿«ä¸‰',
            '1åˆ†å¿«ä¸‰', '3åˆ†å¿«ä¸‰', '5åˆ†å¿«ä¸‰', '10åˆ†å¿«ä¸‰', 'åŠ å·å¿«ä¸‰',
            'å¹¸è¿å¿«ä¸‰', 'å¤§å‘å¿«ä¸‰', 'å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 
            'æ¾³é—¨å¿«ä¸‰', 'é¦™æ¸¯å¿«ä¸‰', 'æ±Ÿè‹å¿«ä¸‰'
        ],
        'min_number': 1,
        'max_number': 6,
        'hezhi_min': 3,
        'hezhi_max': 18
    },
    'LHC': {
        'lotteries': [
            'æ–°æ¾³é—¨å…­åˆå½©', 'æ¾³é—¨å…­åˆå½©', 'é¦™æ¸¯å…­åˆå½©', 'ä¸€åˆ†å…­åˆå½©',
            'äº”åˆ†å…­åˆå½©', 'ä¸‰åˆ†å…­åˆå½©', 'é¦™æ¸¯â‘¥åˆå½©', 'åˆ†åˆ†å…­åˆå½©',
            'å¿«ä¹6åˆå½©', 'æ¸¯â‘¥åˆå½©', 'å°æ¹¾å¤§ä¹é€', 'å…­åˆ', 'lhc', 'å…­åˆå½©',
            'â‘¥åˆ', '6åˆ', 'å¤§å‘å…­åˆå½©'
        ],
        'min_number': 1,
        'max_number': 49
    },
    'SSC': {
        'lotteries': [
            'åˆ†åˆ†æ—¶æ—¶å½©', 'ä¸‰åˆ†æ—¶æ—¶å½©', 'äº”åˆ†æ—¶æ—¶å½©', 'å®¾æœæ—¶æ—¶å½©',
            '1åˆ†æ—¶æ—¶å½©', '3åˆ†æ—¶æ—¶å½©', '5åˆ†æ—¶æ—¶å½©', 'æ—§é‡åº†æ—¶æ—¶å½©',
            'å¹¸è¿æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©', 'æ–°ç–†æ—¶æ—¶å½©', 'å¤©æ´¥æ—¶æ—¶å½©',
            'é‡åº†æ—¶æ—¶å½©', 'ä¸Šæµ·æ—¶æ—¶å½©', 'å¹¿ä¸œæ—¶æ—¶å½©', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©'
        ],
        'min_number': 0,
        'max_number': 9
    },
    '3D': {
        'lotteries': [
            'æ’åˆ—ä¸‰', 'æ’åˆ—3', 'å¹¸è¿æ’åˆ—3', 'ä¸€åˆ†æ’åˆ—3', 'äºŒåˆ†æ’åˆ—3', 'ä¸‰åˆ†æ’åˆ—3', 
            'äº”åˆ†æ’åˆ—3', 'ååˆ†æ’åˆ—3', 'å¤§å‘æ’åˆ—3', 'å¥½è¿æ’åˆ—3', 'ç¦å½©3D', 'æé€Ÿ3D',
            'æé€Ÿæ’åˆ—3', 'å¹¸è¿3D', 'ä¸€åˆ†3D', 'äºŒåˆ†3D', 'ä¸‰åˆ†3D', 'äº”åˆ†3D', 
            'ååˆ†3D', 'å¤§å‘3D', 'å¥½è¿3D'
        ],
        'min_number': 0,
        'max_number': 9,
        'position_names': ['ç™¾ä½', 'åä½', 'ä¸ªä½']
    }
}

class LotteryIdentifier:
    def __init__(self):
        self.lottery_configs = LOTTERY_CONFIGS
        self.general_keywords = {
            'PK10': ['pk10', 'pkæ‹¾', 'é£è‰‡', 'èµ›è½¦', 'èµ›è»Š', 'å¹¸è¿10', 'åŒ—äº¬èµ›è½¦', 'æé€Ÿèµ›è½¦'],
            'K3': ['å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 'éª°å®', 'ä¸‰å†›'],
            'LHC': ['å…­åˆ', 'lhc', 'å…­åˆå½©', 'â‘¥åˆ', '6åˆ', 'ç‰¹ç ', 'å¹³ç‰¹', 'è¿è‚–'],
            'SSC': ['æ—¶æ—¶å½©', 'ssc', 'åˆ†åˆ†å½©', 'æ™‚æ™‚å½©', 'é‡åº†æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©'],
            '3D': ['æ’åˆ—ä¸‰', 'æ’åˆ—3', 'ç¦å½©3d', '3d', 'æé€Ÿ3d', 'æ’åˆ—', 'p3', 'pä¸‰']
        }
        
        self.lottery_aliases = {
            'åˆ†åˆ†PKæ‹¾': 'PK10', 'ä¸‰åˆ†PKæ‹¾': 'PK10', 'äº”åˆ†PKæ‹¾': 'PK10',
            'æ–°å¹¸è¿é£è‰‡': 'PK10', 'æ¾³æ´²å¹¸è¿10': 'PK10', 'ä¸€åˆ†PK10': 'PK10',
            'å®¾æœPK10': 'PK10', 'æé€Ÿé£è‰‡': 'PK10', 'æ¾³æ´²é£è‰‡': 'PK10',
            'å¹¸è¿èµ›è½¦': 'PK10', 'åˆ†åˆ†èµ›è½¦': 'PK10', 'åŒ—äº¬PK10': 'PK10',
            'æ—§åŒ—äº¬PK10': 'PK10', 'æé€Ÿèµ›è½¦': 'PK10', 'å¹¸è¿èµ›è»Š': 'PK10',
            'åŒ—äº¬èµ›è½¦': 'PK10', 'æé€ŸPK10': 'PK10', 'å¹¸è¿PK10': 'PK10',
            'åˆ†åˆ†å¿«ä¸‰': 'K3', 'ä¸‰åˆ†å¿«3': 'K3', 'äº”åˆ†å¿«3': 'K3', 'æ¾³æ´²å¿«ä¸‰': 'K3',
            'å®¾æœå¿«ä¸‰': 'K3', '1åˆ†å¿«ä¸‰': 'K3', '3åˆ†å¿«ä¸‰': 'K3', '5åˆ†å¿«ä¸‰': 'K3',
            '10åˆ†å¿«ä¸‰': 'K3', 'åŠ å·å¿«ä¸‰': 'K3', 'å¹¸è¿å¿«ä¸‰': 'K3', 'å¤§å‘å¿«ä¸‰': 'K3',
            'æ¾³é—¨å¿«ä¸‰': 'K3', 'é¦™æ¸¯å¿«ä¸‰': 'K3', 'æ±Ÿè‹å¿«ä¸‰': 'K3',
            'æ–°æ¾³é—¨å…­åˆå½©': 'LHC', 'æ¾³é—¨å…­åˆå½©': 'LHC', 'é¦™æ¸¯å…­åˆå½©': 'LHC',
            'ä¸€åˆ†å…­åˆå½©': 'LHC', 'äº”åˆ†å…­åˆå½©': 'LHC', 'ä¸‰åˆ†å…­åˆå½©': 'LHC',
            'é¦™æ¸¯â‘¥åˆå½©': 'LHC', 'åˆ†åˆ†å…­åˆå½©': 'LHC', 'å¿«ä¹6åˆå½©': 'LHC',
            'æ¸¯â‘¥åˆå½©': 'LHC', 'å°æ¹¾å¤§ä¹é€': 'LHC', 'å¤§å‘å…­åˆå½©': 'LHC',
            'åˆ†åˆ†æ—¶æ—¶å½©': 'SSC', 'ä¸‰åˆ†æ—¶æ—¶å½©': 'SSC', 'äº”åˆ†æ—¶æ—¶å½©': 'SSC',
            'å®¾æœæ—¶æ—¶å½©': 'SSC', '1åˆ†æ—¶æ—¶å½©': 'SSC', '3åˆ†æ—¶æ—¶å½©': 'SSC',
            '5åˆ†æ—¶æ—¶å½©': 'SSC', 'æ—§é‡åº†æ—¶æ—¶å½©': 'SSC', 'å¹¸è¿æ—¶æ—¶å½©': 'SSC',
            'è…¾è®¯åˆ†åˆ†å½©': 'SSC', 'æ–°ç–†æ—¶æ—¶å½©': 'SSC', 'å¤©æ´¥æ—¶æ—¶å½©': 'SSC',
            'é‡åº†æ—¶æ—¶å½©': 'SSC', 'ä¸Šæµ·æ—¶æ—¶å½©': 'SSC', 'å¹¿ä¸œæ—¶æ—¶å½©': 'SSC',
            'æ’åˆ—ä¸‰': '3D', 'æ’åˆ—3': '3D', 'å¹¸è¿æ’åˆ—3': '3D', 'ä¸€åˆ†æ’åˆ—3': '3D',
            'äºŒåˆ†æ’åˆ—3': '3D', 'ä¸‰åˆ†æ’åˆ—3': '3D', 'äº”åˆ†æ’åˆ—3': '3D', 'ååˆ†æ’åˆ—3': '3D',
            'å¤§å‘æ’åˆ—3': '3D', 'å¥½è¿æ’åˆ—3': '3D', 'ç¦å½©3D': '3D', 'æé€Ÿ3D': '3D',
            'æé€Ÿæ’åˆ—3': '3D', 'å¹¸è¿3D': '3D', 'ä¸€åˆ†3D': '3D', 'äºŒåˆ†3D': '3D',
            'ä¸‰åˆ†3D': '3D', 'äº”åˆ†3D': '3D', 'ååˆ†3D': '3D', 'å¤§å‘3D': '3D', 'å¥½è¿3D': '3D'
        }

    def identify_lottery_type(self, lottery_name):
        """å½©ç§ç±»å‹è¯†åˆ«"""
        lottery_str = str(lottery_name).strip()
        
        if lottery_str in self.lottery_aliases:
            return self.lottery_aliases[lottery_str]
        
        for lottery_type, config in self.lottery_configs.items():
            for lottery in config['lotteries']:
                if lottery in lottery_str:
                    return lottery_type
        
        lottery_lower = lottery_str.lower()
        
        for lottery_type, keywords in self.general_keywords.items():
            for keyword in keywords:
                if keyword.lower() in lottery_lower:
                    return lottery_type
        
        return lottery_str

# ==================== ç©æ³•åˆ†ç±»å™¨ ====================
class PlayCategoryNormalizer:
    def __init__(self):
        self.category_mapping = self._create_category_mapping()
    
    def _create_category_mapping(self):
        """åˆ›å»ºç©æ³•åˆ†ç±»æ˜ å°„"""
        mapping = {
            # å¿«ä¸‰ç©æ³•
            'å’Œå€¼': 'å’Œå€¼', 'å’Œå€¼_å¤§å°å•åŒ': 'å’Œå€¼', 'ä¸¤é¢': 'ä¸¤é¢',
            'äºŒä¸åŒå·': 'äºŒä¸åŒå·', 'ä¸‰ä¸åŒå·': 'ä¸‰ä¸åŒå·', 'ç‹¬èƒ†': 'ç‹¬èƒ†',
            'ç‚¹æ•°': 'å’Œå€¼', 'ä¸‰å†›': 'ç‹¬èƒ†', 'ä¸‰è»': 'ç‹¬èƒ†',
            
            # å…­åˆå½©ç©æ³•
            'ç‰¹ç ': 'ç‰¹ç ', 'æ­£1ç‰¹': 'æ­£1ç‰¹', 'æ­£ç ç‰¹_æ­£ä¸€ç‰¹': 'æ­£1ç‰¹',
            'æ­£2ç‰¹': 'æ­£2ç‰¹', 'æ­£ç ç‰¹_æ­£äºŒç‰¹': 'æ­£2ç‰¹', 'æ­£3ç‰¹': 'æ­£3ç‰¹',
            'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹', 'æ­£4ç‰¹': 'æ­£4ç‰¹', 'æ­£ç ç‰¹_æ­£å››ç‰¹': 'æ­£4ç‰¹',
            'æ­£5ç‰¹': 'æ­£5ç‰¹', 'æ­£ç ç‰¹_æ­£äº”ç‰¹': 'æ­£5ç‰¹', 'æ­£6ç‰¹': 'æ­£6ç‰¹',
            'æ­£ç ç‰¹_æ­£å…­ç‰¹': 'æ­£6ç‰¹', 'æ­£ç ': 'æ­£ç ', 'æ­£ç‰¹': 'æ­£ç‰¹',
            'å°¾æ•°': 'å°¾æ•°', 'ç‰¹è‚–': 'ç‰¹è‚–', 'å¹³ç‰¹': 'å¹³ç‰¹', 'ä¸€è‚–': 'ä¸€è‚–',
            'è¿è‚–': 'è¿è‚–', 'è¿å°¾': 'è¿å°¾', 'é¾™è™': 'é¾™è™', 'äº”è¡Œ': 'äº”è¡Œ',
            'è‰²æ³¢': 'è‰²æ³¢', 'åŠæ³¢': 'åŠæ³¢',
            
            # 3Dç³»åˆ—ç©æ³•
            'ä¸¤é¢': 'ä¸¤é¢', 'å¤§å°å•åŒ': 'ä¸¤é¢', 'ç™¾ä½': 'ç™¾ä½', 'åä½': 'åä½', 
            'ä¸ªä½': 'ä¸ªä½', 'ç™¾å': 'ç™¾å', 'ç™¾ä¸ª': 'ç™¾ä¸ª', 'åä¸ª': 'åä¸ª',
            'ç™¾åä¸ª': 'ç™¾åä¸ª', 'å®šä½èƒ†': 'å®šä½èƒ†', 'å®šä½èƒ†_ç™¾ä½': 'å®šä½èƒ†_ç™¾ä½',
            'å®šä½èƒ†_åä½': 'å®šä½èƒ†_åä½', 'å®šä½èƒ†_ä¸ªä½': 'å®šä½èƒ†_ä¸ªä½',
            
            # æ—¶æ—¶å½©ç©æ³•
            'æ–—ç‰›': 'æ–—ç‰›', '1-5çƒ': '1-5çƒ', 'ç¬¬1çƒ': 'ç¬¬1çƒ', 'ç¬¬2çƒ': 'ç¬¬2çƒ',
            'ç¬¬3çƒ': 'ç¬¬3çƒ', 'ç¬¬4çƒ': 'ç¬¬4çƒ', 'ç¬¬5çƒ': 'ç¬¬5çƒ', 'æ€»å’Œ': 'æ€»å’Œ',
            'æ­£ç ': 'æ­£ç ', 'å®šä½èƒ†': 'å®šä½èƒ†',
            
            # PKæ‹¾/èµ›è½¦ç©æ³•
            'å‰ä¸€': 'å† å†›', 'å®šä½èƒ†': 'å®šä½èƒ†', '1-5å': '1-5å', '6-10å': '6-10å',
            'å† å†›': 'å† å†›', 'äºšå†›': 'äºšå†›', 'å­£å†›': 'ç¬¬ä¸‰å', 'ç¬¬3å': 'ç¬¬ä¸‰å',
            'ç¬¬4å': 'ç¬¬å››å', 'ç¬¬5å': 'ç¬¬äº”å', 'ç¬¬6å': 'ç¬¬å…­å',
            'ç¬¬7å': 'ç¬¬ä¸ƒå', 'ç¬¬8å': 'ç¬¬å…«å', 'ç¬¬9å': 'ç¬¬ä¹å',
            'ç¬¬10å': 'ç¬¬åå', 'åŒé¢': 'ä¸¤é¢', 'å† äºšå’Œ': 'å† äºšå’Œ'
        }
        return mapping
    
    def normalize_category(self, category):
        """ç»Ÿä¸€ç©æ³•åˆ†ç±»åç§°"""
        category_str = str(category).strip()
        
        # ç›´æ¥æ˜ å°„
        if category_str in self.category_mapping:
            return self.category_mapping[category_str]
        
        # å…³é”®è¯åŒ¹é…
        for key, value in self.category_mapping.items():
            if key in category_str:
                return value
        
        # æ™ºèƒ½åŒ¹é…
        category_lower = category_str.lower()
        
        # PK10/èµ›è½¦æ™ºèƒ½åŒ¹é…
        if any(word in category_lower for word in ['å† å†›', 'ç¬¬ä¸€å', 'ç¬¬1å', '1st']):
            return 'å† å†›'
        elif any(word in category_lower for word in ['äºšå†›', 'ç¬¬äºŒå', 'ç¬¬2å', '2nd']):
            return 'äºšå†›'
        elif any(word in category_lower for word in ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›', '3rd']):
            return 'ç¬¬ä¸‰å'
        elif any(word in category_lower for word in ['ç¬¬å››å', 'ç¬¬4å', '4th']):
            return 'ç¬¬å››å'
        elif any(word in category_lower for word in ['ç¬¬äº”å', 'ç¬¬5å', '5th']):
            return 'ç¬¬äº”å'
        elif any(word in category_lower for word in ['ç¬¬å…­å', 'ç¬¬6å', '6th']):
            return 'ç¬¬å…­å'
        elif any(word in category_lower for word in ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th']):
            return 'ç¬¬ä¸ƒå'
        elif any(word in category_lower for word in ['ç¬¬å…«å', 'ç¬¬8å', '8th']):
            return 'ç¬¬å…«å'
        elif any(word in category_lower for word in ['ç¬¬ä¹å', 'ç¬¬9å', '9th']):
            return 'ç¬¬ä¹å'
        elif any(word in category_lower for word in ['ç¬¬åå', 'ç¬¬10å', '10th']):
            return 'ç¬¬åå'
        
        # 3Dç³»åˆ—æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ç™¾ä½']):
            return 'ç™¾ä½'
        elif any(word in category_lower for word in ['åä½']):
            return 'åä½'
        elif any(word in category_lower for word in ['ä¸ªä½']):
            return 'ä¸ªä½'
        
        # æ—¶æ—¶å½©æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ç¬¬1çƒ', 'ä¸‡ä½']):
            return 'ç¬¬1çƒ'
        elif any(word in category_lower for word in ['ç¬¬2çƒ', 'åƒä½']):
            return 'ç¬¬2çƒ'
        elif any(word in category_lower for word in ['ç¬¬3çƒ', 'ç™¾ä½']):
            return 'ç¬¬3çƒ'
        elif any(word in category_lower for word in ['ç¬¬4çƒ', 'åä½']):
            return 'ç¬¬4çƒ'
        elif any(word in category_lower for word in ['ç¬¬5çƒ', 'ä¸ªä½']):
            return 'ç¬¬5çƒ'
        
        return category_str

# ==================== å†…å®¹è§£æå™¨ - ä¿®å¤ç‰ˆ ====================
class ContentParser:
    @staticmethod
    def enhanced_direction_extraction(content, play_category, lottery_type, config):
        """ğŸ¯ å¢å¼ºç‰ˆæ–¹å‘æå– - å¤„ç†å„ç§æ ¼å¼"""
        try:
            if pd.isna(content) or not content:
                return ""
            
            content_str = str(content).strip()
            play_str = str(play_category).strip() if pd.notna(play_category) else ""
            
            # ğŸ¯ è°ƒè¯•ä¿¡æ¯
            logger.debug(f"æ–¹å‘æå– - å†…å®¹: '{content_str}', ç©æ³•: '{play_str}'")
            
            # æ–¹æ³•1: åŸºç¡€æ–¹å‘è¯æå–
            directions = ContentParser.extract_basic_directions(content_str, config)
            if directions:
                return directions[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–¹å‘
            
            # æ–¹æ³•2: æ•°å­—æ¨æ–­æ–¹å‘ (é’ˆå¯¹å®šä½èƒ†ç­‰)
            number_direction = ContentParser.extract_direction_from_numbers(content_str, play_str, lottery_type)
            if number_direction:
                return number_direction
            
            # æ–¹æ³•3: ç©æ³•å…³é”®è¯æ¨æ–­
            play_direction = ContentParser.extract_direction_from_play(play_str, content_str)
            if play_direction:
                return play_direction
            
            # æ–¹æ³•4: å†…å®¹æ¨¡å¼åŒ¹é…
            pattern_direction = ContentParser.extract_direction_from_patterns(content_str)
            if pattern_direction:
                return pattern_direction
            
            return ""
            
        except Exception as e:
            logger.warning(f"æ–¹å‘æå–å¤±è´¥: {content}, é”™è¯¯: {e}")
            return ""
    
    @staticmethod
    def extract_direction_from_numbers(content, play_category, lottery_type):
        """ä»æ•°å­—å†…å®¹æ¨æ–­æ–¹å‘"""
        try:
            content_str = str(content)
            
            # æå–æ‰€æœ‰æ•°å­—
            numbers = re.findall(r'\d+', content_str)
            numbers = [int(num) for num in numbers if num]
            
            if not numbers:
                return ""
            
            # æ ¹æ®å½©ç§å’Œç©æ³•æ¨æ–­æ–¹å‘
            if lottery_type in ['PK10', '10_number']:
                # PK10: 1-5ä¸ºå°, 6-10ä¸ºå¤§
                if all(1 <= num <= 5 for num in numbers):
                    return 'å°'
                elif all(6 <= num <= 10 for num in numbers):
                    return 'å¤§'
            
            elif lottery_type in ['K3', 'fast_three']:
                # å¿«ä¸‰: å’Œå€¼åˆ¤æ–­
                if len(numbers) == 1:
                    total = numbers[0]
                    if 3 <= total <= 10:
                        return 'å°'
                    elif 11 <= total <= 18:
                        return 'å¤§'
            
            elif lottery_type in ['SSC', '3D']:
                # æ—¶æ—¶å½©/3D: å•ä¸ªæ•°å­—åˆ¤æ–­
                if len(numbers) == 1:
                    num = numbers[0]
                    if num in [0, 2, 4, 6, 8]:
                        return 'åŒ'
                    elif num in [1, 3, 5, 7, 9]:
                        return 'å•'
            
            return ""
        except:
            return ""
    
    @staticmethod
    def extract_direction_from_play(play_category, content):
        """ä»ç©æ³•åˆ†ç±»æ¨æ–­æ–¹å‘"""
        play_str = str(play_category).lower()
        content_str = str(content).lower()
        
        # ä¸¤é¢ç©æ³•
        if 'ä¸¤é¢' in play_str or 'åŒé¢' in play_str:
            if 'å¤§' in content_str:
                return 'å¤§'
            elif 'å°' in content_str:
                return 'å°'
            elif 'å•' in content_str:
                return 'å•'
            elif 'åŒ' in content_str:
                return 'åŒ'
        
        # é¾™è™ç©æ³•
        if 'é¾™è™' in play_str:
            if 'é¾™' in content_str:
                return 'é¾™'
            elif 'è™' in content_str:
                return 'è™'
        
        # å’Œå€¼ç©æ³•
        if 'å’Œå€¼' in play_str:
            if 'å¤§' in content_str:
                return 'å’Œå€¼-å¤§'
            elif 'å°' in content_str:
                return 'å’Œå€¼-å°'
            elif 'å•' in content_str:
                return 'å’Œå€¼-å•'
            elif 'åŒ' in content_str:
                return 'å’Œå€¼-åŒ'
        
        return ""
    
    @staticmethod
    def extract_direction_from_patterns(content):
        """ä»å†…å®¹æ¨¡å¼æ¨æ–­æ–¹å‘"""
        content_lower = str(content).lower()
        
        # å¸¸è§æ–¹å‘æ¨¡å¼
        patterns = {
            'å¤§': ['å¤§', 'da', 'big', 'large', 'd'],
            'å°': ['å°', 'xiao', 'small', 'little', 'x'],
            'å•': ['å•', 'dan', 'odd', 'o'],
            'åŒ': ['åŒ', 'shuang', 'even', 'e', 's'],
            'é¾™': ['é¾™', 'long', 'dragon', 'l'],
            'è™': ['è™', 'hu', 'tiger', 'h']
        }
        
        for direction, keywords in patterns.items():
            for keyword in keywords:
                if keyword in content_lower:
                    return direction
        
        return ""

    @staticmethod
    def extract_position_from_play_category(play_category, lottery_type, config):
        """ä»ç©æ³•åˆ†ç±»ä¸­æå–ä½ç½®ä¿¡æ¯"""
        play_str = str(play_category).strip()
        
        if not play_str:
            return 'æœªçŸ¥ä½ç½®'
        
        # æ ¹æ®å½©ç§ç±»å‹è·å–ä½ç½®å…³é”®è¯
        position_keywords = config.position_keywords.get(lottery_type, {})
        
        for position, keywords in position_keywords.items():
            for keyword in keywords:
                if keyword in play_str:
                    return position
        
        return 'æœªçŸ¥ä½ç½®'

    @staticmethod
    def parse_pk10_vertical_format(content):
        """è§£æPK10ç«–çº¿åˆ†éš”æ ¼å¼"""
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            positions = ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                        'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
            
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    # æ³¨æ„ï¼šè¿™é‡Œè§£ææ•°å­—ï¼Œä½†æˆ‘ä»¬åªå…³å¿ƒæ–¹å‘ï¼Œæ‰€ä»¥è¿™ä¸ªå‡½æ•°ä¸»è¦ç”¨äºä½ç½®æå–
                    numbers = []
                    if ',' in part_clean:
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£æPK10ç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)

    @staticmethod
    def parse_3d_vertical_format(content):
        """è§£æ3Dç«–çº¿åˆ†éš”æ ¼å¼"""
        try:
            content_str = str(content).strip()
            bets_by_position = defaultdict(list)
            
            if not content_str:
                return bets_by_position
            
            positions = ['ç™¾ä½', 'åä½', 'ä¸ªä½']
            
            parts = content_str.split('|')
            
            for i, part in enumerate(parts):
                if i < len(positions):
                    position = positions[i]
                    part_clean = part.strip()
                    
                    if not part_clean or part_clean == '_' or part_clean == '':
                        continue
                    
                    # æ³¨æ„ï¼šè¿™é‡Œè§£ææ•°å­—ï¼Œä½†æˆ‘ä»¬åªå…³å¿ƒæ–¹å‘
                    numbers = []
                    if ',' in part_clean:
                        number_strs = part_clean.split(',')
                        for num_str in number_strs:
                            num_clean = num_str.strip()
                            if num_clean.isdigit():
                                numbers.append(int(num_clean))
                    else:
                        if part_clean.isdigit():
                            numbers.append(int(part_clean))
                    
                    bets_by_position[position].extend(numbers)
            
            return bets_by_position
        except Exception as e:
            logger.warning(f"è§£æ3Dç«–çº¿æ ¼å¼å¤±è´¥: {content}, é”™è¯¯: {str(e)}")
            return defaultdict(list)

# ==================== ä¿®å¤çš„å¯¹åˆ·æ£€æµ‹å™¨ ====================
class WashTradeDetector:
    def __init__(self, config=None):
        self.config = config or Config()
        self.data_processor = DataProcessor()
        self.lottery_identifier = LotteryIdentifier()
        self.play_normalizer = PlayCategoryNormalizer()
        self.content_parser = ContentParser()
        
        self.data_processed = False
        self.df_valid = None
        self.export_data = []
        
        # æŒ‰å½©ç§å­˜å‚¨è´¦æˆ·ç»Ÿè®¡
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        self.performance_stats = {}

        self._cache_clear()
    
    def _cache_clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cached_extract_bet_amount.cache_clear()
        self.cached_extract_direction.cache_clear()
    
    @lru_cache(maxsize=2000)  # ğŸ”„ å¢å¤§ç¼“å­˜å®¹é‡
    def cached_extract_bet_amount(self, amount_text):
        """å¢å¼ºç¼“å­˜é‡‘é¢æå–"""
        return self.extract_bet_amount_safe(amount_text)
    
    @lru_cache(maxsize=1000)  # ğŸ”„ å¢å¤§ç¼“å­˜å®¹é‡
    def cached_extract_direction(self, content, play_category, lottery_type):
        """å¢å¼ºç¼“å­˜æ–¹å‘æå–"""
        return self.enhanced_extract_direction_with_position(content, play_category, lottery_type)
    
    def upload_and_process(self, uploaded_file):
        """ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶"""
        try:
            if uploaded_file is None:
                st.error("âŒ æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
                return None, None
            
            filename = uploaded_file.name
            logger.info(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {filename}")
            
            if not any(filename.endswith(ext) for ext in self.config.supported_file_types):
                st.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
                return None, None
            
            with st.spinner("ğŸ”„ æ­£åœ¨æ¸…æ´—æ•°æ®..."):
                df_clean = self.data_processor.clean_data(uploaded_file)
            
            if df_clean is not None and len(df_clean) > 0:
                # ğŸ†• ç¬¬6ç‚¹ï¼šè°ƒç”¨å¢å¼ºçš„æ•°æ®å¤„ç†ï¼ˆåŒ…å«è¯¦ç»†è°ƒè¯•ä¿¡æ¯ï¼‰
                df_enhanced = self.enhance_data_processing_with_debug(df_clean)
                return df_enhanced, filename
            else:
                return None, None
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            return None, None
    
    # ğŸ†• ç¬¬6ç‚¹ï¼šé‡å‘½åæˆ–æ›¿æ¢åŸæœ‰çš„ enhance_data_processing æ–¹æ³•
    def enhance_data_processing_with_debug(self, df_clean):
        """å¢å¼ºçš„æ•°æ®å¤„ç†æµç¨‹ - åŒ…å«è¯¦ç»†è°ƒè¯•ä¿¡æ¯"""
        try:
            # ğŸ†• è¯¦ç»†è°ƒè¯•ï¼šæ˜¾ç¤ºæ•°æ®æ ·æœ¬
            st.subheader("ğŸ” æ•°æ®æ ·æœ¬åˆ†æ")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("åŸå§‹æ•°æ®æ ·æœ¬:")
                st.dataframe(df_clean[['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹']].head(10))
            
            with col2:
                st.write("å½©ç§ç±»å‹åˆ†å¸ƒ:")
                if 'å½©ç§' in df_clean.columns:
                    lottery_dist = df_clean['å½©ç§'].value_counts()
                    st.dataframe(lottery_dist)
            
            # å½©ç§è¯†åˆ«
            if 'å½©ç§' in df_clean.columns:
                df_clean['åŸå§‹å½©ç§'] = df_clean['å½©ç§']
                df_clean['å½©ç§ç±»å‹'] = df_clean['å½©ç§'].apply(self.lottery_identifier.identify_lottery_type)
                st.info(f"ğŸ² å½©ç§è¯†åˆ«å®Œæˆï¼Œå…±è¯†åˆ« {df_clean['å½©ç§ç±»å‹'].nunique()} ç§å½©ç§ç±»å‹")
            
            # ç©æ³•åˆ†ç±»ç»Ÿä¸€
            if 'ç©æ³•' in df_clean.columns:
                df_clean['ç©æ³•åˆ†ç±»'] = df_clean['ç©æ³•'].apply(self.play_normalizer.normalize_category)
                st.info(f"ğŸ¯ ç©æ³•åˆ†ç±»å®Œæˆï¼Œå…± {df_clean['ç©æ³•åˆ†ç±»'].nunique()} ç§ç©æ³•åˆ†ç±»")
            
            # è®¡ç®—è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
            self.calculate_account_total_periods_by_lottery(df_clean)
            
            # æå–æŠ•æ³¨é‡‘é¢å’Œæ–¹å‘ - ä½¿ç”¨ç¼“å­˜ç‰ˆæœ¬
            st.info("ğŸ’° æ­£åœ¨æå–æŠ•æ³¨é‡‘é¢å’Œæ–¹å‘...")
            progress_bar = st.progress(0)
            total_rows = len(df_clean)
            
            # ğŸ†• è¯¦ç»†è°ƒè¯•ï¼šæ˜¾ç¤ºæå–è¿‡ç¨‹
            sample_extractions = []
            
            # åˆ†æ‰¹å¤„ç†æ˜¾ç¤ºè¿›åº¦
            batch_size = 1000
            for i in range(0, total_rows, batch_size):
                end_idx = min(i + batch_size, total_rows)
                batch_df = df_clean.iloc[i:end_idx]
                
                # å¤„ç†å½“å‰æ‰¹æ¬¡
                df_clean.loc[i:end_idx-1, 'æŠ•æ³¨é‡‘é¢'] = batch_df['é‡‘é¢'].apply(
                    lambda x: self.cached_extract_bet_amount(str(x))
                )
                df_clean.loc[i:end_idx-1, 'æŠ•æ³¨æ–¹å‘'] = batch_df.apply(
                    lambda row: self.enhanced_extract_direction_with_position(
                        row['å†…å®¹'], 
                        row.get('ç©æ³•', ''), 
                        row['å½©ç§ç±»å‹'] if 'å½©ç§ç±»å‹' in df_clean.columns else 'six_mark'
                    ), 
                    axis=1
                )
                
                # ğŸ†• æ”¶é›†æ ·æœ¬æå–ç»“æœç”¨äºè°ƒè¯•
                if i == 0 and len(batch_df) > 0:
                    for idx, row in batch_df.head(5).iterrows():
                        sample_extractions.append({
                            'å†…å®¹': row['å†…å®¹'],
                            'ç©æ³•': row.get('ç©æ³•', ''),
                            'å½©ç§ç±»å‹': row.get('å½©ç§ç±»å‹', 'six_mark'),
                            'æå–é‡‘é¢': self.cached_extract_bet_amount(str(row['é‡‘é¢'])),
                            'æå–æ–¹å‘': self.cached_extract_direction(
                                row['å†…å®¹'], 
                                row.get('ç©æ³•', ''), 
                                row.get('å½©ç§ç±»å‹', 'six_mark')
                            )
                        })
                
                # æ›´æ–°è¿›åº¦
                progress = (end_idx) / total_rows
                progress_bar.progress(progress)
            
            progress_bar.empty()
            
            # ğŸ†• æ˜¾ç¤ºæå–æ ·æœ¬ç»“æœ
            st.subheader("ğŸ” æå–ç»“æœæ ·æœ¬")
            if sample_extractions:
                extraction_df = pd.DataFrame(sample_extractions)
                st.dataframe(extraction_df)
            
            # ğŸ†• è¯¦ç»†è°ƒè¯•ï¼šæ˜¾ç¤ºæå–ç»Ÿè®¡
            st.subheader("ğŸ“Š æå–ç»Ÿè®¡ä¿¡æ¯")
            
            # é‡‘é¢æå–ç»Ÿè®¡
            amount_stats = df_clean['æŠ•æ³¨é‡‘é¢'].describe()
            st.write("é‡‘é¢æå–ç»Ÿè®¡:")
            st.write(f"- æœ€å°å€¼: {amount_stats['min']:.2f}")
            st.write(f"- æœ€å¤§å€¼: {amount_stats['max']:.2f}")
            st.write(f"- å¹³å‡å€¼: {amount_stats['mean']:.2f}")
            st.write(f"- é›¶é‡‘é¢è®°å½•: {len(df_clean[df_clean['æŠ•æ³¨é‡‘é¢'] == 0])}")
            
            # æ–¹å‘æå–ç»Ÿè®¡
            direction_stats = df_clean['æŠ•æ³¨æ–¹å‘'].value_counts()
            st.write("æ–¹å‘æå–ç»Ÿè®¡:")
            if len(direction_stats) > 0:
                st.dataframe(direction_stats.head(10))
            else:
                st.write("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½•æ–¹å‘")
            
            # è¿‡æ»¤æœ‰æ•ˆè®°å½•
            initial_count = len(df_clean)
            
            # ğŸ†• è¯¦ç»†è°ƒè¯•ï¼šæ˜¾ç¤ºè¿‡æ»¤æ¡ä»¶
            st.subheader("ğŸ” è¿‡æ»¤æ¡ä»¶åˆ†æ")
            st.write(f"è¿‡æ»¤æ¡ä»¶:")
            st.write(f"- æœ€å°é‡‘é¢é˜ˆå€¼: {self.config.min_amount}")
            st.write(f"- æ–¹å‘ä¸ä¸ºç©º")
            
            empty_direction_count = len(df_clean[df_clean['æŠ•æ³¨æ–¹å‘'] == ''])
            low_amount_count = len(df_clean[df_clean['æŠ•æ³¨é‡‘é¢'] < self.config.min_amount])
            
            st.write(f"è¿‡æ»¤å‰ç»Ÿè®¡:")
            st.write(f"- æ€»è®°å½•æ•°: {initial_count}")
            st.write(f"- æ–¹å‘ä¸ºç©ºçš„è®°å½•: {empty_direction_count}")
            st.write(f"- é‡‘é¢å°äºé˜ˆå€¼çš„è®°å½•: {low_amount_count}")
            
            df_valid = df_clean[
                (df_clean['æŠ•æ³¨æ–¹å‘'] != '') & 
                (df_clean['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
            ].copy()
            
            st.write(f"è¿‡æ»¤åè®°å½•æ•°: {len(df_valid)}")
            
            if len(df_valid) == 0:
                st.error("âŒ è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆè®°å½•")
                
                # ğŸ†• è¯¦ç»†è¯Šæ–­é—®é¢˜
                st.subheader("ğŸ” é—®é¢˜è¯Šæ–­")
                
                # æ£€æŸ¥é‡‘é¢æå–é—®é¢˜
                if amount_stats['max'] == 0:
                    st.error("âŒ é‡‘é¢æå–å…¨éƒ¨ä¸º0ï¼Œè¯·æ£€æŸ¥é‡‘é¢åˆ—æ ¼å¼")
                    st.write("é‡‘é¢åˆ—æ ·æœ¬:")
                    st.dataframe(df_clean[['é‡‘é¢']].head(10))
                
                # æ£€æŸ¥æ–¹å‘æå–é—®é¢˜
                if empty_direction_count == initial_count:
                    st.error("âŒ æ–¹å‘æå–å…¨éƒ¨ä¸ºç©ºï¼Œè¯·æ£€æŸ¥å†…å®¹å’Œç©æ³•åˆ—")
                    st.write("å†…å®¹å’Œç©æ³•åˆ—æ ·æœ¬:")
                    st.dataframe(df_clean[['å†…å®¹', 'ç©æ³•']].head(10))
                    
                    # æµ‹è¯•æ–¹å‘æå–
                    st.write("æ–¹å‘æå–æµ‹è¯•:")
                    test_samples = []
                    for idx, row in df_clean.head(5).iterrows():
                        test_direction = self.cached_extract_direction(
                            row['å†…å®¹'], 
                            row.get('ç©æ³•', ''), 
                            row.get('å½©ç§ç±»å‹', 'six_mark')
                        )
                        test_samples.append({
                            'å†…å®¹': row['å†…å®¹'],
                            'ç©æ³•': row.get('ç©æ³•', ''),
                            'å½©ç§ç±»å‹': row.get('å½©ç§ç±»å‹', 'six_mark'),
                            'æå–æ–¹å‘': test_direction
                        })
                    st.dataframe(pd.DataFrame(test_samples))
                
                return pd.DataFrame()

            self.data_processed = True
            self.df_valid = df_valid

            st.success(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæœ‰æ•ˆè®°å½•: {len(df_valid)}")
            
            # ğŸ†• æ˜¾ç¤ºæœ‰æ•ˆæ•°æ®ç»Ÿè®¡
            st.subheader("ğŸ“Š æœ‰æ•ˆæ•°æ®ç»Ÿè®¡")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æœ‰æ•ˆè®°å½•æ•°", len(df_valid))
            with col2:
                st.metric("å”¯ä¸€è´¦æˆ·æ•°", df_valid['ä¼šå‘˜è´¦å·'].nunique())
            with col3:
                st.metric("å”¯ä¸€æœŸå·æ•°", df_valid['æœŸå·'].nunique())
            
            # æ˜¾ç¤ºæœ‰æ•ˆæ•°æ®æ ·æœ¬
            with st.expander("ğŸ“‹ æœ‰æ•ˆæ•°æ®æ ·æœ¬", expanded=False):
                st.dataframe(df_valid[['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•', 'å†…å®¹', 'æŠ•æ³¨æ–¹å‘', 'æŠ•æ³¨é‡‘é¢']].head(10))

            return df_valid
                
        except Exception as e:
            st.error(f"âŒ æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            logger.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
            return pd.DataFrame()
    
    def enhance_data_processing(self, df_clean):
        """å¢å¼ºçš„æ•°æ®å¤„ç†æµç¨‹ - æ·»åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯"""
        try:
            # å½©ç§è¯†åˆ«
            if 'å½©ç§' in df_clean.columns:
                df_clean['åŸå§‹å½©ç§'] = df_clean['å½©ç§']
                df_clean['å½©ç§ç±»å‹'] = df_clean['å½©ç§'].apply(self.lottery_identifier.identify_lottery_type)
                st.info(f"ğŸ² å½©ç§è¯†åˆ«å®Œæˆï¼Œå…±è¯†åˆ« {df_clean['å½©ç§ç±»å‹'].nunique()} ç§å½©ç§ç±»å‹")
            
            # ç©æ³•åˆ†ç±»ç»Ÿä¸€
            if 'ç©æ³•' in df_clean.columns:
                df_clean['ç©æ³•åˆ†ç±»'] = df_clean['ç©æ³•'].apply(self.play_normalizer.normalize_category)
                st.info(f"ğŸ¯ ç©æ³•åˆ†ç±»å®Œæˆï¼Œå…± {df_clean['ç©æ³•åˆ†ç±»'].nunique()} ç§ç©æ³•åˆ†ç±»")
            
            # è®¡ç®—è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
            self.calculate_account_total_periods_by_lottery(df_clean)
            
            # ğŸ†• è¯¦ç»†è°ƒè¯•ï¼šæ˜¾ç¤ºæ•°æ®æ ·æœ¬
            st.subheader("ğŸ” æ•°æ®æ ·æœ¬åˆ†æ")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("åŸå§‹æ•°æ®æ ·æœ¬:")
                st.dataframe(df_clean[['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹']].head(10))
            
            with col2:
                st.write("å½©ç§ç±»å‹åˆ†å¸ƒ:")
                lottery_dist = df_clean['å½©ç§ç±»å‹'].value_counts()
                st.dataframe(lottery_dist)
            
            # æå–æŠ•æ³¨é‡‘é¢å’Œæ–¹å‘ - ä½¿ç”¨ç¼“å­˜ç‰ˆæœ¬
            st.info("ğŸ’° æ­£åœ¨æå–æŠ•æ³¨é‡‘é¢å’Œæ–¹å‘...")
            progress_bar = st.progress(0)
            total_rows = len(df_clean)
            
            # ğŸ†• è¯¦ç»†è°ƒè¯•ï¼šæ˜¾ç¤ºæå–è¿‡ç¨‹
            sample_extractions = []
            
            # åˆ†æ‰¹å¤„ç†æ˜¾ç¤ºè¿›åº¦
            batch_size = 1000
            for i in range(0, total_rows, batch_size):
                end_idx = min(i + batch_size, total_rows)
                batch_df = df_clean.iloc[i:end_idx]
                
                # å¤„ç†å½“å‰æ‰¹æ¬¡
                df_clean.loc[i:end_idx-1, 'æŠ•æ³¨é‡‘é¢'] = batch_df['é‡‘é¢'].apply(
                    lambda x: self.cached_extract_bet_amount(str(x))
                )
                df_clean.loc[i:end_idx-1, 'æŠ•æ³¨æ–¹å‘'] = batch_df.apply(
                    lambda row: self.cached_extract_direction(
                        row['å†…å®¹'], 
                        row.get('ç©æ³•', ''), 
                        row['å½©ç§ç±»å‹'] if 'å½©ç§ç±»å‹' in df_clean.columns else 'six_mark'
                    ), 
                    axis=1
                )
                
                # ğŸ†• æ”¶é›†æ ·æœ¬æå–ç»“æœç”¨äºè°ƒè¯•
                if i == 0 and len(batch_df) > 0:
                    for idx, row in batch_df.head(5).iterrows():
                        sample_extractions.append({
                            'å†…å®¹': row['å†…å®¹'],
                            'ç©æ³•': row.get('ç©æ³•', ''),
                            'å½©ç§ç±»å‹': row.get('å½©ç§ç±»å‹', 'six_mark'),
                            'æå–é‡‘é¢': self.cached_extract_bet_amount(str(row['é‡‘é¢'])),
                            'æå–æ–¹å‘': self.cached_extract_direction(
                                row['å†…å®¹'], 
                                row.get('ç©æ³•', ''), 
                                row.get('å½©ç§ç±»å‹', 'six_mark')
                            )
                        })
                
                # æ›´æ–°è¿›åº¦
                progress = (end_idx) / total_rows
                progress_bar.progress(progress)
            
            progress_bar.empty()
            
            # ğŸ†• æ˜¾ç¤ºæå–æ ·æœ¬ç»“æœ
            st.subheader("ğŸ” æå–ç»“æœæ ·æœ¬")
            if sample_extractions:
                extraction_df = pd.DataFrame(sample_extractions)
                st.dataframe(extraction_df)
            
            # ğŸ†• è¯¦ç»†è°ƒè¯•ï¼šæ˜¾ç¤ºæå–ç»Ÿè®¡
            st.subheader("ğŸ“Š æå–ç»Ÿè®¡ä¿¡æ¯")
            
            # é‡‘é¢æå–ç»Ÿè®¡
            amount_stats = df_clean['æŠ•æ³¨é‡‘é¢'].describe()
            st.write("é‡‘é¢æå–ç»Ÿè®¡:")
            st.write(f"- æœ€å°å€¼: {amount_stats['min']:.2f}")
            st.write(f"- æœ€å¤§å€¼: {amount_stats['max']:.2f}")
            st.write(f"- å¹³å‡å€¼: {amount_stats['mean']:.2f}")
            st.write(f"- é›¶é‡‘é¢è®°å½•: {len(df_clean[df_clean['æŠ•æ³¨é‡‘é¢'] == 0])}")
            
            # æ–¹å‘æå–ç»Ÿè®¡
            direction_stats = df_clean['æŠ•æ³¨æ–¹å‘'].value_counts()
            st.write("æ–¹å‘æå–ç»Ÿè®¡:")
            if len(direction_stats) > 0:
                st.dataframe(direction_stats.head(10))
            else:
                st.write("âŒ æ²¡æœ‰æå–åˆ°ä»»ä½•æ–¹å‘")
            
            # è¿‡æ»¤æœ‰æ•ˆè®°å½•
            initial_count = len(df_clean)
            
            # ğŸ†• è¯¦ç»†è°ƒè¯•ï¼šæ˜¾ç¤ºè¿‡æ»¤æ¡ä»¶
            st.subheader("ğŸ” è¿‡æ»¤æ¡ä»¶åˆ†æ")
            st.write(f"è¿‡æ»¤æ¡ä»¶:")
            st.write(f"- æœ€å°é‡‘é¢é˜ˆå€¼: {self.config.min_amount}")
            st.write(f"- æ–¹å‘ä¸ä¸ºç©º")
            
            empty_direction_count = len(df_clean[df_clean['æŠ•æ³¨æ–¹å‘'] == ''])
            low_amount_count = len(df_clean[df_clean['æŠ•æ³¨é‡‘é¢'] < self.config.min_amount])
            
            st.write(f"è¿‡æ»¤å‰ç»Ÿè®¡:")
            st.write(f"- æ€»è®°å½•æ•°: {initial_count}")
            st.write(f"- æ–¹å‘ä¸ºç©ºçš„è®°å½•: {empty_direction_count}")
            st.write(f"- é‡‘é¢å°äºé˜ˆå€¼çš„è®°å½•: {low_amount_count}")
            
            df_valid = df_clean[
                (df_clean['æŠ•æ³¨æ–¹å‘'] != '') & 
                (df_clean['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
            ].copy()
            
            st.write(f"è¿‡æ»¤åè®°å½•æ•°: {len(df_valid)}")
            
            if len(df_valid) == 0:
                st.error("âŒ è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆè®°å½•")
                
                # ğŸ†• è¯¦ç»†è¯Šæ–­é—®é¢˜
                st.subheader("ğŸ” é—®é¢˜è¯Šæ–­")
                
                # æ£€æŸ¥é‡‘é¢æå–é—®é¢˜
                if amount_stats['max'] == 0:
                    st.error("âŒ é‡‘é¢æå–å…¨éƒ¨ä¸º0ï¼Œè¯·æ£€æŸ¥é‡‘é¢åˆ—æ ¼å¼")
                    st.write("é‡‘é¢åˆ—æ ·æœ¬:")
                    st.dataframe(df_clean[['é‡‘é¢']].head(10))
                
                # æ£€æŸ¥æ–¹å‘æå–é—®é¢˜
                if empty_direction_count == initial_count:
                    st.error("âŒ æ–¹å‘æå–å…¨éƒ¨ä¸ºç©ºï¼Œè¯·æ£€æŸ¥å†…å®¹å’Œç©æ³•åˆ—")
                    st.write("å†…å®¹å’Œç©æ³•åˆ—æ ·æœ¬:")
                    st.dataframe(df_clean[['å†…å®¹', 'ç©æ³•']].head(10))
                    
                    # æµ‹è¯•æ–¹å‘æå–
                    st.write("æ–¹å‘æå–æµ‹è¯•:")
                    test_samples = []
                    for idx, row in df_clean.head(5).iterrows():
                        test_direction = self.cached_extract_direction(
                            row['å†…å®¹'], 
                            row.get('ç©æ³•', ''), 
                            row.get('å½©ç§ç±»å‹', 'six_mark')
                        )
                        test_samples.append({
                            'å†…å®¹': row['å†…å®¹'],
                            'ç©æ³•': row.get('ç©æ³•', ''),
                            'å½©ç§ç±»å‹': row.get('å½©ç§ç±»å‹', 'six_mark'),
                            'æå–æ–¹å‘': test_direction
                        })
                    st.dataframe(pd.DataFrame(test_samples))
                
                return pd.DataFrame()
    
            self.data_processed = True
            self.df_valid = df_valid
    
            st.success(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæœ‰æ•ˆè®°å½•: {len(df_valid)}")
            
            # ğŸ†• æ˜¾ç¤ºæœ‰æ•ˆæ•°æ®ç»Ÿè®¡
            st.subheader("ğŸ“Š æœ‰æ•ˆæ•°æ®ç»Ÿè®¡")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æœ‰æ•ˆè®°å½•æ•°", len(df_valid))
            with col2:
                st.metric("å”¯ä¸€è´¦æˆ·æ•°", df_valid['ä¼šå‘˜è´¦å·'].nunique())
            with col3:
                st.metric("å”¯ä¸€æœŸå·æ•°", df_valid['æœŸå·'].nunique())
            
            # æ˜¾ç¤ºæœ‰æ•ˆæ•°æ®æ ·æœ¬
            with st.expander("ğŸ“‹ æœ‰æ•ˆæ•°æ®æ ·æœ¬", expanded=False):
                st.dataframe(df_valid[['ä¼šå‘˜è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•', 'å†…å®¹', 'æŠ•æ³¨æ–¹å‘', 'æŠ•æ³¨é‡‘é¢']].head(10))
    
            return df_valid
                
        except Exception as e:
            st.error(f"âŒ æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            logger.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
            return pd.DataFrame()
    
    def extract_bet_amount_safe(self, amount_text):
        """å®‰å…¨æå–æŠ•æ³¨é‡‘é¢ - å¢å¼ºç‰ˆå¤„ç†å„ç§æ ¼å¼"""
        try:
            if pd.isna(amount_text):
                return 0
            
            text = str(amount_text).strip()
            
            # ğŸ†• è°ƒè¯•æ—¥å¿—
            logger.debug(f"é‡‘é¢æå–è¾“å…¥: '{text}'")
            
            # å¤„ç†ç©ºå­—ç¬¦ä¸²
            if text == '':
                return 0
            
            # æ–¹æ³•1: ç›´æ¥è½¬æ¢ï¼ˆå¤„ç†çº¯æ•°å­—ï¼‰
            try:
                # ç§»é™¤æ‰€æœ‰éæ•°å­—å­—ç¬¦ï¼ˆé™¤äº†ç‚¹å’Œè´Ÿå·ï¼‰
                cleaned_text = re.sub(r'[^\d.-]', '', text)
                if cleaned_text and cleaned_text != '-' and cleaned_text != '.':
                    amount = float(cleaned_text)
                    if amount >= self.config.min_amount:
                        logger.debug(f"ç›´æ¥è½¬æ¢æˆåŠŸ: {text} -> {amount}")
                        return amount
            except Exception as e:
                logger.debug(f"ç›´æ¥è½¬æ¢å¤±è´¥: {text}, é”™è¯¯: {e}")
                pass
            
            # æ–¹æ³•2: å¤„ç†åƒä½åˆ†éš”ç¬¦æ ¼å¼
            try:
                # ç§»é™¤é€—å·å’Œå…¨è§’é€—å·ï¼Œç„¶åè½¬æ¢
                cleaned_text = text.replace(',', '').replace('ï¼Œ', '')
                amount = float(cleaned_text)
                if amount >= self.config.min_amount:
                    logger.debug(f"åƒä½åˆ†éš”ç¬¦è½¬æ¢æˆåŠŸ: {text} -> {amount}")
                    return amount
            except Exception as e:
                logger.debug(f"åƒä½åˆ†éš”ç¬¦è½¬æ¢å¤±è´¥: {text}, é”™è¯¯: {e}")
                pass
            
            # æ–¹æ³•3: å¤„ç†ç§‘å­¦è®¡æ•°æ³•
            if 'E' in text or 'e' in text:
                try:
                    amount = float(text)
                    if amount >= self.config.min_amount:
                        logger.debug(f"ç§‘å­¦è®¡æ•°æ³•è½¬æ¢æˆåŠŸ: {text} -> {amount}")
                        return amount
                except:
                    pass
            
            # æ–¹æ³•4: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å„ç§æ ¼å¼
            patterns = [
                r'æŠ•æ³¨\s*[:ï¼š]?\s*([\d,.]+)',
                r'é‡‘é¢\s*[:ï¼š]?\s*([\d,.]+)',
                r'ä¸‹æ³¨é‡‘é¢\s*([\d,.]+)',
                r'([\d,.]+)\s*å…ƒ',
                r'ï¿¥\s*([\d,.]+)',
                r'Â¥\s*([\d,.]+)',
                r'([\d,.]+)\s*RMB',
                r'([\d,.]+)$'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    amount_str = match.group(1).replace(',', '').replace('ï¼Œ', '')
                    try:
                        amount = float(amount_str)
                        if amount >= self.config.min_amount:
                            logger.debug(f"æ­£åˆ™åŒ¹é…æˆåŠŸ: {text} -> {amount}")
                            return amount
                    except:
                        continue
            
            logger.debug(f"æ‰€æœ‰æå–æ–¹æ³•å¤±è´¥: {text}")
            return 0
                
        except Exception as e:
            logger.warning(f"é‡‘é¢æå–å¤±è´¥: {amount_text}, é”™è¯¯: {str(e)}")
            return 0
    
    def enhanced_extract_direction_with_position(self, content, play_category, lottery_type):
        """ğŸ¯ æœ€ç»ˆä¿®å¤ç‰ˆæ–¹å‘æå–"""
        try:
            if pd.isna(content) or not content:
                return ""
            
            # ä½¿ç”¨å¢å¼ºçš„æ–¹å‘æå–
            direction = self.content_parser.enhanced_direction_extraction(
                content, play_category, lottery_type, self.config
            )
            
            # å¦‚æœè¿˜æ˜¯ç©ºï¼Œå°è¯•æœ€åçš„æ‰‹æ®µ
            if not direction:
                direction = self._last_resort_direction_extraction(content, play_category)
            
            return direction
            
        except Exception as e:
            logger.warning(f"æ–¹å‘æå–å¤±è´¥: {content}, é”™è¯¯: {e}")
            return ""
    
    def _last_resort_direction_extraction(self, content, play_category):
        """æœ€åçš„æ‰‹æ®µï¼šåŸºäºå†…å®¹å’Œç©æ³•çš„å¯å‘å¼æå–"""
        content_str = str(content).lower()
        play_str = str(play_category).lower()
        
        # æ£€æŸ¥å†…å®¹ä¸­çš„å…³é”®è¯
        direction_keywords = {
            'å¤§': ['å¤§', 'da', 'big'],
            'å°': ['å°', 'xiao', 'small'], 
            'å•': ['å•', 'dan', 'odd'],
            'åŒ': ['åŒ', 'shuang', 'even'],
            'é¾™': ['é¾™', 'long', 'dragon'],
            'è™': ['è™', 'hu', 'tiger']
        }
        
        for direction, keywords in direction_keywords.items():
            for keyword in keywords:
                if keyword in content_str:
                    return direction
        
        # æ£€æŸ¥ç©æ³•ä¸­çš„æ–¹å‘æç¤º
        if 'å¤§' in play_str:
            return 'å¤§'
        elif 'å°' in play_str:
            return 'å°'
        elif 'å•' in play_str:
            return 'å•'
        elif 'åŒ' in play_str:
            return 'åŒ'
        elif 'é¾™' in play_str:
            return 'é¾™'
        elif 'è™' in play_str:
            return 'è™'
        
        return ""
    
    def _extract_direction_for_dingweidan(self, content, play_category, lottery_type):
        """å¤„ç†å®šä½èƒ†ç©æ³•çš„æ–¹å‘æå–"""
        content_lower = content.lower()
        
        # ğŸ†• ä¿®å¤ï¼šä»å†…å®¹ä¸­æå–ä½ç½®ä¿¡æ¯
        position_keywords = {
            'å† å†›': ['å† å†›', 'ç¬¬1å', 'ç¬¬ä¸€å', '1st', 'å‰ä¸€'],
            'äºšå†›': ['äºšå†›', 'ç¬¬2å', 'ç¬¬äºŒå', '2nd'],
            'å­£å†›': ['å­£å†›', 'ç¬¬3å', 'ç¬¬ä¸‰å', '3rd'],
            'ç¬¬å››å': ['ç¬¬å››å', 'ç¬¬4å', '4th'],
            'ç¬¬äº”å': ['ç¬¬äº”å', 'ç¬¬5å', '5th'],
            'ç¬¬å…­å': ['ç¬¬å…­å', 'ç¬¬6å', '6th'],
            'ç¬¬ä¸ƒå': ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th'],
            'ç¬¬å…«å': ['ç¬¬å…«å', 'ç¬¬8å', '8th'],
            'ç¬¬ä¹å': ['ç¬¬ä¹å', 'ç¬¬9å', '9th'],
            'ç¬¬åå': ['ç¬¬åå', 'ç¬¬10å', '10th'],
        }
        
        # æŸ¥æ‰¾ä½ç½®
        detected_position = None
        for position, keywords in position_keywords.items():
            for keyword in keywords:
                if keyword in content_lower:
                    detected_position = position
                    break
            if detected_position:
                break
        
        # ğŸ†• ä¿®å¤ï¼šä»å·ç æ¨æ–­æ–¹å‘ï¼ˆé’ˆå¯¹PK10/èµ›è½¦ï¼‰
        if detected_position and lottery_type in ['PK10', '10_number']:
            # æå–å·ç 
            numbers = self._extract_numbers_from_content(content)
            if numbers:
                # æ ¹æ®å·ç æ¨æ–­æ–¹å‘ï¼ˆå°:1-5, å¤§:6-10ï¼‰
                if all(1 <= num <= 5 for num in numbers):
                    direction = 'å°'
                elif all(6 <= num <= 10 for num in numbers):
                    direction = 'å¤§'
                else:
                    # æ··åˆå·ç ï¼Œæ— æ³•ç¡®å®šæ–¹å‘
                    direction = 'æœªçŸ¥'
                
                if direction != 'æœªçŸ¥':
                    return f"{detected_position}-{direction}"
        
        return detected_position if detected_position else ""
    
    def _extract_direction_for_liangmian(self, content, play_category, lottery_type):
        """å¤„ç†ä¸¤é¢ç©æ³•çš„æ–¹å‘æå–"""
        content_lower = content.lower()
        
        # ç›´æ¥æå–æ–¹å‘è¯
        direction_keywords = {
            'å¤§': ['å¤§', 'da', 'big'],
            'å°': ['å°', 'xiao', 'small'], 
            'å•': ['å•', 'dan', 'odd'],
            'åŒ': ['åŒ', 'shuang', 'even']
        }
        
        for direction, keywords in direction_keywords.items():
            for keyword in keywords:
                if keyword in content_lower:
                    return direction
        
        return ""
    
    def _extract_direction_for_hezhi(self, content, play_category, lottery_type):
        """å¤„ç†å’Œå€¼ç©æ³•çš„æ–¹å‘æå–"""
        content_lower = content.lower()
        
        # å¿«ä¸‰å’Œå€¼æ–¹å‘
        if lottery_type in ['K3', 'fast_three']:
            direction_keywords = {
                'å¤§': ['å¤§', 'da', 'big'],
                'å°': ['å°', 'xiao', 'small'],
                'å•': ['å•', 'dan', 'odd'],
                'åŒ': ['åŒ', 'shuang', 'even']
            }
            
            for direction, keywords in direction_keywords.items():
                for keyword in keywords:
                    if keyword in content_lower:
                        return f"å’Œå€¼-{direction}"
        
        return "å’Œå€¼"
    
    def _extract_direction_for_longhu(self, content, play_category, lottery_type):
        """å¤„ç†é¾™è™ç©æ³•çš„æ–¹å‘æå–"""
        content_lower = content.lower()
        
        direction_keywords = {
            'é¾™': ['é¾™', 'long', 'dragon'],
            'è™': ['è™', 'hu', 'tiger']
        }
        
        for direction, keywords in direction_keywords.items():
            for keyword in keywords:
                if keyword in content_lower:
                    return direction
        
        return ""
    
    def _extract_direction_generic(self, content, play_category, lottery_type):
        """é€šç”¨æ–¹å‘æå–æ–¹æ³•"""
        content_lower = content.lower()
        
        # å°è¯•æå–æ‰€æœ‰å¯èƒ½çš„æ–¹å‘
        all_directions = []
        
        # æ£€æŸ¥åŸºç¡€æ–¹å‘
        base_directions = ['å¤§', 'å°', 'å•', 'åŒ', 'é¾™', 'è™', 'è´¨', 'åˆ']
        for direction in base_directions:
            if direction in content_lower:
                all_directions.append(direction)
        
        # æ£€æŸ¥ç‰¹æ®Šæ–¹å‘
        special_directions = {
            'ç‰¹å¤§': ['ç‰¹å¤§', 'æå¤§'],
            'ç‰¹å°': ['ç‰¹å°', 'æå°'], 
            'ç‰¹å•': ['ç‰¹å•'],
            'ç‰¹åŒ': ['ç‰¹åŒ']
        }
        
        for direction, keywords in special_directions.items():
            for keyword in keywords:
                if keyword in content_lower:
                    all_directions.append(direction)
        
        if all_directions:
            return all_directions[0]  # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–¹å‘
        
        return ""
    
    def _extract_numbers_from_content(self, content):
        """ä»å†…å®¹ä¸­æå–å·ç """
        try:
            content_str = str(content)
            numbers = []
            
            # æå–æ‰€æœ‰1-2ä½æ•°å­—
            number_matches = re.findall(r'\b\d{1,2}\b', content_str)
            for match in number_matches:
                num = int(match)
                if 1 <= num <= 49:  # å¸¸è§å½©ç¥¨å·ç èŒƒå›´
                    numbers.append(num)
            
            return numbers
        except:
            return []
    
    def _extract_position_from_content(self, content, lottery_type):
        """ä»å†…å®¹ä¸­æå–ä½ç½®ä¿¡æ¯"""
        content_str = str(content).strip()
        
        # æ ¹æ®å½©ç§ç±»å‹è·å–ä½ç½®å…³é”®è¯
        position_keywords = self.config.position_keywords.get(lottery_type, {})
        
        for position, keywords in position_keywords.items():
            for keyword in keywords:
                if keyword in content_str:
                    return position
        
        # ç‰¹æ®Šå¤„ç†ç«–çº¿æ ¼å¼
        if '|' in content_str:
            if lottery_type == 'PK10':
                bets_by_position = self.content_parser.parse_pk10_vertical_format(content_str)
                for position in bets_by_position:
                    if bets_by_position[position]:
                        return position
            elif lottery_type == '3D':
                bets_by_position = self.content_parser.parse_3d_vertical_format(content_str)
                for position in bets_by_position:
                    if bets_by_position[position]:
                        return position
        
        return 'æœªçŸ¥ä½ç½®'
    
    def calculate_account_total_periods_by_lottery(self, df):
        """æŒ‰å½©ç§è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°ç»Ÿè®¡"""
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        
        lottery_col = 'åŸå§‹å½©ç§' if 'åŸå§‹å½©ç§' in df.columns else 'å½©ç§'
        
        for lottery in df[lottery_col].unique():
            df_lottery = df[df[lottery_col] == lottery]
            
            period_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·')['æœŸå·'].nunique().to_dict()
            self.account_total_periods_by_lottery[lottery] = period_counts
            
            record_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·').size().to_dict()
            self.account_record_stats_by_lottery[lottery] = record_counts
    
    def detect_all_wash_trades(self):
        """æ£€æµ‹æ‰€æœ‰ç±»å‹çš„å¯¹åˆ·äº¤æ˜“"""
        if not self.data_processed or self.df_valid is None or len(self.df_valid) == 0:
            st.error("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ç”¨äºæ£€æµ‹")
            return []
        
        self.performance_stats = {
            'start_time': datetime.now(),
            'total_records': len(self.df_valid),
            'total_periods': self.df_valid['æœŸå·'].nunique(),
            'total_accounts': self.df_valid['ä¼šå‘˜è´¦å·'].nunique()
        }
        
        df_filtered = self.exclude_multi_direction_accounts(self.df_valid)
        
        if len(df_filtered) == 0:
            st.error("âŒ è¿‡æ»¤åæ— æœ‰æ•ˆæ•°æ®")
            return []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_patterns = []
        total_steps = self.config.max_accounts_in_group - 1
        
        for account_count in range(2, self.config.max_accounts_in_group + 1):
            status_text.text(f"ğŸ” æ£€æµ‹{account_count}ä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼...")
            patterns = self.detect_n_account_patterns_optimized(df_filtered, account_count)
            all_patterns.extend(patterns)
            
            progress = (account_count - 1) / total_steps
            progress_bar.progress(progress)
        
        progress_bar.progress(1.0)
        status_text.text("âœ… æ£€æµ‹å®Œæˆ")
        
        self.performance_stats['end_time'] = datetime.now()
        self.performance_stats['detection_time'] = (
            self.performance_stats['end_time'] - self.performance_stats['start_time']
        ).total_seconds()
        self.performance_stats['total_patterns'] = len(all_patterns)
        
        self.display_performance_stats()
        
        return all_patterns
    
    def detect_n_account_patterns_optimized(self, df_filtered, n_accounts):
        """ä¼˜åŒ–ç‰ˆçš„Nä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼æ£€æµ‹"""
        wash_records = []
        
        period_groups = df_filtered.groupby(['æœŸå·', 'åŸå§‹å½©ç§'])
        
        valid_direction_combinations = self._get_valid_direction_combinations(n_accounts)
        
        batch_size = 100
        period_keys = list(period_groups.groups.keys())
        
        for i in range(0, len(period_keys), batch_size):
            batch_keys = period_keys[i:i+batch_size]
            
            for period_key in batch_keys:
                period_data = period_groups.get_group(period_key)
                period_accounts = period_data['ä¼šå‘˜è´¦å·'].unique()
                
                if len(period_accounts) < n_accounts:
                    continue
                
                batch_patterns = self._detect_combinations_for_period(
                    period_data, period_accounts, n_accounts, valid_direction_combinations
                )
                wash_records.extend(batch_patterns)
        
        return self.find_continuous_patterns_optimized(wash_records)
    
    def _get_valid_direction_combinations(self, n_accounts):
        """ğŸ¯ å®Œå–„ç‰ˆæœ‰æ•ˆæ–¹å‘ç»„åˆç”Ÿæˆ - ä¸“æ³¨äºæ ¸å¿ƒå¯¹ç«‹æ–¹å‘"""
        valid_combinations = []
        
        # ğŸ¯ åªä¸“æ³¨äº2ä¸ªè´¦æˆ·çš„å¯¹ç«‹æ£€æµ‹
        if n_accounts == 2:
            for opposites in self.config.opposite_groups:
                if len(opposites) == 2:  # ç¡®ä¿åªæœ‰ä¸¤ä¸ªå¯¹ç«‹æ–¹å‘
                    dir1, dir2 = list(opposites)
                    valid_combinations.append({
                        'directions': [dir1, dir2],
                        'dir1_count': 1,
                        'dir2_count': 1,
                        'opposite_type': f"{dir1}-{dir2}"
                    })
            
            # ğŸ¯ å®Œå–„ï¼šå¸¦ä½ç½®çš„å¯¹ç«‹ç»„åˆ
            positions = ['å† å†›', 'äºšå†›', 'å­£å†›', 'ç¬¬å››å', 'ç¬¬äº”å', 'ç¬¬å…­å', 
                        'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå',
                        'ç™¾ä½', 'åä½', 'ä¸ªä½', 'ç¬¬1çƒ', 'ç¬¬2çƒ', 'ç¬¬3çƒ', 'ç¬¬4çƒ', 'ç¬¬5çƒ']
            
            for position in positions:
                for opposites in self.config.opposite_groups:
                    if len(opposites) == 2:
                        dir1, dir2 = list(opposites)
                        valid_combinations.append({
                            'directions': [f"{position}-{dir1}", f"{position}-{dir2}"],
                            'dir1_count': 1,
                            'dir2_count': 1,
                            'opposite_type': f"{position}-{dir1} vs {position}-{dir2}"
                        })
        
        return valid_combinations

    def _identify_opposite_type(self, direction1, direction2):
        """ğŸ¯ æ–°å¢ï¼šæ™ºèƒ½è¯†åˆ«å¯¹ç«‹ç±»å‹ - å®Œå–„ç‰ˆ"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯åŸºç¡€å¯¹ç«‹
        for opposites in self.config.opposite_groups:
            if direction1 in opposites and direction2 in opposites:
                return f"{direction1}-{direction2}"
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¦ä½ç½®çš„å¯¹ç«‹
        if '-' in direction1 and '-' in direction2:
            try:
                pos1, dir1 = direction1.split('-', 1)
                pos2, dir2 = direction2.split('-', 1)
                
                if pos1 == pos2:  # åŒä¸€ä½ç½®
                    for opposites in self.config.opposite_groups:
                        if dir1 in opposites and dir2 in opposites:
                            return f"{pos1}-{dir1} vs {pos2}-{dir2}"
            except ValueError:
                pass
        
        # æ™ºèƒ½è¯†åˆ«ç›¸ä¼¼å¯¹ç«‹
        direction_pairs = [
            ('å¤§', 'å°'), ('å•', 'åŒ'), ('é¾™', 'è™'), ('è´¨', 'åˆ'),
            ('å®¶', 'é‡'), ('ç‰¹å¤§', 'ç‰¹å°'), ('ç‰¹å•', 'ç‰¹åŒ'), 
            ('æ€»å’Œå¤§', 'æ€»å’Œå°'), ('æ€»å’Œå•', 'æ€»å’ŒåŒ'),
            ('ä¸‰å†›å¤§', 'ä¸‰å†›å°'), ('ä¸‰å†›å•', 'ä¸‰å†›åŒ')
        ]
        
        for pair1, pair2 in direction_pairs:
            if (direction1 == pair1 and direction2 == pair2) or (direction1 == pair2 and direction2 == pair1):
                return f"{pair1}-{pair2}"
        
        # å¦‚æœéƒ½ä¸æ˜¯å·²çŸ¥å¯¹ç«‹ï¼Œè¿”å›åŸºç¡€æ ¼å¼
        return f"{direction1}-{direction2}"
    
    def _detect_combinations_for_period(self, period_data, period_accounts, n_accounts, valid_combinations):
        """ä¸ºå•ä¸ªæœŸå·æ£€æµ‹ç»„åˆ - å®Œå–„ç‰ˆ"""
        patterns = []
        
        # è·å–å½“å‰å½©ç§
        lottery = period_data['åŸå§‹å½©ç§'].iloc[0] if 'åŸå§‹å½©ç§' in period_data.columns else period_data['å½©ç§'].iloc[0]
        
        # ğŸ¯ æ„å»ºè´¦æˆ·ä¿¡æ¯å­—å…¸
        account_info = {}
        for _, row in period_data.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            direction = row['æŠ•æ³¨æ–¹å‘']
            amount = row['æŠ•æ³¨é‡‘é¢']
            
            if account not in account_info:
                account_info[account] = []
            account_info[account].append({
                'direction': direction,
                'amount': amount
            })
        
        # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„è´¦æˆ·ç»„åˆ
        for account_group in combinations(period_accounts, n_accounts):
            # æ£€æŸ¥è´¦æˆ·æœŸæ•°å·®å¼‚
            if not self._check_account_period_difference(account_group, lottery):
                continue
            
            group_directions = []
            group_amounts = []
            
            for account in account_group:
                if account in account_info and account_info[account]:
                    first_bet = account_info[account][0]
                    group_directions.append(first_bet['direction'])
                    group_amounts.append(first_bet['amount'])
            
            if len(group_directions) != n_accounts:
                continue
            
            # ğŸ¯ æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æœ‰æ•ˆçš„æ–¹å‘ç»„åˆ
            matched_combo = None
            for combo in valid_combinations:
                target_directions = combo['directions']
                
                actual_directions_sorted = sorted(group_directions)
                target_directions_sorted = sorted(target_directions)
                
                if actual_directions_sorted == target_directions_sorted:
                    matched_combo = combo
                    break
            
            # ğŸ¯ æ–°å¢ï¼šå¦‚æœæ²¡æœ‰åŒ¹é…é¢„å®šä¹‰ç»„åˆï¼Œå°è¯•æ™ºèƒ½è¯†åˆ«
            if not matched_combo and n_accounts == 2:
                # å°è¯•æ™ºèƒ½è¯†åˆ«å¯¹ç«‹ç±»å‹
                dir1, dir2 = group_directions
                opposite_type = self._identify_opposite_type(dir1, dir2)
                
                # å¦‚æœè¯†åˆ«å‡ºæœ‰æ•ˆçš„å¯¹ç«‹ç±»å‹
                if '-' in opposite_type and 'vs' not in opposite_type:  # åŸºç¡€å¯¹ç«‹æ ¼å¼
                    matched_combo = {
                        'directions': [dir1, dir2],
                        'dir1_count': 1,
                        'dir2_count': 1,
                        'opposite_type': opposite_type
                    }
            
            if matched_combo:
                # è®¡ç®—ä¸¤ä¸ªæ–¹å‘çš„æ€»é‡‘é¢
                dir1_total = 0
                dir2_total = 0
                dir1 = matched_combo['directions'][0]  # å–ç¬¬ä¸€ä¸ªæ–¹å‘ä½œä¸ºå‚è€ƒ
                
                for direction, amount in zip(group_directions, group_amounts):
                    if direction == dir1:
                        dir1_total += amount
                    else:
                        dir2_total += amount
                
                # æ£€æŸ¥é‡‘é¢ç›¸ä¼¼åº¦
                similarity_threshold = self.config.account_count_similarity_thresholds.get(
                    n_accounts, self.config.amount_similarity_threshold
                )
                
                if dir1_total > 0 and dir2_total > 0:
                    similarity = min(dir1_total, dir2_total) / max(dir1_total, dir2_total)
                    
                    if similarity >= similarity_threshold:
                        lottery_type = period_data['å½©ç§ç±»å‹'].iloc[0] if 'å½©ç§ç±»å‹' in period_data.columns else 'æœªçŸ¥'
                        
                        # ğŸ¯ ä½¿ç”¨æ™ºèƒ½è¯†åˆ«çš„å¯¹ç«‹ç±»å‹
                        pattern_str = self._format_pattern_string(matched_combo['opposite_type'], matched_combo['dir1_count'], matched_combo['dir2_count'])
                        
                        record = {
                            'æœŸå·': period_data['æœŸå·'].iloc[0],
                            'å½©ç§': lottery,
                            'å½©ç§ç±»å‹': lottery_type,
                            'è´¦æˆ·ç»„': list(account_group),
                            'æ–¹å‘ç»„': group_directions,
                            'é‡‘é¢ç»„': group_amounts,
                            'æ€»é‡‘é¢': dir1_total + dir2_total,
                            'ç›¸ä¼¼åº¦': similarity,
                            'è´¦æˆ·æ•°é‡': n_accounts,
                            'æ¨¡å¼': pattern_str,
                            'å¯¹ç«‹ç±»å‹': matched_combo['opposite_type']
                        }
                        
                        patterns.append(record)
        
        return patterns
    
    def _format_pattern_string(self, opposite_type, dir1_count, dir2_count):
        """æ ¼å¼åŒ–æ¨¡å¼å­—ç¬¦ä¸²"""
        if ' vs ' in opposite_type:
            # å¸¦ä½ç½®çš„å¯¹ç«‹ç±»å‹ï¼Œå¦‚ "ç¬¬3çƒ-å° vs ç¬¬3çƒ-å¤§"
            pattern_parts = opposite_type.split(' vs ')
            if len(pattern_parts) == 2:
                dir1_part = pattern_parts[0].split('-')
                dir2_part = pattern_parts[1].split('-')
                if len(dir1_part) == 2 and len(dir2_part) == 2:
                    # æ ¼å¼ï¼šä½ç½®-æ–¹å‘(æ•°é‡ä¸ª) vs ä½ç½®-æ–¹å‘(æ•°é‡ä¸ª)
                    return f"{dir1_part[0]}-{dir1_part[1]}({dir1_count}ä¸ª) vs {dir2_part[0]}-{dir2_part[1]}({dir2_count}ä¸ª)"
                else:
                    return f"{pattern_parts[0]}({dir1_count}ä¸ª) vs {pattern_parts[1]}({dir2_count}ä¸ª)"
            else:
                return opposite_type
        else:
            # åŸºç¡€å¯¹ç«‹ç±»å‹ï¼Œå¦‚ "å¤§-å°"
            opposite_parts = opposite_type.split('-')
            if len(opposite_parts) == 2:
                return f"{opposite_parts[0]}({dir1_count}ä¸ª) vs {opposite_parts[1]}({dir2_count}ä¸ª)"
            else:
                return opposite_type
    
    def _check_account_period_difference(self, account_group, lottery):
        """æ£€æŸ¥è´¦æˆ·ç»„å†…è´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°å·®å¼‚æ˜¯å¦åœ¨é˜ˆå€¼å†…"""
        if lottery not in self.account_total_periods_by_lottery:
            return True  # å¦‚æœæ²¡æœ‰è¯¥å½©ç§çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œé»˜è®¤å…è®¸ç»„åˆ
        
        total_periods_stats = self.account_total_periods_by_lottery[lottery]
        
        # è·å–è´¦æˆ·ç»„å†…æ¯ä¸ªè´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°
        account_periods = []
        for account in account_group:
            if account in total_periods_stats:
                account_periods.append(total_periods_stats[account])
            else:
                # å¦‚æœæŸä¸ªè´¦æˆ·æ²¡æœ‰ç»Ÿè®¡ä¿¡æ¯ï¼Œæ— æ³•æ¯”è¾ƒï¼Œé»˜è®¤å…è®¸ç»„åˆ
                return True
        
        # å¦‚æœåªæœ‰ä¸€ä¸ªè´¦æˆ·æœ‰æœŸæ•°ä¿¡æ¯ï¼Œæ— æ³•æ¯”è¾ƒï¼Œé»˜è®¤å…è®¸ç»„åˆ
        if len(account_periods) < 2:
            return True
        
        # è®¡ç®—æœ€å¤§å’Œæœ€å°æœŸæ•°å·®å¼‚
        max_period = max(account_periods)
        min_period = min(account_periods)
        period_diff = max_period - min_period
        
        # å¦‚æœæœŸæ•°å·®å¼‚è¶…è¿‡é˜ˆå€¼ï¼Œä¸å…è®¸ç»„åˆ
        if period_diff > self.config.account_period_diff_threshold:
            logger.info(f"è·³è¿‡è´¦æˆ·ç»„ {account_group}ï¼ŒæœŸæ•°å·®å¼‚ {period_diff} > {self.config.account_period_diff_threshold}")
            return False
        
        return True
    
    def find_continuous_patterns_optimized(self, wash_records):
        """ä¼˜åŒ–ç‰ˆçš„è¿ç»­å¯¹åˆ·æ¨¡å¼æ£€æµ‹"""
        if not wash_records:
            return []
        
        account_group_patterns = defaultdict(list)
        for record in wash_records:
            account_group_key = (tuple(sorted(record['è´¦æˆ·ç»„'])), record['å½©ç§'])
            account_group_patterns[account_group_key].append(record)
        
        continuous_patterns = []
        
        for (account_group, lottery), records in account_group_patterns.items():
            sorted_records = sorted(records, key=lambda x: x['æœŸå·'])
            
            # æ ¹æ®æ–°çš„é˜ˆå€¼è¦æ±‚ç¡®å®šæœ€å°å¯¹åˆ·æœŸæ•°
            required_min_periods = self.get_required_min_periods(account_group, lottery)
            
            if len(sorted_records) >= required_min_periods:
                total_investment = sum(r['æ€»é‡‘é¢'] for r in sorted_records)
                similarities = [r['ç›¸ä¼¼åº¦'] for r in sorted_records]
                avg_similarity = np.mean(similarities) if similarities else 0
                
                opposite_type_counts = defaultdict(int)
                for record in sorted_records:
                    opposite_type_counts[record['å¯¹ç«‹ç±»å‹']] += 1
                
                pattern_count = defaultdict(int)
                for record in sorted_records:
                    pattern_count[record['æ¨¡å¼']] += 1
                
                # ğŸ¯ ä¼˜åŒ–ä¸»è¦å¯¹ç«‹ç±»å‹æ˜¾ç¤º
                main_opposite_type = max(opposite_type_counts.items(), key=lambda x: x[1])[0]
                # å¦‚æœä¸»è¦å¯¹ç«‹ç±»å‹åŒ…å« " vs "ï¼Œåˆ™è¿›è¡Œæ ¼å¼åŒ–
                if ' vs ' in main_opposite_type:
                    parts = main_opposite_type.split(' vs ')
                    if len(parts) == 2:
                        # æå–ä½ç½®å’Œæ–¹å‘ï¼Œæ ¼å¼åŒ–ä¸º "ä½ç½®-æ–¹å‘1-æ–¹å‘2"
                        pos_dir1 = parts[0].split('-')
                        pos_dir2 = parts[1].split('-')
                        if len(pos_dir1) >= 2 and len(pos_dir2) >= 2:
                            # å‡è®¾ä½ç½®ç›¸åŒï¼Œåªæ˜¾ç¤ºä¸€æ¬¡ä½ç½®
                            position = pos_dir1[0]  # å–ç¬¬ä¸€ä¸ªä½ç½®
                            dir1 = pos_dir1[-1]     # å–æœ€åä¸€ä¸ªéƒ¨åˆ†ä½œä¸ºæ–¹å‘
                            dir2 = pos_dir2[-1]     # å–æœ€åä¸€ä¸ªéƒ¨åˆ†ä½œä¸ºæ–¹å‘
                            main_opposite_type = f"{position}-{dir1}-{dir2}"
                        else:
                            main_opposite_type = f"{parts[0]}-{parts[1].split('-')[-1]}" if '-' in parts[1] else f"{parts[0]}-{parts[1]}"
                
                # è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
                account_stats_info = []
                total_periods_stats = self.account_total_periods_by_lottery.get(lottery, {})
                record_stats = self.account_record_stats_by_lottery.get(lottery, {})
                
                for account in account_group:
                    total_periods = total_periods_stats.get(account, 0)
                    records_count = record_stats.get(account, 0)
                    account_stats_info.append(f"{account}({total_periods}æœŸ/{records_count}è®°å½•)")
                
                activity_level = self.get_account_group_activity_level(account_group, lottery)
                
                continuous_patterns.append({
                    'è´¦æˆ·ç»„': list(account_group),
                    'å½©ç§': lottery,
                    'å½©ç§ç±»å‹': records[0]['å½©ç§ç±»å‹'] if records else 'æœªçŸ¥',
                    'è´¦æˆ·æ•°é‡': len(account_group),
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': main_opposite_type,
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': dict(opposite_type_counts),
                    'å¯¹åˆ·æœŸæ•°': len(sorted_records),
                    'æ€»æŠ•æ³¨é‡‘é¢': total_investment,
                    'å¹³å‡ç›¸ä¼¼åº¦': avg_similarity,
                    'æ¨¡å¼åˆ†å¸ƒ': dict(pattern_count),
                    'è¯¦ç»†è®°å½•': sorted_records,
                    'è´¦æˆ·æ´»è·ƒåº¦': activity_level,
                    'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': account_stats_info,
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': required_min_periods
                })
        
        return continuous_patterns

    def _calculate_detailed_account_stats(self, patterns):
        """è®¡ç®—è¯¦ç»†è´¦æˆ·ç»Ÿè®¡ - è°ƒæ•´åˆ—åä»¥åŒ¹é…å›¾ç‰‡æ ¼å¼"""
        account_participation = defaultdict(lambda: {
            'periods': set(),
            'lotteries': set(),
            'positions': set(),
            'total_combinations': 0,
            'total_bet_amount': 0,
            'continuous_periods': 0,
            'actual_bet_records': []
        })
        
        # ä»åŸå§‹æ•°æ®ä¸­æ”¶é›†è´¦æˆ·çš„å®é™…æŠ•æ³¨é‡‘é¢
        if self.df_valid is not None:
            for _, row in self.df_valid.iterrows():
                account = row['ä¼šå‘˜è´¦å·']
                amount = row['æŠ•æ³¨é‡‘é¢']
                period = row['æœŸå·']
                lottery = row['å½©ç§'] if 'å½©ç§' in row else 'æœªçŸ¥'
                
                if account in account_participation:
                    account_participation[account]['actual_bet_records'].append({
                        'amount': amount,
                        'period': period,
                        'lottery': lottery
                    })
        
        # æ”¶é›†è´¦æˆ·å‚ä¸ä¿¡æ¯
        for pattern in patterns:
            for account in pattern['è´¦æˆ·ç»„']:
                account_info = account_participation[account]
                
                # æ·»åŠ æœŸå·
                for record in pattern['è¯¦ç»†è®°å½•']:
                    account_info['periods'].add(record['æœŸå·'])
                
                # æ·»åŠ å½©ç§
                account_info['lotteries'].add(pattern['å½©ç§'])
                
                # æ·»åŠ ä½ç½®ä¿¡æ¯
                for record in pattern['è¯¦ç»†è®°å½•']:
                    for direction in record['æ–¹å‘ç»„']:
                        if '-' in direction:
                            position = direction.split('-')[0]
                            account_info['positions'].add(position)
                
                account_info['total_combinations'] += 1
                account_info['continuous_periods'] = max(account_info['continuous_periods'], pattern['å¯¹åˆ·æœŸæ•°'])
                
                # è®¡ç®—è¯¥è´¦æˆ·åœ¨å¯¹åˆ·æ¨¡å¼ä¸­çš„å®é™…æŠ•æ³¨é‡‘é¢
                pattern_bet_amount = 0
                for record in pattern['è¯¦ç»†è®°å½•']:
                    for acc, amt in zip(record['è´¦æˆ·ç»„'], record['é‡‘é¢ç»„']):
                        if acc == account:
                            pattern_bet_amount += amt
                
                account_info['total_bet_amount'] += pattern_bet_amount
        
        # è½¬æ¢ä¸ºæ˜¾ç¤ºæ ¼å¼ - è°ƒæ•´åˆ—åä»¥åŒ¹é…å›¾ç‰‡
        account_stats = []
        for account, info in account_participation.items():
            stat_record = {
                'è´¦æˆ·': account,
                'å‚ä¸ç»„åˆæ•°': info['total_combinations'],
                'æ¶‰åŠæœŸæ•°': len(info['periods']),  # å¯¹åº”å›¾ç‰‡ä¸­çš„"æ¶‰åŠæŒ‡æ•°"
                'æ¶‰åŠå½©ç§': len(info['lotteries']),  # å¯¹åº”å›¾ç‰‡ä¸­çš„"æ¶‰åŠæ—¶é—´"
                'æ€»æŠ•æ³¨é‡‘é¢': info['total_bet_amount'],  # å¯¹åº”å›¾ç‰‡ä¸­çš„"æ€»æŠ•æ”¾é‡‘é¢"
                'å¹³å‡æ¯ç»„é‡‘é¢': info['total_bet_amount'] / info['total_combinations'] if info['total_combinations'] > 0 else 0  # å¯¹åº”å›¾ç‰‡ä¸­çš„"å¹³å‡æŠ•æ”¾é‡‘é¢"
            }
            
            account_stats.append(stat_record)
        
        return sorted(account_stats, key=lambda x: x['æ€»æŠ•æ³¨é‡‘é¢'], reverse=True)

    def exclude_multi_direction_accounts(self, df_valid):
        """æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨"""
        multi_direction_mask = (
            df_valid.groupby(['æœŸå·', 'ä¼šå‘˜è´¦å·'])['æŠ•æ³¨æ–¹å‘']
            .transform('nunique') > 1
        )
        
        df_filtered = df_valid[~multi_direction_mask].copy()
        
        return df_filtered
    
    def get_account_group_activity_level(self, account_group, lottery):
        """è·å–æ´»è·ƒåº¦æ°´å¹³"""
        if lottery not in self.account_total_periods_by_lottery:
            return 'unknown'
        
        total_periods_stats = self.account_total_periods_by_lottery[lottery]
        
        # è®¡ç®—è´¦æˆ·ç»„ä¸­åœ¨æŒ‡å®šå½©ç§çš„æœ€å°æ€»æŠ•æ³¨æœŸæ•°
        min_total_periods = min(total_periods_stats.get(account, 0) for account in account_group)
        
        # æŒ‰ç…§æ–°çš„æ´»è·ƒåº¦é˜ˆå€¼
        if min_total_periods <= self.config.period_thresholds['low_activity']:
            return 'low'        # æ€»æŠ•æ³¨æœŸæ•°1-10
        elif min_total_periods <= self.config.period_thresholds['medium_activity_high']:
            return 'medium'     # æ€»æŠ•æ³¨æœŸæ•°11-50
        elif min_total_periods <= self.config.period_thresholds['high_activity_high']:
            return 'high'       # æ€»æŠ•æ³¨æœŸæ•°51-100
        else:
            return 'very_high'  # æ€»æŠ•æ³¨æœŸæ•°100ä»¥ä¸Š
    
    def get_required_min_periods(self, account_group, lottery):
        """æ ¹æ®æ–°çš„æ´»è·ƒåº¦é˜ˆå€¼è·å–æ‰€éœ€çš„æœ€å°å¯¹åˆ·æœŸæ•°"""
        activity_level = self.get_account_group_activity_level(account_group, lottery)
        
        if activity_level == 'low':
            return self.config.period_thresholds['min_periods_low']      # 3æœŸ
        elif activity_level == 'medium':
            return self.config.period_thresholds['min_periods_medium']   # 5æœŸ
        elif activity_level == 'high':
            return self.config.period_thresholds['min_periods_high']     # 8æœŸ
        else:
            return self.config.period_thresholds['min_periods_very_high'] # 11æœŸ
    
    def display_performance_stats(self):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
        if not self.performance_stats:
            return
        
        with st.expander("ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡", expanded=False):
            st.write(f"**æ•°æ®å¤„ç†ç»Ÿè®¡:**")
            st.write(f"- æ€»è®°å½•æ•°: {self.performance_stats['total_records']:,}")
            st.write(f"- æ€»æœŸå·æ•°: {self.performance_stats['total_periods']:,}")
            st.write(f"- æ€»è´¦æˆ·æ•°: {self.performance_stats['total_accounts']:,}")
            
            if 'detection_time' in self.performance_stats:
                st.write(f"**æ£€æµ‹æ€§èƒ½:**")
                st.write(f"- æ£€æµ‹æ—¶é—´: {self.performance_stats['detection_time']:.2f} ç§’")
                st.write(f"- å‘ç°æ¨¡å¼: {self.performance_stats['total_patterns']} ä¸ª")
    
    def display_detailed_results(self, patterns):
        """æ˜¾ç¤ºè¯¦ç»†æ£€æµ‹ç»“æœ - ä¸“æ³¨äºæ ¸å¿ƒå¯¹ç«‹æ–¹å‘"""
        st.write("\n" + "="*60)
        st.write("ğŸ¯ åŒè´¦æˆ·æ ¸å¿ƒå¯¹ç«‹æ–¹å‘å¯¹åˆ·æ£€æµ‹ç»“æœ")
        st.write("="*60)
        
        if not patterns:
            st.error("âŒ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„è¿ç»­å¯¹åˆ·æ¨¡å¼")
            return
    
        # ========== æ€»ä½“ç»Ÿè®¡ ==========
        st.subheader("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        
        total_groups = len(patterns)
        total_accounts = sum(p['è´¦æˆ·æ•°é‡'] for p in patterns)
        total_wash_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        # ğŸ¯ ä¸“æ³¨äºæ ¸å¿ƒå¯¹ç«‹ç±»å‹ç»Ÿè®¡
        opposite_type_stats = defaultdict(int)
        for pattern in patterns:
            for opposite_type, count in pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ'].items():
                opposite_type_stats[opposite_type] += count
        
        # ç¬¬ä¸€è¡Œï¼šæ€»ä½“æŒ‡æ ‡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»å¯¹åˆ·ç»„æ•°", total_groups)
        with col2:
            st.metric("æ¶‰åŠè´¦æˆ·æ•°", total_accounts)
        with col3:
            st.metric("æ€»å¯¹åˆ·æœŸæ•°", total_wash_periods)
        with col4:
            st.metric("æ€»æ¶‰åŠé‡‘é¢", f"Â¥{total_amount:,.2f}")
        
        # ========== å½©ç§ç±»å‹ç»Ÿè®¡ ==========
        st.subheader("ğŸ² å½©ç§ç±»å‹ç»Ÿè®¡")
        
        lottery_stats = defaultdict(int)
        for pattern in patterns:
            lottery_stats[pattern['å½©ç§']] += 1
        
        lottery_cols = st.columns(min(5, len(lottery_stats)))
        
        for i, (lottery, count) in enumerate(lottery_stats.items()):
            if i < len(lottery_cols):
                with lottery_cols[i]:
                    st.metric(
                        label=lottery,
                        value=f"{count}ç»„"
                    )
        
        # ========== æ ¸å¿ƒå¯¹ç«‹ç±»å‹åˆ†å¸ƒ ==========
        st.subheader("ğŸ¯ æ ¸å¿ƒå¯¹ç«‹ç±»å‹åˆ†å¸ƒ")
        
        # æ˜¾ç¤ºå‰5ä¸ªä¸»è¦å¯¹ç«‹ç±»å‹
        top_opposites = sorted(opposite_type_stats.items(), key=lambda x: x[1], reverse=True)[:5]
        
        for opposite_type, count in top_opposites:
            # ç®€åŒ–å¯¹ç«‹ç±»å‹æ˜¾ç¤º
            if ' vs ' in opposite_type:
                display_type = opposite_type.replace(' vs ', '-')
            else:
                display_type = opposite_type
            st.write(f"- **{display_type}**: {count}æœŸ")
        
        # ========== è¯¦ç»†å¯¹åˆ·ç»„åˆ†æ ==========
        st.write("\n" + "="*60)
        st.subheader("ğŸ” è¯¦ç»†å¯¹åˆ·ç»„åˆ†æ")
        
        patterns_by_lottery = defaultdict(list)
        for pattern in patterns:
            lottery_key = pattern['å½©ç§']
            patterns_by_lottery[lottery_key].append(pattern)
        
        for lottery, lottery_patterns in patterns_by_lottery.items():
            with st.expander(f"ğŸ² å½©ç§ï¼š{lottery}ï¼ˆå‘ç°{len(lottery_patterns)}ç»„ï¼‰", expanded=True):
                for i, pattern in enumerate(lottery_patterns, 1):
                    st.markdown(f"**å¯¹åˆ·ç»„ {i}:** {' â†” '.join(pattern['è´¦æˆ·ç»„'])}")
                    
                    activity_icon = "ğŸŸ¢" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'low' else "ğŸŸ¡" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'medium' else "ğŸŸ " if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'high' else "ğŸ”´"
                    st.markdown(f"**æ´»è·ƒåº¦:** {activity_icon} {pattern['è´¦æˆ·æ´»è·ƒåº¦']} | **å½©ç§:** {pattern['å½©ç§']} | **ä¸»è¦ç±»å‹:** {pattern['ä¸»è¦å¯¹ç«‹ç±»å‹']}")
                    
                    st.markdown(f"**è´¦æˆ·åœ¨è¯¥å½©ç§æŠ•æ³¨æœŸæ•°/è®°å½•æ•°:** {', '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯'])}")
                    st.markdown(f"**å¯¹åˆ·æœŸæ•°:** {pattern['å¯¹åˆ·æœŸæ•°']}æœŸ (è¦æ±‚â‰¥{pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°']}æœŸ)")
                    st.markdown(f"**æ€»é‡‘é¢:** {pattern['æ€»æŠ•æ³¨é‡‘é¢']:.2f}å…ƒ | **å¹³å‡åŒ¹é…:** {pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}")
                    
                    st.markdown("**è¯¦ç»†è®°å½•:**")
                    for j, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                        account_directions = []
                        for account, direction, amount in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„']):
                            account_directions.append(f"{account}({direction}:{amount})")
                        
                        st.write(f"{j}. æœŸå·: {record['æœŸå·']} | æ–¹å‘: {' â†” '.join(account_directions)} | åŒ¹é…åº¦: {record['ç›¸ä¼¼åº¦']:.2%}")
                    
                    if i < len(lottery_patterns):
                        st.markdown("---")
    
    def display_summary_statistics(self, patterns):
        """æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡ - æ ¹æ®æœ€æ–°å›¾ç‰‡æ ·å¼è°ƒæ•´"""
        if not patterns:
            return
            
        st.subheader("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        
        total_groups = len(patterns)
        total_accounts = sum(p['è´¦æˆ·æ•°é‡'] for p in patterns)
        total_wash_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        account_count_stats = defaultdict(int)
        for pattern in patterns:
            account_count_stats[pattern['è´¦æˆ·æ•°é‡']] += 1
        
        lottery_stats = defaultdict(int)
        for pattern in patterns:
            lottery_stats[pattern['å½©ç§']] += 1
        
        activity_stats = defaultdict(int)
        for pattern in patterns:
            activity_stats[pattern['è´¦æˆ·æ´»è·ƒåº¦']] += 1
        
        opposite_type_stats = defaultdict(int)
        for pattern in patterns:
            for opposite_type, count in pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ'].items():
                opposite_type_stats[opposite_type] += count
        
        # ========== ç¬¬ä¸€è¡Œï¼šæ€»ä½“æŒ‡æ ‡ ==========
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("æ€»å¯¹åˆ·ç»„æ•°", total_groups)
        
        with col2:
            st.metric("æ¶‰åŠè´¦æˆ·æ•°", total_accounts)
        
        with col3:
            st.metric("æ€»å¯¹åˆ·æœŸæ•°", total_wash_periods)
        
        with col4:
            st.metric("æ€»æ¶‰åŠé‡‘é¢", f"Â¥{total_amount:,.2f}")
        
        # ========== ç¬¬äºŒè¡Œï¼šå½©ç§ç±»å‹ç»Ÿè®¡ ==========
        st.subheader("ğŸ² å½©ç§ç±»å‹ç»Ÿè®¡")
        
        # å®šä¹‰å½©ç§ç±»å‹æ˜¾ç¤ºåç§°
        lottery_display_names = {
            'PK10': 'PK10/èµ›è½¦',
            'K3': 'å¿«ä¸‰',
            'LHC': 'å…­åˆå½©', 
            'SSC': 'æ—¶æ—¶å½©',
            '3D': '3Dç³»åˆ—'
        }
        
        # åˆ›å»ºå½©ç§ç»Ÿè®¡åˆ—
        lottery_cols = st.columns(min(5, len(lottery_stats)))
        
        for i, (lottery, count) in enumerate(lottery_stats.items()):
            if i < len(lottery_cols):
                with lottery_cols[i]:
                    display_name = lottery_display_names.get(lottery, lottery)
                    st.metric(
                        label=display_name,
                        value=f"{count}ç»„"
                    )
        
        # ========== ç¬¬ä¸‰è¡Œï¼šè´¦æˆ·ç»„åˆåˆ†å¸ƒå’Œæ´»è·ƒåº¦åˆ†å¸ƒ ==========
        col_left, col_right = st.columns(2)
        
        with col_left:
            st.subheader("ğŸ‘¥ è´¦æˆ·ç»„åˆåˆ†å¸ƒ")
            
            for account_count, group_count in sorted(account_count_stats.items()):
                # è®¡ç®—è¯¥ç±»å‹ç»„åˆçš„æ€»å¯¹åˆ·æœŸæ•°
                account_type_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns if p['è´¦æˆ·æ•°é‡'] == account_count)
                st.write(f"- **{account_count}ç»„**: {group_count}ç»„ ({account_type_periods}æœŸ)")
        
        with col_right:
            st.subheader("ğŸ“ˆ æ´»è·ƒåº¦åˆ†å¸ƒ")
            
            activity_display_names = {
                'low': 'ä½æ´»è·ƒåº¦',
                'medium': 'ä¸­æ´»è·ƒåº¦',
                'high': 'é«˜æ´»è·ƒåº¦',
                'very_high': 'æé«˜æ´»è·ƒåº¦'
            }
            
            for activity, count in activity_stats.items():
                display_name = activity_display_names.get(activity, activity)
                # è®¡ç®—è¯¥æ´»è·ƒåº¦çš„æ€»å¯¹åˆ·æœŸæ•°
                activity_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns if p['è´¦æˆ·æ´»è·ƒåº¦'] == activity)
                st.write(f"- **{display_name}**: {count}ç»„ ({activity_periods}æœŸ)")
        
        # ========== ç¬¬å››è¡Œï¼šå…³é”®æŒ‡æ ‡ ==========
        st.subheader("ğŸ“ˆ å…³é”®æŒ‡æ ‡")
        
        # è®¡ç®—å¹³å‡æ¯ç»„é‡‘é¢
        avg_group_amount = total_amount / total_groups if total_groups > 0 else 0
        
        metric_col1, metric_col2, metric_col3 = st.columns(3)
        
        with metric_col1:
            st.metric("å¹³å‡æ¯ç»„é‡‘é¢", f"Â¥{avg_group_amount:,.2f}")
        
        with metric_col2:
            # è®¡ç®—ä¸šåŠ¡ç±»å‹æ€»é‡‘é¢
            business_total = total_amount
            st.metric("ä¸šåŠ¡ç±»å‹æ€»é¢", f"Â¥{business_total:,.2f}")
        
        with metric_col3:
            # æ˜¾ç¤ºæ€»è´¦æˆ·æ•°
            st.metric("å‚ä¸æ€»è´¦æˆ·æ•°", total_accounts)
        
        # ========== ç¬¬äº”è¡Œï¼šä¸»è¦å¯¹ç«‹ç±»å‹ ==========
        st.subheader("ğŸ¯ ä¸»è¦å¯¹ç«‹ç±»å‹")
        
        # æ˜¾ç¤ºå‰3ä¸ªä¸»è¦å¯¹ç«‹ç±»å‹
        top_opposites = sorted(opposite_type_stats.items(), key=lambda x: x[1], reverse=True)[:3]
        
        for opposite_type, count in top_opposites:
            # ç®€åŒ–å¯¹ç«‹ç±»å‹æ˜¾ç¤º
            if ' vs ' in opposite_type:
                display_type = opposite_type.replace(' vs ', '-')
            else:
                display_type = opposite_type
            st.write(f"- **{display_type}**: {count}æœŸ")

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•° - ç®€åŒ–ç‰ˆ"""
    st.title("ğŸ¯ æ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    with st.sidebar:
        st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
        uploaded_file = st.file_uploader(
            "è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶", 
            type=['xlsx', 'xls', 'csv'],
            help="æ”¯æŒExcelå’ŒCSVæ ¼å¼"
        )
    
    if uploaded_file is not None:
        try:
            # ğŸ†• ç®€åŒ–é…ç½®
            st.sidebar.header("âš™ï¸ åŸºç¡€é…ç½®")
            min_amount = st.sidebar.number_input("æœ€å°æŠ•æ³¨é‡‘é¢", value=1, min_value=1)
            base_similarity = st.sidebar.slider("é‡‘é¢åŒ¹é…åº¦", 0.5, 1.0, 0.8, 0.05)
            
            config = Config()
            config.min_amount = min_amount
            config.amount_similarity_threshold = base_similarity
            config.max_accounts_in_group = 2  # ğŸ†• ä¸“æ³¨äº2è´¦æˆ·æ£€æµ‹
            
            detector = WashTradeDetector(config)
            
            # ğŸ†• æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            st.success(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
            st.info("ğŸ”„ å¼€å§‹å¤„ç†æ•°æ®...")
            
            # å¤„ç†æ•°æ®
            with st.spinner("æ­£åœ¨è§£ææ•°æ®..."):
                df_enhanced, filename = detector.upload_and_process(uploaded_file)
            
            if df_enhanced is not None and len(df_enhanced) > 0:
                st.success(f"âœ… æ•°æ®å¤„ç†å®Œæˆï¼Œæœ‰æ•ˆè®°å½•: {len(df_enhanced)}")
                
                # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆ", expanded=True):
                    st.dataframe(df_enhanced.head(10))
                
                # å¼€å§‹æ£€æµ‹
                st.info("ğŸš€ å¼€å§‹æ£€æµ‹å¯¹åˆ·äº¤æ˜“...")
                with st.spinner("æ­£åœ¨æ£€æµ‹å¯¹åˆ·æ¨¡å¼..."):
                    patterns = detector.detect_all_wash_trades()
                
                if patterns:
                    st.success(f"âœ… æ£€æµ‹å®Œæˆï¼å‘ç° {len(patterns)} ä¸ªå¯¹åˆ·ç»„")
                    detector.display_detailed_results(patterns)
                else:
                    st.warning("âš ï¸ æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„å¯¹åˆ·è¡Œä¸º")
            else:
                st.error("âŒ æ•°æ®å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
                
        except Exception as e:
            st.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
            # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä½†ä¸ä¸­æ–­
            with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…", expanded=False):
                st.code(traceback.format_exc())
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("ğŸ” æ™ºèƒ½æ£€æµ‹")
            st.markdown("""
            - å¤šè´¦æˆ·å¯¹åˆ·æ¨¡å¼è¯†åˆ«
            - æ™ºèƒ½é‡‘é¢åŒ¹é…åˆ†æ
            - æ´»è·ƒåº¦è‡ªé€‚åº”é˜ˆå€¼
            - å®æ—¶è¿›åº¦ç›‘æ§
            """)
        
        with col2:
            st.subheader("ğŸ“Š ä¸“ä¸šåˆ†æ")
            st.markdown("""
            - å®Œæ•´å½©ç§æ”¯æŒï¼ˆæ–°å¢3Dç³»åˆ—ï¼‰
            - ç©æ³•åˆ†ç±»æ ‡å‡†åŒ–
            - æ•°æ®è´¨é‡éªŒè¯
            - è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
            """)
        
        with col3:
            st.subheader("ğŸš€ é«˜æ•ˆå¤„ç†")
            st.markdown("""
            - å¤§æ•°æ®é‡ä¼˜åŒ–
            - å¹¶è¡Œæ£€æµ‹ç®—æ³•
            - ä¸€é”®å¯¼å‡ºç»“æœ
            - å®æ—¶æ€§èƒ½ç›‘æ§
            """)
    
    with st.expander("ğŸ“– ç³»ç»Ÿä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½è¯´æ˜

        **ğŸ¯ æ£€æµ‹é€»è¾‘ï¼š**
        - **æ€»æŠ•æ³¨æœŸæ•°**ï¼šè´¦æˆ·åœ¨ç‰¹å®šå½©ç§ä¸­çš„æ‰€æœ‰æœŸå·æŠ•æ³¨æ¬¡æ•°
        - **å¯¹åˆ·æœŸæ•°**ï¼šè´¦æˆ·ç»„å®é™…å‘ç”Ÿå¯¹åˆ·è¡Œä¸ºçš„æœŸæ•°
        - æ ¹æ®**æ€»æŠ•æ³¨æœŸæ•°**åˆ¤å®šè´¦æˆ·æ´»è·ƒåº¦ï¼Œè®¾ç½®ä¸åŒçš„**å¯¹åˆ·æœŸæ•°**é˜ˆå€¼

        **ğŸ“Š æ–°æ´»è·ƒåº¦åˆ¤å®šï¼š**
        - **1-10æœŸ**ï¼šè¦æ±‚â‰¥3æœŸè¿ç»­å¯¹åˆ·
        - **11-50æœŸ**ï¼šè¦æ±‚â‰¥5æœŸè¿ç»­å¯¹åˆ·  
        - **51-100æœŸ**ï¼šè¦æ±‚â‰¥8æœŸè¿ç»­å¯¹åˆ·
        - **100æœŸä»¥ä¸Š**ï¼šè¦æ±‚â‰¥11æœŸè¿ç»­å¯¹åˆ·

        **ğŸ¯ å¤šè´¦æˆ·åŒ¹é…åº¦è¦æ±‚ï¼š**
        - **2ä¸ªè´¦æˆ·**ï¼š80%åŒ¹é…åº¦
        - **3ä¸ªè´¦æˆ·**ï¼š85%åŒ¹é…åº¦  
        - **4ä¸ªè´¦æˆ·**ï¼š90%åŒ¹é…åº¦
        - **5ä¸ªè´¦æˆ·**ï¼š95%åŒ¹é…åº¦

        **ğŸ”„ è´¦æˆ·æœŸæ•°å·®å¼‚æ£€æŸ¥ï¼š**
        - é¿å…æœŸæ•°å·®å¼‚è¿‡å¤§çš„è´¦æˆ·ç»„åˆ
        - é»˜è®¤é˜ˆå€¼ï¼š150æœŸ
        - å¯è‡ªå®šä¹‰è°ƒæ•´é˜ˆå€¼

        **ğŸ² æ”¯æŒçš„æ–¹å‘æ£€æµ‹ï¼š**
        - **åŸºç¡€æ–¹å‘**ï¼šå¤§ã€å°ã€å•ã€åŒã€é¾™ã€è™ã€è´¨ã€åˆ
        - **å˜å¼‚å½¢å¼**ï¼šç‰¹å¤§ã€ç‰¹å°ã€æ€»å’Œå•ã€æ€»å’Œå¤§ç­‰ï¼ˆè‡ªåŠ¨æ˜ å°„åˆ°åŸºç¡€æ–¹å‘ï¼‰
        - **ä½ç½®ç²¾åº¦**ï¼šå† å†›åˆ°ç¬¬ååã€ç™¾ä½åä½ä¸ªä½ç­‰ç²¾ç¡®ä½ç½®åˆ¤æ–­

        **âš¡ è‡ªåŠ¨æ£€æµ‹ï¼š**
        - æ•°æ®ä¸Šä¼ åè‡ªåŠ¨å¼€å§‹å¤„ç†å’Œåˆ†æ
        - æ— éœ€æ‰‹åŠ¨ç‚¹å‡»å¼€å§‹æ£€æµ‹æŒ‰é’®
        """)

if __name__ == "__main__":
    main()
