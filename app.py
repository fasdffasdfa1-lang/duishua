import pandas as pd
import numpy as np
import streamlit as st
import io
import re
import logging
from collections import defaultdict
from datetime import datetime
from itertools import combinations
import warnings
import traceback
import hashlib
from functools import lru_cache

# é…ç½®æ—¥å¿—å’Œè­¦å‘Š
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('MultiAccountWashTrade')

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤çš„é…ç½® ====================
LOTTERY_CONFIGS = {
    'PK10': {
        'lotteries': [
            'åˆ†åˆ†PKæ‹¾', 'ä¸‰åˆ†PKæ‹¾', 'äº”åˆ†PKæ‹¾', 'æ–°å¹¸è¿é£è‰‡', 'æ¾³æ´²å¹¸è¿10',
            'ä¸€åˆ†PK10', 'å®¾æœPK10', 'æé€Ÿé£è‰‡', 'æ¾³æ´²é£è‰‡', 'å¹¸è¿èµ›è½¦',
            'åˆ†åˆ†èµ›è½¦', 'åŒ—äº¬PK10', 'æ—§åŒ—äº¬PK10', 'æé€Ÿèµ›è½¦', 'å¹¸è¿èµ›è»Š', 
            'åŒ—äº¬èµ›è½¦', 'æé€ŸPK10', 'å¹¸è¿PK10', 'èµ›è½¦', 'èµ›è»Š'
        ],
        'min_number': 1,
        'max_number': 10,
        'gyh_min': 3,
        'gyh_max': 19,
        'position_names': ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                          'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
    },
    'K3': {
        'lotteries': [
            'åˆ†åˆ†å¿«ä¸‰', 'ä¸‰åˆ†å¿«3', 'äº”åˆ†å¿«3', 'æ¾³æ´²å¿«ä¸‰', 'å®¾æœå¿«ä¸‰',
            '1åˆ†å¿«ä¸‰', '3åˆ†å¿«ä¸‰', '5åˆ†å¿«ä¸‰', '10åˆ†å¿«ä¸‰', 'åŠ å·å¿«ä¸‰',
            'å¹¸è¿å¿«ä¸‰', 'å¤§å‘å¿«ä¸‰', 'å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 
            'æ¾³é—¨å¿«ä¸‰', 'é¦™æ¸¯å¿«ä¸‰', 'æ±Ÿè‹å¿«ä¸‰'
        ],
        'min_number': 1,
        'max_number': 6,
        'hezhi_min': 3,
        'hezhi_max': 18
    },
    'LHC': {
        'lotteries': [
            'æ–°æ¾³é—¨å…­åˆå½©', 'æ¾³é—¨å…­åˆå½©', 'é¦™æ¸¯å…­åˆå½©', 'ä¸€åˆ†å…­åˆå½©',
            'äº”åˆ†å…­åˆå½©', 'ä¸‰åˆ†å…­åˆå½©', 'é¦™æ¸¯â‘¥åˆå½©', 'åˆ†åˆ†å…­åˆå½©',
            'å¿«ä¹6åˆå½©', 'æ¸¯â‘¥åˆå½©', 'å°æ¹¾å¤§ä¹é€', 'å…­åˆ', 'lhc', 'å…­åˆå½©',
            'â‘¥åˆ', '6åˆ', 'å¤§å‘å…­åˆå½©'
        ],
        'min_number': 1,
        'max_number': 49
    },
    'SSC': {
        'lotteries': [
            'åˆ†åˆ†æ—¶æ—¶å½©', 'ä¸‰åˆ†æ—¶æ—¶å½©', 'äº”åˆ†æ—¶æ—¶å½©', 'å®¾æœæ—¶æ—¶å½©',
            '1åˆ†æ—¶æ—¶å½©', '3åˆ†æ—¶æ—¶å½©', '5åˆ†æ—¶æ—¶å½©', 'æ—§é‡åº†æ—¶æ—¶å½©',
            'å¹¸è¿æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©', 'æ–°ç–†æ—¶æ—¶å½©', 'å¤©æ´¥æ—¶æ—¶å½©',
            'é‡åº†æ—¶æ—¶å½©', 'ä¸Šæµ·æ—¶æ—¶å½©', 'å¹¿ä¸œæ—¶æ—¶å½©', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©'
        ],
        'min_number': 0,
        'max_number': 9
    },
    'THREE_COLOR': {
        'lotteries': [
            'ä¸€åˆ†ä¸‰è‰²å½©', '30ç§’ä¸‰è‰²å½©', 'äº”åˆ†ä¸‰è‰²å½©', 'ä¸‰åˆ†ä¸‰è‰²å½©',
            'ä¸‰è‰²', 'ä¸‰è‰²å½©', 'ä¸‰è‰²çƒ'
        ],
        'min_number': 0,
        'max_number': 9
    }
}

class Config:
    """é…ç½®å‚æ•°ç±» - å¢å¼ºç‰ˆ"""
    def __init__(self):
        self.min_amount = 10
        self.amount_similarity_threshold = 0.8
        self.min_continuous_periods = 3
        self.max_accounts_in_group = 5
        self.supported_file_types = ['.xlsx', '.xls', '.csv']
        
        # å¢å¼ºçš„åˆ—åæ˜ å°„é…ç½® - ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤
        self.column_mappings = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
        
        # ä¿®æ­£ï¼šæ ¹æ®è´¦æˆ·æ€»æŠ•æ³¨æœŸæ•°è®¾ç½®ä¸åŒçš„å¯¹åˆ·æœŸæ•°é˜ˆå€¼
        self.period_thresholds = {
            'low_activity': 10,        # ä½æ´»è·ƒåº¦è´¦æˆ·é˜ˆå€¼ï¼ˆæ€»æŠ•æ³¨æœŸæ•°â‰¤10ï¼‰
            'medium_activity_low': 11,  # ä¸­æ´»è·ƒåº¦ä¸‹é™ï¼ˆæ€»æŠ•æ³¨æœŸæ•°11-200ï¼‰
            'medium_activity_high': 200, # ä¸­æ´»è·ƒåº¦ä¸Šé™
            'min_periods_low': 3,       # ä½æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
            'min_periods_medium': 5,    # ä¸­æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
            'min_periods_high': 8       # é«˜æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
        }
        
        # æ‰©å±•ï¼šå¢åŠ é¾™è™æ–¹å‘æ¨¡å¼
        self.direction_patterns = {
            'å°': ['ä¸¤é¢-å°', 'å’Œå€¼-å°', 'å°', 'small', 'xia'],
            'å¤§': ['ä¸¤é¢-å¤§', 'å’Œå€¼-å¤§', 'å¤§', 'big', 'da'], 
            'å•': ['ä¸¤é¢-å•', 'å’Œå€¼-å•', 'å•', 'odd', 'dan'],
            'åŒ': ['ä¸¤é¢-åŒ', 'å’Œå€¼-åŒ', 'åŒ', 'even', 'shuang'],
            'é¾™': ['é¾™', 'long', 'é¾', 'dragon'],
            'è™': ['è™', 'hu', 'tiger']
        }
        
        # æ‰©å±•ï¼šå¢åŠ é¾™è™å¯¹ç«‹ç»„
        self.opposite_groups = [{'å¤§', 'å°'}, {'å•', 'åŒ'}, {'é¾™', 'è™'}]

# ==================== ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤çš„æ•°æ®å¤„ç†å™¨ ====================
class DataProcessor:
    def __init__(self):
        self.required_columns = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹', 'é‡‘é¢']
        self.column_mapping = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
    
    def smart_column_identification(self, df_columns):
        """æ™ºèƒ½åˆ—è¯†åˆ« - ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤"""
        identified_columns = {}
        actual_columns = [str(col).strip() for col in df_columns]
        
        with st.expander("ğŸ” åˆ—åè¯†åˆ«è¯¦æƒ…", expanded=False):
            st.info(f"æ£€æµ‹åˆ°çš„åˆ—å: {actual_columns}")
            
            for standard_col, possible_names in self.column_mapping.items():
                found = False
                for actual_col in actual_columns:
                    actual_col_lower = actual_col.lower().replace(' ', '').replace('_', '').replace('-', '')
                    
                    for possible_name in possible_names:
                        possible_name_lower = possible_name.lower().replace(' ', '').replace('_', '').replace('-', '')
                        
                        # å¢å¼ºä¼šå‘˜è´¦å·è¯†åˆ«
                        if standard_col == 'ä¼šå‘˜è´¦å·':
                            # æ›´å®½æ¾çš„åŒ¹é…è§„åˆ™
                            account_keywords = ['ä¼šå‘˜', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·', 'ç©å®¶', 'id']
                            if any(keyword in actual_col_lower for keyword in account_keywords):
                                identified_columns[actual_col] = standard_col
                                st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                                found = True
                                break
                        else:
                            # å…¶ä»–åˆ—çš„åŸæœ‰åŒ¹é…é€»è¾‘
                            if (possible_name_lower in actual_col_lower or 
                                actual_col_lower in possible_name_lower or
                                len(set(possible_name_lower) & set(actual_col_lower)) / len(possible_name_lower) > 0.7):
                                identified_columns[actual_col] = standard_col
                                st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                                found = True
                                break
                    
                    if found:
                        break
                
                if not found:
                    st.warning(f"âš ï¸ æœªè¯†åˆ«åˆ° {standard_col} å¯¹åº”çš„åˆ—å")
        
        return identified_columns
    
    def find_data_start(self, df):
        """æ™ºèƒ½æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®"""
        for row_idx in range(min(20, len(df))):
            for col_idx in range(min(10, len(df.columns))):
                cell_value = str(df.iloc[row_idx, col_idx])
                if pd.notna(cell_value) and any(keyword in cell_value for keyword in ['ä¼šå‘˜', 'è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•', 'å†…å®¹', 'è®¢å•', 'ç”¨æˆ·']):
                    return row_idx, col_idx
        return 0, 0
    
    def validate_data_quality(self, df):
        """æ•°æ®è´¨é‡éªŒè¯ - ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤"""
        logger.info("æ­£åœ¨è¿›è¡Œæ•°æ®è´¨é‡éªŒè¯...")
        issues = []
        
        # æ£€æŸ¥å¿…è¦åˆ—
        missing_cols = [col for col in self.required_columns if col not in df.columns]
        if missing_cols:
            issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        
        # æ£€æŸ¥ç©ºå€¼
        for col in self.required_columns:
            if col in df.columns:
                null_count = df[col].isnull().sum()
                if null_count > 0:
                    issues.append(f"åˆ— '{col}' æœ‰ {null_count} ä¸ªç©ºå€¼")
        
        # ç‰¹åˆ«æ£€æŸ¥ä¼šå‘˜è´¦å·çš„å®Œæ•´æ€§
        if 'ä¼šå‘˜è´¦å·' in df.columns:
            # æ£€æŸ¥æ˜¯å¦æœ‰è¢«æˆªæ–­çš„è´¦å·
            truncated_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(r'\.\.\.|â€¦', na=False)]
            if len(truncated_accounts) > 0:
                issues.append(f"å‘ç° {len(truncated_accounts)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„ä¼šå‘˜è´¦å·")
            
            # æ£€æŸ¥è´¦å·é•¿åº¦å¼‚å¸¸çš„æƒ…å†µ
            account_lengths = df['ä¼šå‘˜è´¦å·'].str.len()
            if account_lengths.max() > 50:  # å‡è®¾æ­£å¸¸è´¦å·é•¿åº¦ä¸è¶…è¿‡50ä¸ªå­—ç¬¦
                issues.append("å‘ç°å¼‚å¸¸é•¿åº¦çš„ä¼šå‘˜è´¦å·")
            
            # æ˜¾ç¤ºè´¦å·æ ¼å¼æ ·æœ¬
            unique_accounts = df['ä¼šå‘˜è´¦å·'].unique()[:5]
            sample_info = " | ".join([f"'{acc}'" for acc in unique_accounts])
            st.info(f"ä¼šå‘˜è´¦å·æ ¼å¼æ ·æœ¬: {sample_info}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if 'æœŸå·' in df.columns:
            # ä¿®å¤æœŸå·æ ¼å¼é—®é¢˜ï¼šå»æ‰.0
            df['æœŸå·'] = df['æœŸå·'].astype(str).str.replace(r'\.0$', '', regex=True)
            # å…è®¸æœŸå·åŒ…å«å­—æ¯å’Œæ•°å­—
            invalid_periods = df[~df['æœŸå·'].str.match(r'^[\dA-Za-z]+$')]
            if len(invalid_periods) > 0:
                issues.append(f"å‘ç° {len(invalid_periods)} æ¡æ— æ•ˆæœŸå·è®°å½•")
        
        # æ£€æŸ¥é‡å¤æ•°æ®
        duplicate_count = df.duplicated().sum()
        if duplicate_count > 0:
            issues.append(f"å‘ç° {duplicate_count} æ¡é‡å¤è®°å½•")
        
        if issues:
            with st.expander("âš ï¸ æ•°æ®è´¨é‡é—®é¢˜", expanded=True):
                for issue in issues:
                    st.warning(f"  - {issue}")
        else:
            st.success("âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
        
        return issues
    
    def clean_data(self, uploaded_file):
        """æ•°æ®æ¸…æ´—ä¸»å‡½æ•° - ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤å¹¶æ”¹è¿›"""
        try:
            # ç¬¬ä¸€æ¬¡è¯»å–ç”¨äºå®šä½
            df_temp = pd.read_excel(uploaded_file, header=None, nrows=50)
            st.info(f"åŸå§‹æ•°æ®ç»´åº¦: {df_temp.shape}")
            
            # æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®
            start_row, start_col = self.find_data_start(df_temp)
            st.info(f"æ•°æ®èµ·å§‹ä½ç½®: ç¬¬{start_row+1}è¡Œ, ç¬¬{start_col+1}åˆ—")
            
            # é‡æ–°è¯»å–æ•°æ® - ç‰¹åˆ«å¤„ç†å¸¸è§„æ ¼å¼å•å…ƒæ ¼
            df_clean = pd.read_excel(
                uploaded_file, 
                header=start_row,
                skiprows=range(start_row + 1) if start_row > 0 else None,
                dtype=str,  # å°†æ‰€æœ‰åˆ—è¯»å–ä¸ºå­—ç¬¦ä¸²
                na_filter=False,  # ä¸è¿‡æ»¤ç©ºå€¼
                keep_default_na=False,  # ä¸ä½¿ç”¨é»˜è®¤çš„NAå€¼å¤„ç†
                converters={}  # ä¸ºç©ºï¼Œè®©pandasä¸è¦è¿›è¡Œä»»ä½•è½¬æ¢
            )
            
            # åˆ é™¤èµ·å§‹åˆ—ä¹‹å‰çš„æ‰€æœ‰åˆ—
            if start_col > 0:
                df_clean = df_clean.iloc[:, start_col:]
            
            st.info(f"æ¸…ç†åæ•°æ®ç»´åº¦: {df_clean.shape}")
            
            # æ™ºèƒ½åˆ—è¯†åˆ«
            column_mapping = self.smart_column_identification(df_clean.columns)
            if column_mapping:
                df_clean = df_clean.rename(columns=column_mapping)
                st.success("âœ… åˆ—åè¯†åˆ«å®Œæˆ!")
                for old_col, new_col in column_mapping.items():
                    logger.info(f"  {old_col} -> {new_col}")
            
            # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
            missing_columns = [col for col in self.required_columns if col not in df_clean.columns]
            if missing_columns and len(df_clean.columns) >= 4:
                st.warning("è‡ªåŠ¨æ˜ å°„åˆ—å...")
                manual_mapping = {}
                col_names = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'å†…å®¹', 'ç©æ³•', 'é‡‘é¢']
                for i, col_name in enumerate(col_names):
                    if i < len(df_clean.columns):
                        manual_mapping[df_clean.columns[i]] = col_name
                
                df_clean = df_clean.rename(columns=manual_mapping)
                st.info(f"æ‰‹åŠ¨é‡å‘½ååçš„åˆ—: {list(df_clean.columns)}")
            
            # æ•°æ®æ¸…ç†
            initial_count = len(df_clean)
            df_clean = df_clean.dropna(subset=[col for col in self.required_columns if col in df_clean.columns])
            df_clean = df_clean.dropna(axis=1, how='all')
            
            # æ•°æ®ç±»å‹è½¬æ¢ - ç‰¹åˆ«å°å¿ƒå¤„ç†ä¼šå‘˜è´¦å·
            for col in self.required_columns:
                if col in df_clean.columns:
                    if col == 'ä¼šå‘˜è´¦å·':
                        # ç‰¹åˆ«å¤„ç†ä¼šå‘˜è´¦å·ï¼šç¡®ä¿ä¸ä¸¢å¤±ä»»ä½•å­—ç¬¦
                        df_clean[col] = df_clean[col].apply(
                            lambda x: str(x) if pd.notna(x) else ''
                        )
                    else:
                        df_clean[col] = df_clean[col].astype(str).str.strip()
            
            # ä¿®å¤æœŸå·æ ¼å¼ï¼šå»æ‰.0
            if 'æœŸå·' in df_clean.columns:
                df_clean['æœŸå·'] = df_clean['æœŸå·'].str.replace(r'\.0$', '', regex=True)
            
            # æ•°æ®è´¨é‡éªŒè¯
            self.validate_data_quality(df_clean)
            
            st.success(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆ: {initial_count} -> {len(df_clean)} æ¡è®°å½•")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.info(f"ğŸ“Š å”¯ä¸€ä¼šå‘˜è´¦å·æ•°: {df_clean['ä¼šå‘˜è´¦å·'].nunique()}")
            
            # å½©ç§åˆ†å¸ƒæ˜¾ç¤º
            if 'å½©ç§' in df_clean.columns:
                lottery_dist = df_clean['å½©ç§'].value_counts()
                with st.expander("ğŸ¯ å½©ç§åˆ†å¸ƒ", expanded=False):
                    st.dataframe(lottery_dist.reset_index().rename(columns={'index': 'å½©ç§', 'å½©ç§': 'æ•°é‡'}))
            
            return df_clean
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            logger.error(f"æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            return None

    def debug_account_issues(self, df):
        """è°ƒè¯•ä¼šå‘˜è´¦å·é—®é¢˜ - ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤"""
        st.subheader("ğŸ” ä¼šå‘˜è´¦å·è°ƒè¯•ä¿¡æ¯")
        
        if 'ä¼šå‘˜è´¦å·' not in df.columns:
            st.error("æœªæ‰¾åˆ°ä¼šå‘˜è´¦å·åˆ—")
            return
        
        # æ˜¾ç¤ºè´¦å·ç»Ÿè®¡ä¿¡æ¯
        st.write("### è´¦å·ç»Ÿè®¡")
        st.write(f"æ€»è®°å½•æ•°: {len(df)}")
        st.write(f"å”¯ä¸€è´¦å·æ•°: {df['ä¼šå‘˜è´¦å·'].nunique()}")
        
        # æ˜¾ç¤ºè´¦å·é•¿åº¦åˆ†å¸ƒ
        df['è´¦å·é•¿åº¦'] = df['ä¼šå‘˜è´¦å·'].str.len()
        length_stats = df['è´¦å·é•¿åº¦'].describe()
        st.write("### è´¦å·é•¿åº¦ç»Ÿè®¡")
        st.write(length_stats)
        
        # æ˜¾ç¤ºå¯èƒ½çš„é—®é¢˜è´¦å·
        st.write("### å¯èƒ½çš„é—®é¢˜è´¦å·")
        
        # æŸ¥æ‰¾éå¸¸çŸ­çš„è´¦å·ï¼ˆå¯èƒ½è¢«æˆªæ–­ï¼‰
        short_accounts = df[df['è´¦å·é•¿åº¦'] < 3]['ä¼šå‘˜è´¦å·'].unique()
        if len(short_accounts) > 0:
            st.warning(f"å‘ç° {len(short_accounts)} ä¸ªè¿‡çŸ­çš„è´¦å·: {list(short_accounts)}")
        
        # æŸ¥æ‰¾åŒ…å«ç‰¹æ®Šæˆªæ–­ç¬¦å·çš„è´¦å·
        truncated_patterns = [r'\.\.\.', r'â€¦', r'\.$', r'_\d+$']
        for pattern in truncated_patterns:
            truncated = df[df['ä¼šå‘˜è´¦å·'].str.contains(pattern, na=False)]['ä¼šå‘˜è´¦å·'].unique()
            if len(truncated) > 0:
                st.warning(f"å‘ç° {len(truncated)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„è´¦å·ï¼ˆæ¨¡å¼: {pattern}ï¼‰: {list(truncated)}")
        
        # æŸ¥æ‰¾åŒ…å«ä¸‹åˆ’çº¿çš„è´¦å·ï¼ˆå¦‚ _551531wxh_ï¼‰
        underscore_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains('_', na=False)]['ä¼šå‘˜è´¦å·'].unique()
        if len(underscore_accounts) > 0:
            st.info(f"å‘ç° {len(underscore_accounts)} ä¸ªåŒ…å«ä¸‹åˆ’çº¿çš„è´¦å·:")
            for account in underscore_accounts:
                # ä½¿ç”¨Markdownè½¬ä¹‰æ¥ç¡®ä¿ä¸‹åˆ’çº¿æ­£ç¡®æ˜¾ç¤º
                account_display = account.replace('_', '\\_')  # è½¬ä¹‰ä¸‹åˆ’çº¿
                st.markdown(f"- `{account_display}` (é•¿åº¦: {len(account)}, æ˜¾ç¤º: '{account}')")
        
        # æ˜¾ç¤ºå‰30ä¸ªè´¦å·æ ·æœ¬ - ä½¿ç”¨Markdownæ ¼å¼ç¡®ä¿æ­£ç¡®æ˜¾ç¤º
        st.write("### è´¦å·æ ·æœ¬ï¼ˆå‰30ä¸ªï¼‰")
        sample_accounts = df['ä¼šå‘˜è´¦å·'].head(30).tolist()
        for i, account in enumerate(sample_accounts, 1):
            # ä½¿ç”¨Markdownæ ¼å¼æ˜¾ç¤ºè´¦å·ï¼Œç¡®ä¿ç‰¹æ®Šå­—ç¬¦æ­£ç¡®æ˜¾ç¤º
            account_display = account.replace('_', '\\_')  # è½¬ä¹‰ä¸‹åˆ’çº¿
            st.markdown(f"{i:2d}. `{account_display}` (é•¿åº¦: {len(account)})")
        
        # æ˜¾ç¤ºæ•°æ®ç±»å‹çš„è¯¦ç»†ä¿¡æ¯
        st.write("### æ•°æ®ç±»å‹ä¿¡æ¯")
        st.write(f"ä¼šå‘˜è´¦å·åˆ—çš„æ•°æ®ç±»å‹: {df['ä¼šå‘˜è´¦å·'].dtype}")
        
        # æ˜¾ç¤ºåŒ…å«ç‰¹æ®Šå­—ç¬¦çš„è´¦å·
        st.write("### åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„è´¦å·")
        special_chars = ['_', '-', '.', '@', '#', '$', '%', '&', '*']
        for char in special_chars:
            special_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(char, na=False, regex=False)]['ä¼šå‘˜è´¦å·'].unique()
            if len(special_accounts) > 0:
                st.write(f"åŒ…å« '{char}' çš„è´¦å· ({len(special_accounts)}ä¸ª):")
                for account in special_accounts[:10]:
                    st.code(f"  {account}")
                if len(special_accounts) > 10:
                    st.write(f"  ... è¿˜æœ‰ {len(special_accounts) - 10} ä¸ª")

# ==================== å¢å¼ºçš„å½©ç§è¯†åˆ«å™¨ ====================
class LotteryIdentifier:
    def __init__(self):
        self.lottery_configs = LOTTERY_CONFIGS
        # æ·»åŠ é€šç”¨å½©ç§å…³é”®è¯è¯†åˆ«
        self.general_keywords = {
            'PK10': ['pk10', 'pkæ‹¾', 'é£è‰‡', 'èµ›è½¦', 'èµ›è»Š', 'å¹¸è¿10', 'åŒ—äº¬èµ›è½¦', 'æé€Ÿèµ›è½¦'],
            'K3': ['å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 'éª°å®', 'ä¸‰å†›'],
            'LHC': ['å…­åˆ', 'lhc', 'å…­åˆå½©', 'â‘¥åˆ', '6åˆ', 'ç‰¹ç ', 'å¹³ç‰¹', 'è¿è‚–'],
            'SSC': ['æ—¶æ—¶å½©', 'ssc', 'åˆ†åˆ†å½©', 'æ™‚æ™‚å½©', 'é‡åº†æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©'],
            'THREE_COLOR': ['ä¸‰è‰²', 'ä¸‰è‰²å½©', 'ä¸‰è‰²çƒ'],
            # å¯ä»¥ç»§ç»­æ·»åŠ æ›´å¤šå½©ç§ç±»å‹
            '11é€‰5': ['11é€‰5', 'åä¸€é€‰äº”', 'å¹¿ä¸œ11é€‰5', 'å±±ä¸œ11é€‰5'],
            '3D': ['3d', 'ç¦å½©3d', 'ä½“å½©3d', 'æ’åˆ—ä¸‰'],
            'KL8': ['å¿«ä¹8', 'å¿«ä¹8', 'kl8', 'keno'],
            'MARK_SIX': ['mark six', 'ä¸‡å­—ç¥¨', 'æ•°å­—å½©']
        }
        
        # å½©ç§åˆ«åæ˜ å°„
        self.lottery_aliases = {
            'åˆ†åˆ†PKæ‹¾': 'PK10', 'ä¸‰åˆ†PKæ‹¾': 'PK10', 'äº”åˆ†PKæ‹¾': 'PK10',
            'æ–°å¹¸è¿é£è‰‡': 'PK10', 'æ¾³æ´²å¹¸è¿10': 'PK10', 'ä¸€åˆ†PK10': 'PK10',
            'å®¾æœPK10': 'PK10', 'æé€Ÿé£è‰‡': 'PK10', 'æ¾³æ´²é£è‰‡': 'PK10',
            'å¹¸è¿èµ›è½¦': 'PK10', 'åˆ†åˆ†èµ›è½¦': 'PK10', 'åŒ—äº¬PK10': 'PK10',
            'æ—§åŒ—äº¬PK10': 'PK10', 'æé€Ÿèµ›è½¦': 'PK10', 'å¹¸è¿èµ›è»Š': 'PK10',
            'åŒ—äº¬èµ›è½¦': 'PK10', 'æé€ŸPK10': 'PK10', 'å¹¸è¿PK10': 'PK10',
            # K3 åˆ«å
            'åˆ†åˆ†å¿«ä¸‰': 'K3', 'ä¸‰åˆ†å¿«3': 'K3', 'äº”åˆ†å¿«3': 'K3', 'æ¾³æ´²å¿«ä¸‰': 'K3',
            'å®¾æœå¿«ä¸‰': 'K3', '1åˆ†å¿«ä¸‰': 'K3', '3åˆ†å¿«ä¸‰': 'K3', '5åˆ†å¿«ä¸‰': 'K3',
            '10åˆ†å¿«ä¸‰': 'K3', 'åŠ å·å¿«ä¸‰': 'K3', 'å¹¸è¿å¿«ä¸‰': 'K3', 'å¤§å‘å¿«ä¸‰': 'K3',
            'æ¾³é—¨å¿«ä¸‰': 'K3', 'é¦™æ¸¯å¿«ä¸‰': 'K3', 'æ±Ÿè‹å¿«ä¸‰': 'K3',
            # LHC åˆ«å
            'æ–°æ¾³é—¨å…­åˆå½©': 'LHC', 'æ¾³é—¨å…­åˆå½©': 'LHC', 'é¦™æ¸¯å…­åˆå½©': 'LHC',
            'ä¸€åˆ†å…­åˆå½©': 'LHC', 'äº”åˆ†å…­åˆå½©': 'LHC', 'ä¸‰åˆ†å…­åˆå½©': 'LHC',
            'é¦™æ¸¯â‘¥åˆå½©': 'LHC', 'åˆ†åˆ†å…­åˆå½©': 'LHC', 'å¿«ä¹6åˆå½©': 'LHC',
            'æ¸¯â‘¥åˆå½©': 'LHC', 'å°æ¹¾å¤§ä¹é€': 'LHC', 'å¤§å‘å…­åˆå½©': 'LHC',
            # SSC åˆ«å
            'åˆ†åˆ†æ—¶æ—¶å½©': 'SSC', 'ä¸‰åˆ†æ—¶æ—¶å½©': 'SSC', 'äº”åˆ†æ—¶æ—¶å½©': 'SSC',
            'å®¾æœæ—¶æ—¶å½©': 'SSC', '1åˆ†æ—¶æ—¶å½©': 'SSC', '3åˆ†æ—¶æ—¶å½©': 'SSC',
            '5åˆ†æ—¶æ—¶å½©': 'SSC', 'æ—§é‡åº†æ—¶æ—¶å½©': 'SSC', 'å¹¸è¿æ—¶æ—¶å½©': 'SSC',
            'è…¾è®¯åˆ†åˆ†å½©': 'SSC', 'æ–°ç–†æ—¶æ—¶å½©': 'SSC', 'å¤©æ´¥æ—¶æ—¶å½©': 'SSC',
            'é‡åº†æ—¶æ—¶å½©': 'SSC', 'ä¸Šæµ·æ—¶æ—¶å½©': 'SSC', 'å¹¿ä¸œæ—¶æ—¶å½©': 'SSC',
            # ä¸‰è‰²å½©åˆ«å
            'ä¸€åˆ†ä¸‰è‰²å½©': 'THREE_COLOR', '30ç§’ä¸‰è‰²å½©': 'THREE_COLOR',
            'äº”åˆ†ä¸‰è‰²å½©': 'THREE_COLOR', 'ä¸‰åˆ†ä¸‰è‰²å½©': 'THREE_COLOR'
        }

    def identify_lottery_type(self, lottery_name):
        """å¢å¼ºçš„å½©ç§ç±»å‹è¯†åˆ« - è‡ªåŠ¨å­¦ä¹ æ–°å½©ç§"""
        lottery_str = str(lottery_name).strip()
        
        # 1. é¦–å…ˆæ£€æŸ¥åˆ«åæ˜ å°„
        if lottery_str in self.lottery_aliases:
            return self.lottery_aliases[lottery_str]
        
        # 2. æ£€æŸ¥é¢„è®¾å½©ç§åˆ—è¡¨
        for lottery_type, config in self.lottery_configs.items():
            for lottery in config['lotteries']:
                if lottery in lottery_str:
                    return lottery_type
        
        lottery_lower = lottery_str.lower()
        
        # 3. ä½¿ç”¨å…³é”®è¯è¯†åˆ«
        for lottery_type, keywords in self.general_keywords.items():
            for keyword in keywords:
                if keyword.lower() in lottery_lower:
                    return lottery_type
        
        # 4. æ™ºèƒ½æ¨¡å¼åŒ¹é…
        if self._is_pk10_like(lottery_lower):
            return 'PK10'
        elif self._is_k3_like(lottery_lower):
            return 'K3'
        elif self._is_lhc_like(lottery_lower):
            return 'LHC'
        elif self._is_ssc_like(lottery_lower):
            return 'SSC'
        elif self._is_three_color_like(lottery_lower):
            return 'THREE_COLOR'
        elif self._is_11x5_like(lottery_lower):
            return '11é€‰5'
        elif self._is_3d_like(lottery_lower):
            return '3D'
        elif self._is_kl8_like(lottery_lower):
            return 'KL8'
        
        # 5. å¦‚æœè¿˜æ˜¯æ— æ³•è¯†åˆ«ï¼Œè®°å½•å¹¶è¿”å›åŸåç§°ï¼Œè€Œä¸æ˜¯"æœªçŸ¥å½©ç§"
        return lottery_str  # è¿”å›åŸåç§°è€Œä¸æ˜¯"æœªçŸ¥å½©ç§"

    def _is_pk10_like(self, lottery_lower):
        """åˆ¤æ–­æ˜¯å¦ä¸ºPK10ç±»å½©ç§"""
        pk10_patterns = [
            r'.*pk.*10.*', r'.*pk.*æ‹¾.*', r'.*é£è‰‡.*', r'.*èµ›è½¦.*', 
            r'.*å¹¸è¿.*10.*', r'.*åŒ—äº¬.*è½¦.*', r'.*æé€Ÿ.*è½¦.*'
        ]
        return any(re.search(pattern, lottery_lower) for pattern in pk10_patterns)

    def _is_k3_like(self, lottery_lower):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¿«ä¸‰ç±»å½©ç§"""
        k3_patterns = [r'.*å¿«ä¸‰.*', r'.*å¿«3.*', r'.*k3.*', r'.*éª°å®.*', r'.*ä¸‰å†›.*']
        return any(re.search(pattern, lottery_lower) for pattern in k3_patterns)

    def _is_lhc_like(self, lottery_lower):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå…­åˆå½©ç±»å½©ç§"""
        lhc_patterns = [r'.*å…­åˆ.*', r'.*lhc.*', r'.*ç‰¹ç .*', r'.*å¹³ç‰¹.*', r'.*è¿è‚–.*']
        return any(re.search(pattern, lottery_lower) for pattern in lhc_patterns)

    def _is_ssc_like(self, lottery_lower):
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ—¶æ—¶å½©ç±»å½©ç§"""
        ssc_patterns = [r'.*æ—¶æ—¶å½©.*', r'.*ssc.*', r'.*åˆ†åˆ†å½©.*', r'.*\dæ˜Ÿ.*', r'.*å®šä½.*']
        return any(re.search(pattern, lottery_lower) for pattern in ssc_patterns)

    def _is_three_color_like(self, lottery_lower):
        """åˆ¤æ–­æ˜¯å¦ä¸ºä¸‰è‰²å½©ç±»å½©ç§"""
        return 'ä¸‰è‰²' in lottery_lower

    def _is_11x5_like(self, lottery_lower):
        """åˆ¤æ–­æ˜¯å¦ä¸º11é€‰5ç±»å½©ç§"""
        patterns = [r'.*11é€‰5.*', r'.*åä¸€é€‰äº”.*', r'.*\dé€‰\d.*']
        return any(re.search(pattern, lottery_lower) for pattern in patterns)

    def _is_3d_like(self, lottery_lower):
        """åˆ¤æ–­æ˜¯å¦ä¸º3Dç±»å½©ç§"""
        patterns = [r'.*3d.*', r'.*ç¦å½©.*', r'.*ä½“å½©.*', r'.*æ’åˆ—ä¸‰.*']
        return any(re.search(pattern, lottery_lower) for pattern in patterns)

    def _is_kl8_like(self, lottery_lower):
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¿«ä¹8ç±»å½©ç§"""
        patterns = [r'.*å¿«ä¹8.*', r'.*keno.*', r'.*kl8.*']
        return any(re.search(pattern, lottery_lower) for pattern in patterns)

    def learn_new_lottery(self, lottery_name, lottery_type):
        """å­¦ä¹ æ–°çš„å½©ç§æ˜ å°„"""
        self.lottery_aliases[lottery_name] = lottery_type
        # è¿™é‡Œå¯ä»¥æ·»åŠ å°†æ–°å­¦ä¹ çš„å½©ç§ä¿å­˜åˆ°æ–‡ä»¶æˆ–æ•°æ®åº“çš„é€»è¾‘

    def analyze_lottery_distribution(self, df):
        """åˆ†æå½©ç§åˆ†å¸ƒå¹¶è¯†åˆ«æœªçŸ¥å½©ç§"""
        if 'å½©ç§' not in df.columns:
            return {}
        
        lottery_counts = df['å½©ç§'].value_counts()
        identified_lotteries = {}
        unknown_lotteries = {}
        
        for lottery, count in lottery_counts.items():
            lottery_type = self.identify_lottery_type(lottery)
            if lottery_type == lottery:  # å¦‚æœè¿”å›åŸåç§°ï¼Œè¯´æ˜æ˜¯æœªçŸ¥å½©ç§
                unknown_lotteries[lottery] = count
            else:
                identified_lotteries[lottery] = lottery_type
        
        return {
            'identified': identified_lotteries,
            'unknown': unknown_lotteries,
            'total_identified': len(identified_lotteries),
            'total_unknown': len(unknown_lotteries)
        }

# ==================== ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤çš„ç©æ³•åˆ†ç±»å™¨ ====================
class PlayCategoryNormalizer:
    def __init__(self):
        self.category_mapping = self._create_category_mapping()
    
    def _create_category_mapping(self):
        """åˆ›å»ºç©æ³•åˆ†ç±»æ˜ å°„çš„å®Œæ•´æ˜ å°„"""
        mapping = {
            # å¿«ä¸‰ç©æ³•
            'å’Œå€¼': 'å’Œå€¼',
            'å’Œå€¼_å¤§å°å•åŒ': 'å’Œå€¼',
            'ä¸¤é¢': 'ä¸¤é¢',
            'äºŒä¸åŒå·': 'äºŒä¸åŒå·',
            'ä¸‰ä¸åŒå·': 'ä¸‰ä¸åŒå·',
            'ç‹¬èƒ†': 'ç‹¬èƒ†',
            'ç‚¹æ•°': 'å’Œå€¼',
            'ä¸‰å†›': 'ç‹¬èƒ†',
            'ä¸‰è»': 'ç‹¬èƒ†',
            'ä¸‰å†›_å¤§å°': 'ç‹¬èƒ†',
            'ä¸‰å†›_å•åŒ': 'ç‹¬èƒ†',
            
            # å…­åˆå½©ç©æ³•å®Œæ•´æ˜ å°„
            'ç‰¹ç ': 'ç‰¹ç ',
            'æ­£1ç‰¹': 'æ­£1ç‰¹',
            'æ­£ç ç‰¹_æ­£ä¸€ç‰¹': 'æ­£1ç‰¹',
            'æ­£2ç‰¹': 'æ­£2ç‰¹',
            'æ­£ç ç‰¹_æ­£äºŒç‰¹': 'æ­£2ç‰¹',
            'æ­£3ç‰¹': 'æ­£3ç‰¹',
            'æ­£ç ç‰¹_æ­£ä¸‰ç‰¹': 'æ­£3ç‰¹',
            'æ­£4ç‰¹': 'æ­£4ç‰¹',
            'æ­£ç ç‰¹_æ­£å››ç‰¹': 'æ­£4ç‰¹',
            'æ­£5ç‰¹': 'æ­£5ç‰¹',
            'æ­£ç ç‰¹_æ­£äº”ç‰¹': 'æ­£5ç‰¹',
            'æ­£6ç‰¹': 'æ­£6ç‰¹',
            'æ­£ç ç‰¹_æ­£å…­ç‰¹': 'æ­£6ç‰¹',
            'æ­£ç ': 'æ­£ç ',
            'æ­£ç‰¹': 'æ­£ç‰¹',
            'æ­£ç›ç‰¹': 'æ­£ç‰¹',
            'æ­£ç 1-6': 'æ­£ç ',
            
            # å°¾æ•°ç›¸å…³ç©æ³•ç‹¬ç«‹æ˜ å°„
            'å°¾æ•°': 'å°¾æ•°',
            'å°¾æ•°_å¤´å°¾æ•°': 'å°¾æ•°_å¤´å°¾æ•°',
            'ç‰¹å°¾': 'ç‰¹å°¾',
            'å…¨å°¾': 'å…¨å°¾',
            'å°¾æ•°_æ­£ç‰¹å°¾æ•°': 'å°¾æ•°',
            
            # å…¶ä»–å…­åˆå½©ç©æ³•
            'ç‰¹è‚–': 'ç‰¹è‚–',
            'ç”Ÿè‚–_ç‰¹è‚–': 'ç‰¹è‚–',
            'å¹³ç‰¹': 'å¹³ç‰¹',
            'ç”Ÿè‚–_æ­£è‚–': 'å¹³ç‰¹',
            'ç”Ÿè‚–_ä¸€è‚–': 'ä¸€è‚–',
            'è¿è‚–': 'è¿è‚–',
            'è¿å°¾': 'è¿å°¾',
            'é¾™è™': 'é¾™è™',
            'äº”è¡Œ': 'äº”è¡Œ',

            # æ³¢è‰²ç›¸å…³ç©æ³•
            'è‰²æ³¢': 'è‰²æ³¢',
            'ä¸ƒè‰²æ³¢': 'è‰²æ³¢',
            'æ³¢è‰²': 'è‰²æ³¢',

            #åŠæ³¢ç›¸å…³ç©æ³•æ˜ å°„
            'åŠæ³¢': 'åŠæ³¢',
            'è“æ³¢': 'åŠæ³¢',
            'ç»¿æ³¢': 'åŠæ³¢',
            'çº¢æ³¢': 'åŠæ³¢',
            'åŠæ³¢_çº¢æ³¢': 'åŠæ³¢',
            'åŠæ³¢_è“æ³¢': 'åŠæ³¢',
            'åŠæ³¢_ç»¿æ³¢': 'åŠæ³¢',

            # æ­£ç 1-6ç›¸å…³æ˜ å°„
            'æ­£ç 1-6': 'æ­£ç 1-6',
            'æ­£ç 1~6': 'æ­£ç 1-6',
            'æ­£ç 1-6ç‰¹': 'æ­£ç 1-6',
            'æ­£ç 1~6ç‰¹': 'æ­£ç 1-6',
            
            # æ—¶æ—¶å½©ç©æ³•
            'æ–—ç‰›': 'æ–—ç‰›',
            '1-5çƒ': '1-5çƒ',
            'ç¬¬1çƒ': 'ç¬¬1çƒ',
            'ç¬¬2çƒ': 'ç¬¬2çƒ',
            'ç¬¬3çƒ': 'ç¬¬3çƒ',
            'ç¬¬4çƒ': 'ç¬¬4çƒ',
            'ç¬¬5çƒ': 'ç¬¬5çƒ',
            'æ€»å’Œ': 'æ€»å’Œ',
            'æ­£ç ': 'æ­£ç ',
            'æ­£ç ç‰¹': 'æ­£ç ',
            'æ­£ç _ç‰¹': 'æ­£ç ',
            'å®šä½èƒ†': 'å®šä½èƒ†',
            'å®šä½_ä¸‡ä½': 'å®šä½_ä¸‡ä½',
            'å®šä½_åƒä½': 'å®šä½_åƒä½',
            'å®šä½_ç™¾ä½': 'å®šä½_ç™¾ä½',
            'å®šä½_åä½': 'å®šä½_åä½',
            'å®šä½_ä¸ªä½': 'å®šä½_ä¸ªä½',
            'ä¸¤é¢': 'ä¸¤é¢',
            
            # PKæ‹¾/èµ›è½¦ç©æ³•
            'å‰ä¸€': 'å† å†›',
            'å®šä½èƒ†': 'å®šä½èƒ†',
            '1-5å': '1-5å',
            '6-10å': '6-10å',
            'å† å†›': 'å† å†›',
            'äºšå†›': 'äºšå†›',
            'å­£å†›': 'ç¬¬ä¸‰å',
            'ç¬¬3å': 'ç¬¬ä¸‰å',
            'ç¬¬4å': 'ç¬¬å››å',
            'ç¬¬5å': 'ç¬¬äº”å',
            'ç¬¬6å': 'ç¬¬å…­å',
            'ç¬¬7å': 'ç¬¬ä¸ƒå',
            'ç¬¬8å': 'ç¬¬å…«å',
            'ç¬¬9å': 'ç¬¬ä¹å',
            'ç¬¬10å': 'ç¬¬åå',
            'åŒé¢': 'ä¸¤é¢',
            'å† äºšå’Œ': 'å† äºšå’Œ',
            'å† äºšå’Œ_å¤§å°å•åŒ': 'å† äºšå’Œ_å¤§å°å•åŒ',
            'å† äºšå’Œ_å’Œå€¼': 'å† äºšå’Œ_å’Œå€¼',
            
            # å¤§å°å•åŒç‹¬ç«‹ç©æ³•
            'å¤§å°_å† å†›': 'å¤§å°_å† å†›',
            'å¤§å°_äºšå†›': 'å¤§å°_äºšå†›',
            'å¤§å°_å­£å†›': 'å¤§å°_å­£å†›',
            'å•åŒ_å† å†›': 'å•åŒ_å† å†›',
            'å•åŒ_äºšå†›': 'å•åŒ_äºšå†›',
            'å•åŒ_å­£å†›': 'å•åŒ_å­£å†›',
            
            # é¾™è™ç‹¬ç«‹ç©æ³•
            'é¾™è™_å† å†›': 'é¾™è™_å† å†›',
            'é¾™è™_å†  å†›': 'é¾™è™_å† å†›',
            'é¾™è™_äºšå†›': 'é¾™è™_äºšå†›',
            'é¾™è™_äºš å†›': 'é¾™è™_äºšå†›',
            'é¾™è™_å­£å†›': 'é¾™è™_å­£å†›',
            'é¾™è™_å­£ å†›': 'é¾™è™_å­£å†›',
            
            # å®šä½èƒ†ç»†åˆ†
            'å®šä½èƒ†_ç¬¬1~5å': 'å®šä½èƒ†_ç¬¬1~5å',
            'å®šä½èƒ†_ç¬¬6~10å': 'å®šä½èƒ†_ç¬¬6~10å',
            'å®šä½èƒ†_1~5': 'å®šä½èƒ†_ç¬¬1~5å',
            'å®šä½èƒ†_6~10': 'å®šä½èƒ†_ç¬¬6~10å',
            'å®šä½èƒ†_1-5': 'å®šä½èƒ†_ç¬¬1~5å', 
            'å®šä½èƒ†_6-10': 'å®šä½èƒ†_ç¬¬6~10å',
            'å®šä½èƒ†_1~5å': 'å®šä½èƒ†_ç¬¬1~5å',
            'å®šä½èƒ†_6~10å': 'å®šä½èƒ†_ç¬¬6~10å',
            
            # å¤§å°å•åŒç©æ³•å˜ä½“
            'å¤§å°å•åŒ': 'ä¸¤é¢',
            'å¤§å°': 'å¤§å°',
            'å•åŒ': 'å•åŒ',
            
            # é¾™è™ç©æ³•å˜ä½“
            'é¾™è™æ–—': 'é¾™è™',
            'å† äºšé¾™è™': 'é¾™è™_å† å†›',
            'å† å†›é¾™è™': 'é¾™è™_å† å†›',
            
            # æ—¶æ—¶å½©å®šä½èƒ†å˜ä½“
            'å®šä½_ä¸‡ä½': 'å®šä½_ä¸‡ä½',
            'å®šä½_åƒä½': 'å®šä½_åƒä½', 
            'å®šä½_ç™¾ä½': 'å®šä½_ç™¾ä½',
            'å®šä½_åä½': 'å®šä½_åä½',
            'å®šä½_ä¸ªä½': 'å®šä½_ä¸ªä½',
            'ä¸‡ä½': 'å®šä½_ä¸‡ä½',
            'åƒä½': 'å®šä½_åƒä½',
            'ç™¾ä½': 'å®šä½_ç™¾ä½',
            'åä½': 'å®šä½_åä½',
            'ä¸ªä½': 'å®šä½_ä¸ªä½',
            
            # å…­åˆå½©ç©æ³•å˜ä½“
            'ç‰¹ç A': 'ç‰¹ç ',
            'ç‰¹ç B': 'ç‰¹ç ', 
            'æ­£ç A': 'æ­£ç ',
            'æ­£ç B': 'æ­£ç ',
            'æ­£ç 1': 'æ­£1ç‰¹',
            'æ­£ç 2': 'æ­£2ç‰¹',
            'æ­£ç 3': 'æ­£3ç‰¹',
            'æ­£ç 4': 'æ­£4ç‰¹',
            'æ­£ç 5': 'æ­£5ç‰¹',
            'æ­£ç 6': 'æ­£6ç‰¹',
            
            # ä¸‰è‰²å½©
            'æ­£ç ': 'æ­£ç ',
            'ä¸¤é¢': 'ä¸¤é¢',
            'è‰²æ³¢': 'è‰²æ³¢',
            'ç‰¹ç ': 'ç‰¹ç '
        }
        return mapping
    
    def normalize_category(self, category):
        """ç»Ÿä¸€ç©æ³•åˆ†ç±»åç§°"""
        category_str = str(category).strip()
        
        # ç›´æ¥æ˜ å°„
        if category_str in self.category_mapping:
            return self.category_mapping[category_str]
        
        # å…³é”®è¯åŒ¹é…
        for key, value in self.category_mapping.items():
            if key in category_str:
                return value
        
        category_lower = category_str.lower()
        
        # PK10/èµ›è½¦æ™ºèƒ½åŒ¹é…
        if any(word in category_lower for word in ['å®šä½èƒ†_ç¬¬1~5å', 'å®šä½èƒ†1~5', 'å®šä½èƒ†1-5']):
            return 'å®šä½èƒ†_ç¬¬1~5å'
        elif any(word in category_lower for word in ['å®šä½èƒ†_ç¬¬6~10å', 'å®šä½èƒ†6~10', 'å®šä½èƒ†6-10']):
            return 'å®šä½èƒ†_ç¬¬6~10å'
        elif any(word in category_lower for word in ['1-5å', '1~5å', '1-5', '1~5']):
            return '1-5å'
        elif any(word in category_lower for word in ['6-10å', '6~10å', '6-10', '6~10']):
            return '6-10å'
        elif any(word in category_lower for word in ['å† å†›', 'ç¬¬ä¸€å', 'ç¬¬1å', '1st']):
            return 'å† å†›'
        elif any(word in category_lower for word in ['äºšå†›', 'ç¬¬äºŒå', 'ç¬¬2å', '2nd']):
            return 'äºšå†›'
        elif any(word in category_lower for word in ['ç¬¬ä¸‰å', 'ç¬¬3å', 'å­£å†›', '3rd']):
            return 'ç¬¬ä¸‰å'
        elif any(word in category_lower for word in ['ç¬¬å››å', 'ç¬¬4å', '4th']):
            return 'ç¬¬å››å'
        elif any(word in category_lower for word in ['ç¬¬äº”å', 'ç¬¬5å', '5th']):
            return 'ç¬¬äº”å'
        elif any(word in category_lower for word in ['ç¬¬å…­å', 'ç¬¬6å', '6th']):
            return 'ç¬¬å…­å'
        elif any(word in category_lower for word in ['ç¬¬ä¸ƒå', 'ç¬¬7å', '7th']):
            return 'ç¬¬ä¸ƒå'
        elif any(word in category_lower for word in ['ç¬¬å…«å', 'ç¬¬8å', '8th']):
            return 'ç¬¬å…«å'
        elif any(word in category_lower for word in ['ç¬¬ä¹å', 'ç¬¬9å', '9th']):
            return 'ç¬¬ä¹å'
        elif any(word in category_lower for word in ['ç¬¬åå', 'ç¬¬10å', '10th']):
            return 'ç¬¬åå'
        elif any(word in category_lower for word in ['å‰ä¸€']):
            return 'å† å†›'
        
        # æ—¶æ—¶å½©å®šä½èƒ†æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ä¸‡ä½', 'ç¬¬ä¸€ä½', 'ç¬¬ä¸€çƒ']):
            return 'å®šä½_ä¸‡ä½'
        elif any(word in category_lower for word in ['åƒä½', 'ç¬¬äºŒä½', 'ç¬¬äºŒçƒ']):
            return 'å®šä½_åƒä½'
        elif any(word in category_lower for word in ['ç™¾ä½', 'ç¬¬ä¸‰ä½', 'ç¬¬ä¸‰çƒ']):
            return 'å®šä½_ç™¾ä½'
        elif any(word in category_lower for word in ['åä½', 'ç¬¬å››ä½', 'ç¬¬å››çƒ']):
            return 'å®šä½_åä½'
        elif any(word in category_lower for word in ['ä¸ªä½', 'ç¬¬äº”ä½', 'ç¬¬äº”çƒ']):
            return 'å®šä½_ä¸ªä½'
        elif any(word in category_lower for word in ['å®šä½èƒ†']):
            return 'å®šä½èƒ†'
        
        # å…­åˆå½©æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['ç‰¹ç ']):
            return 'ç‰¹ç '
        elif any(word in category_lower for word in ['æ­£ç ']):
            return 'æ­£ç '
        elif any(word in category_lower for word in ['æ­£ç‰¹', 'æ­£ç›ç‰¹']):
            return 'æ­£ç‰¹'
        elif any(word in category_lower for word in ['å°¾æ•°']):
            return 'å°¾æ•°'
        elif any(word in category_lower for word in ['å¹³ç‰¹']):
            return 'å¹³ç‰¹'
        elif any(word in category_lower for word in ['ç‰¹è‚–']):
            return 'ç‰¹è‚–'
        elif any(word in category_lower for word in ['ä¸€è‚–']):
            return 'ä¸€è‚–'
        elif any(word in category_lower for word in ['è¿è‚–']):
            return 'è¿è‚–'
        elif any(word in category_lower for word in ['è¿å°¾']):
            return 'è¿å°¾'
        elif any(word in category_lower for word in ['é¾™è™']):
            return 'é¾™è™'
        elif any(word in category_lower for word in ['äº”è¡Œ']):
            return 'äº”è¡Œ'
        elif any(word in category_lower for word in ['è‰²æ³¢', 'ä¸ƒè‰²æ³¢', 'æ³¢è‰²']):
            return 'è‰²æ³¢'
        elif any(word in category_lower for word in ['åŠæ³¢']):
            return 'åŠæ³¢'
        
        # å¿«ä¸‰æ™ºèƒ½åŒ¹é…
        elif any(word in category_lower for word in ['å’Œå€¼', 'ç‚¹æ•°']):
            return 'å’Œå€¼'
        elif any(word in category_lower for word in ['ç‹¬èƒ†', 'ä¸‰å†›', 'ä¸‰è»']):
            return 'ç‹¬èƒ†'
        elif any(word in category_lower for word in ['äºŒä¸åŒå·']):
            return 'äºŒä¸åŒå·'
        elif any(word in category_lower for word in ['ä¸‰ä¸åŒå·']):
            return 'ä¸‰ä¸åŒå·'
        
        return category_str

# ==================== å¢å¼ºçš„å¯¹åˆ·æ£€æµ‹å™¨ ====================
class WashTradeDetector:
    def __init__(self, config=None):
        self.config = config or Config()
        self.data_processor = DataProcessor()
        self.lottery_identifier = LotteryIdentifier()
        self.play_normalizer = PlayCategoryNormalizer()
        
        self.data_processed = False
        self.df_valid = None
        self.export_data = []
        
        # ä¿®æ­£ï¼šæŒ‰å½©ç§å­˜å‚¨è´¦æˆ·æ€»æŠ•æ³¨æœŸæ•°ç»Ÿè®¡
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        self.column_mapping_used = {}
        self.performance_stats = {}
    
    def upload_and_process(self, uploaded_file):
        """ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶ - ä½¿ç”¨å¢å¼ºçš„æ•°æ®å¤„ç†å™¨"""
        try:
            if uploaded_file is None:
                st.error("âŒ æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
                return None, None
            
            filename = uploaded_file.name
            logger.info(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {filename}")
            
            if not any(filename.endswith(ext) for ext in self.config.supported_file_types):
                st.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
                return None, None
            
            # ä½¿ç”¨å¢å¼ºçš„æ•°æ®å¤„ç†å™¨
            with st.spinner("ğŸ”„ æ­£åœ¨æ¸…æ´—æ•°æ®..."):
                df_clean = self.data_processor.clean_data(uploaded_file)
            
            if df_clean is not None and len(df_clean) > 0:
                # å¢å¼ºçš„æ•°æ®å¤„ç†
                df_enhanced = self.enhance_data_processing(df_clean)
                return df_enhanced, filename
            else:
                return None, None
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            return None, None
    
    def enhance_data_processing(self, df_clean):
        """å¢å¼ºçš„æ•°æ®å¤„ç†æµç¨‹ - ä¿®å¤å½©ç§åç§°æ˜¾ç¤ºé—®é¢˜"""
        try:
            # 0. å…ˆåˆ†æå½©ç§åˆ†å¸ƒ
            lottery_analysis = self.lottery_identifier.analyze_lottery_distribution(df_clean)
            
            # æ˜¾ç¤ºå½©ç§åˆ†æç»“æœ
            if lottery_analysis['total_unknown'] > 0:
                st.warning(f"å‘ç° {lottery_analysis['total_unknown']} ä¸ªæ–°å½©ç§ï¼Œç³»ç»Ÿæ­£åœ¨è‡ªåŠ¨å­¦ä¹ ...")
                with st.expander("ğŸ” æ–°å½©ç§è¯¦æƒ…", expanded=True):
                    st.write("**æ–°å‘ç°çš„å½©ç§:**")
                    for lottery, count in lottery_analysis['unknown'].items():
                        st.write(f"- {lottery}: {count} æ¡è®°å½•")
            
            # 1. å½©ç§è¯†åˆ« - ä¿ç•™åŸå§‹å½©ç§åç§°ï¼ŒåŒæ—¶æ·»åŠ å½©ç§ç±»å‹
            if 'å½©ç§' in df_clean.columns:
                # ä¿å­˜åŸå§‹å½©ç§åç§°
                df_clean['åŸå§‹å½©ç§'] = df_clean['å½©ç§']
                
                # æ·»åŠ å½©ç§ç±»å‹åˆ†ç±»
                df_clean['å½©ç§ç±»å‹'] = df_clean['å½©ç§'].apply(self.lottery_identifier.identify_lottery_type)
                
                # æ˜¾ç¤ºå½©ç§è¯†åˆ«ç»Ÿè®¡
                identified_stats = df_clean['å½©ç§ç±»å‹'].value_counts()
                with st.expander("ğŸ¯ å½©ç§è¯†åˆ«ç»Ÿè®¡", expanded=False):
                    st.dataframe(identified_stats.reset_index().rename(
                        columns={'index': 'å½©ç§ç±»å‹', 'å½©ç§ç±»å‹': 'æ•°é‡'}
                    ))
            
            # 2. ç©æ³•åˆ†ç±»ç»Ÿä¸€
            if 'ç©æ³•' in df_clean.columns:
                df_clean['ç©æ³•åˆ†ç±»'] = df_clean['ç©æ³•'].apply(self.play_normalizer.normalize_category)
            
            # 3. è®¡ç®—è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯ - ä½¿ç”¨åŸå§‹å½©ç§åç§°
            self.calculate_account_total_periods_by_lottery(df_clean)
            
            # 4. æå–æŠ•æ³¨é‡‘é¢å’Œæ–¹å‘
            df_clean['æŠ•æ³¨é‡‘é¢'] = df_clean['é‡‘é¢'].apply(lambda x: self.extract_bet_amount_safe(x))
            df_clean['æŠ•æ³¨æ–¹å‘'] = df_clean['å†…å®¹'].apply(lambda x: self.enhanced_extract_direction(x))
            
            # è¿‡æ»¤æœ‰æ•ˆè®°å½•
            df_valid = df_clean[
                (df_clean['æŠ•æ³¨æ–¹å‘'] != '') & 
                (df_clean['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
            ].copy()
            
            if len(df_valid) == 0:
                st.error("âŒ è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆè®°å½•")
                return pd.DataFrame()
            
            self.data_processed = True
            self.df_valid = df_valid
            
            # æ˜¾ç¤ºè´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
            self.display_account_statistics(df_valid)
            
            return df_valid
            
        except Exception as e:
            logger.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            st.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def display_account_statistics(self, df_valid):
        """æ˜¾ç¤ºè´¦æˆ·ç»Ÿè®¡ä¿¡æ¯"""
        with st.expander("ğŸ“Š è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯", expanded=False):
            # æ˜¾ç¤ºæ¯ä¸ªå½©ç§çš„è´¦æˆ·ç»Ÿè®¡
            for lottery in df_valid['åŸå§‹å½©ç§'].unique():
                df_lottery = df_valid[df_valid['åŸå§‹å½©ç§'] == lottery]
                account_stats = df_lottery.groupby('ä¼šå‘˜è´¦å·').agg({
                    'æœŸå·': 'nunique',
                    'æŠ•æ³¨é‡‘é¢': 'count'
                }).rename(columns={'æœŸå·': 'æŠ•æ³¨æœŸæ•°', 'æŠ•æ³¨é‡‘é¢': 'è®°å½•æ•°'})
                
                st.write(f"**{lottery}** è´¦æˆ·ç»Ÿè®¡:")
                st.dataframe(account_stats.head(20))  # åªæ˜¾ç¤ºå‰20ä¸ªè´¦æˆ·
    
    def extract_bet_amount_safe(self, amount_text):
        """å®‰å…¨æå–æŠ•æ³¨é‡‘é¢ - æ”¹è¿›ç‰ˆæœ¬"""
        try:
            if pd.isna(amount_text):
                return 0
            
            text = str(amount_text).strip()
            
            # é¦–å…ˆå°è¯•ç›´æ¥è½¬æ¢
            try:
                cleaned_text = text.replace(',', '').replace('ï¼Œ', '').replace(' ', '')
                if re.match(r'^-?\d+(\.\d+)?$', cleaned_text):
                    amount = float(cleaned_text)
                    if amount >= self.config.min_amount:
                        return amount
            except:
                pass
            
            # ä½¿ç”¨å¤šç§æ¨¡å¼åŒ¹é…
            patterns = [
                r'æŠ•æ³¨[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'ä¸‹æ³¨[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'é‡‘é¢[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'æ€»é¢[:ï¼š]?\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'(\d+[,ï¼Œ]?\d*\.?\d*)\s*å…ƒ',
                r'ï¿¥\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'Â¥\s*(\d+[,ï¼Œ]?\d*\.?\d*)',
                r'[\$ï¿¥Â¥]?\s*(\d+[,ï¼Œ]?\d*\.?\d+)',
                r'(\d+[,ï¼Œ]?\d*\.?\d+)',
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text)
                if match:
                    amount_str = match.group(1).replace(',', '').replace('ï¼Œ', '').replace(' ', '')
                    try:
                        amount = float(amount_str)
                        if amount >= self.config.min_amount:
                            return amount
                    except:
                        continue
            
            # æœ€åå°è¯•æå–æ‰€æœ‰æ•°å­—
            numbers = re.findall(r'\d+\.?\d*', text)
            if numbers:
                try:
                    amount = float(numbers[0])
                    if amount >= self.config.min_amount:
                        return amount
                except:
                    pass
            
            return 0
            
        except Exception as e:
            logger.warning(f"é‡‘é¢æå–å¤±è´¥: {amount_text}, é”™è¯¯: {e}")
            return 0
    
    def enhanced_extract_direction(self, content):
        """å¢å¼ºçš„æŠ•æ³¨æ–¹å‘æå– - ç»“åˆç©æ³•åˆ†ç±»"""
        try:
            if pd.isna(content):
                return ""
            
            content_str = str(content).strip().lower()
            
            # åŸºç¡€æ–¹å‘æå–
            for direction, patterns in self.config.direction_patterns.items():
                for pattern in patterns:
                    if pattern.lower() in content_str:
                        return direction
            
            return ""
        except Exception as e:
            logger.warning(f"æ–¹å‘æå–å¤±è´¥: {content}, é”™è¯¯: {e}")
            return ""
    
    def calculate_account_total_periods_by_lottery(self, df):
        """ä¿®æ­£ï¼šæŒ‰å½©ç§è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°ç»Ÿè®¡ï¼ˆä½¿ç”¨åŸå§‹å½©ç§åç§°ï¼‰"""
        self.account_total_periods_by_lottery = defaultdict(dict)
        self.account_record_stats_by_lottery = defaultdict(dict)
        
        # ä½¿ç”¨åŸå§‹å½©ç§åç§°è¿›è¡Œåˆ†ç»„ï¼Œè€Œä¸æ˜¯å½©ç§ç±»å‹
        lottery_col = 'åŸå§‹å½©ç§' if 'åŸå§‹å½©ç§' in df.columns else 'å½©ç§'
        
        for lottery in df[lottery_col].unique():
            df_lottery = df[df[lottery_col] == lottery]
            
            # è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„æ€»æŠ•æ³¨æœŸæ•°ï¼ˆå”¯ä¸€æœŸå·æ•°ï¼‰
            period_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·')['æœŸå·'].nunique().to_dict()
            self.account_total_periods_by_lottery[lottery] = period_counts
            
            # è®¡ç®—æ¯ä¸ªè´¦æˆ·çš„è®°å½•æ•°
            record_counts = df_lottery.groupby('ä¼šå‘˜è´¦å·').size().to_dict()
            self.account_record_stats_by_lottery[lottery] = record_counts
    
    def detect_all_wash_trades(self):
        """æ£€æµ‹æ‰€æœ‰ç±»å‹çš„å¯¹åˆ·äº¤æ˜“"""
        if not self.data_processed or self.df_valid is None or len(self.df_valid) == 0:
            st.error("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯ç”¨äºæ£€æµ‹")
            return []
        
        self.performance_stats = {
            'start_time': datetime.now(),
            'total_records': len(self.df_valid),
            'total_periods': self.df_valid['æœŸå·'].nunique(),
            'total_accounts': self.df_valid['ä¼šå‘˜è´¦å·'].nunique()
        }
        
        df_filtered = self.exclude_multi_direction_accounts(self.df_valid)
        
        if len(df_filtered) == 0:
            st.error("âŒ è¿‡æ»¤åæ— æœ‰æ•ˆæ•°æ®")
            return []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_patterns = []
        total_steps = self.config.max_accounts_in_group - 1
        
        for account_count in range(2, self.config.max_accounts_in_group + 1):
            status_text.text(f"ğŸ” æ£€æµ‹{account_count}ä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼...")
            patterns = self.detect_n_account_patterns_optimized(df_filtered, account_count)
            all_patterns.extend(patterns)
            
            progress = (account_count - 1) / total_steps
            progress_bar.progress(progress)
        
        progress_bar.progress(1.0)
        status_text.text("âœ… æ£€æµ‹å®Œæˆ")
        
        self.performance_stats['end_time'] = datetime.now()
        self.performance_stats['detection_time'] = (
            self.performance_stats['end_time'] - self.performance_stats['start_time']
        ).total_seconds()
        self.performance_stats['total_patterns'] = len(all_patterns)
        
        self.display_performance_stats()
        
        return all_patterns
    
    def detect_n_account_patterns_optimized(self, df_filtered, n_accounts):
        """ä¼˜åŒ–ç‰ˆçš„Nä¸ªè´¦æˆ·å¯¹åˆ·æ¨¡å¼æ£€æµ‹ - ä½¿ç”¨åŸå§‹å½©ç§åç§°"""
        wash_records = []
        
        # ä½¿ç”¨åŸå§‹å½©ç§åç§°è¿›è¡Œåˆ†ç»„ï¼Œè€Œä¸æ˜¯å½©ç§ç±»å‹
        period_groups = df_filtered.groupby(['æœŸå·', 'åŸå§‹å½©ç§'])
        
        valid_direction_combinations = self._get_valid_direction_combinations(n_accounts)
        
        batch_size = 100
        period_keys = list(period_groups.groups.keys())
        
        for i in range(0, len(period_keys), batch_size):
            batch_keys = period_keys[i:i+batch_size]
            
            for period_key in batch_keys:
                period_data = period_groups.get_group(period_key)
                period_accounts = period_data['ä¼šå‘˜è´¦å·'].unique()
                
                if len(period_accounts) < n_accounts:
                    continue
                
                batch_patterns = self._detect_combinations_for_period(
                    period_data, period_accounts, n_accounts, valid_direction_combinations
                )
                wash_records.extend(batch_patterns)
        
        return self.find_continuous_patterns_optimized(wash_records)
    
    def _get_valid_direction_combinations(self, n_accounts):
        """è·å–æœ‰æ•ˆçš„æ–¹å‘ç»„åˆ - ä¿®å¤ç‰ˆæœ¬"""
        valid_combinations = []
        
        # å¯¹äº2ä¸ªè´¦æˆ·ï¼šæ ‡å‡†çš„å¯¹ç«‹ç»„
        if n_accounts == 2:
            for opposites in self.config.opposite_groups:
                dir1, dir2 = list(opposites)
                valid_combinations.append({
                    'directions': [dir1, dir2],
                    'dir1_count': 1,
                    'dir2_count': 1,
                    'opposite_type': f"{dir1}-{dir2}"
                })
        
        # å¯¹äº3ä¸ªåŠä»¥ä¸Šè´¦æˆ·ï¼šå…è®¸å¤šç§åˆ†å¸ƒ
        else:
            for opposites in self.config.opposite_groups:
                dir1, dir2 = list(opposites)
                
                # å¯¹äºnä¸ªè´¦æˆ·ï¼Œå…è®¸ä»1åˆ°n-1çš„å„ç§åˆ†å¸ƒ
                for i in range(1, n_accounts):
                    j = n_accounts - i
                    valid_combinations.append({
                        'directions': [dir1] * i + [dir2] * j,
                        'dir1_count': i,
                        'dir2_count': j,
                        'opposite_type': f"{dir1}-{dir2}"
                    })
        
        return valid_combinations
    
    def _detect_combinations_for_period(self, period_data, period_accounts, n_accounts, valid_combinations):
        """ä¸ºå•ä¸ªæœŸå·æ£€æµ‹ç»„åˆ - ä¿®å¤ç‰ˆæœ¬"""
        patterns = []
        
        # æ„å»ºè´¦æˆ·ä¿¡æ¯å­—å…¸
        account_info = {}
        for _, row in period_data.iterrows():
            account = row['ä¼šå‘˜è´¦å·']
            direction = row['æŠ•æ³¨æ–¹å‘']
            amount = row['æŠ•æ³¨é‡‘é¢']
            
            if account not in account_info:
                account_info[account] = []
            account_info[account].append({
                'direction': direction,
                'amount': amount
            })
        
        # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„è´¦æˆ·ç»„åˆ
        for account_group in combinations(period_accounts, n_accounts):
            # æ£€æŸ¥è¿™ä¸ªè´¦æˆ·ç»„æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ–¹å‘ç»„åˆ
            group_directions = []
            group_amounts = []
            
            # æ”¶é›†è¿™ä¸ªè´¦æˆ·ç»„çš„æ‰€æœ‰æ–¹å‘å’Œé‡‘é¢
            for account in account_group:
                if account in account_info:
                    # åªå–æ¯ä¸ªè´¦æˆ·çš„ç¬¬ä¸€ä¸ªæŠ•æ³¨è®°å½•ï¼ˆå‡è®¾ä¸€ä¸ªè´¦æˆ·åœ¨ä¸€ä¸ªæœŸå·åªæœ‰ä¸€ä¸ªæ–¹å‘ï¼‰
                    if account_info[account]:
                        first_bet = account_info[account][0]
                        group_directions.append(first_bet['direction'])
                        group_amounts.append(first_bet['amount'])
            
            # å¦‚æœæ”¶é›†åˆ°çš„æ–¹å‘æ•°é‡ä¸ç­‰äºè´¦æˆ·æ•°é‡ï¼Œè·³è¿‡
            if len(group_directions) != n_accounts:
                continue
            
            # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æœ‰æ•ˆçš„æ–¹å‘ç»„åˆ
            for combo in valid_combinations:
                target_directions = combo['directions']
                
                # æ£€æŸ¥å®é™…æ–¹å‘æ˜¯å¦ä¸ç›®æ ‡æ–¹å‘åŒ¹é…ï¼ˆè€ƒè™‘é¡ºåºï¼‰
                actual_directions_sorted = sorted(group_directions)
                target_directions_sorted = sorted(target_directions)
                
                if actual_directions_sorted == target_directions_sorted:
                    # è®¡ç®—ä¸¤ä¸ªæ–¹å‘çš„æ€»é‡‘é¢
                    dir1_total = 0
                    dir2_total = 0
                    dir1 = combo['opposite_type'].split('-')[0]
                    
                    for direction, amount in zip(group_directions, group_amounts):
                        if direction == dir1:
                            dir1_total += amount
                        else:
                            dir2_total += amount
                    
                    # æ£€æŸ¥é‡‘é¢ç›¸ä¼¼åº¦
                    if dir1_total > 0 and dir2_total > 0:
                        similarity = min(dir1_total, dir2_total) / max(dir1_total, dir2_total)
                        
                        if similarity >= self.config.amount_similarity_threshold:
                            # è·å–å½©ç§ä¿¡æ¯ - ä½¿ç”¨åŸå§‹å½©ç§åç§°
                            lottery = period_data['åŸå§‹å½©ç§'].iloc[0] if 'åŸå§‹å½©ç§' in period_data.columns else period_data['å½©ç§'].iloc[0]
                            lottery_type = period_data['å½©ç§ç±»å‹'].iloc[0] if 'å½©ç§ç±»å‹' in period_data.columns else 'æœªçŸ¥'
                            
                            record = {
                                'æœŸå·': period_data['æœŸå·'].iloc[0],
                                'å½©ç§': lottery,  # ä½¿ç”¨åŸå§‹å½©ç§åç§°
                                'å½©ç§ç±»å‹': lottery_type,  # æ·»åŠ å½©ç§ç±»å‹
                                'è´¦æˆ·ç»„': list(account_group),
                                'æ–¹å‘ç»„': group_directions,
                                'é‡‘é¢ç»„': group_amounts,
                                'æ€»é‡‘é¢': dir1_total + dir2_total,
                                'ç›¸ä¼¼åº¦': similarity,
                                'è´¦æˆ·æ•°é‡': n_accounts,
                                'æ¨¡å¼': f"{combo['opposite_type'].split('-')[0]}({combo['dir1_count']}ä¸ª) vs {combo['opposite_type'].split('-')[1]}({combo['dir2_count']}ä¸ª)",
                                'å¯¹ç«‹ç±»å‹': combo['opposite_type']
                            }
                            
                            patterns.append(record)
        
        return patterns
    
    def find_continuous_patterns_optimized(self, wash_records):
        """ä¼˜åŒ–ç‰ˆçš„è¿ç»­å¯¹åˆ·æ¨¡å¼æ£€æµ‹ - ä½¿ç”¨åŸå§‹å½©ç§åç§°"""
        if not wash_records:
            return []
        
        account_group_patterns = defaultdict(list)
        for record in wash_records:
            # ä½¿ç”¨åŸå§‹å½©ç§åç§°è¿›è¡Œåˆ†ç»„
            account_group_key = (tuple(sorted(record['è´¦æˆ·ç»„'])), record['å½©ç§'])
            account_group_patterns[account_group_key].append(record)
        
        continuous_patterns = []
        
        for (account_group, lottery), records in account_group_patterns.items():
            sorted_records = sorted(records, key=lambda x: x['æœŸå·'])
            
            # ä¿®æ­£ï¼šæ ¹æ®è´¦æˆ·ç»„çš„æ€»æŠ•æ³¨æœŸæ•°ç¡®å®šæœ€å°å¯¹åˆ·æœŸæ•°è¦æ±‚
            required_min_periods = self.get_required_min_periods(account_group, lottery)
            
            # è°ƒè¯•ä¿¡æ¯
            account_count = len(account_group)
            if account_count > 2:  # åªå¯¹3ä¸ªåŠä»¥ä¸Šè´¦æˆ·æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                st.write(f"  è°ƒè¯•: è´¦æˆ·ç»„{account_group}åœ¨{lottery}æœ‰{len(sorted_records)}æœŸå¯¹åˆ·ï¼Œè¦æ±‚{required_min_periods}æœŸ")
            
            if len(sorted_records) >= required_min_periods:
                total_investment = sum(r['æ€»é‡‘é¢'] for r in sorted_records)
                similarities = [r['ç›¸ä¼¼åº¦'] for r in sorted_records]
                avg_similarity = np.mean(similarities) if similarities else 0
                
                opposite_type_counts = defaultdict(int)
                for record in sorted_records:
                    opposite_type_counts[record['å¯¹ç«‹ç±»å‹']] += 1
                
                pattern_count = defaultdict(int)
                for record in sorted_records:
                    pattern_count[record['æ¨¡å¼']] += 1
                
                main_opposite_type = max(opposite_type_counts.items(), key=lambda x: x[1])[0]
                
                # ä¿®æ­£ï¼šæ˜¾ç¤ºæ¯ä¸ªè´¦æˆ·çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
                account_stats_info = []
                total_periods_stats = self.account_total_periods_by_lottery.get(lottery, {})
                record_stats = self.account_record_stats_by_lottery.get(lottery, {})
                
                for account in account_group:
                    total_periods = total_periods_stats.get(account, 0)
                    records_count = record_stats.get(account, 0)
                    account_stats_info.append(f"{account}({total_periods}æœŸ/{records_count}è®°å½•)")
                
                activity_level = self.get_account_group_activity_level(account_group, lottery)
                
                continuous_patterns.append({
                    'è´¦æˆ·ç»„': list(account_group),
                    'å½©ç§': lottery,  # å®Œæ•´çš„åŸå§‹å½©ç§åç§°
                    'å½©ç§ç±»å‹': records[0]['å½©ç§ç±»å‹'] if records else 'æœªçŸ¥',
                    'è´¦æˆ·æ•°é‡': len(account_group),
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': main_opposite_type,
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': dict(opposite_type_counts),
                    'å¯¹åˆ·æœŸæ•°': len(sorted_records),
                    'æ€»æŠ•æ³¨é‡‘é¢': total_investment,
                    'å¹³å‡ç›¸ä¼¼åº¦': avg_similarity,
                    'æ¨¡å¼åˆ†å¸ƒ': dict(pattern_count),
                    'è¯¦ç»†è®°å½•': sorted_records,
                    'è´¦æˆ·æ´»è·ƒåº¦': activity_level,
                    'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': account_stats_info,
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': required_min_periods
                })
        
        return continuous_patterns

    def exclude_multi_direction_accounts(self, df_valid):
        """æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨"""
        multi_direction_mask = (
            df_valid.groupby(['æœŸå·', 'ä¼šå‘˜è´¦å·'])['æŠ•æ³¨æ–¹å‘']
            .transform('nunique') > 1
        )
        
        df_filtered = df_valid[~multi_direction_mask].copy()
        
        return df_filtered
    
    def get_account_group_activity_level(self, account_group, lottery):
        """ä¿®æ­£ï¼šæ ¹æ®è´¦æˆ·ç»„åœ¨ç‰¹å®šå½©ç§çš„æ€»æŠ•æ³¨æœŸæ•°è·å–æ´»è·ƒåº¦æ°´å¹³"""
        if lottery not in self.account_total_periods_by_lottery:
            return 'unknown'
        
        total_periods_stats = self.account_total_periods_by_lottery[lottery]
        
        # è®¡ç®—è´¦æˆ·ç»„ä¸­åœ¨æŒ‡å®šå½©ç§çš„æœ€å°æ€»æŠ•æ³¨æœŸæ•°ï¼ˆç”¨äºæ´»è·ƒåº¦åˆ¤æ–­ï¼‰
        min_total_periods = min(total_periods_stats.get(account, 0) for account in account_group)
        
        # æŒ‰ç…§æ‚¨è¦æ±‚çš„æ´»è·ƒåº¦é˜ˆå€¼è®¾ç½®
        if min_total_periods <= self.config.period_thresholds['low_activity']:
            return 'low'        # æ€»æŠ•æ³¨æœŸæ•°â‰¤10
        elif min_total_periods <= self.config.period_thresholds['medium_activity_high']:
            return 'medium'     # æ€»æŠ•æ³¨æœŸæ•°11-200
        else:
            return 'high'       # æ€»æŠ•æ³¨æœŸæ•°â‰¥201
    
    def get_required_min_periods(self, account_group, lottery):
        """ä¿®æ­£ï¼šæ ¹æ®è´¦æˆ·ç»„çš„æ€»æŠ•æ³¨æœŸæ•°æ´»è·ƒåº¦è·å–æ‰€éœ€çš„æœ€å°å¯¹åˆ·æœŸæ•°"""
        activity_level = self.get_account_group_activity_level(account_group, lottery)
        
        if activity_level == 'low':
            return self.config.period_thresholds['min_periods_low']    # 3æœŸ
        elif activity_level == 'medium':
            return self.config.period_thresholds['min_periods_medium'] # 5æœŸ
        else:
            return self.config.period_thresholds['min_periods_high']   # 8æœŸ
    
    def display_performance_stats(self):
        """æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡"""
        if not self.performance_stats:
            return
        
        with st.expander("ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡", expanded=False):
            st.write(f"**æ•°æ®å¤„ç†ç»Ÿè®¡:**")
            st.write(f"- æ€»è®°å½•æ•°: {self.performance_stats['total_records']:,}")
            st.write(f"- æ€»æœŸå·æ•°: {self.performance_stats['total_periods']:,}")
            st.write(f"- æ€»è´¦æˆ·æ•°: {self.performance_stats['total_accounts']:,}")
            
            if 'detection_time' in self.performance_stats:
                st.write(f"**æ£€æµ‹æ€§èƒ½:**")
                st.write(f"- æ£€æµ‹æ—¶é—´: {self.performance_stats['detection_time']:.2f} ç§’")
                st.write(f"- å‘ç°æ¨¡å¼: {self.performance_stats['total_patterns']} ä¸ª")
                
                if self.performance_stats['detection_time'] > 0:
                    records_per_second = self.performance_stats['total_records'] / self.performance_stats['detection_time']
                    st.write(f"- å¤„ç†é€Ÿåº¦: {records_per_second:.1f} æ¡è®°å½•/ç§’")
    
    def display_detailed_results(self, patterns):
        """æ˜¾ç¤ºè¯¦ç»†æ£€æµ‹ç»“æœ - ä½¿ç”¨å®Œæ•´çš„åŸå§‹å½©ç§åç§°"""
        st.write("\n" + "="*60)
        st.write("ğŸ¯ å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç»“æœ")
        st.write("="*60)
        
        if not patterns:
            st.error("âŒ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„è¿ç»­å¯¹åˆ·æ¨¡å¼")
            return
        
        # æŒ‰å®Œæ•´çš„åŸå§‹å½©ç§åç§°åˆ†ç»„
        patterns_by_lottery = defaultdict(list)
        for pattern in patterns:
            # ä½¿ç”¨å®Œæ•´çš„åŸå§‹å½©ç§åç§°è¿›è¡Œåˆ†ç»„
            lottery_key = pattern['å½©ç§']
            patterns_by_lottery[lottery_key].append(pattern)
        
        for lottery, lottery_patterns in patterns_by_lottery.items():
            # ä½¿ç”¨expanderåŒ…è£…æ¯ä¸ªå½©ç§ï¼Œé»˜è®¤å±•å¼€
            with st.expander(f"ğŸ² å½©ç§ï¼š{lottery}ï¼ˆå‘ç°{len(lottery_patterns)}ç»„ï¼‰", expanded=True):
                for i, pattern in enumerate(lottery_patterns, 1):
                    # å¯¹åˆ·ç»„ä¿¡æ¯
                    st.markdown(f"**å¯¹åˆ·ç»„ {i}:** {' â†” '.join(pattern['è´¦æˆ·ç»„'])}")
                    
                    # æ´»è·ƒåº¦ä¿¡æ¯
                    activity_icon = "ğŸŸ¢" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'low' else "ğŸŸ¡" if pattern['è´¦æˆ·æ´»è·ƒåº¦'] == 'medium' else "ğŸ”´"
                    st.markdown(f"**æ´»è·ƒåº¦:** {activity_icon} {pattern['è´¦æˆ·æ´»è·ƒåº¦']} | **å½©ç§:** {pattern['å½©ç§']} | **ä¸»è¦ç±»å‹:** {pattern['ä¸»è¦å¯¹ç«‹ç±»å‹']}")
                    
                    # è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
                    st.markdown(f"**è´¦æˆ·åœ¨è¯¥å½©ç§æŠ•æ³¨æœŸæ•°/è®°å½•æ•°:** {', '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯'])}")
                    
                    # å¯¹åˆ·æœŸæ•°
                    st.markdown(f"**å¯¹åˆ·æœŸæ•°:** {pattern['å¯¹åˆ·æœŸæ•°']}æœŸ (è¦æ±‚â‰¥{pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°']}æœŸ)")
                    
                    # é‡‘é¢ä¿¡æ¯
                    st.markdown(f"**æ€»é‡‘é¢:** {pattern['æ€»æŠ•æ³¨é‡‘é¢']:.2f}å…ƒ | **å¹³å‡åŒ¹é…:** {pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}")
                    
                    # è¯¦ç»†è®°å½• - ç›´æ¥å±•å¼€æ˜¾ç¤º
                    st.markdown("**è¯¦ç»†è®°å½•:**")
                    for j, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                        account_directions = []
                        for account, direction, amount in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„']):
                            account_directions.append(f"{account}({direction}:{amount})")
                        
                        st.markdown(f"{j}. **æœŸå·:** {record['æœŸå·']} | **æ¨¡å¼:** {record['æ¨¡å¼']} | **æ–¹å‘:** {' â†” '.join(account_directions)} | **åŒ¹é…åº¦:** {record['ç›¸ä¼¼åº¦']:.2%}")
                    
                    # å¯¹åˆ·ç»„ä¹‹é—´çš„åˆ†éš”çº¿
                    if i < len(lottery_patterns):
                        st.markdown("---")
        
        self.display_summary_statistics(patterns)
    
    def display_summary_statistics(self, patterns):
        """æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡"""
        if not patterns:
            return
            
        st.write(f"\n{'='*60}")
        st.write("ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        st.write(f"{'='*60}")
        
        total_groups = len(patterns)
        total_accounts = sum(p['è´¦æˆ·æ•°é‡'] for p in patterns)
        total_wash_periods = sum(p['å¯¹åˆ·æœŸæ•°'] for p in patterns)
        total_amount = sum(p['æ€»æŠ•æ³¨é‡‘é¢'] for p in patterns)
        
        account_count_stats = defaultdict(int)
        for pattern in patterns:
            account_count_stats[pattern['è´¦æˆ·æ•°é‡']] += 1
        
        lottery_stats = defaultdict(int)
        for pattern in patterns:
            lottery_stats[pattern['å½©ç§']] += 1
        
        # æ´»è·ƒåº¦åˆ†å¸ƒ
        activity_stats = defaultdict(int)
        for pattern in patterns:
            activity_stats[pattern['è´¦æˆ·æ´»è·ƒåº¦']] += 1
        
        # å¯¹ç«‹ç±»å‹åˆ†å¸ƒ
        opposite_type_stats = defaultdict(int)
        for pattern in patterns:
            for opposite_type, count in pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ'].items():
                opposite_type_stats[opposite_type] += count
        
        st.write(f"**ğŸ¯ æ£€æµ‹ç»“æœæ±‡æ€»:**")
        st.write(f"- å¯¹åˆ·ç»„æ•°: {total_groups} ç»„")
        st.write(f"- æ¶‰åŠè´¦æˆ·: {total_accounts} ä¸ª")
        st.write(f"- æ€»å¯¹åˆ·æœŸæ•°: {total_wash_periods} æœŸ")
        st.write(f"- æ€»æ¶‰åŠé‡‘é¢: {total_amount:.2f} å…ƒ")
        
        st.write(f"**ğŸ‘¥ æŒ‰è´¦æˆ·æ•°é‡åˆ†å¸ƒ:**")
        for account_count, count in sorted(account_count_stats.items()):
            st.write(f"- {account_count}ä¸ªè´¦æˆ·ç»„: {count} ç»„")
        
        st.write(f"**ğŸ² æŒ‰å½©ç§åˆ†å¸ƒ:**")
        for lottery, count in lottery_stats.items():
            st.write(f"- {lottery}: {count} ç»„")
            
        st.write(f"**ğŸ“ˆ æŒ‰æ´»è·ƒåº¦åˆ†å¸ƒ:**")
        for activity, count in activity_stats.items():
            st.write(f"- {activity}æ´»è·ƒåº¦: {count} ç»„")
            
        st.write(f"**ğŸ¯ æŒ‰å¯¹ç«‹ç±»å‹åˆ†å¸ƒ:**")
        for opposite_type, count in opposite_type_stats.items():
            st.write(f"- {opposite_type}: {count} æœŸå¯¹åˆ·")
    
    def export_to_excel(self, patterns, filename):
        """å¯¼å‡ºæ£€æµ‹ç»“æœåˆ°Excelæ–‡ä»¶"""
        if not patterns:
            st.error("âŒ æ²¡æœ‰å¯¹åˆ·æ•°æ®å¯å¯¼å‡º")
            return None, None
        
        export_data = []
        
        for group_idx, pattern in enumerate(patterns, 1):
            for record_idx, record in enumerate(pattern['è¯¦ç»†è®°å½•'], 1):
                account_directions = []
                for account, direction, amount in zip(record['è´¦æˆ·ç»„'], record['æ–¹å‘ç»„'], record['é‡‘é¢ç»„']):
                    account_directions.append(f"{account}({direction}:{amount})")
                
                export_data.append({
                    'å¯¹åˆ·ç»„ç¼–å·': group_idx,
                    'è´¦æˆ·ç»„': ' â†” '.join(pattern['è´¦æˆ·ç»„']),
                    'å½©ç§': pattern['å½©ç§'],
                    'è´¦æˆ·æ•°é‡': pattern['è´¦æˆ·æ•°é‡'],
                    'è´¦æˆ·æ´»è·ƒåº¦': pattern['è´¦æˆ·æ´»è·ƒåº¦'],
                    'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': ', '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯']),
                    'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°'],
                    'ä¸»è¦å¯¹ç«‹ç±»å‹': pattern['ä¸»è¦å¯¹ç«‹ç±»å‹'],
                    'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': str(pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ']),
                    'å¯¹åˆ·æœŸæ•°': pattern['å¯¹åˆ·æœŸæ•°'],
                    'æ€»æŠ•æ³¨é‡‘é¢': pattern['æ€»æŠ•æ³¨é‡‘é¢'],
                    'å¹³å‡ç›¸ä¼¼åº¦': f"{pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}",
                    'æ¨¡å¼åˆ†å¸ƒ': str(pattern['æ¨¡å¼åˆ†å¸ƒ']),
                    'æœŸå·': record['æœŸå·'],
                    'å¯¹ç«‹ç±»å‹': record['å¯¹ç«‹ç±»å‹'],
                    'æ¨¡å¼': record['æ¨¡å¼'],
                    'é‡‘é¢': record['æ€»é‡‘é¢'],
                    'åŒ¹é…åº¦': f"{record['ç›¸ä¼¼åº¦']:.2%}",
                    'è´¦æˆ·æ–¹å‘': ' | '.join(account_directions)
                })
        
        df_export = pd.DataFrame(export_data)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        export_filename = f"å¯¹åˆ·æ£€æµ‹æŠ¥å‘Š_æ™ºèƒ½ç‰ˆ_{timestamp}.xlsx"
        
        try:
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df_export.to_excel(writer, sheet_name='è¯¦ç»†è®°å½•', index=False)
                
                summary_data = []
                for group_idx, pattern in enumerate(patterns, 1):
                    summary_data.append({
                        'å¯¹åˆ·ç»„ç¼–å·': group_idx,
                        'è´¦æˆ·ç»„': ' â†” '.join(pattern['è´¦æˆ·ç»„']),
                        'å½©ç§': pattern['å½©ç§'],
                        'è´¦æˆ·æ•°é‡': pattern['è´¦æˆ·æ•°é‡'],
                        'è´¦æˆ·æ´»è·ƒåº¦': pattern['è´¦æˆ·æ´»è·ƒåº¦'],
                        'è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯': ', '.join(pattern['è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯']),
                        'è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°': pattern['è¦æ±‚æœ€å°å¯¹åˆ·æœŸæ•°'],
                        'ä¸»è¦å¯¹ç«‹ç±»å‹': pattern['ä¸»è¦å¯¹ç«‹ç±»å‹'],
                        'å¯¹ç«‹ç±»å‹åˆ†å¸ƒ': str(pattern['å¯¹ç«‹ç±»å‹åˆ†å¸ƒ']),
                        'å¯¹åˆ·æœŸæ•°': pattern['å¯¹åˆ·æœŸæ•°'],
                        'æ€»æŠ•æ³¨é‡‘é¢': pattern['æ€»æŠ•æ³¨é‡‘é¢'],
                        'å¹³å‡ç›¸ä¼¼åº¦': f"{pattern['å¹³å‡ç›¸ä¼¼åº¦']:.2%}",
                        'æ¨¡å¼åˆ†å¸ƒ': str(pattern['æ¨¡å¼åˆ†å¸ƒ'])
                    })
                
                df_summary = pd.DataFrame(summary_data)
                df_summary.to_excel(writer, sheet_name='å¯¹åˆ·ç»„æ±‡æ€»', index=False)
            
            output.seek(0)
            st.success(f"âœ… ExcelæŠ¥å‘Šå·²ç”Ÿæˆ: {export_filename}")
            
            return output, export_filename
            
        except Exception as e:
            st.error(f"âŒ å¯¼å‡ºExcelå¤±è´¥: {str(e)}")
            return None, None

# ==================== ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ¯ æ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ")
    st.markdown("---")
    
    # ==================== å·¦ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼  ====================
    with st.sidebar:
        st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
        
        uploaded_file = st.file_uploader(
            "è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶", 
            type=['xlsx', 'xls', 'csv'],
            help="è¯·ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—ï¼šä¼šå‘˜è´¦å·ã€æœŸå·ã€å†…å®¹ã€é‡‘é¢"
        )
    
    # ==================== ä¸»åŒºåŸŸ - é…ç½®å’Œç»“æœæ˜¾ç¤º ====================
    if uploaded_file is not None:
        try:
            # é…ç½®å‚æ•°
            st.sidebar.header("âš™ï¸ æ£€æµ‹å‚æ•°é…ç½®")
            
            min_amount = st.sidebar.number_input("æœ€å°æŠ•æ³¨é‡‘é¢", value=10, min_value=1, help="ä½äºæ­¤é‡‘é¢çš„è®°å½•å°†è¢«è¿‡æ»¤")
            similarity_threshold = st.sidebar.slider("é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼", 0.8, 1.0, 0.9, 0.01, help="å¯¹ç«‹æ–¹å‘é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼")
            max_accounts = st.sidebar.slider("æœ€å¤§æ£€æµ‹è´¦æˆ·æ•°", 2, 8, 5, help="æ£€æµ‹çš„æœ€å¤§è´¦æˆ·ç»„åˆæ•°é‡")
            
            # æ´»è·ƒåº¦é˜ˆå€¼é…ç½®
            st.sidebar.subheader("ğŸ“Š æ´»è·ƒåº¦é˜ˆå€¼é…ç½®")
            st.sidebar.markdown("**ä½æ´»è·ƒåº¦:** æ€»æŠ•æ³¨æœŸæ•°â‰¤10æœŸ")
            st.sidebar.markdown("**ä¸­æ´»è·ƒåº¦:** æ€»æŠ•æ³¨æœŸæ•°11-200æœŸ")  
            st.sidebar.markdown("**é«˜æ´»è·ƒåº¦:** æ€»æŠ•æ³¨æœŸæ•°â‰¥201æœŸ")
            
            min_periods_low = st.sidebar.number_input("ä½æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=3, min_value=1, 
                                                    help="æ€»æŠ•æ³¨æœŸæ•°â‰¤10çš„è´¦æˆ·ï¼Œè¦æ±‚â‰¥3æœŸè¿ç»­å¯¹åˆ·")
            min_periods_medium = st.sidebar.number_input("ä¸­æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=5, min_value=1,
                                                       help="æ€»æŠ•æ³¨æœŸæ•°11-200çš„è´¦æˆ·ï¼Œè¦æ±‚â‰¥5æœŸè¿ç»­å¯¹åˆ·")
            min_periods_high = st.sidebar.number_input("é«˜æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=8, min_value=1,
                                                     help="æ€»æŠ•æ³¨æœŸæ•°â‰¥201çš„è´¦æˆ·ï¼Œè¦æ±‚â‰¥8æœŸè¿ç»­å¯¹åˆ·")
            
            # è°ƒè¯•é€‰é¡¹
            st.sidebar.subheader("ğŸ”§ è°ƒè¯•é€‰é¡¹")
            debug_mode = st.sidebar.checkbox("å¯ç”¨è°ƒè¯•æ¨¡å¼", value=False)
            account_debug = st.sidebar.checkbox("å¯ç”¨è´¦å·è°ƒè¯•", value=False)
            
            # æ›´æ–°é…ç½®å‚æ•°
            config = Config()
            config.min_amount = min_amount
            config.amount_similarity_threshold = similarity_threshold
            config.max_accounts_in_group = max_accounts
            config.period_thresholds = {
                'low_activity': 10,
                'medium_activity_low': 11,  
                'medium_activity_high': 200, 
                'min_periods_low': min_periods_low,
                'min_periods_medium': min_periods_medium,
                'min_periods_high': min_periods_high
            }
            
            detector = WashTradeDetector(config)
            
            st.success(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
            
            # è‡ªåŠ¨å¼€å§‹å¤„ç†å’Œåˆ†æ
            with st.spinner("ğŸ”„ æ­£åœ¨è§£ææ•°æ®..."):
                df_enhanced, filename = detector.upload_and_process(uploaded_file)
                
                if df_enhanced is not None and len(df_enhanced) > 0:
                    st.success("âœ… æ•°æ®è§£æå®Œæˆ")
                    
                    # æ•°æ®æ¦‚è§ˆ
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æœ‰æ•ˆè®°å½•æ•°", f"{len(df_enhanced):,}")
                    with col2:
                        st.metric("å”¯ä¸€æœŸå·æ•°", f"{df_enhanced['æœŸå·'].nunique():,}")
                    with col3:
                        st.metric("å”¯ä¸€è´¦æˆ·æ•°", f"{df_enhanced['ä¼šå‘˜è´¦å·'].nunique():,}")
                    with col4:
                        if 'å½©ç§ç±»å‹' in df_enhanced.columns:
                            st.metric("å½©ç§ç±»å‹æ•°", f"{df_enhanced['å½©ç§ç±»å‹'].nunique()}")
                    
                    # æ•°æ®è¯¦æƒ… - é»˜è®¤æŠ˜å 
                    with st.expander("ğŸ“Š æ•°æ®è¯¦æƒ…", expanded=False):
                        tab1, tab2, tab3 = st.tabs(["æ•°æ®æ¦‚è§ˆ", "å½©ç§åˆ†å¸ƒ", "ç©æ³•åˆ†å¸ƒ"])
                        
                        with tab1:
                            st.dataframe(df_enhanced.head(100), use_container_width=True)
                            
                        with tab2:
                            if 'å½©ç§ç±»å‹' in df_enhanced.columns:
                                lottery_type_stats = df_enhanced['å½©ç§ç±»å‹'].value_counts()
                                st.bar_chart(lottery_type_stats)
                                st.dataframe(lottery_type_stats.reset_index().rename(
                                    columns={'index': 'å½©ç§ç±»å‹', 'å½©ç§ç±»å‹': 'æ•°é‡'}
                                ))
                        
                        with tab3:
                            if 'ç©æ³•åˆ†ç±»' in df_enhanced.columns:
                                play_stats = df_enhanced['ç©æ³•åˆ†ç±»'].value_counts().head(15)
                                st.bar_chart(play_stats)
                                st.dataframe(play_stats.reset_index().rename(
                                    columns={'index': 'ç©æ³•åˆ†ç±»', 'ç©æ³•åˆ†ç±»': 'æ•°é‡'}
                                ))
                    
                    # å¦‚æœå¯ç”¨äº†è´¦å·è°ƒè¯•ï¼Œæ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                    if account_debug:
                        with st.expander("ğŸ” è´¦å·è°ƒè¯•ä¿¡æ¯", expanded=False):
                            detector.data_processor.debug_account_issues(df_enhanced)
                    
                    # è‡ªåŠ¨å¼€å§‹æ£€æµ‹
                    st.info("ğŸš€ è‡ªåŠ¨å¼€å§‹æ£€æµ‹å¯¹åˆ·äº¤æ˜“...")
                    with st.spinner("ğŸ” æ­£åœ¨æ£€æµ‹å¯¹åˆ·äº¤æ˜“..."):
                        patterns = detector.detect_all_wash_trades()
                    
                    if patterns:
                        st.success(f"âœ… æ£€æµ‹å®Œæˆï¼å‘ç° {len(patterns)} ä¸ªå¯¹åˆ·ç»„")
                        
                        detector.display_detailed_results(patterns)
                        
                        excel_output, export_filename = detector.export_to_excel(patterns, filename)
                        
                        if excel_output is not None:
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½æ£€æµ‹æŠ¥å‘Š",
                                data=excel_output,
                                file_name=export_filename,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True
                            )
                    else:
                        st.warning("âš ï¸ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„å¯¹åˆ·è¡Œä¸º")
                else:
                    st.error("âŒ æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
            
        except Exception as e:
            st.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
            st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
    else:
        # æœªä¸Šä¼ æ–‡ä»¶æ—¶çš„æ¬¢è¿ç•Œé¢
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ")
        
        # åŠŸèƒ½ç‰¹è‰²ä»‹ç»
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("ğŸ” æ™ºèƒ½æ£€æµ‹")
            st.markdown("""
            - å¤šè´¦æˆ·å¯¹åˆ·æ¨¡å¼è¯†åˆ«
            - æ™ºèƒ½é‡‘é¢åŒ¹é…åˆ†æ
            - æ´»è·ƒåº¦è‡ªé€‚åº”é˜ˆå€¼
            - å®æ—¶è¿›åº¦ç›‘æ§
            """)
        
        with col2:
            st.subheader("ğŸ“Š ä¸“ä¸šåˆ†æ")
            st.markdown("""
            - å®Œæ•´å½©ç§æ”¯æŒ
            - ç©æ³•åˆ†ç±»æ ‡å‡†åŒ–
            - æ•°æ®è´¨é‡éªŒè¯
            - è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
            """)
        
        with col3:
            st.subheader("ğŸš€ é«˜æ•ˆå¤„ç†")
            st.markdown("""
            - å¤§æ•°æ®é‡ä¼˜åŒ–
            - å¹¶è¡Œæ£€æµ‹ç®—æ³•
            - ä¸€é”®å¯¼å‡ºç»“æœ
            - å®æ—¶æ€§èƒ½ç›‘æ§
            """)
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ç³»ç»Ÿä½¿ç”¨è¯´æ˜", expanded=False):
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½è¯´æ˜

        **ğŸ¯ æ£€æµ‹é€»è¾‘ï¼š**
        - **æ€»æŠ•æ³¨æœŸæ•°**ï¼šè´¦æˆ·åœ¨ç‰¹å®šå½©ç§ä¸­çš„æ‰€æœ‰æœŸå·æŠ•æ³¨æ¬¡æ•°
        - **å¯¹åˆ·æœŸæ•°**ï¼šè´¦æˆ·ç»„å®é™…å‘ç”Ÿå¯¹åˆ·è¡Œä¸ºçš„æœŸæ•°
        - æ ¹æ®**æ€»æŠ•æ³¨æœŸæ•°**åˆ¤å®šè´¦æˆ·æ´»è·ƒåº¦ï¼Œè®¾ç½®ä¸åŒçš„**å¯¹åˆ·æœŸæ•°**é˜ˆå€¼

        **ğŸ“Š æ´»è·ƒåº¦åˆ¤å®šï¼š**
        - **ä½æ´»è·ƒåº¦è´¦æˆ·**ï¼šæ€»æŠ•æ³¨æœŸæ•° â‰¤ 10æœŸ â†’ è¦æ±‚ â‰¥ 3æœŸè¿ç»­å¯¹åˆ·
        - **ä¸­æ´»è·ƒåº¦è´¦æˆ·**ï¼šæ€»æŠ•æ³¨æœŸæ•° 11-200æœŸ â†’ è¦æ±‚ â‰¥ 5æœŸè¿ç»­å¯¹åˆ·  
        - **é«˜æ´»è·ƒåº¦è´¦æˆ·**ï¼šæ€»æŠ•æ³¨æœŸæ•° â‰¥ 201æœŸ â†’ è¦æ±‚ â‰¥ 8æœŸè¿ç»­å¯¹åˆ·

        **ğŸ¯ å¯¹åˆ·æ£€æµ‹è§„åˆ™ï¼š**
        - æ£€æµ‹2-5ä¸ªè´¦æˆ·ä¹‹é—´çš„å¯¹åˆ·è¡Œä¸º
        - **æ”¯æŒçš„å¯¹ç«‹æŠ•æ³¨ç±»å‹ï¼š**
          - å¤§ vs å°
          - å• vs åŒ  
          - é¾™ vs è™
        - é‡‘é¢åŒ¹é…åº¦ â‰¥ 90%
        - æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨

        **âš¡ è‡ªåŠ¨æ£€æµ‹ï¼š**
        - æ•°æ®ä¸Šä¼ åè‡ªåŠ¨å¼€å§‹å¤„ç†å’Œåˆ†æ
        - æ— éœ€æ‰‹åŠ¨ç‚¹å‡»å¼€å§‹æ£€æµ‹æŒ‰é’®
        """)

if __name__ == "__main__":
    main()
