import pandas as pd
import numpy as np
import streamlit as st
import io
import re
import logging
from collections import defaultdict
from datetime import datetime
from itertools import combinations
import warnings
import traceback
import hashlib
from functools import lru_cache

# é…ç½®æ—¥å¿—å’Œè­¦å‘Š
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('MultiAccountWashTrade')

# Streamlit é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤çš„é…ç½® ====================
LOTTERY_CONFIGS = {
    'PK10': {
        'lotteries': [
            'åˆ†åˆ†PKæ‹¾', 'ä¸‰åˆ†PKæ‹¾', 'äº”åˆ†PKæ‹¾', 'æ–°å¹¸è¿é£è‰‡', 'æ¾³æ´²å¹¸è¿10',
            'ä¸€åˆ†PK10', 'å®¾æœPK10', 'æé€Ÿé£è‰‡', 'æ¾³æ´²é£è‰‡', 'å¹¸è¿èµ›è½¦',
            'åˆ†åˆ†èµ›è½¦', 'åŒ—äº¬PK10', 'æ—§åŒ—äº¬PK10', 'æé€Ÿèµ›è½¦', 'å¹¸è¿èµ›è»Š', 
            'åŒ—äº¬èµ›è½¦', 'æé€ŸPK10', 'å¹¸è¿PK10', 'èµ›è½¦', 'èµ›è»Š'
        ],
        'min_number': 1,
        'max_number': 10,
        'gyh_min': 3,
        'gyh_max': 19,
        'position_names': ['å† å†›', 'äºšå†›', 'ç¬¬ä¸‰å', 'ç¬¬å››å', 'ç¬¬äº”å', 
                          'ç¬¬å…­å', 'ç¬¬ä¸ƒå', 'ç¬¬å…«å', 'ç¬¬ä¹å', 'ç¬¬åå']
    },
    'K3': {
        'lotteries': [
            'åˆ†åˆ†å¿«ä¸‰', 'ä¸‰åˆ†å¿«3', 'äº”åˆ†å¿«3', 'æ¾³æ´²å¿«ä¸‰', 'å®¾æœå¿«ä¸‰',
            '1åˆ†å¿«ä¸‰', '3åˆ†å¿«ä¸‰', '5åˆ†å¿«ä¸‰', '10åˆ†å¿«ä¸‰', 'åŠ å·å¿«ä¸‰',
            'å¹¸è¿å¿«ä¸‰', 'å¤§å‘å¿«ä¸‰', 'å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰', 
            'æ¾³é—¨å¿«ä¸‰', 'é¦™æ¸¯å¿«ä¸‰', 'æ±Ÿè‹å¿«ä¸‰'
        ],
        'min_number': 1,
        'max_number': 6,
        'hezhi_min': 3,
        'hezhi_max': 18
    },
    'LHC': {
        'lotteries': [
            'æ–°æ¾³é—¨å…­åˆå½©', 'æ¾³é—¨å…­åˆå½©', 'é¦™æ¸¯å…­åˆå½©', 'ä¸€åˆ†å…­åˆå½©',
            'äº”åˆ†å…­åˆå½©', 'ä¸‰åˆ†å…­åˆå½©', 'é¦™æ¸¯â‘¥åˆå½©', 'åˆ†åˆ†å…­åˆå½©',
            'å¿«ä¹6åˆå½©', 'æ¸¯â‘¥åˆå½©', 'å°æ¹¾å¤§ä¹é€', 'å…­åˆ', 'lhc', 'å…­åˆå½©',
            'â‘¥åˆ', '6åˆ', 'å¤§å‘å…­åˆå½©'
        ],
        'min_number': 1,
        'max_number': 49
    },
    'SSC': {
        'lotteries': [
            'åˆ†åˆ†æ—¶æ—¶å½©', 'ä¸‰åˆ†æ—¶æ—¶å½©', 'äº”åˆ†æ—¶æ—¶å½©', 'å®¾æœæ—¶æ—¶å½©',
            '1åˆ†æ—¶æ—¶å½©', '3åˆ†æ—¶æ—¶å½©', '5åˆ†æ—¶æ—¶å½©', 'æ—§é‡åº†æ—¶æ—¶å½©',
            'å¹¸è¿æ—¶æ—¶å½©', 'è…¾è®¯åˆ†åˆ†å½©', 'æ–°ç–†æ—¶æ—¶å½©', 'å¤©æ´¥æ—¶æ—¶å½©',
            'é‡åº†æ—¶æ—¶å½©', 'ä¸Šæµ·æ—¶æ—¶å½©', 'å¹¿ä¸œæ—¶æ—¶å½©', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©'
        ],
        'min_number': 0,
        'max_number': 9
    },
    'THREE_COLOR': {
        'lotteries': [
            'ä¸€åˆ†ä¸‰è‰²å½©', '30ç§’ä¸‰è‰²å½©', 'äº”åˆ†ä¸‰è‰²å½©', 'ä¸‰åˆ†ä¸‰è‰²å½©',
            'ä¸‰è‰²', 'ä¸‰è‰²å½©', 'ä¸‰è‰²çƒ'
        ],
        'min_number': 0,
        'max_number': 9
    }
}

class Config:
    """é…ç½®å‚æ•°ç±» - å¢å¼ºç‰ˆ"""
    def __init__(self):
        self.min_amount = 10
        self.amount_similarity_threshold = 0.9
        self.min_continuous_periods = 3
        self.max_accounts_in_group = 5
        self.supported_file_types = ['.xlsx', '.xls', '.csv']
        
        # å¢å¼ºçš„åˆ—åæ˜ å°„é…ç½® - ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤
        self.column_mappings = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
        
        # ä¿®æ­£ï¼šæ ¹æ®è´¦æˆ·æ€»æŠ•æ³¨æœŸæ•°è®¾ç½®ä¸åŒçš„å¯¹åˆ·æœŸæ•°é˜ˆå€¼
        self.period_thresholds = {
            'low_activity': 10,        # ä½æ´»è·ƒåº¦è´¦æˆ·é˜ˆå€¼ï¼ˆæ€»æŠ•æ³¨æœŸæ•°â‰¤10ï¼‰
            'medium_activity_low': 11,  # ä¸­æ´»è·ƒåº¦ä¸‹é™ï¼ˆæ€»æŠ•æ³¨æœŸæ•°11-200ï¼‰
            'medium_activity_high': 200, # ä¸­æ´»è·ƒåº¦ä¸Šé™
            'min_periods_low': 3,       # ä½æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
            'min_periods_medium': 5,    # ä¸­æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
            'min_periods_high': 8       # é«˜æ´»è·ƒåº¦è´¦æˆ·æœ€å°å¯¹åˆ·æœŸæ•°
        }
        
        # æ‰©å±•ï¼šå¢åŠ é¾™è™æ–¹å‘æ¨¡å¼
        self.direction_patterns = {
            'å°': ['ä¸¤é¢-å°', 'å’Œå€¼-å°', 'å°', 'small', 'xia'],
            'å¤§': ['ä¸¤é¢-å¤§', 'å’Œå€¼-å¤§', 'å¤§', 'big', 'da'], 
            'å•': ['ä¸¤é¢-å•', 'å’Œå€¼-å•', 'å•', 'odd', 'dan'],
            'åŒ': ['ä¸¤é¢-åŒ', 'å’Œå€¼-åŒ', 'åŒ', 'even', 'shuang'],
            'é¾™': ['é¾™', 'long', 'é¾', 'dragon'],
            'è™': ['è™', 'hu', 'tiger']
        }
        
        # æ‰©å±•ï¼šå¢åŠ é¾™è™å¯¹ç«‹ç»„
        self.opposite_groups = [{'å¤§', 'å°'}, {'å•', 'åŒ'}, {'é¾™', 'è™'}]

# ==================== ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤çš„æ•°æ®å¤„ç†å™¨ ====================
class DataProcessor:
    def __init__(self):
        self.required_columns = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'ç©æ³•', 'å†…å®¹', 'é‡‘é¢']
        self.column_mapping = {
            'ä¼šå‘˜è´¦å·': ['ä¼šå‘˜è´¦å·', 'ä¼šå‘˜è´¦æˆ·', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·è´¦å·', 'ç©å®¶è´¦å·', 'ç”¨æˆ·ID', 'ç©å®¶ID'],
            'å½©ç§': ['å½©ç§', 'å½©ç¥', 'å½©ç¥¨ç§ç±»', 'æ¸¸æˆç±»å‹', 'å½©ç¥¨ç±»å‹', 'æ¸¸æˆå½©ç§', 'å½©ç¥¨åç§°'],
            'æœŸå·': ['æœŸå·', 'æœŸæ•°', 'æœŸæ¬¡', 'æœŸ', 'å¥–æœŸ', 'æœŸå·ä¿¡æ¯', 'æœŸå·ç¼–å·'],
            'ç©æ³•': ['ç©æ³•', 'ç©æ³•åˆ†ç±»', 'æŠ•æ³¨ç±»å‹', 'ç±»å‹', 'æŠ•æ³¨ç©æ³•', 'ç©æ³•ç±»å‹', 'åˆ†ç±»'],
            'å†…å®¹': ['å†…å®¹', 'æŠ•æ³¨å†…å®¹', 'ä¸‹æ³¨å†…å®¹', 'æ³¨å•å†…å®¹', 'æŠ•æ³¨å·ç ', 'å·ç å†…å®¹', 'æŠ•æ³¨ä¿¡æ¯'],
            'é‡‘é¢': ['é‡‘é¢', 'ä¸‹æ³¨æ€»é¢', 'æŠ•æ³¨é‡‘é¢', 'æ€»é¢', 'ä¸‹æ³¨é‡‘é¢', 'æŠ•æ³¨é¢', 'é‡‘é¢æ•°å€¼']
        }
    
    def smart_column_identification(self, df_columns):
        """æ™ºèƒ½åˆ—è¯†åˆ« - ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤"""
        identified_columns = {}
        actual_columns = [str(col).strip() for col in df_columns]
        
        with st.expander("ğŸ” åˆ—åè¯†åˆ«è¯¦æƒ…", expanded=False):
            st.info(f"æ£€æµ‹åˆ°çš„åˆ—å: {actual_columns}")
            
            for standard_col, possible_names in self.column_mapping.items():
                found = False
                for actual_col in actual_columns:
                    actual_col_lower = actual_col.lower().replace(' ', '').replace('_', '').replace('-', '')
                    
                    for possible_name in possible_names:
                        possible_name_lower = possible_name.lower().replace(' ', '').replace('_', '').replace('-', '')
                        
                        # å¢å¼ºä¼šå‘˜è´¦å·è¯†åˆ«
                        if standard_col == 'ä¼šå‘˜è´¦å·':
                            # æ›´å®½æ¾çš„åŒ¹é…è§„åˆ™
                            account_keywords = ['ä¼šå‘˜', 'è´¦å·', 'è´¦æˆ·', 'ç”¨æˆ·', 'ç©å®¶', 'id']
                            if any(keyword in actual_col_lower for keyword in account_keywords):
                                identified_columns[actual_col] = standard_col
                                st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                                found = True
                                break
                        else:
                            # å…¶ä»–åˆ—çš„åŸæœ‰åŒ¹é…é€»è¾‘
                            if (possible_name_lower in actual_col_lower or 
                                actual_col_lower in possible_name_lower or
                                len(set(possible_name_lower) & set(actual_col_lower)) / len(possible_name_lower) > 0.7):
                                identified_columns[actual_col] = standard_col
                                st.success(f"âœ… è¯†åˆ«åˆ—å: {actual_col} -> {standard_col}")
                                found = True
                                break
                    
                    if found:
                        break
                
                if not found:
                    st.warning(f"âš ï¸ æœªè¯†åˆ«åˆ° {standard_col} å¯¹åº”çš„åˆ—å")
        
        return identified_columns
    
    def find_data_start(self, df):
        """æ™ºèƒ½æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®"""
        for row_idx in range(min(20, len(df))):
            for col_idx in range(min(10, len(df.columns))):
                cell_value = str(df.iloc[row_idx, col_idx])
                if pd.notna(cell_value) and any(keyword in cell_value for keyword in ['ä¼šå‘˜', 'è´¦å·', 'æœŸå·', 'å½©ç§', 'ç©æ³•', 'å†…å®¹', 'è®¢å•', 'ç”¨æˆ·']):
                    return row_idx, col_idx
        return 0, 0
    
    def validate_data_quality(self, df):
        """æ•°æ®è´¨é‡éªŒè¯ - ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤"""
        logger.info("æ­£åœ¨è¿›è¡Œæ•°æ®è´¨é‡éªŒè¯...")
        issues = []
        
        # æ£€æŸ¥å¿…è¦åˆ—
        missing_cols = [col for col in self.required_columns if col not in df.columns]
        if missing_cols:
            issues.append(f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
        
        # æ£€æŸ¥ç©ºå€¼
        for col in self.required_columns:
            if col in df.columns:
                null_count = df[col].isnull().sum()
                if null_count > 0:
                    issues.append(f"åˆ— '{col}' æœ‰ {null_count} ä¸ªç©ºå€¼")
        
        # ç‰¹åˆ«æ£€æŸ¥ä¼šå‘˜è´¦å·çš„å®Œæ•´æ€§
        if 'ä¼šå‘˜è´¦å·' in df.columns:
            # æ£€æŸ¥æ˜¯å¦æœ‰è¢«æˆªæ–­çš„è´¦å·
            truncated_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(r'\.\.\.|â€¦', na=False)]
            if len(truncated_accounts) > 0:
                issues.append(f"å‘ç° {len(truncated_accounts)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„ä¼šå‘˜è´¦å·")
            
            # æ£€æŸ¥è´¦å·é•¿åº¦å¼‚å¸¸çš„æƒ…å†µ
            account_lengths = df['ä¼šå‘˜è´¦å·'].str.len()
            if account_lengths.max() > 50:  # å‡è®¾æ­£å¸¸è´¦å·é•¿åº¦ä¸è¶…è¿‡50ä¸ªå­—ç¬¦
                issues.append("å‘ç°å¼‚å¸¸é•¿åº¦çš„ä¼šå‘˜è´¦å·")
            
            # æ˜¾ç¤ºè´¦å·æ ¼å¼æ ·æœ¬
            unique_accounts = df['ä¼šå‘˜è´¦å·'].unique()[:5]
            sample_info = " | ".join([f"'{acc}'" for acc in unique_accounts])
            st.info(f"ä¼šå‘˜è´¦å·æ ¼å¼æ ·æœ¬: {sample_info}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        if 'æœŸå·' in df.columns:
            # ä¿®å¤æœŸå·æ ¼å¼é—®é¢˜ï¼šå»æ‰.0
            df['æœŸå·'] = df['æœŸå·'].astype(str).str.replace(r'\.0$', '', regex=True)
            # å…è®¸æœŸå·åŒ…å«å­—æ¯å’Œæ•°å­—
            invalid_periods = df[~df['æœŸå·'].str.match(r'^[\dA-Za-z]+$')]
            if len(invalid_periods) > 0:
                issues.append(f"å‘ç° {len(invalid_periods)} æ¡æ— æ•ˆæœŸå·è®°å½•")
        
        # æ£€æŸ¥é‡å¤æ•°æ®
        duplicate_count = df.duplicated().sum()
        if duplicate_count > 0:
            issues.append(f"å‘ç° {duplicate_count} æ¡é‡å¤è®°å½•")
        
        if issues:
            with st.expander("âš ï¸ æ•°æ®è´¨é‡é—®é¢˜", expanded=True):
                for issue in issues:
                    st.warning(f"  - {issue}")
        else:
            st.success("âœ… æ•°æ®è´¨é‡æ£€æŸ¥é€šè¿‡")
        
        return issues
    
    def clean_data(self, uploaded_file):
        """æ•°æ®æ¸…æ´—ä¸»å‡½æ•° - ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤å¹¶æ”¹è¿›"""
        try:
            # ç¬¬ä¸€æ¬¡è¯»å–ç”¨äºå®šä½
            df_temp = pd.read_excel(uploaded_file, header=None, nrows=50)
            st.info(f"åŸå§‹æ•°æ®ç»´åº¦: {df_temp.shape}")
            
            # æ‰¾åˆ°æ•°æ®èµ·å§‹ä½ç½®
            start_row, start_col = self.find_data_start(df_temp)
            st.info(f"æ•°æ®èµ·å§‹ä½ç½®: ç¬¬{start_row+1}è¡Œ, ç¬¬{start_col+1}åˆ—")
            
            # é‡æ–°è¯»å–æ•°æ® - ç‰¹åˆ«å¤„ç†å¸¸è§„æ ¼å¼å•å…ƒæ ¼
            df_clean = pd.read_excel(
                uploaded_file, 
                header=start_row,
                skiprows=range(start_row + 1) if start_row > 0 else None,
                dtype=str,  # å°†æ‰€æœ‰åˆ—è¯»å–ä¸ºå­—ç¬¦ä¸²
                na_filter=False,  # ä¸è¿‡æ»¤ç©ºå€¼
                keep_default_na=False,  # ä¸ä½¿ç”¨é»˜è®¤çš„NAå€¼å¤„ç†
                converters={}  # ä¸ºç©ºï¼Œè®©pandasä¸è¦è¿›è¡Œä»»ä½•è½¬æ¢
            )
            
            # åˆ é™¤èµ·å§‹åˆ—ä¹‹å‰çš„æ‰€æœ‰åˆ—
            if start_col > 0:
                df_clean = df_clean.iloc[:, start_col:]
            
            st.info(f"æ¸…ç†åæ•°æ®ç»´åº¦: {df_clean.shape}")
            
            # æ™ºèƒ½åˆ—è¯†åˆ«
            column_mapping = self.smart_column_identification(df_clean.columns)
            if column_mapping:
                df_clean = df_clean.rename(columns=column_mapping)
                st.success("âœ… åˆ—åè¯†åˆ«å®Œæˆ!")
                for old_col, new_col in column_mapping.items():
                    logger.info(f"  {old_col} -> {new_col}")
            
            # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
            missing_columns = [col for col in self.required_columns if col not in df_clean.columns]
            if missing_columns and len(df_clean.columns) >= 4:
                st.warning("è‡ªåŠ¨æ˜ å°„åˆ—å...")
                manual_mapping = {}
                col_names = ['ä¼šå‘˜è´¦å·', 'å½©ç§', 'æœŸå·', 'å†…å®¹', 'ç©æ³•', 'é‡‘é¢']
                for i, col_name in enumerate(col_names):
                    if i < len(df_clean.columns):
                        manual_mapping[df_clean.columns[i]] = col_name
                
                df_clean = df_clean.rename(columns=manual_mapping)
                st.info(f"æ‰‹åŠ¨é‡å‘½ååçš„åˆ—: {list(df_clean.columns)}")
            
            # æ•°æ®æ¸…ç†
            initial_count = len(df_clean)
            df_clean = df_clean.dropna(subset=[col for col in self.required_columns if col in df_clean.columns])
            df_clean = df_clean.dropna(axis=1, how='all')
            
            # æ•°æ®ç±»å‹è½¬æ¢ - ç‰¹åˆ«å°å¿ƒå¤„ç†ä¼šå‘˜è´¦å·
            for col in self.required_columns:
                if col in df_clean.columns:
                    if col == 'ä¼šå‘˜è´¦å·':
                        # ç‰¹åˆ«å¤„ç†ä¼šå‘˜è´¦å·ï¼šç¡®ä¿ä¸ä¸¢å¤±ä»»ä½•å­—ç¬¦
                        df_clean[col] = df_clean[col].apply(
                            lambda x: str(x) if pd.notna(x) else ''
                        )
                    else:
                        df_clean[col] = df_clean[col].astype(str).str.strip()
            
            # ä¿®å¤æœŸå·æ ¼å¼ï¼šå»æ‰.0
            if 'æœŸå·' in df_clean.columns:
                df_clean['æœŸå·'] = df_clean['æœŸå·'].str.replace(r'\.0$', '', regex=True)
            
            # æ•°æ®è´¨é‡éªŒè¯
            self.validate_data_quality(df_clean)
            
            st.success(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆ: {initial_count} -> {len(df_clean)} æ¡è®°å½•")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.info(f"ğŸ“Š å”¯ä¸€ä¼šå‘˜è´¦å·æ•°: {df_clean['ä¼šå‘˜è´¦å·'].nunique()}")
            
            # å½©ç§åˆ†å¸ƒæ˜¾ç¤º
            if 'å½©ç§' in df_clean.columns:
                lottery_dist = df_clean['å½©ç§'].value_counts()
                with st.expander("ğŸ¯ å½©ç§åˆ†å¸ƒ", expanded=False):
                    st.dataframe(lottery_dist.reset_index().rename(columns={'index': 'å½©ç§', 'å½©ç§': 'æ•°é‡'}))
            
            return df_clean
            
        except Exception as e:
            st.error(f"âŒ æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            logger.error(f"æ•°æ®æ¸…æ´—å¤±è´¥: {str(e)}")
            return None

    def debug_account_issues(self, df):
        """è°ƒè¯•ä¼šå‘˜è´¦å·é—®é¢˜ - ä»ç¬¬ä¸€å¥—ä»£ç ç§»æ¤"""
        st.subheader("ğŸ” ä¼šå‘˜è´¦å·è°ƒè¯•ä¿¡æ¯")
        
        if 'ä¼šå‘˜è´¦å·' not in df.columns:
            st.error("æœªæ‰¾åˆ°ä¼šå‘˜è´¦å·åˆ—")
            return
        
        # æ˜¾ç¤ºè´¦å·ç»Ÿè®¡ä¿¡æ¯
        st.write("### è´¦å·ç»Ÿè®¡")
        st.write(f"æ€»è®°å½•æ•°: {len(df)}")
        st.write(f"å”¯ä¸€è´¦å·æ•°: {df['ä¼šå‘˜è´¦å·'].nunique()}")
        
        # æ˜¾ç¤ºè´¦å·é•¿åº¦åˆ†å¸ƒ
        df['è´¦å·é•¿åº¦'] = df['ä¼šå‘˜è´¦å·'].str.len()
        length_stats = df['è´¦å·é•¿åº¦'].describe()
        st.write("### è´¦å·é•¿åº¦ç»Ÿè®¡")
        st.write(length_stats)
        
        # æ˜¾ç¤ºå¯èƒ½çš„é—®é¢˜è´¦å·
        st.write("### å¯èƒ½çš„é—®é¢˜è´¦å·")
        
        # æŸ¥æ‰¾éå¸¸çŸ­çš„è´¦å·ï¼ˆå¯èƒ½è¢«æˆªæ–­ï¼‰
        short_accounts = df[df['è´¦å·é•¿åº¦'] < 3]['ä¼šå‘˜è´¦å·'].unique()
        if len(short_accounts) > 0:
            st.warning(f"å‘ç° {len(short_accounts)} ä¸ªè¿‡çŸ­çš„è´¦å·: {list(short_accounts)}")
        
        # æŸ¥æ‰¾åŒ…å«ç‰¹æ®Šæˆªæ–­ç¬¦å·çš„è´¦å·
        truncated_patterns = [r'\.\.\.', r'â€¦', r'\.$', r'_\d+$']
        for pattern in truncated_patterns:
            truncated = df[df['ä¼šå‘˜è´¦å·'].str.contains(pattern, na=False)]['ä¼šå‘˜è´¦å·'].unique()
            if len(truncated) > 0:
                st.warning(f"å‘ç° {len(truncated)} ä¸ªå¯èƒ½è¢«æˆªæ–­çš„è´¦å·ï¼ˆæ¨¡å¼: {pattern}ï¼‰: {list(truncated)}")
        
        # æŸ¥æ‰¾åŒ…å«ä¸‹åˆ’çº¿çš„è´¦å·ï¼ˆå¦‚ _551531wxh_ï¼‰
        underscore_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains('_', na=False)]['ä¼šå‘˜è´¦å·'].unique()
        if len(underscore_accounts) > 0:
            st.info(f"å‘ç° {len(underscore_accounts)} ä¸ªåŒ…å«ä¸‹åˆ’çº¿çš„è´¦å·:")
            for account in underscore_accounts:
                # ä½¿ç”¨Markdownè½¬ä¹‰æ¥ç¡®ä¿ä¸‹åˆ’çº¿æ­£ç¡®æ˜¾ç¤º
                account_display = account.replace('_', '\\_')  # è½¬ä¹‰ä¸‹åˆ’çº¿
                st.markdown(f"- `{account_display}` (é•¿åº¦: {len(account)}, æ˜¾ç¤º: '{account}')")
        
        # æ˜¾ç¤ºå‰30ä¸ªè´¦å·æ ·æœ¬ - ä½¿ç”¨Markdownæ ¼å¼ç¡®ä¿æ­£ç¡®æ˜¾ç¤º
        st.write("### è´¦å·æ ·æœ¬ï¼ˆå‰30ä¸ªï¼‰")
        sample_accounts = df['ä¼šå‘˜è´¦å·'].head(30).tolist()
        for i, account in enumerate(sample_accounts, 1):
            # ä½¿ç”¨Markdownæ ¼å¼æ˜¾ç¤ºè´¦å·ï¼Œç¡®ä¿ç‰¹æ®Šå­—ç¬¦æ­£ç¡®æ˜¾ç¤º
            account_display = account.replace('_', '\\_')  # è½¬ä¹‰ä¸‹åˆ’çº¿
            st.markdown(f"{i:2d}. `{account_display}` (é•¿åº¦: {len(account)})")
        
        # æ˜¾ç¤ºæ•°æ®ç±»å‹çš„è¯¦ç»†ä¿¡æ¯
        st.write("### æ•°æ®ç±»å‹ä¿¡æ¯")
        st.write(f"ä¼šå‘˜è´¦å·åˆ—çš„æ•°æ®ç±»å‹: {df['ä¼šå‘˜è´¦å·'].dtype}")
        
        # æ˜¾ç¤ºåŒ…å«ç‰¹æ®Šå­—ç¬¦çš„è´¦å·
        st.write("### åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„è´¦å·")
        special_chars = ['_', '-', '.', '@', '#', '$', '%', '&', '*']
        for char in special_chars:
            special_accounts = df[df['ä¼šå‘˜è´¦å·'].str.contains(char, na=False, regex=False)]['ä¼šå‘˜è´¦å·'].unique()
            if len(special_accounts) > 0:
                st.write(f"åŒ…å« '{char}' çš„è´¦å· ({len(special_accounts)}ä¸ª):")
                for account in special_accounts[:10]:
                    st.code(f"  {account}")
                if len(special_accounts) > 10:
                    st.write(f"  ... è¿˜æœ‰ {len(special_accounts) - 10} ä¸ª")

# ==================== å¢å¼ºçš„å½©ç§è¯†åˆ«å™¨ ====================
class EnhancedLotteryIdentifier:
    def __init__(self):
        self.lottery_configs = LOTTERY_CONFIGS
        self.unknown_lottery_patterns = {}
        self.identified_unknown_lotteries = {}
        
    def identify_lottery_type(self, lottery_name):
        """å¢å¼ºçš„å½©ç§è¯†åˆ« - åŒ…å«æœªçŸ¥å½©ç§çš„æ™ºèƒ½è¯†åˆ«å’Œè®°å½•"""
        lottery_str = str(lottery_name).strip()
        
        # 1. é¦–å…ˆå°è¯•æ ‡å‡†è¯†åˆ«
        for lottery_type, config in self.lottery_configs.items():
            for lottery in config['lotteries']:
                if lottery in lottery_str:
                    return lottery_type
        
        lottery_lower = lottery_str.lower()
        
        # 2. å…³é”®è¯è¯†åˆ«
        if any(word in lottery_lower for word in ['pk', 'é£è‰‡', 'èµ›è½¦', 'å¹¸è¿10', 'pk10', 'pkæ‹¾', 'èµ›è»Š']):
            return 'PK10'
        elif any(word in lottery_lower for word in ['å¿«ä¸‰', 'å¿«3', 'k3', 'kä¸‰']):
            return 'K3'
        elif any(word in lottery_lower for word in ['å…­åˆ', 'lhc', 'å…­åˆå½©', 'â‘¥åˆ', '6åˆ']):
            return 'LHC'
        elif any(word in lottery_lower for word in ['æ—¶æ—¶å½©', 'ssc', 'åˆ†åˆ†å½©', 'æ—¶æ—¶å½©', 'æ™‚æ™‚å½©']):
            return 'SSC'
        elif any(word in lottery_lower for word in ['ä¸‰è‰²', 'ä¸‰è‰²å½©', 'ä¸‰è‰²çƒ']):
            return 'THREE_COLOR'
        
        # 3. æ™ºèƒ½è¯†åˆ«æœªçŸ¥å½©ç§
        return self.smart_identify_unknown_lottery(lottery_str)
    
    def smart_identify_unknown_lottery(self, lottery_name):
        """æ™ºèƒ½è¯†åˆ«æœªçŸ¥å½©ç§å¹¶è®°å½•æ¨¡å¼"""
        lottery_str = str(lottery_name).strip()
        
        # è®°å½•æœªçŸ¥å½©ç§
        if lottery_str not in self.identified_unknown_lotteries:
            self.identified_unknown_lotteries[lottery_str] = {
                'count': 0,
                'first_seen': datetime.now(),
                'patterns': set(),
                'inferred_type': None
            }
        
        self.identified_unknown_lotteries[lottery_str]['count'] += 1
        
        # åŸºäºç©æ³•æ¨¡å¼æ¨æ–­å½©ç§ç±»å‹
        inferred_type = self.infer_lottery_type_by_patterns(lottery_str)
        if inferred_type:
            self.identified_unknown_lotteries[lottery_str]['inferred_type'] = inferred_type
            return inferred_type
        
        # å¦‚æœæ— æ³•æ¨æ–­ï¼Œæ ‡è®°ä¸ºæœªçŸ¥ä½†è®°å½•ç‰¹å¾
        return 'æœªçŸ¥å½©ç§'
    
    def infer_lottery_type_by_patterns(self, lottery_name):
        """åŸºäºç©æ³•æ¨¡å¼æ¨æ–­å½©ç§ç±»å‹"""
        lottery_lower = lottery_name.lower()
        
        # åŸºäºå¼€å¥–å·ç ç‰¹å¾æ¨æ–­
        number_patterns = {
            'PK10': [r'1[0-9]é€‰1', r'å† äºš', r'å‰[ä¸€äºŒä¸‰]', r'ç¬¬[1-9]å', r'å®šä½èƒ†.*[1-9]'],
            'K3': [r'å’Œå€¼', r'ä¸‰å†›', r'ç‹¬èƒ†', r'äºŒä¸åŒ', r'ä¸‰ä¸åŒ'],
            'SSC': [r'ç¬¬[1-5]çƒ', r'å®šä½èƒ†', r'ä¸‡ä½', r'åƒä½', r'ç™¾ä½', r'åä½', r'ä¸ªä½'],
            'LHC': [r'ç‰¹ç ', r'æ­£ç ', r'å¹³ç‰¹', r'ç‰¹è‚–', r'è¿è‚–', r'å°¾æ•°', r'è‰²æ³¢'],
            'THREE_COLOR': [r'ä¸‰è‰²', r'çº¢è“ç»¿', r'ä¸‰è‰²å½©']
        }
        
        for lottery_type, patterns in number_patterns.items():
            for pattern in patterns:
                if re.search(pattern, lottery_lower):
                    return lottery_type
        
        # åŸºäºå¼€å¥–æ—¶é—´æ¨¡å¼æ¨æ–­
        time_patterns = {
            'PK10': [r'[135]åˆ†', r'æé€Ÿ', r'é«˜é¢‘'],
            'SSC': [r'[135]åˆ†', r'åˆ†åˆ†å½©', r'æ—¶æ—¶å½©'],
            'K3': [r'[135]åˆ†', r'å¿«ä¸‰'],
            'LHC': [r'[15]åˆ†', r'å…­åˆå½©']
        }
        
        for lottery_type, patterns in time_patterns.items():
            for pattern in patterns:
                if re.search(pattern, lottery_lower):
                    return lottery_type
        
        return None
    
    def record_play_pattern(self, lottery_name, play_category, content):
        """è®°å½•æœªçŸ¥å½©ç§çš„ç©æ³•æ¨¡å¼"""
        if lottery_name not in self.unknown_lottery_patterns:
            self.unknown_lottery_patterns[lottery_name] = {
                'play_categories': set(),
                'content_patterns': set(),
                'sample_contents': []
            }
        
        patterns = self.unknown_lottery_patterns[lottery_name]
        patterns['play_categories'].add(play_category)
        
        # åˆ†æå†…å®¹æ¨¡å¼
        content_str = str(content)
        if len(patterns['sample_contents']) < 10:  # åªä¿ç•™10ä¸ªæ ·æœ¬
            patterns['sample_contents'].append(content_str)
        
        # æå–æ•°å­—æ¨¡å¼
        number_patterns = re.findall(r'\d+', content_str)
        if number_patterns:
            patterns['content_patterns'].update(number_patterns)
    
    def get_unknown_lottery_stats(self):
        """è·å–æœªçŸ¥å½©ç§ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_unknown': len(self.identified_unknown_lotteries),
            'unknown_details': {},
            'recommendations': []
        }
        
        for lottery_name, data in self.identified_unknown_lotteries.items():
            stats['unknown_details'][lottery_name] = {
                'count': data['count'],
                'inferred_type': data['inferred_type'],
                'first_seen': data['first_seen'].strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # å¦‚æœè¿™ä¸ªæœªçŸ¥å½©ç§å‡ºç°é¢‘ç‡é«˜ï¼Œç”Ÿæˆé…ç½®å»ºè®®
            if data['count'] >= 10 and lottery_name in self.unknown_lottery_patterns:
                patterns = self.unknown_lottery_patterns[lottery_name]
                inferred_type = data['inferred_type'] or 'æœªçŸ¥ç±»å‹'
                
                recommendation = {
                    'lottery_name': lottery_name,
                    'count': data['count'],
                    'inferred_type': inferred_type,
                    'play_categories': list(patterns['play_categories']),
                    'sample_patterns': list(patterns['content_patterns'])[:5]
                }
                stats['recommendations'].append(recommendation)
        
        return stats

# ==================== æ›´æ–°æ•°æ®å¤„ç†å™¨ ====================
class EnhancedDataProcessor(DataProcessor):
    def __init__(self):
        super().__init__()
        self.lottery_identifier = EnhancedLotteryIdentifier()
    
    def enhance_data_processing(self, df_clean):
        """å¢å¼ºçš„æ•°æ®å¤„ç†æµç¨‹ - åŒ…å«æœªçŸ¥å½©ç§è¯†åˆ«"""
        try:
            # 1. å½©ç§è¯†åˆ«ï¼ˆåŒ…å«æœªçŸ¥å½©ç§å¤„ç†ï¼‰
            if 'å½©ç§' in df_clean.columns:
                df_clean['å½©ç§ç±»å‹'] = df_clean['å½©ç§'].apply(
                    self.lottery_identifier.identify_lottery_type
                )
                
                # è®°å½•æœªçŸ¥å½©ç§çš„ç©æ³•æ¨¡å¼
                unknown_mask = df_clean['å½©ç§ç±»å‹'] == 'æœªçŸ¥å½©ç§'
                if unknown_mask.any():
                    unknown_df = df_clean[unknown_mask]
                    for _, row in unknown_df.iterrows():
                        play_category = row.get('ç©æ³•åˆ†ç±»', '')
                        content = row.get('å†…å®¹', '')
                        self.lottery_identifier.record_play_pattern(
                            row['å½©ç§'], play_category, content
                        )
            
            # 2. ç©æ³•åˆ†ç±»ç»Ÿä¸€
            if 'ç©æ³•' in df_clean.columns:
                df_clean['ç©æ³•åˆ†ç±»'] = df_clean['ç©æ³•'].apply(self.play_normalizer.normalize_category)
            
            # 3. è®¡ç®—è´¦æˆ·ç»Ÿè®¡ä¿¡æ¯
            self.calculate_account_total_periods_by_lottery(df_clean)
            
            # 4. æå–æŠ•æ³¨é‡‘é¢å’Œæ–¹å‘
            df_clean['æŠ•æ³¨é‡‘é¢'] = df_clean['é‡‘é¢'].apply(lambda x: self.extract_bet_amount_safe(x))
            df_clean['æŠ•æ³¨æ–¹å‘'] = df_clean['å†…å®¹'].apply(lambda x: self.enhanced_extract_direction(x))
            
            # è¿‡æ»¤æœ‰æ•ˆè®°å½•
            df_valid = df_clean[
                (df_clean['æŠ•æ³¨æ–¹å‘'] != '') & 
                (df_clean['æŠ•æ³¨é‡‘é¢'] >= self.config.min_amount)
            ].copy()
            
            if len(df_valid) == 0:
                st.error("âŒ è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆè®°å½•")
                return pd.DataFrame()
            
            self.data_processed = True
            self.df_valid = df_valid
            
            # æ˜¾ç¤ºæœªçŸ¥å½©ç§ç»Ÿè®¡
            self.display_unknown_lottery_stats()
            
            return df_valid
            
        except Exception as e:
            logger.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            st.error(f"æ•°æ®å¤„ç†å¢å¼ºå¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def display_unknown_lottery_stats(self):
        """æ˜¾ç¤ºæœªçŸ¥å½©ç§ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.lottery_identifier.get_unknown_lottery_stats()
        
        if stats['total_unknown'] > 0:
            with st.expander("ğŸ” æœªçŸ¥å½©ç§è¯†åˆ«æŠ¥å‘Š", expanded=True):
                st.warning(f"å‘ç° {stats['total_unknown']} ä¸ªæœªçŸ¥å½©ç§")
                
                # æ˜¾ç¤ºæœªçŸ¥å½©ç§è¯¦æƒ…
                for lottery_name, data in stats['unknown_details'].items():
                    st.write(f"**å½©ç§åç§°:** {lottery_name}")
                    st.write(f"  - å‡ºç°æ¬¡æ•°: {data['count']}")
                    st.write(f"  - æ¨æ–­ç±»å‹: {data['inferred_type'] or 'æœªè¯†åˆ«'}")
                    st.write(f"  - é¦–æ¬¡å‡ºç°: {data['first_seen']}")
                
                # æ˜¾ç¤ºé…ç½®å»ºè®®
                if stats['recommendations']:
                    st.subheader("ğŸ¯ é…ç½®å»ºè®®")
                    st.info("ä»¥ä¸‹å½©ç§å‡ºç°é¢‘ç‡è¾ƒé«˜ï¼Œå»ºè®®æ·»åŠ åˆ°é…ç½®ä¸­:")
                    
                    for rec in stats['recommendations']:
                        with st.expander(f"å»ºè®®æ·»åŠ : {rec['lottery_name']} (å‡ºç°{rec['count']}æ¬¡)"):
                            st.write(f"**æ¨æ–­ç±»å‹:** {rec['inferred_type']}")
                            st.write(f"**ç©æ³•åˆ†ç±»:** {', '.join(rec['play_categories'])}")
                            st.write(f"**å†…å®¹æ¨¡å¼:** {rec['sample_patterns']}")
                            
                            # ç”Ÿæˆé…ç½®ä»£ç å»ºè®®
                            config_suggestion = self.generate_config_suggestion(rec)
                            st.code(config_suggestion, language='python')
    
    def generate_config_suggestion(self, recommendation):
        """ç”Ÿæˆé…ç½®ä»£ç å»ºè®®"""
        lottery_name = recommendation['lottery_name']
        inferred_type = recommendation['inferred_type']
        
        if inferred_type != 'æœªçŸ¥ç±»å‹':
            config_key = inferred_type.upper()
            suggestion = f"""
# å»ºè®®æ·»åŠ åˆ° {config_key} é…ç½®ä¸­:
LOTTERY_CONFIGS['{config_key}']['lotteries'].append('{lottery_name}')
"""
        else:
            suggestion = f"""
# å»ºè®®æ·»åŠ æ–°çš„å½©ç§é…ç½®:
LOTTERY_CONFIGS['NEW_LOTTERY'] = {{
    'lotteries': ['{lottery_name}'],
    # éœ€è¦è¡¥å……å…¶ä»–é…ç½®å‚æ•°...
}}
"""
        return suggestion

# ==================== æ›´æ–°å¯¹åˆ·æ£€æµ‹å™¨ ====================
class EnhancedWashTradeDetector(WashTradeDetector):
    def __init__(self, config=None):
        super().__init__(config)
        self.data_processor = EnhancedDataProcessor()  # ä½¿ç”¨å¢å¼ºçš„æ•°æ®å¤„ç†å™¨
    
    def upload_and_process(self, uploaded_file):
        """ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶ - ä½¿ç”¨å¢å¼ºçš„æ•°æ®å¤„ç†å™¨"""
        try:
            if uploaded_file is None:
                st.error("âŒ æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶")
                return None, None
            
            filename = uploaded_file.name
            logger.info(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {filename}")
            
            if not any(filename.endswith(ext) for ext in self.config.supported_file_types):
                st.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {filename}")
                return None, None
            
            # ä½¿ç”¨å¢å¼ºçš„æ•°æ®å¤„ç†å™¨
            with st.spinner("ğŸ”„ æ­£åœ¨æ¸…æ´—æ•°æ®..."):
                df_clean = self.data_processor.clean_data(uploaded_file)
            
            if df_clean is not None and len(df_clean) > 0:
                # å¢å¼ºçš„æ•°æ®å¤„ç†ï¼ˆåŒ…å«æœªçŸ¥å½©ç§è¯†åˆ«ï¼‰
                df_enhanced = self.data_processor.enhance_data_processing(df_clean)
                return df_enhanced, filename
            else:
                return None, None
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            st.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
            return None, None

# ==================== æ›´æ–°ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ¯ æ™ºèƒ½å¤šè´¦æˆ·å¯¹åˆ·æ£€æµ‹ç³»ç»Ÿ - å¢å¼ºç‰ˆ")
    st.markdown("---")
    
    # ==================== å·¦ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼  ====================
    with st.sidebar:
        st.header("ğŸ“ æ•°æ®ä¸Šä¼ ")
        
        uploaded_file = st.file_uploader(
            "è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶", 
            type=['xlsx', 'xls', 'csv'],
            help="è¯·ç¡®ä¿æ–‡ä»¶åŒ…å«å¿…è¦çš„åˆ—ï¼šä¼šå‘˜è´¦å·ã€æœŸå·ã€å†…å®¹ã€é‡‘é¢"
        )
    
    # ==================== ä¸»åŒºåŸŸ - é…ç½®å’Œç»“æœæ˜¾ç¤º ====================
    if uploaded_file is not None:
        try:
            # é…ç½®å‚æ•°
            st.sidebar.header("âš™ï¸ æ£€æµ‹å‚æ•°é…ç½®")
            
            min_amount = st.sidebar.number_input("æœ€å°æŠ•æ³¨é‡‘é¢", value=10, min_value=1, help="ä½äºæ­¤é‡‘é¢çš„è®°å½•å°†è¢«è¿‡æ»¤")
            similarity_threshold = st.sidebar.slider("é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼", 0.8, 1.0, 0.9, 0.01, help="å¯¹ç«‹æ–¹å‘é‡‘é¢åŒ¹é…åº¦é˜ˆå€¼")
            max_accounts = st.sidebar.slider("æœ€å¤§æ£€æµ‹è´¦æˆ·æ•°", 2, 8, 5, help="æ£€æµ‹çš„æœ€å¤§è´¦æˆ·ç»„åˆæ•°é‡")
            
            # æ´»è·ƒåº¦é˜ˆå€¼é…ç½®
            st.sidebar.subheader("ğŸ“Š æ´»è·ƒåº¦é˜ˆå€¼é…ç½®")
            st.sidebar.markdown("**ä½æ´»è·ƒåº¦:** æ€»æŠ•æ³¨æœŸæ•°â‰¤10æœŸ")
            st.sidebar.markdown("**ä¸­æ´»è·ƒåº¦:** æ€»æŠ•æ³¨æœŸæ•°11-200æœŸ")  
            st.sidebar.markdown("**é«˜æ´»è·ƒåº¦:** æ€»æŠ•æ³¨æœŸæ•°â‰¥201æœŸ")
            
            min_periods_low = st.sidebar.number_input("ä½æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=3, min_value=1, 
                                                    help="æ€»æŠ•æ³¨æœŸæ•°â‰¤10çš„è´¦æˆ·ï¼Œè¦æ±‚â‰¥3æœŸè¿ç»­å¯¹åˆ·")
            min_periods_medium = st.sidebar.number_input("ä¸­æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=5, min_value=1,
                                                       help="æ€»æŠ•æ³¨æœŸæ•°11-200çš„è´¦æˆ·ï¼Œè¦æ±‚â‰¥5æœŸè¿ç»­å¯¹åˆ·")
            min_periods_high = st.sidebar.number_input("é«˜æ´»è·ƒåº¦æœ€å°å¯¹åˆ·æœŸæ•°", value=8, min_value=1,
                                                     help="æ€»æŠ•æ³¨æœŸæ•°â‰¥201çš„è´¦æˆ·ï¼Œè¦æ±‚â‰¥8æœŸè¿ç»­å¯¹åˆ·")
            
            # è°ƒè¯•é€‰é¡¹
            st.sidebar.subheader("ğŸ”§ è°ƒè¯•é€‰é¡¹")
            debug_mode = st.sidebar.checkbox("å¯ç”¨è°ƒè¯•æ¨¡å¼", value=False)
            account_debug = st.sidebar.checkbox("å¯ç”¨è´¦å·è°ƒè¯•", value=False)
            lottery_debug = st.sidebar.checkbox("å¯ç”¨å½©ç§è¯†åˆ«è°ƒè¯•", value=False)
            
            # æ›´æ–°é…ç½®å‚æ•°
            config = Config()
            config.min_amount = min_amount
            config.amount_similarity_threshold = similarity_threshold
            config.max_accounts_in_group = max_accounts
            config.period_thresholds = {
                'low_activity': 10,
                'medium_activity_low': 11,  
                'medium_activity_high': 200, 
                'min_periods_low': min_periods_low,
                'min_periods_medium': min_periods_medium,
                'min_periods_high': min_periods_high
            }
            
            # ä½¿ç”¨å¢å¼ºçš„æ£€æµ‹å™¨
            detector = EnhancedWashTradeDetector(config)
            
            st.success(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶: {uploaded_file.name}")
            
            # è‡ªåŠ¨å¼€å§‹å¤„ç†å’Œåˆ†æ
            with st.spinner("ğŸ”„ æ­£åœ¨è§£ææ•°æ®..."):
                df_enhanced, filename = detector.upload_and_process(uploaded_file)
                
                if df_enhanced is not None and len(df_enhanced) > 0:
                    st.success("âœ… æ•°æ®è§£æå®Œæˆ")
                    
                    # æ•°æ®æ¦‚è§ˆ
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æœ‰æ•ˆè®°å½•æ•°", f"{len(df_enhanced):,}")
                    with col2:
                        st.metric("å”¯ä¸€æœŸå·æ•°", f"{df_enhanced['æœŸå·'].nunique():,}")
                    with col3:
                        st.metric("å”¯ä¸€è´¦æˆ·æ•°", f"{df_enhanced['ä¼šå‘˜è´¦å·'].nunique():,}")
                    with col4:
                        if 'å½©ç§ç±»å‹' in df_enhanced.columns:
                            known_count = (df_enhanced['å½©ç§ç±»å‹'] != 'æœªçŸ¥å½©ç§').sum()
                            unknown_count = (df_enhanced['å½©ç§ç±»å‹'] == 'æœªçŸ¥å½©ç§').sum()
                            st.metric("å½©ç§è¯†åˆ«", f"{known_count}å·²çŸ¥/{unknown_count}æœªçŸ¥")
                    
                    # å½©ç§è¯†åˆ«è¯¦æƒ…
                    if lottery_debug and 'å½©ç§ç±»å‹' in df_enhanced.columns:
                        with st.expander("ğŸ¯ å½©ç§è¯†åˆ«è¯¦æƒ…", expanded=False):
                            lottery_stats = df_enhanced['å½©ç§ç±»å‹'].value_counts()
                            st.write("**å½©ç§ç±»å‹åˆ†å¸ƒ:**")
                            st.dataframe(lottery_stats)
                            
                            # æ˜¾ç¤ºåŸå§‹å½©ç§åç§°ä¸è¯†åˆ«ç»“æœçš„å¯¹åº”å…³ç³»
                            if 'å½©ç§' in df_enhanced.columns:
                                cross_tab = pd.crosstab(df_enhanced['å½©ç§'], df_enhanced['å½©ç§ç±»å‹'])
                                st.write("**åŸå§‹å½©ç§åç§°ä¸è¯†åˆ«ç»“æœå¯¹åº”å…³ç³»:**")
                                st.dataframe(cross_tab)
                    
                    # æ•°æ®è¯¦æƒ… - é»˜è®¤æŠ˜å 
                    with st.expander("ğŸ“Š æ•°æ®è¯¦æƒ…", expanded=False):
                        tab1, tab2, tab3 = st.tabs(["æ•°æ®æ¦‚è§ˆ", "å½©ç§åˆ†å¸ƒ", "ç©æ³•åˆ†å¸ƒ"])
                        
                        with tab1:
                            st.dataframe(df_enhanced.head(100), use_container_width=True)
                            
                        with tab2:
                            if 'å½©ç§ç±»å‹' in df_enhanced.columns:
                                lottery_type_stats = df_enhanced['å½©ç§ç±»å‹'].value_counts()
                                st.bar_chart(lottery_type_stats)
                                st.dataframe(lottery_type_stats.reset_index().rename(
                                    columns={'index': 'å½©ç§ç±»å‹', 'å½©ç§ç±»å‹': 'æ•°é‡'}
                                ))
                        
                        with tab3:
                            if 'ç©æ³•åˆ†ç±»' in df_enhanced.columns:
                                play_stats = df_enhanced['ç©æ³•åˆ†ç±»'].value_counts().head(15)
                                st.bar_chart(play_stats)
                                st.dataframe(play_stats.reset_index().rename(
                                    columns={'index': 'ç©æ³•åˆ†ç±»', 'ç©æ³•åˆ†ç±»': 'æ•°é‡'}
                                ))
                    
                    # å¦‚æœå¯ç”¨äº†è´¦å·è°ƒè¯•ï¼Œæ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                    if account_debug:
                        with st.expander("ğŸ” è´¦å·è°ƒè¯•ä¿¡æ¯", expanded=False):
                            detector.data_processor.debug_account_issues(df_enhanced)
                    
                    # è‡ªåŠ¨å¼€å§‹æ£€æµ‹
                    st.info("ğŸš€ è‡ªåŠ¨å¼€å§‹æ£€æµ‹å¯¹åˆ·äº¤æ˜“...")
                    with st.spinner("ğŸ” æ­£åœ¨æ£€æµ‹å¯¹åˆ·äº¤æ˜“..."):
                        patterns = detector.detect_all_wash_trades()
                    
                    if patterns:
                        st.success(f"âœ… æ£€æµ‹å®Œæˆï¼å‘ç° {len(patterns)} ä¸ªå¯¹åˆ·ç»„")
                        
                        detector.display_detailed_results(patterns)
                        
                        excel_output, export_filename = detector.export_to_excel(patterns, filename)
                        
                        if excel_output is not None:
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½æ£€æµ‹æŠ¥å‘Š",
                                data=excel_output,
                                file_name=export_filename,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True
                            )
                    else:
                        st.warning("âš ï¸ æœªå‘ç°ç¬¦åˆé˜ˆå€¼æ¡ä»¶çš„å¯¹åˆ·è¡Œä¸º")
                else:
                    st.error("âŒ æ•°æ®è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
            
        except Exception as e:
            st.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
            st.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{traceback.format_exc()}")
    else:
        # æœªä¸Šä¼ æ–‡ä»¶æ—¶çš„æ¬¢è¿ç•Œé¢
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ")
        
        # åŠŸèƒ½ç‰¹è‰²ä»‹ç»
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.subheader("ğŸ” æ™ºèƒ½æ£€æµ‹")
            st.markdown("""
            - å¤šè´¦æˆ·å¯¹åˆ·æ¨¡å¼è¯†åˆ«
            - **æ™ºèƒ½å½©ç§è¯†åˆ«**
            - æ™ºèƒ½é‡‘é¢åŒ¹é…åˆ†æ
            - æ´»è·ƒåº¦è‡ªé€‚åº”é˜ˆå€¼
            """)
        
        with col2:
            st.subheader("ğŸ“Š ä¸“ä¸šåˆ†æ")
            st.markdown("""
            - **æœªçŸ¥å½©ç§è‡ªåŠ¨å­¦ä¹ **
            - ç©æ³•åˆ†ç±»æ ‡å‡†åŒ–
            - æ•°æ®è´¨é‡éªŒè¯
            - è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
            """)
        
        with col3:
            st.subheader("ğŸš€ é«˜æ•ˆå¤„ç†")
            st.markdown("""
            - å¤§æ•°æ®é‡ä¼˜åŒ–
            - å¹¶è¡Œæ£€æµ‹ç®—æ³•
            - ä¸€é”®å¯¼å‡ºç»“æœ
            - **é…ç½®å»ºè®®ç”Ÿæˆ**
            """)
    
    # ä½¿ç”¨è¯´æ˜
    with st.expander("ğŸ“– ç³»ç»Ÿä½¿ç”¨è¯´æ˜ - å¢å¼ºç‰ˆ", expanded=False):
        st.markdown("""
        ### ç³»ç»ŸåŠŸèƒ½è¯´æ˜ - å¢å¼ºç‰ˆ

        **ğŸ¯ æ™ºèƒ½å½©ç§è¯†åˆ«:**
        - **è‡ªåŠ¨è¯†åˆ«**: æ”¯æŒPK10ã€K3ã€å…­åˆå½©ã€æ—¶æ—¶å½©ç­‰ä¸»æµå½©ç§
        - **æœªçŸ¥å½©ç§å­¦ä¹ **: è‡ªåŠ¨è¯†åˆ«æœªçŸ¥å½©ç§å¹¶è®°å½•ç‰¹å¾æ¨¡å¼
        - **æ™ºèƒ½æ¨æ–­**: åŸºäºç©æ³•æ¨¡å¼å’Œæ—¶é—´ç‰¹å¾æ¨æ–­å½©ç§ç±»å‹
        - **é…ç½®å»ºè®®**: ä¸ºé«˜é¢‘æœªçŸ¥å½©ç§ç”Ÿæˆé…ç½®ä»£ç å»ºè®®

        **ğŸ“Š æ£€æµ‹é€»è¾‘ï¼š**
        - **æ€»æŠ•æ³¨æœŸæ•°**ï¼šè´¦æˆ·åœ¨ç‰¹å®šå½©ç§ä¸­çš„æ‰€æœ‰æœŸå·æŠ•æ³¨æ¬¡æ•°
        - **å¯¹åˆ·æœŸæ•°**ï¼šè´¦æˆ·ç»„å®é™…å‘ç”Ÿå¯¹åˆ·è¡Œä¸ºçš„æœŸæ•°
        - æ ¹æ®**æ€»æŠ•æ³¨æœŸæ•°**åˆ¤å®šè´¦æˆ·æ´»è·ƒåº¦ï¼Œè®¾ç½®ä¸åŒçš„**å¯¹åˆ·æœŸæ•°**é˜ˆå€¼

        **ğŸ“ˆ æ´»è·ƒåº¦åˆ¤å®šï¼š**
        - **ä½æ´»è·ƒåº¦è´¦æˆ·**ï¼šæ€»æŠ•æ³¨æœŸæ•° â‰¤ 10æœŸ â†’ è¦æ±‚ â‰¥ 3æœŸè¿ç»­å¯¹åˆ·
        - **ä¸­æ´»è·ƒåº¦è´¦æˆ·**ï¼šæ€»æŠ•æ³¨æœŸæ•° 11-200æœŸ â†’ è¦æ±‚ â‰¥ 5æœŸè¿ç»­å¯¹åˆ·  
        - **é«˜æ´»è·ƒåº¦è´¦æˆ·**ï¼šæ€»æŠ•æ³¨æœŸæ•° â‰¥ 201æœŸ â†’ è¦æ±‚ â‰¥ 8æœŸè¿ç»­å¯¹åˆ·

        **ğŸ¯ å¯¹åˆ·æ£€æµ‹è§„åˆ™ï¼š**
        - æ£€æµ‹2-5ä¸ªè´¦æˆ·ä¹‹é—´çš„å¯¹åˆ·è¡Œä¸º
        - **æ”¯æŒçš„å¯¹ç«‹æŠ•æ³¨ç±»å‹ï¼š**
          - å¤§ vs å°
          - å• vs åŒ  
          - é¾™ vs è™
        - é‡‘é¢åŒ¹é…åº¦ â‰¥ 90%
        - æ’é™¤åŒä¸€è´¦æˆ·å¤šæ–¹å‘ä¸‹æ³¨

        **ğŸ”§ è°ƒè¯•åŠŸèƒ½:**
        - è´¦å·è°ƒè¯•ï¼šåˆ†æè´¦å·æ ¼å¼å’Œå¯èƒ½çš„é—®é¢˜
        - å½©ç§è¯†åˆ«è°ƒè¯•ï¼šæŸ¥çœ‹å½©ç§è¯†åˆ«è¯¦æƒ…å’Œå¯¹åº”å…³ç³»
        - æœªçŸ¥å½©ç§æŠ¥å‘Šï¼šè‡ªåŠ¨ç”Ÿæˆé…ç½®å»ºè®®
        """)

if __name__ == "__main__":
    main()
